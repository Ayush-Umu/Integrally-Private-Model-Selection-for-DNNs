{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177bdb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import math\n",
    "from scipy.stats import ks_2samp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundR(x, r):\n",
    "    return [np.round(i,r) for i in np.array(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f787983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(model_weights):\n",
    "  for i in range(len(model_weights)):\n",
    "    for j in range(len(model_weights[i])):\n",
    "      if isinstance(model_weights[i][j], np.ndarray):\n",
    "        for k in range(len(model_weights[i][j])):\n",
    "          #print(\"chalra h\", i, j, k)\n",
    "            if (np.round(model_weights[i][j][k],2)==0):\n",
    "                model_weights[i][j][k]=float(f'{model_weights[i][j][k]:.1g}')\n",
    "            else:\n",
    "                model_weights[i][j][k]=np.round(model_weights[i][j][k],2)\n",
    "      else:\n",
    "        if (np.round(model_weights[i][j],2)==0):\n",
    "          model_weights[i][j]=float(f'{model_weights[i][j]:.1g}')\n",
    "        else:\n",
    "          model_weights[i][j]=np.round(model_weights[i][j],2)\n",
    "  return model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870997ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_comparison1(node1, node2, epsilon=0.05):\n",
    "  for x, y in zip(node1,node2):\n",
    "    #print(x,y)\n",
    "    if isinstance(x, list):\n",
    "        if((np.linalg.norm(np.array(x)-np.array(y))/len(x))<=epsilon):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if(math.sqrt((x-y)*(x-y))<=epsilon):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de9aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_comparison(node1, node2):\n",
    "  for x, y in zip(node1,node2):\n",
    "    #print(x,y)\n",
    "    if isinstance(x, list):\n",
    "        if(sorted(x)==sorted(y)):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if(x==y):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b62e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_comparison(layer1, layer2):\n",
    "  for node1 in layer1:\n",
    "    present=False\n",
    "    for node2 in layer2:\n",
    "      if (node_comparison1(node1, node2)):\n",
    "        present=True\n",
    "    if present==False:\n",
    "      return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc218dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_models(Model_weights1, Model_weights2):\n",
    "  for i in range(0,len(Model_weights1), 2):\n",
    "    layer1=[]\n",
    "    layer2=[]\n",
    "    for j in range(len(Model_weights1[i+1].T)):\n",
    "      Node1=[]\n",
    "      Node2=[]\n",
    "      Node1.append(list(Model_weights1[i].T[j]))\n",
    "      Node1.append(Model_weights1[i+1][j])\n",
    "      if (i+2<len(Model_weights1)):\n",
    "        Node1.append(list(Model_weights1[i+2][j]))\n",
    "      Node2.append(list(Model_weights2[i].T[j]))\n",
    "      Node2.append(Model_weights2[i+1][j])\n",
    "      if (i+2<len(Model_weights2)):\n",
    "        Node2.append(list(Model_weights2[i+2][j]))\n",
    "      layer1.append(Node1)\n",
    "      layer2.append(Node2)\n",
    "    if (layer_comparison(layer1, layer2)):\n",
    "      continue\n",
    "    else:\n",
    "      return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f26338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_model(inp, out):\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(5, input_dim=inp, kernel_initializer='normal', activation='relu'),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dense(5, activation='relu'),\n",
    "        Dense(out, activation='softmax')\n",
    "        ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e1b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_model_2(inp, out):\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(1024, input_dim=inp, kernel_initializer='normal', activation='relu'),\n",
    "        Dense(out, activation='softmax')\n",
    "        ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce7a395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_model_3(inp, out):\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(10, input_dim=inp, kernel_initializer='normal', activation='relu'),\n",
    "        Dense(20, activation='relu'),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dense(out, activation='softmax')\n",
    "        ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca67943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_model_4(inp, out):\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(5, input_dim=inp, kernel_initializer='normal', activation='relu'),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dense(20, activation='relu'),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dense(5, activation='relu'),\n",
    "        Dense(out, activation='softmax')\n",
    "        ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b11030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DP_initial_model(inp, out):\n",
    "    model=tf.keras.Sequential([\n",
    "        Dense(5, input_dim=inp, kernel_initializer='normal', activation='relu'),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dense(5, activation='relu'),\n",
    "        Dense(out, activation='softmax')\n",
    "        ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b806754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is used to average out all the models in the epsilon range\n",
    "#the problem is different here than compared with model comparison. Shape not important.\n",
    "def get_avg_weights(models_weights, inp_shape, out_shape):\n",
    "    avg_sum=get_initial_model(inp_shape, out_shape).get_weights()\n",
    "    #print(avg_sum)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                for k in range(len(avg_sum[i][j])):\n",
    "                    avg_sum[i][j][k]=0\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=0\n",
    "    #print(avg_sum)\n",
    "    print(models_weights[0])\n",
    "    for i in range(len(models_weights)):\n",
    "        for j in range(0, len(avg_sum),2):\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            #if(isinstance(avg_sum[j][0], np.ndarray)):\n",
    "            for k in range(len(avg_sum[j])):\n",
    "                avg_sum[j][k]=[avg_sum[j][k][l]+models_weights[i][j][k][l] for l in range(len(avg_sum[j][k]))]\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            #else: gayab kr diya\n",
    "            print('andr aara h')\n",
    "            for k in range(len(avg_sum[j+1])):\n",
    "                avg_sum[j+1][k]=avg_sum[j+1][k]+models_weights[i][j+1][k]\n",
    "    print(\"yhn tk\")\n",
    "    mean_size=len(models_weights)\n",
    "    print(mean_size)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                #print(\"yhn tk\")\n",
    "                avg_sum[i][j]=[avg_sum[i][j][k]/mean_size for k in range(len(avg_sum[i][j]))]\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=avg_sum[i+1][j]/mean_size\n",
    "    print(\"Done\")\n",
    "    return avg_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd2d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is used to average out all the models in the epsilon range\n",
    "#the problem is different here than compared with model comparison. Shape not important.\n",
    "def get_avg_weights_2(models_weights, inp_shape, out_shape):\n",
    "    avg_sum=get_initial_model_2(inp_shape, out_shape).get_weights()\n",
    "    #print(avg_sum)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                for k in range(len(avg_sum[i][j])):\n",
    "                    avg_sum[i][j][k]=0\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=0\n",
    "    #print(avg_sum)\n",
    "    print(models_weights[0])\n",
    "    for i in range(len(models_weights)):\n",
    "        for j in range(0, len(avg_sum),2):\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            #if(isinstance(avg_sum[j][0], np.ndarray)):\n",
    "            for k in range(len(avg_sum[j])):\n",
    "                avg_sum[j][k]=[avg_sum[j][k][l]+models_weights[i][j][k][l] for l in range(len(avg_sum[j][k]))]\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            #else: gayab kr diya\n",
    "            print('andr aara h')\n",
    "            for k in range(len(avg_sum[j+1])):\n",
    "                avg_sum[j+1][k]=avg_sum[j+1][k]+models_weights[i][j+1][k]\n",
    "    print(\"yhn tk\")\n",
    "    mean_size=len(models_weights)\n",
    "    print(mean_size)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                #print(\"yhn tk\")\n",
    "                avg_sum[i][j]=[avg_sum[i][j][k]/mean_size for k in range(len(avg_sum[i][j]))]\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=avg_sum[i+1][j]/mean_size\n",
    "    print(\"Done\")\n",
    "    return avg_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf9964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is used to average out all the models in the epsilon range\n",
    "#the problem is different here than compared with model comparison. Shape not important.\n",
    "def get_avg_weights_3(models_weights, inp_shape, out_shape):\n",
    "    avg_sum=get_initial_model_3(inp_shape, out_shape).get_weights()\n",
    "    #print(avg_sum)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                for k in range(len(avg_sum[i][j])):\n",
    "                    avg_sum[i][j][k]=0\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=0\n",
    "    #print(avg_sum)\n",
    "    print(models_weights[0])\n",
    "    for i in range(len(models_weights)):\n",
    "        for j in range(0, len(avg_sum),2):\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            #if(isinstance(avg_sum[j][0], np.ndarray)):\n",
    "            for k in range(len(avg_sum[j])):\n",
    "                avg_sum[j][k]=[avg_sum[j][k][l]+models_weights[i][j][k][l] for l in range(len(avg_sum[j][k]))]\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            #else: gayab kr diya\n",
    "            print('andr aara h')\n",
    "            for k in range(len(avg_sum[j+1])):\n",
    "                avg_sum[j+1][k]=avg_sum[j+1][k]+models_weights[i][j+1][k]\n",
    "    print(\"yhn tk\")\n",
    "    mean_size=len(models_weights)\n",
    "    print(mean_size)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                #print(\"yhn tk\")\n",
    "                avg_sum[i][j]=[avg_sum[i][j][k]/mean_size for k in range(len(avg_sum[i][j]))]\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=avg_sum[i+1][j]/mean_size\n",
    "    print(\"Done\")\n",
    "    return avg_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf60b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is used to average out all the models in the epsilon range\n",
    "#the problem is different here than compared with model comparison. Shape not important.\n",
    "def get_avg_weights_4(models_weights, inp_shape, out_shape):\n",
    "    avg_sum=get_initial_model_4(inp_shape, out_shape).get_weights()\n",
    "    #print(avg_sum)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                for k in range(len(avg_sum[i][j])):\n",
    "                    avg_sum[i][j][k]=0\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=0\n",
    "    #print(avg_sum)\n",
    "    print(models_weights[0])\n",
    "    for i in range(len(models_weights)):\n",
    "        for j in range(0, len(avg_sum),2):\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            #if(isinstance(avg_sum[j][0], np.ndarray)):\n",
    "            for k in range(len(avg_sum[j])):\n",
    "                avg_sum[j][k]=[avg_sum[j][k][l]+models_weights[i][j][k][l] for l in range(len(avg_sum[j][k]))]\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            #else: gayab kr diya\n",
    "            print('andr aara h')\n",
    "            for k in range(len(avg_sum[j+1])):\n",
    "                avg_sum[j+1][k]=avg_sum[j+1][k]+models_weights[i][j+1][k]\n",
    "    print(\"yhn tk\")\n",
    "    mean_size=len(models_weights)\n",
    "    print(mean_size)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                #print(\"yhn tk\")\n",
    "                avg_sum[i][j]=[avg_sum[i][j][k]/mean_size for k in range(len(avg_sum[i][j]))]\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=avg_sum[i+1][j]/mean_size\n",
    "    print(\"Done\")\n",
    "    return avg_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions for f1, precision and recall\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#working over adult income dataset\n",
    "df=pd.read_csv(\"adult.csv\", sep=\";\", na_values='?')\n",
    "df = df.dropna(axis = 0)\n",
    "df = df.reset_index(drop=True)\n",
    "#target class change\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_str = df.select_dtypes(include='object')\n",
    "df_int = df.select_dtypes(exclude='object')\n",
    "#print(df_int.head())\n",
    "\n",
    "#handle categorical data\n",
    "df_str = pd.get_dummies(df_str)\n",
    "\n",
    "#print(df_str.head())\n",
    "\n",
    "target = df_int['income']\n",
    "x = df_int.drop(columns='income')\n",
    "column_names = x.columns.values\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "#scaler.fit(x)\n",
    "x_stndrd = scaler.fit_transform(x)\n",
    "type(x_stndrd)\n",
    "\n",
    "x_stndrd = pd.DataFrame(x_stndrd)\n",
    "x_stndrd.columns = column_names\n",
    "\n",
    "data = pd.concat([x_stndrd,df_str, target],axis=1)\n",
    "Positive = data[data['income']==0]\n",
    "Negative = data[data['income']==1]\n",
    "target_variable='income'\n",
    "print(len(Positive), len(Negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the below code is for binary classification since MNSIT is a multi-class low-resolution image dataset. I am updating the code in the next cell.\n",
    "N=1000\n",
    "#Positive=Pos\n",
    "#Negative=Neg\n",
    "positiveN=int((Positive.shape[0]/data.shape[0])*N)\n",
    "negativeN=int(N-positiveN)\n",
    "print(positiveN, negativeN)\n",
    "#target variable\n",
    "#target_variable=\"default.payment.next.month\"\n",
    "df1=Positive.sample(positiveN)\n",
    "Positive.drop(df1.index, inplace=True)\n",
    "df2=Negative.sample(negativeN)\n",
    "Negative.drop(df2.index, inplace=True)\n",
    "test_data=df1.append(df2, ignore_index=True)\n",
    "test_data=test_data.sample(frac = 1) #This is to shuffel the training and testing data\n",
    "test_data=test_data.sample(frac = 1)\n",
    "test_data=test_data.sample(frac = 1)\n",
    "X_test=test_data.drop(columns=[target_variable])\n",
    "y_test=to_categorical(test_data[target_variable])\n",
    "\n",
    "# adding dense layer\n",
    "initial_model= get_initial_model_2(X_test.shape[1], 2)\n",
    "Models=[]\n",
    "val_acc=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "val_loss=[]\n",
    "train_loss=[]\n",
    "add_weights=[]\n",
    "while Positive.empty==False:\n",
    "  print(positiveN, negativeN)\n",
    "  df1=Positive.sample(min(positiveN, len(Positive)))\n",
    "  Positive.drop(df1.index, inplace=True)\n",
    "  df2=Negative.sample(min(negativeN, len(Negative)))\n",
    "  Negative.drop(df2.index, inplace=True)\n",
    "  train_data=df1.append(df2, ignore_index=True)\n",
    "  train_data=train_data.sample(frac = 1) #shuffel test data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel test data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel test data 3 times\n",
    "    \n",
    "  #all models have different initialization\n",
    "  # define the sequential model\n",
    "  \"\"\"initial_model = keras.Sequential()\n",
    "\n",
    "    # adding dense layer\n",
    "  initial_model.add(Dense(5, input_dim=X_test.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "  initial_model.add(Dense(10, activation='relu'))\n",
    "  initial_model.add(Dense(5, activation='relu'))\n",
    "\n",
    "    # adding dense layer with softmax activation/output layer\n",
    "  initial_model.add(Dense(2, activation='softmax'))\n",
    "  #initial_model.summary()\"\"\"\n",
    "  ann_model=get_initial_model_2(X_test.shape[1], 2) #same intial weights\n",
    "  ann_model.set_weights(initial_model.get_weights())\n",
    "  X_train=train_data.drop(columns=[target_variable])\n",
    "  #train_data[target_variable]=train_data[target_variable]-1 #only for skin_nonskin dataset\n",
    "  y_train=to_categorical(train_data[target_variable])\n",
    "  #print(y_train)\n",
    "  ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m]) # metrics=['accuracy']\n",
    "  history = ann_model.fit(X_train, y_train, epochs=20, validation_split=0.2, verbose=1)\n",
    "  print(history.history['f1_m'][-1])\n",
    "  ann_model.set_weights(update_weights(ann_model.get_weights()))\n",
    "  pred_test=ann_model.predict(X_test)\n",
    "  present=False\n",
    "  for i in range(len(Models)):\n",
    "    if (check_models(Models[i][0], ann_model.get_weights())):\n",
    "      print(\"if any\")\n",
    "      Models[i][1]=Models[i][1]+1\n",
    "      add_weights[i].append(ann_model.get_weights())\n",
    "      val_acc[i].append(history.history['val_f1_m'])\n",
    "      train_acc[i].append(history.history['f1_m'])\n",
    "      test_acc[i].append(f1_m(y_test, pred_test).numpy())\n",
    "      val_loss[i].append(history.history['val_loss'])\n",
    "      train_loss[i].append(history.history['loss'])\n",
    "      present=True\n",
    "      break;\n",
    "  if present==False:\n",
    "    add_weights.append([ann_model.get_weights()])\n",
    "    Models.append([ann_model.get_weights(), 1])\n",
    "    val_acc.append([history.history['val_f1_m']])\n",
    "    train_acc.append([history.history['f1_m']])\n",
    "    test_acc.append([f1_m(y_test, pred_test).numpy()])\n",
    "    val_loss.append([history.history['val_loss']])\n",
    "    train_loss.append([history.history['loss']])\n",
    "for i in range(len(Models)):\n",
    "  print(Models[i][1])\n",
    "print(\"All Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3cbfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(add_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7363c39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a70846",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def4a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this works for getting sorted recurrent models by frequency\n",
    "A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "print(np.array(Models).T[1])\n",
    "print(A)\n",
    "temp=list(np.array(Models)[A])\n",
    "#print(temp[2][1])\n",
    "#A=add_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e101957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing the metrics lists to top 5 models only\n",
    "val_acc=list(np.array(val_acc)[A])\n",
    "test_acc=list(np.array(test_acc)[A])\n",
    "train_acc=list(np.array(train_acc)[A])\n",
    "val_loss=list(np.array(val_loss)[A])\n",
    "train_loss=list(np.array(train_loss)[A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_model_weights=[]\n",
    "for i in range(2):\n",
    "    mean_model_weights.append(get_avg_weights(add_weights[A[i]],X_test.shape[1], 2))\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb06531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean models\n",
    "from sklearn.model_selection import train_test_split\n",
    "mean_models=[]\n",
    "mean_model_train_metrics=[]\n",
    "mean_model_loss=[]\n",
    "mean_model_acc=[]\n",
    "mean_model_test_metrics=[]\n",
    "mean_model_test_loss=[]\n",
    "mean_model_test_acc=[]\n",
    "y = to_categorical(data[target_variable])\n",
    "X = data.drop(columns=target_variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "for i in range(2):\n",
    "    init_model=get_initial_model(X_test.shape[1], 2)\n",
    "    init_model.set_weights(get_avg_weights(add_weights[A[i]],X_test.shape[1], 2))\n",
    "    mean_model_train_metrics.append(init_model.evaluate(X_train, y_train))\n",
    "    mean_model_loss.append(mean_model_train_metrics[i][0])\n",
    "    mean_model_acc.append(mean_model_train_metrics[i][1])\n",
    "    mean_model_test_metrics.append(init_model.evaluate(X_test, y_test))\n",
    "    mean_model_test_loss.append(mean_model_test_metrics[i][0])\n",
    "    mean_model_test_acc.append(mean_model_test_metrics[i][1])\n",
    "print(\"Done for model selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9707330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_model_loss, mean_model_acc)\n",
    "print(mean_model_test_loss, mean_model_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de89ad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#benchmark model\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = to_categorical(data[target_variable])\n",
    "X = data.drop(columns=target_variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "benchmark_model=get_initial_model(X_test.shape[1], 2) #same intial weights\n",
    "#benchmark_model.set_weights(initial_model.get_weights())\n",
    "history = benchmark_model.fit(X_train, y_train, epochs=20, validation_split=0.2, verbose=1)\n",
    "benchmark_model.set_weights(update_weights(benchmark_model.get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55287961",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#benchmark metrics\n",
    "benchmark_loss=history.history['loss']\n",
    "benchmark_val_loss=history.history['val_loss']\n",
    "benchmark_acc=history.history['accuracy']\n",
    "benchmark_val_acc=history.history['val_accuracy']\n",
    "benchmark_test_metrics=benchmark_model.evaluate(X_test, y_test)\n",
    "benchmark_test_loss=benchmark_test_metrics[0]\n",
    "benchmark_test_accuracy=benchmark_test_metrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3dcb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from here onwards the comparison and computation of DP:\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_privacy\n",
    "\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "l2_norm_clip = 1.5\n",
    "noise_multiplier = 0.8\n",
    "num_microbatches = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = to_categorical(data[target_variable])\n",
    "X = data.drop(columns=target_variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "DP_model=get_DP_initial_model(X_test.shape[1], 2) #same intial weights\n",
    "optimizer = tensorflow_privacy.DPKerasAdamOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
    "DP_model.compile(optimizer=optimizer, loss=loss, metrics=[f1_m])\n",
    "history = DP_model.fit(X_train, y_train, batch_size=13, epochs=20, validation_split=0.2, verbose=1)\n",
    "#benchmark_model.set_weights(update_weights(benchmark_model.get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=X_train.shape[0]*0.8,\n",
    "                                              batch_size=1,\n",
    "                                              noise_multiplier=noise_multiplier,\n",
    "                                              epochs=20,\n",
    "                                              delta=1e-5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for epsilon ≈ 1\n",
    "DP_1_loss=history.history['loss']\n",
    "DP_1_f1=history.history['f1_m']\n",
    "DP_1_f1_train=DP_model.evaluate(X_train,y_train)\n",
    "DP_1_f1_test=DP_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de49b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for epsilon ≈ 0.5\n",
    "DP_0_5_loss=history.history['loss']\n",
    "DP_0_5_f1=history.history['f1_m']\n",
    "DP_0_5_f1_train=DP_model.evaluate(X_train,y_train)\n",
    "DP_0_5_f1_test=DP_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e66e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for epsilon ≈ 0.1\n",
    "DP_0_1_loss=history.history['loss']\n",
    "DP_0_1_f1=history.history['f1_m']\n",
    "DP_0_1_f1_train=DP_model.evaluate(X_train,y_train)\n",
    "DP_0_1_f1_test=DP_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa32cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting graphs for loss and accuracies for the top 5 recurrent models:\n",
    "#plotting val_loss and loss for the models generated and the benchmark model.\n",
    "from random import randint\n",
    "import matplotlib.patches as mpatches\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "leg=[]\n",
    "for i in range(len(color)):\n",
    "    leg.append(mpatches.Patch(color=color[i], label=str(len(val_acc[i]))))\n",
    "n = len(val_acc)\n",
    "x_axis=np.arange(1, 21, 1)\n",
    "print(x_axis)\n",
    "for i in range(n):\n",
    "    for j in range(len(val_acc[i])):\n",
    "        plt.plot(x_axis,val_acc[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis, np.mean(val_acc[i], axis=0), color=color[i])\n",
    "#plt.xlim(-0.5,20.5)\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.plot(x_axis, DP_1_f1, '--', color='black')\n",
    "plt.plot(x_axis, benchmark_val_acc, color='black')\n",
    "plt.savefig(\"fig/adult_F1_Val_20Epochs_1000.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d7762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train accuracy \n",
    "from random import randint\n",
    "color = []\n",
    "print(train_acc[4][0])\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "x_axis=np.arange(1, 21, 1)\n",
    "\n",
    "print(x_axis)\n",
    "for i in range(n):\n",
    "    for j in range(len(train_acc[i])):\n",
    "        print(i,j)\n",
    "        plt.plot(x_axis,train_acc[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis,np.mean(train_acc[i], axis=0), color=color[i])\n",
    "plt.plot(x_axis,benchmark_acc, color='black')\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.plot(x_axis, DP_1_f1, 'o', color='black')\n",
    "plt.plot(x_axis, DP_0_5_f1, '-.', color='black')\n",
    "plt.plot(x_axis, DP_0_1_f1, 'd', color='black')\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/adult_F1_train_20Epochs_1000.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b16b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loss\n",
    "from random import randint\n",
    "color = []\n",
    "n = len(train_loss)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0.2, 1.0])\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "for i in range(n):\n",
    "    for j in range(len(train_loss[i])):\n",
    "        plt.plot(x_axis,train_loss[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis,np.mean(train_loss[i], axis=0), color=color[i])\n",
    "plt.plot(x_axis,benchmark_loss, color='black')\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.plot(x_axis, DP_1_loss, 'o', color='black')\n",
    "plt.plot(x_axis, DP_0_5_loss, '-.', color='black')\n",
    "plt.plot(x_axis, DP_0_1_loss, 'd', color='black')\n",
    "plt.xlabel(\"epochs)\"\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/adult_loss_train_20Epochs_1000.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f3bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation loss loss\n",
    "from random import randint\n",
    "color = []\n",
    "n = len(val_acc)\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "for i in range(n):\n",
    "    for j in range(len(train_loss[i])):\n",
    "        plt.plot(x_axis,val_loss[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis,np.mean(val_loss[i], axis=0), color=color[i])\n",
    "plt.plot(x_axis,benchmark_val_loss, color='black')\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/adult_loss_val_20Epochs_1000.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e1dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot test accuracy of smaller test set\n",
    "benchmark_test__accs=[benchmark_test_accuracy]\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0.7, 0.9])\n",
    "for i in range(n):\n",
    "    plt.scatter([i]*len(test_acc[i]),test_acc[i], color=color[i], alpha=0.2)\n",
    "    plt.scatter(i,high_test_accs[i][0], color=color[i])\n",
    "plt.plot(benchmark_test_accs, color='black')\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/adult_test_acc_20Epochs_1000.jpeg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a70e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compute the accuracy for bigger test set 30% benchmark test data\n",
    "high_test_loss=[]\n",
    "high_test_f1=[]\n",
    "for i in range(len(add_weights)):\n",
    "    for j in range(len(add_weights[i])):\n",
    "        high_test_model=get_initial_model(X_test.shape[1], 2) #same intial weights\n",
    "        high_test_model.set_weights(Models[i][0])\n",
    "        high_test_metrics=high_test_model.evaluate(X_test,y_test)\n",
    "        if j == 0:\n",
    "            high_test_loss.append([high_test_metrics[0]])\n",
    "            high_test_f1.append([high_test_metrics[1]])\n",
    "        else:\n",
    "            high_test_loss[i].append(high_test_metrics[0])\n",
    "            high_test_f1[i].append(high_test_metrics[1])\n",
    "print(high_test_loss, high_test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_test_accs=list(np.array(high_test_f1)[A])\n",
    "print(high_test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9933673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot test accuracy of very large test set\n",
    "benchmark_test_accs=[benchmark_test_accuracy]*n\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0.7, 0.9])\n",
    "for i in range(n):\n",
    "    plt.scatter([i]*len(high_test_accs[i]),high_test_accs[i], color=color[i])\n",
    "plt.plot(benchmark_test_accs, color='black')\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/adult_test_acc_large_20Epochs_1000.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e80cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for mean model accuracy and benchmark loss:\n",
    "n=5\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0.65, 0.9])\n",
    "for i in range(n):\n",
    "    plt.plot(i, mean_model_acc[i],'o',color=color[i])\n",
    "    plt.plot(i, mean_model_test_acc[i],'o', mfc='none',color=color[i])\n",
    "plt.plot([benchmark_acc[-1]]*n,color='black')\n",
    "plt.plot([benchmark_test_accuracy]*n,'--',color='black')\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/adult_mean_model_results.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compute the accuracy for bigger test set 30% benchmark test data\n",
    "high_test_loss=[]\n",
    "high_test_f1=[]\n",
    "for i in range(len(add_weights)):\n",
    "    for j in range(len(add_weights[i])):\n",
    "        high_test_model=get_initial_model(X_test.shape[1], 2) #same intial weights\n",
    "        high_test_model.set_weights(Models[i][0])\n",
    "        high_test_metrics=high_test_model.evaluate(X_test,y_test)\n",
    "        if j == 0:\n",
    "            high_test_loss.append([high_test_metrics[0]])\n",
    "            high_test_f1.append([high_test_metrics[1]])\n",
    "        else:\n",
    "            high_test_loss[i].append(high_test_metrics[0])\n",
    "            high_test_f1[i].append(high_test_metrics[1])\n",
    "print(high_test_loss, high_test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6c6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From here on the work is towards the interesting observations.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "#working over adult income dataset\n",
    "df=pd.read_csv(\"adult.csv\", sep=\";\", na_values='?')\n",
    "df = df.dropna(axis = 0)\n",
    "df = df.reset_index(drop=True)\n",
    "#target class change\n",
    "\n",
    "#df['income'] = (df['income']==(\"<=50K\")).astype(int)\n",
    "\n",
    "print(sum((df['income']==1).astype(int)))\n",
    "\n",
    "#divide string and integer columns\n",
    "\n",
    "df_str = df.select_dtypes(include='object')\n",
    "df_int = df.select_dtypes(exclude='object')\n",
    "#print(df_int.head())\n",
    "\n",
    "#handle categorical data\n",
    "df_str = pd.get_dummies(df_str)\n",
    "\n",
    "#print(df_str.head())\n",
    "\n",
    "target = df_int['income']\n",
    "x = df_int.drop(columns='income')\n",
    "column_names = x.columns.values\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "#scaler.fit(x)\n",
    "x_stndrd = scaler.fit_transform(x)\n",
    "type(x_stndrd)\n",
    "\n",
    "x_stndrd = pd.DataFrame(x_stndrd)\n",
    "x_stndrd.columns = column_names\n",
    "\n",
    "data = pd.concat([x_stndrd,df_str, target],axis=1)\n",
    "Positive = data[data['income']==0]\n",
    "Negative = data[data['income']==1]\n",
    "target_variable='income'\n",
    "print(len(Positive), len(Negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3216e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = to_categorical(data[target_variable])\n",
    "X = data.drop(columns=target_variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e49d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the below code is for binary classification since MNSIT is a multi-class low-resolution image dataset. I am updating the code in the next cell.\n",
    "N=500\n",
    "initial_model=get_initial_model(X_test.shape[1], 2)\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "while(N<=len(data)):\n",
    "    positiveN=int((Positive.shape[0]/data.shape[0])*N)\n",
    "    negativeN=int(N-positiveN)\n",
    "    print(positiveN, negativeN)\n",
    "    #target variable\n",
    "    #target_variable=\"default.payment.next.month\"\n",
    "    df1=Positive.sample(positiveN)\n",
    "    df2=Negative.sample(negativeN)\n",
    "    train_data=df1.append(df2, ignore_index=True)\n",
    "    train_data=train_data.sample(frac = 1) #shuffel test data 3 times\n",
    "    train_data=train_data.sample(frac = 1) #shuffel test data 3 times\n",
    "    train_data=train_data.sample(frac = 1) #shuffel test data 3 times\n",
    "    int_model=get_initial_model(X_test.shape[1], 2) #same intial weights\n",
    "    int_model.set_weights(initial_model.get_weights())\n",
    "    int_X_train=train_data.drop(columns=[target_variable])\n",
    "    int_y_train=to_categorical(train_data[target_variable])\n",
    "    int_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m]) # metrics=['accuracy']\n",
    "    history = int_model.fit(int_X_train, int_y_train, epochs=20, validation_split=0.2, verbose=1)\n",
    "    pred_train=int_model.evaluate(X_train, y_train)\n",
    "    train_acc.append(pred_train[1])\n",
    "    pred_test=int_model.evaluate(X_test, y_test)\n",
    "    test_acc.append(pred_test[1])\n",
    "    N=N*2\n",
    "print(train_acc)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13afc5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_acc)\n",
    "print(test_acc)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.xlabel(\"training size\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.legend([\"training accuracy\", \"test accuracy\"], loc =\"lower right\")\n",
    "plt.xticks([0,1,2,3,4,5,6],[\"0.5k\",\"1k\",\"2k\",\"4k\",\"8k\",\"16k\",\"32k\"])\n",
    "plt.savefig(\"fig/adult_interesting_results.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ba40ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6234fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffc52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=X_train.shape[0]*0.8,\n",
    "                                              batch_size=13,\n",
    "                                              noise_multiplier=noise_multiplier,\n",
    "                                              epochs=20,\n",
    "                                              delta=1e-5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba891ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "DP_1_loss=history.history['loss']\n",
    "DP_1_f1=history.history['f1_m']\n",
    "DP_1_f1_train=DP_model.evaluate(X_train,y_train)\n",
    "DP_1_f1_test=DP_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here onwards for ANN-2\n",
    "from sklearn import preprocessing\n",
    "#working over adult income dataset\n",
    "df=pd.read_csv(\"adult.csv\", sep=\";\", na_values='?')\n",
    "df = df.dropna(axis = 0)\n",
    "df = df.reset_index(drop=True)\n",
    "#target class change\n",
    "\n",
    "#df['income'] = (df['income']==(\"<=50K\")).astype(int)\n",
    "\n",
    "print(sum((df['income']==1).astype(int)))\n",
    "\n",
    "#divide string and integer columns\n",
    "\n",
    "df_str = df.select_dtypes(include='object')\n",
    "df_int = df.select_dtypes(exclude='object')\n",
    "#print(df_int.head())\n",
    "\n",
    "#handle categorical data\n",
    "df_str = pd.get_dummies(df_str)\n",
    "\n",
    "#print(df_str.head())\n",
    "\n",
    "target = df_int['income']\n",
    "x = df_int.drop(columns='income')\n",
    "column_names = x.columns.values\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "#scaler.fit(x)\n",
    "x_stndrd = scaler.fit_transform(x)\n",
    "type(x_stndrd)\n",
    "\n",
    "x_stndrd = pd.DataFrame(x_stndrd)\n",
    "x_stndrd.columns = column_names\n",
    "\n",
    "data = pd.concat([x_stndrd,df_str, target],axis=1)\n",
    "Positive = data[data['income']==0]\n",
    "Negative = data[data['income']==1]\n",
    "target_variable='income'\n",
    "print(len(Positive), len(Negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba321b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now trying for aNN-2 get-initial_model2\n",
    "#the below code is for binary classification since MNSIT is a multi-class low-resolution image dataset. I am updating the code in the next cell.\n",
    "N=500\n",
    "#Positive=Pos\n",
    "#Negative=Neg\n",
    "positiveN=int((Positive.shape[0]/data.shape[0])*N)\n",
    "negativeN=int(N-positiveN)\n",
    "print(positiveN, negativeN)\n",
    "#target variable\n",
    "#target_variable=\"default.payment.next.month\"\n",
    "df1=Positive.sample(positiveN)\n",
    "Positive.drop(df1.index, inplace=True)\n",
    "df2=Negative.sample(negativeN)\n",
    "Negative.drop(df2.index, inplace=True)\n",
    "test_data=df1.append(df2, ignore_index=True)\n",
    "test_data=test_data.sample(frac = 1) #This is to shuffel the training and testing data\n",
    "test_data=test_data.sample(frac = 1)\n",
    "test_data=test_data.sample(frac = 1)\n",
    "X_test=test_data.drop(columns=[target_variable])\n",
    "y_test=to_categorical(test_data[target_variable])\n",
    "\n",
    "# adding dense layer\n",
    "initial_model= get_initial_model_2(X_test.shape[1], 2)\n",
    "initial_model.set_weights(update_weights(initial_model.get_weights()))\n",
    "Models=[]\n",
    "val_acc=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "val_loss=[]\n",
    "train_loss=[]\n",
    "add_weights=[]\n",
    "while Positive.empty==False and Negative.empty==False:\n",
    "  print(positiveN, negativeN)\n",
    "  df1=Positive.sample(min(positiveN, len(Positive)))\n",
    "  Positive.drop(df1.index, inplace=True)\n",
    "  df2=Negative.sample(min(negativeN, len(Negative)))\n",
    "  Negative.drop(df2.index, inplace=True)\n",
    "  train_data=df1.append(df2, ignore_index=True)\n",
    "  train_data=train_data.sample(frac = 1) #shuffel train data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel train data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel train data 3 times\n",
    "    \n",
    "  #all models have different initialization\n",
    "  # define the sequential model\n",
    "  \"\"\"initial_model = keras.Sequential()\n",
    "\n",
    "    # adding dense layer\n",
    "  initial_model.add(Dense(5, input_dim=X_test.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "  initial_model.add(Dense(10, activation='relu'))\n",
    "  initial_model.add(Dense(5, activation='relu'))\n",
    "\n",
    "    # adding dense layer with softmax activation/output layer\n",
    "  initial_model.add(Dense(2, activation='softmax'))\n",
    "  #initial_model.summary()\"\"\"\n",
    "  ann_model=get_initial_model_2(X_test.shape[1], 2) #same intial weights\n",
    "  ann_model.set_weights(initial_model.get_weights())\n",
    "  X_train=train_data.drop(columns=[target_variable])\n",
    "  #train_data[target_variable]=train_data[target_variable]-1 #only for skin_nonskin dataset\n",
    "  y_train=to_categorical(train_data[target_variable])\n",
    "  #print(y_train)\n",
    "  ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m]) # metrics=['accuracy']\n",
    "  history = ann_model.fit(X_train, y_train, epochs=20, validation_split=0.2, verbose=1)\n",
    "  print(history.history['f1_m'][-1])\n",
    "  ann_model.set_weights(update_weights(ann_model.get_weights()))\n",
    "  pred_test=ann_model.predict(X_test)\n",
    "  present=False\n",
    "  for i in range(len(Models)):\n",
    "    if (check_models(Models[i][0], ann_model.get_weights())):\n",
    "      print(\"if any\")\n",
    "      Models[i][1]=Models[i][1]+1\n",
    "      add_weights[i].append(ann_model.get_weights())\n",
    "      val_acc[i].append(history.history['val_f1_m'])\n",
    "      train_acc[i].append(history.history['f1_m'])\n",
    "      test_acc[i].append(f1_m(y_test, pred_test).numpy())\n",
    "      val_loss[i].append(history.history['val_loss'])\n",
    "      train_loss[i].append(history.history['loss'])\n",
    "      present=True\n",
    "      break;\n",
    "  if present==False:\n",
    "    add_weights.append([ann_model.get_weights()])\n",
    "    Models.append([ann_model.get_weights(), 1])\n",
    "    val_acc.append([history.history['val_f1_m']])\n",
    "    train_acc.append([history.history['f1_m']])\n",
    "    test_acc.append([f1_m(y_test, pred_test).numpy()])\n",
    "    val_loss.append([history.history['val_loss']])\n",
    "    train_loss.append([history.history['loss']])\n",
    "for i in range(len(Models)):\n",
    "  print(Models[i][1])\n",
    "print(\"All Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_model_weights=get_avg_weights_2(add_weights[0],X_test.shape[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a02b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean models\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = to_categorical(data[target_variable])\n",
    "X = data.drop(columns=target_variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "init_model=get_initial_model_2(X_test.shape[1], 2)\n",
    "init_model.set_weights(mean_model_weights)\n",
    "\n",
    "print(init_model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d2b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here onwards for ANN-2\n",
    "from sklearn import preprocessing\n",
    "#working over adult income dataset\n",
    "df=pd.read_csv(\"adult.csv\", sep=\";\", na_values='?')\n",
    "df = df.dropna(axis = 0)\n",
    "df = df.reset_index(drop=True)\n",
    "#target class change\n",
    "\n",
    "#df['income'] = (df['income']==(\"<=50K\")).astype(int)\n",
    "\n",
    "print(sum((df['income']==1).astype(int)))\n",
    "\n",
    "#divide string and integer columns\n",
    "\n",
    "df_str = df.select_dtypes(include='object')\n",
    "df_int = df.select_dtypes(exclude='object')\n",
    "#print(df_int.head())\n",
    "\n",
    "#handle categorical data\n",
    "df_str = pd.get_dummies(df_str)\n",
    "\n",
    "#print(df_str.head())\n",
    "\n",
    "target = df_int['income']\n",
    "x = df_int.drop(columns='income')\n",
    "column_names = x.columns.values\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "#scaler.fit(x)\n",
    "x_stndrd = scaler.fit_transform(x)\n",
    "type(x_stndrd)\n",
    "\n",
    "x_stndrd = pd.DataFrame(x_stndrd)\n",
    "x_stndrd.columns = column_names\n",
    "\n",
    "data = pd.concat([x_stndrd,df_str, target],axis=1)\n",
    "Positive = data[data['income']==0]\n",
    "Negative = data[data['income']==1]\n",
    "target_variable='income'\n",
    "print(len(Positive), len(Negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179abee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now trying for aNN-2 get-initial_model2\n",
    "#the below code is for binary classification since MNSIT is a multi-class low-resolution image dataset. I am updating the code in the next cell.\n",
    "N=500\n",
    "#Positive=Pos\n",
    "#Negative=Neg\n",
    "positiveN=int((Positive.shape[0]/data.shape[0])*N)\n",
    "negativeN=int(N-positiveN)\n",
    "print(positiveN, negativeN)\n",
    "#target variable\n",
    "#target_variable=\"default.payment.next.month\"\n",
    "df1=Positive.sample(positiveN)\n",
    "Positive.drop(df1.index, inplace=True)\n",
    "df2=Negative.sample(negativeN)\n",
    "Negative.drop(df2.index, inplace=True)\n",
    "test_data=df1.append(df2, ignore_index=True)\n",
    "test_data=test_data.sample(frac = 1) #This is to shuffel the training and testing data\n",
    "test_data=test_data.sample(frac = 1)\n",
    "test_data=test_data.sample(frac = 1)\n",
    "X_test=test_data.drop(columns=[target_variable])\n",
    "y_test=to_categorical(test_data[target_variable])\n",
    "\n",
    "# adding dense layer\n",
    "initial_model= get_initial_model_3(X_test.shape[1], 2)\n",
    "initial_model.set_weights(update_weights(initial_model.get_weights()))\n",
    "Models=[]\n",
    "val_acc=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "val_loss=[]\n",
    "train_loss=[]\n",
    "add_weights=[]\n",
    "while Positive.empty==False and Negative.empty==False:\n",
    "  print(positiveN, negativeN)\n",
    "  df1=Positive.sample(min(positiveN, len(Positive)))\n",
    "  Positive.drop(df1.index, inplace=True)\n",
    "  df2=Negative.sample(min(negativeN, len(Negative)))\n",
    "  Negative.drop(df2.index, inplace=True)\n",
    "  train_data=df1.append(df2, ignore_index=True)\n",
    "  train_data=train_data.sample(frac = 1) #shuffel train data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel train data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel train data 3 times\n",
    "    \n",
    "  #all models have different initialization\n",
    "  # define the sequential model\n",
    "  \"\"\"initial_model = keras.Sequential()\n",
    "\n",
    "    # adding dense layer\n",
    "  initial_model.add(Dense(5, input_dim=X_test.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "  initial_model.add(Dense(10, activation='relu'))\n",
    "  initial_model.add(Dense(5, activation='relu'))\n",
    "\n",
    "    # adding dense layer with softmax activation/output layer\n",
    "  initial_model.add(Dense(2, activation='softmax'))\n",
    "  #initial_model.summary()\"\"\"\n",
    "  ann_model=get_initial_model_3(X_test.shape[1], 2) #same intial weights\n",
    "  ann_model.set_weights(initial_model.get_weights())\n",
    "  X_train=train_data.drop(columns=[target_variable])\n",
    "  #train_data[target_variable]=train_data[target_variable]-1 #only for skin_nonskin dataset\n",
    "  y_train=to_categorical(train_data[target_variable])\n",
    "  #print(y_train)\n",
    "  ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m]) # metrics=['accuracy']\n",
    "  history = ann_model.fit(X_train, y_train, epochs=20, validation_split=0.2, verbose=1)\n",
    "  print(history.history['f1_m'][-1])\n",
    "  ann_model.set_weights(update_weights(ann_model.get_weights()))\n",
    "  pred_test=ann_model.predict(X_test)\n",
    "  present=False\n",
    "  for i in range(len(Models)):\n",
    "    if (check_models(Models[i][0], ann_model.get_weights())):\n",
    "      print(\"if any\")\n",
    "      Models[i][1]=Models[i][1]+1\n",
    "      add_weights[i].append(ann_model.get_weights())\n",
    "      val_acc[i].append(history.history['val_f1_m'])\n",
    "      train_acc[i].append(history.history['f1_m'])\n",
    "      test_acc[i].append(f1_m(y_test, pred_test).numpy())\n",
    "      val_loss[i].append(history.history['val_loss'])\n",
    "      train_loss[i].append(history.history['loss'])\n",
    "      present=True\n",
    "      break;\n",
    "  if present==False:\n",
    "    add_weights.append([ann_model.get_weights()])\n",
    "    Models.append([ann_model.get_weights(), 1])\n",
    "    val_acc.append([history.history['val_f1_m']])\n",
    "    train_acc.append([history.history['f1_m']])\n",
    "    test_acc.append([f1_m(y_test, pred_test).numpy()])\n",
    "    val_loss.append([history.history['val_loss']])\n",
    "    train_loss.append([history.history['loss']])\n",
    "for i in range(len(Models)):\n",
    "  print(Models[i][1])\n",
    "print(\"All Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d2cb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007b6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_model_weights=get_avg_weights_3(add_weights[0],X_test.shape[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a1e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean models\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = to_categorical(data[target_variable])\n",
    "X = data.drop(columns=target_variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "init_model=get_initial_model_3(X_test.shape[1], 2)\n",
    "init_model.set_weights(mean_model_weights)\n",
    "\n",
    "print(init_model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here onwards for ANN-2\n",
    "from sklearn import preprocessing\n",
    "#working over adult income dataset\n",
    "df=pd.read_csv(\"adult.csv\", sep=\";\", na_values='?')\n",
    "df = df.dropna(axis = 0)\n",
    "df = df.reset_index(drop=True)\n",
    "#target class change\n",
    "\n",
    "#df['income'] = (df['income']==(\"<=50K\")).astype(int)\n",
    "\n",
    "print(sum((df['income']==1).astype(int)))\n",
    "\n",
    "#divide string and integer columns\n",
    "\n",
    "df_str = df.select_dtypes(include='object')\n",
    "df_int = df.select_dtypes(exclude='object')\n",
    "#print(df_int.head())\n",
    "\n",
    "#handle categorical data\n",
    "df_str = pd.get_dummies(df_str)\n",
    "\n",
    "#print(df_str.head())\n",
    "\n",
    "target = df_int['income']\n",
    "x = df_int.drop(columns='income')\n",
    "column_names = x.columns.values\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "#scaler.fit(x)\n",
    "x_stndrd = scaler.fit_transform(x)\n",
    "type(x_stndrd)\n",
    "\n",
    "x_stndrd = pd.DataFrame(x_stndrd)\n",
    "x_stndrd.columns = column_names\n",
    "\n",
    "data = pd.concat([x_stndrd,df_str, target],axis=1)\n",
    "Positive = data[data['income']==0]\n",
    "Negative = data[data['income']==1]\n",
    "target_variable='income'\n",
    "print(len(Positive), len(Negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6203e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now trying for aNN-2 get-initial_model2\n",
    "#the below code is for binary classification since MNSIT is a multi-class low-resolution image dataset. I am updating the code in the next cell.\n",
    "N=500\n",
    "#Positive=Pos\n",
    "#Negative=Neg\n",
    "positiveN=int((Positive.shape[0]/data.shape[0])*N)\n",
    "negativeN=int(N-positiveN)\n",
    "print(positiveN, negativeN)\n",
    "#target variable\n",
    "#target_variable=\"default.payment.next.month\"\n",
    "df1=Positive.sample(positiveN)\n",
    "Positive.drop(df1.index, inplace=True)\n",
    "df2=Negative.sample(negativeN)\n",
    "Negative.drop(df2.index, inplace=True)\n",
    "test_data=df1.append(df2, ignore_index=True)\n",
    "test_data=test_data.sample(frac = 1) #This is to shuffel the training and testing data\n",
    "test_data=test_data.sample(frac = 1)\n",
    "test_data=test_data.sample(frac = 1)\n",
    "X_test=test_data.drop(columns=[target_variable])\n",
    "y_test=to_categorical(test_data[target_variable])\n",
    "\n",
    "# adding dense layer\n",
    "initial_model= get_initial_model_4(X_test.shape[1], 2)\n",
    "initial_model.set_weights(update_weights(initial_model.get_weights()))\n",
    "Models=[]\n",
    "val_acc=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "val_loss=[]\n",
    "train_loss=[]\n",
    "add_weights=[]\n",
    "while Positive.empty==False and Negative.empty==False:\n",
    "  print(positiveN, negativeN)\n",
    "  df1=Positive.sample(min(positiveN, len(Positive)))\n",
    "  Positive.drop(df1.index, inplace=True)\n",
    "  df2=Negative.sample(min(negativeN, len(Negative)))\n",
    "  Negative.drop(df2.index, inplace=True)\n",
    "  train_data=df1.append(df2, ignore_index=True)\n",
    "  train_data=train_data.sample(frac = 1) #shuffel train data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel train data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel train data 3 times\n",
    "    \n",
    "  #all models have different initialization\n",
    "  # define the sequential model\n",
    "  \"\"\"initial_model = keras.Sequential()\n",
    "\n",
    "    # adding dense layer\n",
    "  initial_model.add(Dense(5, input_dim=X_test.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "  initial_model.add(Dense(10, activation='relu'))\n",
    "  initial_model.add(Dense(5, activation='relu'))\n",
    "\n",
    "    # adding dense layer with softmax activation/output layer\n",
    "  initial_model.add(Dense(2, activation='softmax'))\n",
    "  #initial_model.summary()\"\"\"\n",
    "  ann_model=get_initial_model_4(X_test.shape[1], 2) #same intial weights\n",
    "  ann_model.set_weights(initial_model.get_weights())\n",
    "  X_train=train_data.drop(columns=[target_variable])\n",
    "  #train_data[target_variable]=train_data[target_variable]-1 #only for skin_nonskin dataset\n",
    "  y_train=to_categorical(train_data[target_variable])\n",
    "  #print(y_train)\n",
    "  ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m]) # metrics=['accuracy']\n",
    "  history = ann_model.fit(X_train, y_train, epochs=20, validation_split=0.2, verbose=1)\n",
    "  print(history.history['f1_m'][-1])\n",
    "  ann_model.set_weights(update_weights(ann_model.get_weights()))\n",
    "  pred_test=ann_model.predict(X_test)\n",
    "  present=False\n",
    "  for i in range(len(Models)):\n",
    "    if (check_models(Models[i][0], ann_model.get_weights())):\n",
    "      print(\"if any\")\n",
    "      Models[i][1]=Models[i][1]+1\n",
    "      add_weights[i].append(ann_model.get_weights())\n",
    "      val_acc[i].append(history.history['val_f1_m'])\n",
    "      train_acc[i].append(history.history['f1_m'])\n",
    "      test_acc[i].append(f1_m(y_test, pred_test).numpy())\n",
    "      val_loss[i].append(history.history['val_loss'])\n",
    "      train_loss[i].append(history.history['loss'])\n",
    "      present=True\n",
    "      break;\n",
    "  if present==False:\n",
    "    add_weights.append([ann_model.get_weights()])\n",
    "    Models.append([ann_model.get_weights(), 1])\n",
    "    val_acc.append([history.history['val_f1_m']])\n",
    "    train_acc.append([history.history['f1_m']])\n",
    "    test_acc.append([f1_m(y_test, pred_test).numpy()])\n",
    "    val_loss.append([history.history['val_loss']])\n",
    "    train_loss.append([history.history['loss']])\n",
    "for i in range(len(Models)):\n",
    "  print(Models[i][1])\n",
    "print(\"All Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e126e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_model_weights=get_avg_weights_4(add_weights[1],X_test.shape[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d65d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean models\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = to_categorical(data[target_variable])\n",
    "X = data.drop(columns=target_variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "init_model=get_initial_model_4(X_test.shape[1], 2)\n",
    "init_model.set_weights(mean_model_weights)\n",
    "\n",
    "print(init_model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e9e46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
