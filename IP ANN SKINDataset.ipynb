{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c65da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from scipy.stats import ks_2samp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3478e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundR(x, r):\n",
    "    return [np.round(i,r) for i in np.array(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "713afee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(model_weights):\n",
    "  for i in range(len(model_weights)):\n",
    "    for j in range(len(model_weights[i])):\n",
    "      if isinstance(model_weights[i][j], np.ndarray):\n",
    "        for k in range(len(model_weights[i][j])):\n",
    "          #print(\"chalra h\", i, j, k)\n",
    "            if (np.round(model_weights[i][j][k],2)==0):\n",
    "                model_weights[i][j][k]=float(f'{model_weights[i][j][k]:.1g}')\n",
    "            else:\n",
    "                model_weights[i][j][k]=np.round(model_weights[i][j][k],2)\n",
    "      else:\n",
    "        if (np.round(model_weights[i][j],2)==0):\n",
    "          model_weights[i][j]=float(f'{model_weights[i][j]:.1g}')\n",
    "        else:\n",
    "          model_weights[i][j]=np.round(model_weights[i][j],2)\n",
    "  return model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b788b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_comparison1(node1, node2, epsilon=0.05):\n",
    "  for x, y in zip(node1,node2):\n",
    "    #print(x,y)\n",
    "    if isinstance(x, list):\n",
    "        if((np.linalg.norm(np.array(x)-np.array(y))/len(x))<=epsilon):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if(abs(x-y)<=epsilon):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07e19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_comparison(node1, node2):\n",
    "  for x, y in zip(node1,node2):\n",
    "    #print(x,y)\n",
    "    if isinstance(x, list):\n",
    "        if(sorted(x)==sorted(y)):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if(x==y):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "947539c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_comparison(layer1, layer2):\n",
    "  for node1 in layer1:\n",
    "    present=False\n",
    "    for node2 in layer2:\n",
    "      if (node_comparison1(node1, node2)):\n",
    "        present=True\n",
    "    if present==False:\n",
    "      return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12640aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_models(Model_weights1, Model_weights2):\n",
    "  for i in range(0,len(Model_weights1), 2):\n",
    "    layer1=[]\n",
    "    layer2=[]\n",
    "    for j in range(len(Model_weights1[i+1].T)):\n",
    "      Node1=[]\n",
    "      Node2=[]\n",
    "      Node1.append(list(Model_weights1[i].T[j]))\n",
    "      Node1.append(Model_weights1[i+1][j])\n",
    "      if (i+2<len(Model_weights1)):\n",
    "        Node1.append(list(Model_weights1[i+2][j]))\n",
    "      Node2.append(list(Model_weights2[i].T[j]))\n",
    "      Node2.append(Model_weights2[i+1][j])\n",
    "      if (i+2<len(Model_weights2)):\n",
    "        Node2.append(list(Model_weights2[i+2][j]))\n",
    "      layer1.append(Node1)\n",
    "      layer2.append(Node2)\n",
    "    if (layer_comparison(layer1, layer2)):\n",
    "      continue\n",
    "    else:\n",
    "      return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92996cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_model(inp, out):\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(5, input_dim=inp, kernel_initializer='normal', activation='relu'),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dense(5, activation='relu'),\n",
    "        Dense(out, activation='softmax')\n",
    "        ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bbc7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is used to average out all the models in the epsilon range\n",
    "#the problem is different here than compared with model comparison. Shape not important.\n",
    "def get_avg_weights(models_weights, inp_shape, out_shape):\n",
    "    avg_sum=get_initial_model(inp_shape, out_shape).get_weights()\n",
    "    #print(avg_sum)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                for k in range(len(avg_sum[i][j])):\n",
    "                    avg_sum[i][j][k]=0\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=0\n",
    "    #print(avg_sum)\n",
    "    print(models_weights[0])\n",
    "    for i in range(len(models_weights)):\n",
    "        for j in range(0, len(avg_sum),2):\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            #if(isinstance(avg_sum[j][0], np.ndarray)):\n",
    "            for k in range(len(avg_sum[j])):\n",
    "                avg_sum[j][k]=[avg_sum[j][k][l]+models_weights[i][j][k][l] for l in range(len(avg_sum[j][k]))]\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            #else: gayab kr diya\n",
    "            print('andr aara h')\n",
    "            for k in range(len(avg_sum[j+1])):\n",
    "                avg_sum[j+1][k]=avg_sum[j+1][k]+models_weights[i][j+1][k]\n",
    "    print(\"yhn tk\")\n",
    "    mean_size=len(models_weights)\n",
    "    print(mean_size)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                #print(\"yhn tk\")\n",
    "                avg_sum[i][j]=[avg_sum[i][j][k]/mean_size for k in range(len(avg_sum[i][j]))]\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=avg_sum[i+1][j]/mean_size\n",
    "    print(\"Done\")\n",
    "    return avg_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83ac50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions for f1, precision and recall\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "466f5f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of               x1        x2        x3  label\n",
      "0       0.290196  0.333333  0.482353    0.0\n",
      "1       0.286275  0.329412  0.478431    0.0\n",
      "2       0.282353  0.325490  0.474510    0.0\n",
      "3       0.274510  0.317647  0.466667    0.0\n",
      "4       0.274510  0.317647  0.466667    0.0\n",
      "...          ...       ...       ...    ...\n",
      "245052  0.639216  0.635294  0.439216    1.0\n",
      "245053  0.639216  0.635294  0.439216    1.0\n",
      "245054  0.639216  0.635294  0.439216    1.0\n",
      "245055  0.639216  0.635294  0.439216    1.0\n",
      "245056  1.000000  1.000000  1.000000    1.0\n",
      "\n",
      "[245057 rows x 4 columns]>\n",
      "50859\n",
      "194198\n"
     ]
    }
   ],
   "source": [
    "#for SKIN_NonSkin dataset\n",
    "dataset = pd.read_csv(\"Skin_NonSkin.csv\",sep=';', names=['x1','x2','x3','label'])\n",
    "#print(dataset['label'])\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "dataset = pd.DataFrame(scaler.fit_transform(dataset), columns=['x1','x2','x3','label'])\n",
    "target_variable=\"label\"\n",
    "print(dataset.head)\n",
    "Positive=dataset[dataset[target_variable]==0]\n",
    "Negative=dataset[dataset[target_variable]==1]\n",
    "print(len(Positive))\n",
    "print(len(Negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7120ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 686us/sample - loss: 0.6603 - f1_m: 0.7950 - val_loss: 0.6346 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.6099 - f1_m: 0.7950 - val_loss: 0.5917 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.5686 - f1_m: 0.7950 - val_loss: 0.5578 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5381 - f1_m: 0.7950 - val_loss: 0.5357 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5179 - f1_m: 0.7950 - val_loss: 0.5211 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5030 - f1_m: 0.7950 - val_loss: 0.5075 - val_f1_m: 0.7411\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4887 - f1_m: 0.7950 - val_loss: 0.4924 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4723 - f1_m: 0.7950 - val_loss: 0.4754 - val_f1_m: 0.7545\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4537 - f1_m: 0.7950 - val_loss: 0.4557 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4322 - f1_m: 0.7950 - val_loss: 0.4326 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4074 - f1_m: 0.7950 - val_loss: 0.4058 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3782 - f1_m: 0.7950 - val_loss: 0.3751 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3461 - f1_m: 0.7950 - val_loss: 0.3417 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3121 - f1_m: 0.7950 - val_loss: 0.3087 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2788 - f1_m: 0.8125 - val_loss: 0.2757 - val_f1_m: 0.8839\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2467 - f1_m: 0.8937 - val_loss: 0.2488 - val_f1_m: 0.8884\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2214 - f1_m: 0.9187 - val_loss: 0.2258 - val_f1_m: 0.9107\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.1990 - f1_m: 0.9225 - val_loss: 0.2092 - val_f1_m: 0.9286\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.1829 - f1_m: 0.9325 - val_loss: 0.1956 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.1711 - f1_m: 0.9350 - val_loss: 0.1871 - val_f1_m: 0.9286\n",
      "0.93499994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 765us/sample - loss: 0.6591 - f1_m: 0.7937 - val_loss: 0.6335 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.6098 - f1_m: 0.7937 - val_loss: 0.5877 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5662 - f1_m: 0.7937 - val_loss: 0.5521 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.5365 - f1_m: 0.7937 - val_loss: 0.5309 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.5205 - f1_m: 0.7937 - val_loss: 0.5185 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.5095 - f1_m: 0.7937 - val_loss: 0.5091 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.5004 - f1_m: 0.7937 - val_loss: 0.4994 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.4893 - f1_m: 0.7937 - val_loss: 0.4866 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.4739 - f1_m: 0.7937 - val_loss: 0.4689 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.4567 - f1_m: 0.7937 - val_loss: 0.4511 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.4362 - f1_m: 0.7937 - val_loss: 0.4296 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4139 - f1_m: 0.7937 - val_loss: 0.4060 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3886 - f1_m: 0.7937 - val_loss: 0.3800 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3619 - f1_m: 0.7937 - val_loss: 0.3529 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3328 - f1_m: 0.7937 - val_loss: 0.3227 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3040 - f1_m: 0.7937 - val_loss: 0.2910 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2744 - f1_m: 0.8312 - val_loss: 0.2642 - val_f1_m: 0.8527\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2486 - f1_m: 0.8913 - val_loss: 0.2420 - val_f1_m: 0.8884\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2260 - f1_m: 0.9100 - val_loss: 0.2204 - val_f1_m: 0.8929\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.2082 - f1_m: 0.9150 - val_loss: 0.2046 - val_f1_m: 0.9196\n",
      "0.9149999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 700us/sample - loss: 0.6574 - f1_m: 0.7962 - val_loss: 0.6346 - val_f1_m: 0.7366\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6084 - f1_m: 0.7962 - val_loss: 0.5907 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5631 - f1_m: 0.7962 - val_loss: 0.5580 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5337 - f1_m: 0.7962 - val_loss: 0.5388 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5167 - f1_m: 0.7962 - val_loss: 0.5277 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5049 - f1_m: 0.7962 - val_loss: 0.5188 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4951 - f1_m: 0.7962 - val_loss: 0.5085 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4850 - f1_m: 0.7962 - val_loss: 0.4959 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4719 - f1_m: 0.7962 - val_loss: 0.4827 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4582 - f1_m: 0.7962 - val_loss: 0.4685 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4434 - f1_m: 0.7962 - val_loss: 0.4505 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4260 - f1_m: 0.7962 - val_loss: 0.4306 - val_f1_m: 0.7902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4062 - f1_m: 0.7962 - val_loss: 0.4086 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3850 - f1_m: 0.7962 - val_loss: 0.3852 - val_f1_m: 0.7500\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3605 - f1_m: 0.7962 - val_loss: 0.3554 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3350 - f1_m: 0.7962 - val_loss: 0.3277 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3112 - f1_m: 0.7962 - val_loss: 0.3000 - val_f1_m: 0.7634\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2853 - f1_m: 0.8062 - val_loss: 0.2714 - val_f1_m: 0.8482\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2633 - f1_m: 0.8712 - val_loss: 0.2516 - val_f1_m: 0.8571\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2433 - f1_m: 0.8875 - val_loss: 0.2255 - val_f1_m: 0.8973\n",
      "0.8874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 676us/sample - loss: 0.6566 - f1_m: 0.7975 - val_loss: 0.6344 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6060 - f1_m: 0.7975 - val_loss: 0.5918 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5617 - f1_m: 0.7975 - val_loss: 0.5595 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5323 - f1_m: 0.7975 - val_loss: 0.5426 - val_f1_m: 0.7589\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5164 - f1_m: 0.7975 - val_loss: 0.5332 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.5498 - f1_m: 0.75 - 0s 59us/sample - loss: 0.5063 - f1_m: 0.7975 - val_loss: 0.5254 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4980 - f1_m: 0.7975 - val_loss: 0.5172 - val_f1_m: 0.7589\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4887 - f1_m: 0.7975 - val_loss: 0.5058 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4765 - f1_m: 0.7975 - val_loss: 0.4907 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4595 - f1_m: 0.7975 - val_loss: 0.4721 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4420 - f1_m: 0.7975 - val_loss: 0.4513 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4220 - f1_m: 0.7975 - val_loss: 0.4280 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3997 - f1_m: 0.7975 - val_loss: 0.4016 - val_f1_m: 0.7455\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3748 - f1_m: 0.7975 - val_loss: 0.3745 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3491 - f1_m: 0.7975 - val_loss: 0.3414 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3215 - f1_m: 0.7975 - val_loss: 0.3085 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2948 - f1_m: 0.7975 - val_loss: 0.2781 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2709 - f1_m: 0.8550 - val_loss: 0.2523 - val_f1_m: 0.8705\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2488 - f1_m: 0.8787 - val_loss: 0.2243 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2315 - f1_m: 0.9000 - val_loss: 0.2062 - val_f1_m: 0.9018\n",
      "0.9\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 674us/sample - loss: 0.6605 - f1_m: 0.7825 - val_loss: 0.6181 - val_f1_m: 0.8393\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.6136 - f1_m: 0.7825 - val_loss: 0.5637 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5757 - f1_m: 0.7825 - val_loss: 0.5149 - val_f1_m: 0.8393\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5481 - f1_m: 0.7825 - val_loss: 0.4843 - val_f1_m: 0.8393\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5324 - f1_m: 0.7825 - val_loss: 0.4659 - val_f1_m: 0.8527\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5212 - f1_m: 0.7825 - val_loss: 0.4520 - val_f1_m: 0.8393\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5097 - f1_m: 0.7825 - val_loss: 0.4436 - val_f1_m: 0.8527\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4961 - f1_m: 0.7825 - val_loss: 0.4261 - val_f1_m: 0.8527\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4825 - f1_m: 0.7825 - val_loss: 0.4128 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4674 - f1_m: 0.7825 - val_loss: 0.3966 - val_f1_m: 0.8393\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4500 - f1_m: 0.7825 - val_loss: 0.3808 - val_f1_m: 0.8527\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4305 - f1_m: 0.7825 - val_loss: 0.3624 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4085 - f1_m: 0.7825 - val_loss: 0.3421 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3845 - f1_m: 0.7825 - val_loss: 0.3232 - val_f1_m: 0.8393\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3582 - f1_m: 0.7825 - val_loss: 0.2974 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3316 - f1_m: 0.7825 - val_loss: 0.2763 - val_f1_m: 0.8527\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3066 - f1_m: 0.7912 - val_loss: 0.2545 - val_f1_m: 0.8973\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2822 - f1_m: 0.8487 - val_loss: 0.2373 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2612 - f1_m: 0.8775 - val_loss: 0.2198 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2414 - f1_m: 0.8937 - val_loss: 0.2066 - val_f1_m: 0.9018\n",
      "0.89374995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 665us/sample - loss: 0.6582 - f1_m: 0.7975 - val_loss: 0.6369 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6061 - f1_m: 0.7987 - val_loss: 0.5956 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5615 - f1_m: 0.7987 - val_loss: 0.5661 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5321 - f1_m: 0.7987 - val_loss: 0.5501 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5150 - f1_m: 0.7987 - val_loss: 0.5403 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5037 - f1_m: 0.7987 - val_loss: 0.5319 - val_f1_m: 0.7277\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4939 - f1_m: 0.7987 - val_loss: 0.5223 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4833 - f1_m: 0.7987 - val_loss: 0.5114 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4714 - f1_m: 0.7987 - val_loss: 0.4971 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4570 - f1_m: 0.7987 - val_loss: 0.4815 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4416 - f1_m: 0.7987 - val_loss: 0.4661 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4256 - f1_m: 0.7987 - val_loss: 0.4482 - val_f1_m: 0.7277\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4059 - f1_m: 0.7987 - val_loss: 0.4256 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3848 - f1_m: 0.7987 - val_loss: 0.4023 - val_f1_m: 0.7277\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3619 - f1_m: 0.7987 - val_loss: 0.3761 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3379 - f1_m: 0.7987 - val_loss: 0.3471 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3132 - f1_m: 0.7987 - val_loss: 0.3180 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2873 - f1_m: 0.7987 - val_loss: 0.2936 - val_f1_m: 0.7679\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2649 - f1_m: 0.8612 - val_loss: 0.2670 - val_f1_m: 0.8482\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2441 - f1_m: 0.8863 - val_loss: 0.2467 - val_f1_m: 0.8929\n",
      "0.88625\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 669us/sample - loss: 0.6558 - f1_m: 0.7962 - val_loss: 0.6349 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6058 - f1_m: 0.7962 - val_loss: 0.5929 - val_f1_m: 0.7634\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5632 - f1_m: 0.7962 - val_loss: 0.5592 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5309 - f1_m: 0.7962 - val_loss: 0.5415 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5148 - f1_m: 0.7962 - val_loss: 0.5301 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5040 - f1_m: 0.7962 - val_loss: 0.5208 - val_f1_m: 0.7500\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4946 - f1_m: 0.7962 - val_loss: 0.5103 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4832 - f1_m: 0.7962 - val_loss: 0.4971 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4698 - f1_m: 0.7962 - val_loss: 0.4831 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4553 - f1_m: 0.7962 - val_loss: 0.4685 - val_f1_m: 0.7634\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4402 - f1_m: 0.7962 - val_loss: 0.4512 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4218 - f1_m: 0.7962 - val_loss: 0.4324 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4022 - f1_m: 0.7962 - val_loss: 0.4117 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3805 - f1_m: 0.7962 - val_loss: 0.3892 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3572 - f1_m: 0.7962 - val_loss: 0.3636 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3321 - f1_m: 0.7962 - val_loss: 0.3380 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3069 - f1_m: 0.7962 - val_loss: 0.3127 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2826 - f1_m: 0.8225 - val_loss: 0.2879 - val_f1_m: 0.8795\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2599 - f1_m: 0.8712 - val_loss: 0.2657 - val_f1_m: 0.8973\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2385 - f1_m: 0.8975 - val_loss: 0.2487 - val_f1_m: 0.9018\n",
      "0.8974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 665us/sample - loss: 0.6567 - f1_m: 0.7925 - val_loss: 0.6319 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6079 - f1_m: 0.7925 - val_loss: 0.5860 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5643 - f1_m: 0.7925 - val_loss: 0.5505 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5361 - f1_m: 0.7925 - val_loss: 0.5286 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5210 - f1_m: 0.7925 - val_loss: 0.5161 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5113 - f1_m: 0.7925 - val_loss: 0.5060 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5016 - f1_m: 0.7925 - val_loss: 0.4961 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4915 - f1_m: 0.7925 - val_loss: 0.4840 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4798 - f1_m: 0.7925 - val_loss: 0.4704 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4661 - f1_m: 0.7925 - val_loss: 0.4561 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4517 - f1_m: 0.7925 - val_loss: 0.4400 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4345 - f1_m: 0.7925 - val_loss: 0.4219 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4152 - f1_m: 0.7925 - val_loss: 0.4004 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3950 - f1_m: 0.7925 - val_loss: 0.3781 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3706 - f1_m: 0.7925 - val_loss: 0.3541 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3459 - f1_m: 0.7925 - val_loss: 0.3273 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3201 - f1_m: 0.7925 - val_loss: 0.3023 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2957 - f1_m: 0.7925 - val_loss: 0.2770 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2711 - f1_m: 0.8737 - val_loss: 0.2541 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2489 - f1_m: 0.9000 - val_loss: 0.2351 - val_f1_m: 0.9330\n",
      "0.9\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 669us/sample - loss: 0.6570 - f1_m: 0.7987 - val_loss: 0.6402 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6061 - f1_m: 0.7987 - val_loss: 0.6007 - val_f1_m: 0.7545\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5596 - f1_m: 0.7987 - val_loss: 0.5713 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5274 - f1_m: 0.7987 - val_loss: 0.5567 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5101 - f1_m: 0.7987 - val_loss: 0.5491 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4989 - f1_m: 0.7987 - val_loss: 0.5406 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4896 - f1_m: 0.7987 - val_loss: 0.5305 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4791 - f1_m: 0.7987 - val_loss: 0.5170 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4625 - f1_m: 0.7987 - val_loss: 0.4954 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4424 - f1_m: 0.7987 - val_loss: 0.4746 - val_f1_m: 0.7679\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4206 - f1_m: 0.7987 - val_loss: 0.4554 - val_f1_m: 0.7411\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3962 - f1_m: 0.7987 - val_loss: 0.4264 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3700 - f1_m: 0.7987 - val_loss: 0.3981 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3421 - f1_m: 0.7987 - val_loss: 0.3677 - val_f1_m: 0.7679\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3113 - f1_m: 0.7987 - val_loss: 0.3421 - val_f1_m: 0.7545\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2821 - f1_m: 0.7987 - val_loss: 0.3105 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2538 - f1_m: 0.8787 - val_loss: 0.2855 - val_f1_m: 0.8393\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2318 - f1_m: 0.9062 - val_loss: 0.2640 - val_f1_m: 0.8750\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2106 - f1_m: 0.9175 - val_loss: 0.2486 - val_f1_m: 0.8795\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1937 - f1_m: 0.9212 - val_loss: 0.2424 - val_f1_m: 0.8705\n",
      "0.9212499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 668us/sample - loss: 0.6552 - f1_m: 0.7925 - val_loss: 0.6304 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6064 - f1_m: 0.7925 - val_loss: 0.5855 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5647 - f1_m: 0.7925 - val_loss: 0.5497 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5361 - f1_m: 0.7925 - val_loss: 0.5285 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5193 - f1_m: 0.7925 - val_loss: 0.5156 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5095 - f1_m: 0.7925 - val_loss: 0.5043 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4976 - f1_m: 0.7925 - val_loss: 0.4911 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4821 - f1_m: 0.7925 - val_loss: 0.4716 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4641 - f1_m: 0.7925 - val_loss: 0.4526 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4439 - f1_m: 0.7925 - val_loss: 0.4314 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4210 - f1_m: 0.7925 - val_loss: 0.4062 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.3946 - f1_m: 0.7925 - val_loss: 0.3785 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3665 - f1_m: 0.7925 - val_loss: 0.3483 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3353 - f1_m: 0.7925 - val_loss: 0.3165 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3037 - f1_m: 0.7925 - val_loss: 0.2843 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2725 - f1_m: 0.8525 - val_loss: 0.2535 - val_f1_m: 0.8705\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2456 - f1_m: 0.8962 - val_loss: 0.2275 - val_f1_m: 0.9330\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2209 - f1_m: 0.9137 - val_loss: 0.2077 - val_f1_m: 0.9375\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2023 - f1_m: 0.9325 - val_loss: 0.1889 - val_f1_m: 0.9509\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.1875 - f1_m: 0.9350 - val_loss: 0.1764 - val_f1_m: 0.9464\n",
      "0.935\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 691us/sample - loss: 0.6581 - f1_m: 0.7887 - val_loss: 0.6276 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6117 - f1_m: 0.7887 - val_loss: 0.5783 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5711 - f1_m: 0.7887 - val_loss: 0.5401 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5440 - f1_m: 0.7887 - val_loss: 0.5122 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5252 - f1_m: 0.7887 - val_loss: 0.4937 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5094 - f1_m: 0.7887 - val_loss: 0.4780 - val_f1_m: 0.8304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4946 - f1_m: 0.7887 - val_loss: 0.4616 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4781 - f1_m: 0.7887 - val_loss: 0.4431 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4591 - f1_m: 0.7887 - val_loss: 0.4220 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4368 - f1_m: 0.7887 - val_loss: 0.3988 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4130 - f1_m: 0.7887 - val_loss: 0.3735 - val_f1_m: 0.8304\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3871 - f1_m: 0.7887 - val_loss: 0.3464 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3590 - f1_m: 0.7887 - val_loss: 0.3178 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3314 - f1_m: 0.7887 - val_loss: 0.2886 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3008 - f1_m: 0.7887 - val_loss: 0.2605 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2737 - f1_m: 0.8763 - val_loss: 0.2322 - val_f1_m: 0.9018\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2485 - f1_m: 0.8975 - val_loss: 0.2104 - val_f1_m: 0.9643\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2266 - f1_m: 0.9200 - val_loss: 0.1865 - val_f1_m: 0.9509\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2091 - f1_m: 0.9312 - val_loss: 0.1710 - val_f1_m: 0.9688\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.1961 - f1_m: 0.9400 - val_loss: 0.1566 - val_f1_m: 0.9688\n",
      "0.93999994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 684us/sample - loss: 0.6581 - f1_m: 0.7925 - val_loss: 0.6325 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6075 - f1_m: 0.7925 - val_loss: 0.5854 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5653 - f1_m: 0.7925 - val_loss: 0.5495 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5378 - f1_m: 0.7925 - val_loss: 0.5278 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5211 - f1_m: 0.7925 - val_loss: 0.5143 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5097 - f1_m: 0.7925 - val_loss: 0.5032 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4987 - f1_m: 0.7925 - val_loss: 0.4914 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4870 - f1_m: 0.7925 - val_loss: 0.4782 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4732 - f1_m: 0.7925 - val_loss: 0.4624 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4577 - f1_m: 0.7925 - val_loss: 0.4460 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4402 - f1_m: 0.7925 - val_loss: 0.4266 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4199 - f1_m: 0.7925 - val_loss: 0.4052 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3977 - f1_m: 0.7925 - val_loss: 0.3804 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3713 - f1_m: 0.7925 - val_loss: 0.3537 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3441 - f1_m: 0.7925 - val_loss: 0.3251 - val_f1_m: 0.7500\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3145 - f1_m: 0.7925 - val_loss: 0.2948 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2846 - f1_m: 0.7975 - val_loss: 0.2651 - val_f1_m: 0.8795\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2565 - f1_m: 0.8912 - val_loss: 0.2392 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2289 - f1_m: 0.9162 - val_loss: 0.2136 - val_f1_m: 0.9375\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2055 - f1_m: 0.9438 - val_loss: 0.1928 - val_f1_m: 0.9509\n",
      "0.94375\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 671us/sample - loss: 0.6607 - f1_m: 0.7787 - val_loss: 0.6152 - val_f1_m: 0.8661\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6141 - f1_m: 0.7787 - val_loss: 0.5558 - val_f1_m: 0.8527\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5770 - f1_m: 0.7787 - val_loss: 0.5032 - val_f1_m: 0.8661\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5503 - f1_m: 0.7787 - val_loss: 0.4726 - val_f1_m: 0.8527\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5354 - f1_m: 0.7787 - val_loss: 0.4515 - val_f1_m: 0.8393\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5242 - f1_m: 0.7787 - val_loss: 0.4384 - val_f1_m: 0.8527\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5127 - f1_m: 0.7787 - val_loss: 0.4262 - val_f1_m: 0.8527\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4995 - f1_m: 0.7787 - val_loss: 0.4131 - val_f1_m: 0.8661\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4853 - f1_m: 0.7787 - val_loss: 0.3987 - val_f1_m: 0.8661\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4697 - f1_m: 0.7787 - val_loss: 0.3838 - val_f1_m: 0.8661\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4511 - f1_m: 0.7787 - val_loss: 0.3644 - val_f1_m: 0.8527\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4299 - f1_m: 0.7787 - val_loss: 0.3501 - val_f1_m: 0.8527\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4067 - f1_m: 0.7787 - val_loss: 0.3283 - val_f1_m: 0.8661\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3802 - f1_m: 0.7787 - val_loss: 0.3059 - val_f1_m: 0.8661\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3540 - f1_m: 0.7787 - val_loss: 0.2819 - val_f1_m: 0.8527\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3236 - f1_m: 0.7787 - val_loss: 0.2597 - val_f1_m: 0.8393\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2952 - f1_m: 0.8125 - val_loss: 0.2408 - val_f1_m: 0.8616\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2681 - f1_m: 0.8925 - val_loss: 0.2212 - val_f1_m: 0.9062\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2430 - f1_m: 0.9112 - val_loss: 0.2058 - val_f1_m: 0.9241\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2222 - f1_m: 0.9262 - val_loss: 0.1917 - val_f1_m: 0.9241\n",
      "0.9262499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 674us/sample - loss: 0.6575 - f1_m: 0.7862 - val_loss: 0.6222 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6101 - f1_m: 0.7862 - val_loss: 0.5692 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5706 - f1_m: 0.7862 - val_loss: 0.5254 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5438 - f1_m: 0.7862 - val_loss: 0.4998 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5272 - f1_m: 0.7862 - val_loss: 0.4844 - val_f1_m: 0.8259\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5162 - f1_m: 0.7862 - val_loss: 0.4711 - val_f1_m: 0.8259\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5053 - f1_m: 0.7862 - val_loss: 0.4586 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4922 - f1_m: 0.7862 - val_loss: 0.4451 - val_f1_m: 0.8393\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4781 - f1_m: 0.7862 - val_loss: 0.4291 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4625 - f1_m: 0.7862 - val_loss: 0.4134 - val_f1_m: 0.8393\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4452 - f1_m: 0.7862 - val_loss: 0.3964 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4248 - f1_m: 0.7862 - val_loss: 0.3730 - val_f1_m: 0.8259\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4034 - f1_m: 0.7862 - val_loss: 0.3510 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3791 - f1_m: 0.7862 - val_loss: 0.3263 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3538 - f1_m: 0.7862 - val_loss: 0.3035 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3269 - f1_m: 0.7862 - val_loss: 0.2770 - val_f1_m: 0.8393\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3012 - f1_m: 0.7875 - val_loss: 0.2518 - val_f1_m: 0.8661\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2763 - f1_m: 0.8525 - val_loss: 0.2359 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2526 - f1_m: 0.8887 - val_loss: 0.2119 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2329 - f1_m: 0.8987 - val_loss: 0.2034 - val_f1_m: 0.9509\n",
      "0.89874995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 674us/sample - loss: 0.6566 - f1_m: 0.7987 - val_loss: 0.6357 - val_f1_m: 0.7545\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6073 - f1_m: 0.7987 - val_loss: 0.5947 - val_f1_m: 0.7545\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5620 - f1_m: 0.7987 - val_loss: 0.5637 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5303 - f1_m: 0.7987 - val_loss: 0.5471 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5119 - f1_m: 0.7987 - val_loss: 0.5379 - val_f1_m: 0.7411\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5003 - f1_m: 0.7987 - val_loss: 0.5302 - val_f1_m: 0.7545\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4905 - f1_m: 0.7987 - val_loss: 0.5199 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4790 - f1_m: 0.7987 - val_loss: 0.5075 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4650 - f1_m: 0.7987 - val_loss: 0.4936 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4509 - f1_m: 0.7987 - val_loss: 0.4793 - val_f1_m: 0.7545\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4361 - f1_m: 0.7987 - val_loss: 0.4615 - val_f1_m: 0.7545\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4187 - f1_m: 0.7987 - val_loss: 0.4426 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3991 - f1_m: 0.7987 - val_loss: 0.4212 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3776 - f1_m: 0.7987 - val_loss: 0.3969 - val_f1_m: 0.7545\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.3546 - f1_m: 0.7987 - val_loss: 0.3723 - val_f1_m: 0.7679\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3297 - f1_m: 0.7987 - val_loss: 0.3466 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3053 - f1_m: 0.7987 - val_loss: 0.3169 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2804 - f1_m: 0.8100 - val_loss: 0.2911 - val_f1_m: 0.8259\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2580 - f1_m: 0.8800 - val_loss: 0.2653 - val_f1_m: 0.8795\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2379 - f1_m: 0.8962 - val_loss: 0.2468 - val_f1_m: 0.8661\n",
      "0.89624995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 697us/sample - loss: 0.6555 - f1_m: 0.8050 - val_loss: 0.6424 - val_f1_m: 0.7143\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6008 - f1_m: 0.8062 - val_loss: 0.6078 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5536 - f1_m: 0.8062 - val_loss: 0.5849 - val_f1_m: 0.7411\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5217 - f1_m: 0.8062 - val_loss: 0.5769 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5029 - f1_m: 0.8062 - val_loss: 0.5718 - val_f1_m: 0.7411\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4913 - f1_m: 0.8062 - val_loss: 0.5689 - val_f1_m: 0.7143\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4825 - f1_m: 0.8062 - val_loss: 0.5583 - val_f1_m: 0.7277\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4722 - f1_m: 0.8062 - val_loss: 0.5476 - val_f1_m: 0.7545\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4604 - f1_m: 0.8062 - val_loss: 0.5363 - val_f1_m: 0.7545\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4473 - f1_m: 0.8062 - val_loss: 0.5170 - val_f1_m: 0.7277\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4325 - f1_m: 0.8062 - val_loss: 0.4997 - val_f1_m: 0.7277\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4153 - f1_m: 0.8062 - val_loss: 0.4803 - val_f1_m: 0.7277\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3967 - f1_m: 0.8062 - val_loss: 0.4581 - val_f1_m: 0.7277\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3754 - f1_m: 0.8062 - val_loss: 0.4329 - val_f1_m: 0.7545\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3525 - f1_m: 0.8062 - val_loss: 0.4032 - val_f1_m: 0.7545\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3279 - f1_m: 0.8062 - val_loss: 0.3745 - val_f1_m: 0.7545\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3025 - f1_m: 0.8062 - val_loss: 0.3399 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2774 - f1_m: 0.8062 - val_loss: 0.3112 - val_f1_m: 0.7054\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2539 - f1_m: 0.8750 - val_loss: 0.2856 - val_f1_m: 0.8661\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2322 - f1_m: 0.8937 - val_loss: 0.2581 - val_f1_m: 0.8929\n",
      "0.89374995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 674us/sample - loss: 0.6584 - f1_m: 0.7900 - val_loss: 0.6285 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6105 - f1_m: 0.7900 - val_loss: 0.5792 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5684 - f1_m: 0.7900 - val_loss: 0.5396 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5414 - f1_m: 0.7900 - val_loss: 0.5134 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5236 - f1_m: 0.7900 - val_loss: 0.4983 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.5914 - f1_m: 0.71 - 0s 61us/sample - loss: 0.5108 - f1_m: 0.7900 - val_loss: 0.4851 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4985 - f1_m: 0.7900 - val_loss: 0.4727 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4841 - f1_m: 0.7900 - val_loss: 0.4583 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4697 - f1_m: 0.7900 - val_loss: 0.4427 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4537 - f1_m: 0.7900 - val_loss: 0.4259 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4353 - f1_m: 0.7900 - val_loss: 0.4077 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4154 - f1_m: 0.7900 - val_loss: 0.3889 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3932 - f1_m: 0.7900 - val_loss: 0.3640 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.3684 - f1_m: 0.7900 - val_loss: 0.3398 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3431 - f1_m: 0.7900 - val_loss: 0.3150 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3164 - f1_m: 0.7900 - val_loss: 0.2879 - val_f1_m: 0.8125\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2931 - f1_m: 0.8062 - val_loss: 0.2682 - val_f1_m: 0.8973\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2660 - f1_m: 0.8887 - val_loss: 0.2423 - val_f1_m: 0.9196\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2422 - f1_m: 0.9087 - val_loss: 0.2230 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2226 - f1_m: 0.9187 - val_loss: 0.2057 - val_f1_m: 0.9286\n",
      "0.9187499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 686us/sample - loss: 0.6572 - f1_m: 0.7962 - val_loss: 0.6352 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6057 - f1_m: 0.7962 - val_loss: 0.5918 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5626 - f1_m: 0.7962 - val_loss: 0.5593 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5347 - f1_m: 0.7962 - val_loss: 0.5411 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5184 - f1_m: 0.7962 - val_loss: 0.5301 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5082 - f1_m: 0.7962 - val_loss: 0.5208 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4989 - f1_m: 0.7962 - val_loss: 0.5103 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4888 - f1_m: 0.7962 - val_loss: 0.4988 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4767 - f1_m: 0.7962 - val_loss: 0.4851 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4631 - f1_m: 0.7962 - val_loss: 0.4704 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4491 - f1_m: 0.7962 - val_loss: 0.4546 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4329 - f1_m: 0.7962 - val_loss: 0.4356 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4146 - f1_m: 0.7962 - val_loss: 0.4142 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3948 - f1_m: 0.7962 - val_loss: 0.3901 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3715 - f1_m: 0.7962 - val_loss: 0.3642 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3472 - f1_m: 0.7962 - val_loss: 0.3357 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3214 - f1_m: 0.7962 - val_loss: 0.3074 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2963 - f1_m: 0.7962 - val_loss: 0.2783 - val_f1_m: 0.7500\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2717 - f1_m: 0.8137 - val_loss: 0.2516 - val_f1_m: 0.8929\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2499 - f1_m: 0.8912 - val_loss: 0.2276 - val_f1_m: 0.9152\n",
      "0.8912499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 694us/sample - loss: 0.6585 - f1_m: 0.7975 - val_loss: 0.6375 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6070 - f1_m: 0.7975 - val_loss: 0.5964 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5641 - f1_m: 0.7975 - val_loss: 0.5659 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5343 - f1_m: 0.7975 - val_loss: 0.5503 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5164 - f1_m: 0.7975 - val_loss: 0.5406 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5055 - f1_m: 0.7975 - val_loss: 0.5320 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4954 - f1_m: 0.7975 - val_loss: 0.5209 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4840 - f1_m: 0.7975 - val_loss: 0.5079 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4711 - f1_m: 0.7975 - val_loss: 0.4919 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4566 - f1_m: 0.7975 - val_loss: 0.4755 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4404 - f1_m: 0.7975 - val_loss: 0.4579 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4231 - f1_m: 0.7975 - val_loss: 0.4381 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4023 - f1_m: 0.7975 - val_loss: 0.4131 - val_f1_m: 0.7589\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3795 - f1_m: 0.7975 - val_loss: 0.3884 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3540 - f1_m: 0.7975 - val_loss: 0.3594 - val_f1_m: 0.7455\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3273 - f1_m: 0.7975 - val_loss: 0.3301 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2999 - f1_m: 0.7975 - val_loss: 0.2999 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2730 - f1_m: 0.8337 - val_loss: 0.2726 - val_f1_m: 0.8750\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2477 - f1_m: 0.8825 - val_loss: 0.2474 - val_f1_m: 0.9196\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2245 - f1_m: 0.9062 - val_loss: 0.2271 - val_f1_m: 0.8973\n",
      "0.90624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 676us/sample - loss: 0.6568 - f1_m: 0.8000 - val_loss: 0.6398 - val_f1_m: 0.7500\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6051 - f1_m: 0.8000 - val_loss: 0.6009 - val_f1_m: 0.7634\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5604 - f1_m: 0.8000 - val_loss: 0.5717 - val_f1_m: 0.7366\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5289 - f1_m: 0.8000 - val_loss: 0.5571 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5122 - f1_m: 0.8000 - val_loss: 0.5488 - val_f1_m: 0.7634\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5007 - f1_m: 0.8000 - val_loss: 0.5392 - val_f1_m: 0.7500\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4916 - f1_m: 0.8000 - val_loss: 0.5297 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4803 - f1_m: 0.8000 - val_loss: 0.5170 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4674 - f1_m: 0.8000 - val_loss: 0.5014 - val_f1_m: 0.7500\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4535 - f1_m: 0.8000 - val_loss: 0.4856 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4373 - f1_m: 0.8000 - val_loss: 0.4681 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4197 - f1_m: 0.8000 - val_loss: 0.4475 - val_f1_m: 0.7500\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4000 - f1_m: 0.8000 - val_loss: 0.4248 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3781 - f1_m: 0.8000 - val_loss: 0.3978 - val_f1_m: 0.7500\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3544 - f1_m: 0.8000 - val_loss: 0.3703 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3300 - f1_m: 0.8000 - val_loss: 0.3404 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3056 - f1_m: 0.8000 - val_loss: 0.3129 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2803 - f1_m: 0.8125 - val_loss: 0.2873 - val_f1_m: 0.8304\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2583 - f1_m: 0.8650 - val_loss: 0.2611 - val_f1_m: 0.8973\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2392 - f1_m: 0.8937 - val_loss: 0.2428 - val_f1_m: 0.8884\n",
      "0.89374995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 672us/sample - loss: 0.6594 - f1_m: 0.7950 - val_loss: 0.6351 - val_f1_m: 0.7500\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6094 - f1_m: 0.7962 - val_loss: 0.5919 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5663 - f1_m: 0.7962 - val_loss: 0.5586 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5376 - f1_m: 0.7962 - val_loss: 0.5397 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5209 - f1_m: 0.7962 - val_loss: 0.5289 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5101 - f1_m: 0.7962 - val_loss: 0.5203 - val_f1_m: 0.7500\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5012 - f1_m: 0.7962 - val_loss: 0.5111 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4908 - f1_m: 0.7962 - val_loss: 0.5005 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4792 - f1_m: 0.7962 - val_loss: 0.4877 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4660 - f1_m: 0.7962 - val_loss: 0.4749 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3725 - f1_m: 0.87 - 0s 60us/sample - loss: 0.4521 - f1_m: 0.7962 - val_loss: 0.4603 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4365 - f1_m: 0.7962 - val_loss: 0.4408 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4174 - f1_m: 0.7962 - val_loss: 0.4201 - val_f1_m: 0.7768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3970 - f1_m: 0.7962 - val_loss: 0.3963 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3747 - f1_m: 0.7962 - val_loss: 0.3710 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3500 - f1_m: 0.7962 - val_loss: 0.3440 - val_f1_m: 0.7500\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3242 - f1_m: 0.7962 - val_loss: 0.3164 - val_f1_m: 0.7500\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2993 - f1_m: 0.7962 - val_loss: 0.2878 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2751 - f1_m: 0.8400 - val_loss: 0.2650 - val_f1_m: 0.8929\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2536 - f1_m: 0.8737 - val_loss: 0.2405 - val_f1_m: 0.9241\n",
      "0.8737499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 680us/sample - loss: 0.6573 - f1_m: 0.7962 - val_loss: 0.6346 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6061 - f1_m: 0.7962 - val_loss: 0.5916 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5625 - f1_m: 0.7962 - val_loss: 0.5586 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5332 - f1_m: 0.7962 - val_loss: 0.5402 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5166 - f1_m: 0.7962 - val_loss: 0.5289 - val_f1_m: 0.7634\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5074 - f1_m: 0.7962 - val_loss: 0.5209 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4973 - f1_m: 0.7962 - val_loss: 0.5109 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.4864 - f1_m: 0.7962 - val_loss: 0.4982 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4736 - f1_m: 0.7962 - val_loss: 0.4851 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4602 - f1_m: 0.7962 - val_loss: 0.4711 - val_f1_m: 0.7500\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4455 - f1_m: 0.7962 - val_loss: 0.4554 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4288 - f1_m: 0.7962 - val_loss: 0.4364 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4098 - f1_m: 0.7962 - val_loss: 0.4154 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3883 - f1_m: 0.7962 - val_loss: 0.3932 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3660 - f1_m: 0.7962 - val_loss: 0.3678 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3424 - f1_m: 0.7962 - val_loss: 0.3427 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3166 - f1_m: 0.7962 - val_loss: 0.3166 - val_f1_m: 0.7634\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2915 - f1_m: 0.7850 - val_loss: 0.2930 - val_f1_m: 0.7187\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2686 - f1_m: 0.8362 - val_loss: 0.2708 - val_f1_m: 0.8884\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2495 - f1_m: 0.8887 - val_loss: 0.2513 - val_f1_m: 0.9062\n",
      "0.8887499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 675us/sample - loss: 0.6587 - f1_m: 0.7925 - val_loss: 0.6311 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.6098 - f1_m: 0.7925 - val_loss: 0.5832 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.5676 - f1_m: 0.7925 - val_loss: 0.5469 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.5376 - f1_m: 0.7925 - val_loss: 0.5249 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.5210 - f1_m: 0.7925 - val_loss: 0.5105 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5094 - f1_m: 0.7925 - val_loss: 0.4994 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4991 - f1_m: 0.7925 - val_loss: 0.4881 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4853 - f1_m: 0.7925 - val_loss: 0.4752 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4712 - f1_m: 0.7925 - val_loss: 0.4601 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4538 - f1_m: 0.7925 - val_loss: 0.4406 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4326 - f1_m: 0.7925 - val_loss: 0.4183 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4073 - f1_m: 0.7925 - val_loss: 0.3912 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3791 - f1_m: 0.7925 - val_loss: 0.3616 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3488 - f1_m: 0.7925 - val_loss: 0.3298 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3170 - f1_m: 0.7925 - val_loss: 0.2982 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2849 - f1_m: 0.7925 - val_loss: 0.2660 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2558 - f1_m: 0.8825 - val_loss: 0.2365 - val_f1_m: 0.9062\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2306 - f1_m: 0.9212 - val_loss: 0.2110 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2095 - f1_m: 0.9225 - val_loss: 0.1905 - val_f1_m: 0.9375\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1938 - f1_m: 0.9250 - val_loss: 0.1748 - val_f1_m: 0.9107\n",
      "0.925\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 762us/sample - loss: 0.6581 - f1_m: 0.7937 - val_loss: 0.6329 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.6072 - f1_m: 0.7937 - val_loss: 0.5867 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5640 - f1_m: 0.7937 - val_loss: 0.5514 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5353 - f1_m: 0.7937 - val_loss: 0.5310 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5191 - f1_m: 0.7937 - val_loss: 0.5184 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5075 - f1_m: 0.7937 - val_loss: 0.5072 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4972 - f1_m: 0.7937 - val_loss: 0.4953 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4849 - f1_m: 0.7937 - val_loss: 0.4818 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4706 - f1_m: 0.7937 - val_loss: 0.4665 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4555 - f1_m: 0.7937 - val_loss: 0.4494 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4393 - f1_m: 0.7937 - val_loss: 0.4305 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4209 - f1_m: 0.7937 - val_loss: 0.4090 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3989 - f1_m: 0.7937 - val_loss: 0.3880 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3757 - f1_m: 0.7937 - val_loss: 0.3593 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3502 - f1_m: 0.7937 - val_loss: 0.3319 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.3224 - f1_m: 0.7937 - val_loss: 0.3045 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.2950 - f1_m: 0.7937 - val_loss: 0.2738 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.2694 - f1_m: 0.8437 - val_loss: 0.2478 - val_f1_m: 0.8973\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.2453 - f1_m: 0.8837 - val_loss: 0.2207 - val_f1_m: 0.8973\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.2241 - f1_m: 0.9275 - val_loss: 0.1997 - val_f1_m: 0.9420\n",
      "0.9275\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 737us/sample - loss: 0.6591 - f1_m: 0.7925 - val_loss: 0.6317 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.6112 - f1_m: 0.7925 - val_loss: 0.5860 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5695 - f1_m: 0.7925 - val_loss: 0.5504 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.5389 - f1_m: 0.7925 - val_loss: 0.5261 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.5182 - f1_m: 0.7925 - val_loss: 0.5105 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.5031 - f1_m: 0.7925 - val_loss: 0.4974 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.4883 - f1_m: 0.7925 - val_loss: 0.4831 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4713 - f1_m: 0.7925 - val_loss: 0.4675 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.4527 - f1_m: 0.7925 - val_loss: 0.4480 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4291 - f1_m: 0.7925 - val_loss: 0.4279 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4060 - f1_m: 0.7925 - val_loss: 0.4048 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3815 - f1_m: 0.7925 - val_loss: 0.3836 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3551 - f1_m: 0.7925 - val_loss: 0.3589 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3268 - f1_m: 0.7925 - val_loss: 0.3345 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2974 - f1_m: 0.7925 - val_loss: 0.3086 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2685 - f1_m: 0.8600 - val_loss: 0.2843 - val_f1_m: 0.8482\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2410 - f1_m: 0.9012 - val_loss: 0.2640 - val_f1_m: 0.8482\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2181 - f1_m: 0.9100 - val_loss: 0.2458 - val_f1_m: 0.8839\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1994 - f1_m: 0.9337 - val_loss: 0.2332 - val_f1_m: 0.8973\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.1858 - f1_m: 0.9300 - val_loss: 0.2223 - val_f1_m: 0.8973\n",
      "0.92999995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 724us/sample - loss: 0.6590 - f1_m: 0.7950 - val_loss: 0.6348 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6098 - f1_m: 0.7962 - val_loss: 0.5904 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.5654 - f1_m: 0.7962 - val_loss: 0.5584 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.5354 - f1_m: 0.7962 - val_loss: 0.5390 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.5168 - f1_m: 0.7962 - val_loss: 0.5269 - val_f1_m: 0.7366\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.5042 - f1_m: 0.7962 - val_loss: 0.5171 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.4922 - f1_m: 0.7962 - val_loss: 0.5061 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4796 - f1_m: 0.7962 - val_loss: 0.4934 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4660 - f1_m: 0.7962 - val_loss: 0.4803 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4499 - f1_m: 0.7962 - val_loss: 0.4642 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4324 - f1_m: 0.7962 - val_loss: 0.4466 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4131 - f1_m: 0.7962 - val_loss: 0.4271 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.3913 - f1_m: 0.7962 - val_loss: 0.4054 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.3675 - f1_m: 0.7962 - val_loss: 0.3826 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3429 - f1_m: 0.7962 - val_loss: 0.3572 - val_f1_m: 0.7366\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3154 - f1_m: 0.7962 - val_loss: 0.3326 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2892 - f1_m: 0.7962 - val_loss: 0.3088 - val_f1_m: 0.7411\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2647 - f1_m: 0.8875 - val_loss: 0.2886 - val_f1_m: 0.8393\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2420 - f1_m: 0.8850 - val_loss: 0.2692 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.2204 - f1_m: 0.9100 - val_loss: 0.2527 - val_f1_m: 0.8973\n",
      "0.9099999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 756us/sample - loss: 0.6569 - f1_m: 0.7900 - val_loss: 0.6279 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.6093 - f1_m: 0.7900 - val_loss: 0.5779 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5659 - f1_m: 0.7900 - val_loss: 0.5401 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5372 - f1_m: 0.7900 - val_loss: 0.5148 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5214 - f1_m: 0.7900 - val_loss: 0.4994 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5096 - f1_m: 0.7900 - val_loss: 0.4871 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4986 - f1_m: 0.7900 - val_loss: 0.4743 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4865 - f1_m: 0.7900 - val_loss: 0.4606 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4716 - f1_m: 0.7900 - val_loss: 0.4455 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4559 - f1_m: 0.7900 - val_loss: 0.4259 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4357 - f1_m: 0.7900 - val_loss: 0.4025 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4118 - f1_m: 0.7900 - val_loss: 0.3758 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3846 - f1_m: 0.7900 - val_loss: 0.3473 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3560 - f1_m: 0.7900 - val_loss: 0.3151 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3245 - f1_m: 0.7900 - val_loss: 0.2865 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2949 - f1_m: 0.7900 - val_loss: 0.2524 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2671 - f1_m: 0.8787 - val_loss: 0.2236 - val_f1_m: 0.9375\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.2405 - f1_m: 0.9050 - val_loss: 0.1985 - val_f1_m: 0.9375\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.2190 - f1_m: 0.9250 - val_loss: 0.1776 - val_f1_m: 0.9554\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.2015 - f1_m: 0.9275 - val_loss: 0.1638 - val_f1_m: 0.9643\n",
      "0.9275\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 728us/sample - loss: 0.6562 - f1_m: 0.7975 - val_loss: 0.6349 - val_f1_m: 0.7723\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.6071 - f1_m: 0.7975 - val_loss: 0.5922 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 0.5636 - f1_m: 0.7975 - val_loss: 0.5621 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.5355 - f1_m: 0.7975 - val_loss: 0.5440 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5177 - f1_m: 0.7975 - val_loss: 0.5329 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5067 - f1_m: 0.7975 - val_loss: 0.5242 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4957 - f1_m: 0.7975 - val_loss: 0.5126 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4829 - f1_m: 0.7975 - val_loss: 0.4966 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4669 - f1_m: 0.7975 - val_loss: 0.4799 - val_f1_m: 0.7589\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.4488 - f1_m: 0.7975 - val_loss: 0.4602 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4295 - f1_m: 0.7975 - val_loss: 0.4384 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4077 - f1_m: 0.7975 - val_loss: 0.4152 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.3831 - f1_m: 0.7975 - val_loss: 0.3865 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.3557 - f1_m: 0.7975 - val_loss: 0.3555 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3271 - f1_m: 0.7975 - val_loss: 0.3243 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.3002 - f1_m: 0.7975 - val_loss: 0.2921 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.2719 - f1_m: 0.8287 - val_loss: 0.2652 - val_f1_m: 0.9062\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.2497 - f1_m: 0.8863 - val_loss: 0.2397 - val_f1_m: 0.8750\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2286 - f1_m: 0.9012 - val_loss: 0.2194 - val_f1_m: 0.9330\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.2121 - f1_m: 0.9175 - val_loss: 0.2036 - val_f1_m: 0.9062\n",
      "0.9174999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 721us/sample - loss: 0.6580 - f1_m: 0.7812 - val_loss: 0.6197 - val_f1_m: 0.8437\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.6128 - f1_m: 0.7812 - val_loss: 0.5645 - val_f1_m: 0.8437\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.5772 - f1_m: 0.7812 - val_loss: 0.5202 - val_f1_m: 0.8571\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.5536 - f1_m: 0.7812 - val_loss: 0.4912 - val_f1_m: 0.8437\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.5396 - f1_m: 0.7812 - val_loss: 0.4738 - val_f1_m: 0.8571\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.5302 - f1_m: 0.7812 - val_loss: 0.4619 - val_f1_m: 0.8304\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.5230 - f1_m: 0.7812 - val_loss: 0.4502 - val_f1_m: 0.8571\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.5155 - f1_m: 0.7812 - val_loss: 0.4407 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5066 - f1_m: 0.7812 - val_loss: 0.4330 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.4973 - f1_m: 0.7812 - val_loss: 0.4216 - val_f1_m: 0.8571\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4869 - f1_m: 0.7812 - val_loss: 0.4107 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4749 - f1_m: 0.7812 - val_loss: 0.3968 - val_f1_m: 0.8437\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.4608 - f1_m: 0.7812 - val_loss: 0.3828 - val_f1_m: 0.8571\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.4447 - f1_m: 0.7812 - val_loss: 0.3668 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.4269 - f1_m: 0.7812 - val_loss: 0.3486 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.4061 - f1_m: 0.7812 - val_loss: 0.3294 - val_f1_m: 0.8437\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.3838 - f1_m: 0.7812 - val_loss: 0.3067 - val_f1_m: 0.8571\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.3617 - f1_m: 0.7812 - val_loss: 0.2843 - val_f1_m: 0.8571\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.3374 - f1_m: 0.7812 - val_loss: 0.2630 - val_f1_m: 0.8437\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.3125 - f1_m: 0.7775 - val_loss: 0.2408 - val_f1_m: 0.8170\n",
      "0.7774999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 674us/sample - loss: 0.6573 - f1_m: 0.7910 - val_loss: 0.6283 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6077 - f1_m: 0.7925 - val_loss: 0.5798 - val_f1_m: 0.7634\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5645 - f1_m: 0.7925 - val_loss: 0.5431 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5360 - f1_m: 0.7925 - val_loss: 0.5217 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5212 - f1_m: 0.7925 - val_loss: 0.5085 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5106 - f1_m: 0.7925 - val_loss: 0.4986 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.4996 - f1_m: 0.7925 - val_loss: 0.4877 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4890 - f1_m: 0.7925 - val_loss: 0.4765 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4759 - f1_m: 0.7925 - val_loss: 0.4627 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4612 - f1_m: 0.7925 - val_loss: 0.4475 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4455 - f1_m: 0.7925 - val_loss: 0.4306 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4280 - f1_m: 0.7925 - val_loss: 0.4107 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4067 - f1_m: 0.7925 - val_loss: 0.3894 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3834 - f1_m: 0.7925 - val_loss: 0.3654 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3580 - f1_m: 0.7925 - val_loss: 0.3381 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3318 - f1_m: 0.7925 - val_loss: 0.3136 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3045 - f1_m: 0.7925 - val_loss: 0.2828 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2772 - f1_m: 0.8175 - val_loss: 0.2583 - val_f1_m: 0.9018\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2537 - f1_m: 0.8987 - val_loss: 0.2324 - val_f1_m: 0.9196\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2312 - f1_m: 0.9012 - val_loss: 0.2176 - val_f1_m: 0.9330\n",
      "0.90124995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 666us/sample - loss: 0.6592 - f1_m: 0.7912 - val_loss: 0.6310 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6087 - f1_m: 0.7912 - val_loss: 0.5837 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5644 - f1_m: 0.7912 - val_loss: 0.5454 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5362 - f1_m: 0.7912 - val_loss: 0.5225 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5197 - f1_m: 0.7912 - val_loss: 0.5096 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5084 - f1_m: 0.7912 - val_loss: 0.4988 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4973 - f1_m: 0.7912 - val_loss: 0.4866 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4829 - f1_m: 0.7912 - val_loss: 0.4690 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4639 - f1_m: 0.7912 - val_loss: 0.4506 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4437 - f1_m: 0.7912 - val_loss: 0.4307 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4208 - f1_m: 0.7912 - val_loss: 0.4075 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3941 - f1_m: 0.7912 - val_loss: 0.3819 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3642 - f1_m: 0.7912 - val_loss: 0.3552 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3312 - f1_m: 0.7912 - val_loss: 0.3239 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2981 - f1_m: 0.7912 - val_loss: 0.2942 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2654 - f1_m: 0.8437 - val_loss: 0.2683 - val_f1_m: 0.8973\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2358 - f1_m: 0.9175 - val_loss: 0.2446 - val_f1_m: 0.8527\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2092 - f1_m: 0.9375 - val_loss: 0.2254 - val_f1_m: 0.9196\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.1876 - f1_m: 0.9450 - val_loss: 0.2114 - val_f1_m: 0.9241\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1727 - f1_m: 0.9513 - val_loss: 0.2015 - val_f1_m: 0.9375\n",
      "0.95125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 666us/sample - loss: 0.6608 - f1_m: 0.7912 - val_loss: 0.6329 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6143 - f1_m: 0.7912 - val_loss: 0.5895 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5761 - f1_m: 0.7912 - val_loss: 0.5542 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5484 - f1_m: 0.7912 - val_loss: 0.5303 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5306 - f1_m: 0.7912 - val_loss: 0.5148 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5167 - f1_m: 0.7912 - val_loss: 0.5024 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5048 - f1_m: 0.7912 - val_loss: 0.4911 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4935 - f1_m: 0.7912 - val_loss: 0.4797 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4797 - f1_m: 0.7912 - val_loss: 0.4665 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4635 - f1_m: 0.7912 - val_loss: 0.4506 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4472 - f1_m: 0.7912 - val_loss: 0.4355 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4291 - f1_m: 0.7912 - val_loss: 0.4172 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4097 - f1_m: 0.7912 - val_loss: 0.3983 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3879 - f1_m: 0.7912 - val_loss: 0.3782 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3656 - f1_m: 0.7912 - val_loss: 0.3574 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3401 - f1_m: 0.7912 - val_loss: 0.3343 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3158 - f1_m: 0.7912 - val_loss: 0.3125 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2920 - f1_m: 0.8112 - val_loss: 0.2903 - val_f1_m: 0.8482\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2688 - f1_m: 0.8775 - val_loss: 0.2730 - val_f1_m: 0.8527\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2484 - f1_m: 0.8837 - val_loss: 0.2538 - val_f1_m: 0.8750\n",
      "0.8837499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 690us/sample - loss: 0.6548 - f1_m: 0.8037 - val_loss: 0.6409 - val_f1_m: 0.7366\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.6033 - f1_m: 0.8037 - val_loss: 0.6048 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5565 - f1_m: 0.8037 - val_loss: 0.5808 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5263 - f1_m: 0.8037 - val_loss: 0.5699 - val_f1_m: 0.7500\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5073 - f1_m: 0.8037 - val_loss: 0.5645 - val_f1_m: 0.7500\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4961 - f1_m: 0.8037 - val_loss: 0.5578 - val_f1_m: 0.7500\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4869 - f1_m: 0.8037 - val_loss: 0.5499 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4764 - f1_m: 0.8037 - val_loss: 0.5353 - val_f1_m: 0.7500\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4645 - f1_m: 0.8037 - val_loss: 0.5231 - val_f1_m: 0.7500\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4505 - f1_m: 0.8037 - val_loss: 0.5058 - val_f1_m: 0.7634\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4350 - f1_m: 0.8037 - val_loss: 0.4881 - val_f1_m: 0.6964\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4178 - f1_m: 0.8037 - val_loss: 0.4688 - val_f1_m: 0.7500\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3991 - f1_m: 0.8037 - val_loss: 0.4455 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3779 - f1_m: 0.8037 - val_loss: 0.4187 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3544 - f1_m: 0.8037 - val_loss: 0.3911 - val_f1_m: 0.7366\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3299 - f1_m: 0.8037 - val_loss: 0.3605 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3044 - f1_m: 0.8037 - val_loss: 0.3325 - val_f1_m: 0.7500\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2801 - f1_m: 0.8125 - val_loss: 0.3007 - val_f1_m: 0.8304\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2572 - f1_m: 0.8800 - val_loss: 0.2739 - val_f1_m: 0.8661\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2357 - f1_m: 0.8925 - val_loss: 0.2526 - val_f1_m: 0.9152\n",
      "0.8924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 677us/sample - loss: 0.6576 - f1_m: 0.7887 - val_loss: 0.6259 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6102 - f1_m: 0.7887 - val_loss: 0.5760 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5698 - f1_m: 0.7887 - val_loss: 0.5351 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5403 - f1_m: 0.7887 - val_loss: 0.5074 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5204 - f1_m: 0.7887 - val_loss: 0.4871 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5040 - f1_m: 0.7887 - val_loss: 0.4708 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4885 - f1_m: 0.7887 - val_loss: 0.4543 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.4711 - f1_m: 0.7887 - val_loss: 0.4373 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4501 - f1_m: 0.7887 - val_loss: 0.4165 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4271 - f1_m: 0.7887 - val_loss: 0.3951 - val_f1_m: 0.8036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4029 - f1_m: 0.7887 - val_loss: 0.3708 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3770 - f1_m: 0.7887 - val_loss: 0.3459 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3497 - f1_m: 0.7887 - val_loss: 0.3196 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3214 - f1_m: 0.7887 - val_loss: 0.2932 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2944 - f1_m: 0.8012 - val_loss: 0.2671 - val_f1_m: 0.8482\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2676 - f1_m: 0.8762 - val_loss: 0.2437 - val_f1_m: 0.8795\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.2444 - f1_m: 0.9025 - val_loss: 0.2225 - val_f1_m: 0.9062\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2239 - f1_m: 0.9112 - val_loss: 0.2062 - val_f1_m: 0.9196\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2084 - f1_m: 0.9300 - val_loss: 0.1907 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.1949 - f1_m: 0.9250 - val_loss: 0.1792 - val_f1_m: 0.9420\n",
      "0.925\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 792us/sample - loss: 0.6583 - f1_m: 0.7875 - val_loss: 0.6253 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.6098 - f1_m: 0.7887 - val_loss: 0.5719 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5684 - f1_m: 0.7887 - val_loss: 0.5313 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5415 - f1_m: 0.7887 - val_loss: 0.5070 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5271 - f1_m: 0.7887 - val_loss: 0.4915 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5159 - f1_m: 0.7887 - val_loss: 0.4837 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5042 - f1_m: 0.7887 - val_loss: 0.4712 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4911 - f1_m: 0.7887 - val_loss: 0.4556 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4728 - f1_m: 0.7887 - val_loss: 0.4352 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4518 - f1_m: 0.7887 - val_loss: 0.4137 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4287 - f1_m: 0.7887 - val_loss: 0.3899 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4030 - f1_m: 0.7887 - val_loss: 0.3647 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3760 - f1_m: 0.7887 - val_loss: 0.3389 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3467 - f1_m: 0.7887 - val_loss: 0.3093 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3153 - f1_m: 0.7887 - val_loss: 0.2810 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2863 - f1_m: 0.8237 - val_loss: 0.2544 - val_f1_m: 0.8661\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2582 - f1_m: 0.8925 - val_loss: 0.2295 - val_f1_m: 0.8973\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2342 - f1_m: 0.9137 - val_loss: 0.2089 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2138 - f1_m: 0.9250 - val_loss: 0.1915 - val_f1_m: 0.9509\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1982 - f1_m: 0.9262 - val_loss: 0.1799 - val_f1_m: 0.9554\n",
      "0.92625\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 671us/sample - loss: 0.6609 - f1_m: 0.7787 - val_loss: 0.6198 - val_f1_m: 0.8482\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6151 - f1_m: 0.7800 - val_loss: 0.5613 - val_f1_m: 0.8348\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5751 - f1_m: 0.7800 - val_loss: 0.5113 - val_f1_m: 0.8616\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5489 - f1_m: 0.7800 - val_loss: 0.4786 - val_f1_m: 0.8616\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5341 - f1_m: 0.7800 - val_loss: 0.4581 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5228 - f1_m: 0.7800 - val_loss: 0.4440 - val_f1_m: 0.8616\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5106 - f1_m: 0.7800 - val_loss: 0.4328 - val_f1_m: 0.8482\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4978 - f1_m: 0.7800 - val_loss: 0.4199 - val_f1_m: 0.8348\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4825 - f1_m: 0.7800 - val_loss: 0.4022 - val_f1_m: 0.8482\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4666 - f1_m: 0.7800 - val_loss: 0.3880 - val_f1_m: 0.8482\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4478 - f1_m: 0.7800 - val_loss: 0.3704 - val_f1_m: 0.8616\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4262 - f1_m: 0.7800 - val_loss: 0.3491 - val_f1_m: 0.8482\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4023 - f1_m: 0.7800 - val_loss: 0.3295 - val_f1_m: 0.8482\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3758 - f1_m: 0.7800 - val_loss: 0.3074 - val_f1_m: 0.8482\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3479 - f1_m: 0.7800 - val_loss: 0.2918 - val_f1_m: 0.8482\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3173 - f1_m: 0.7800 - val_loss: 0.2585 - val_f1_m: 0.8482\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2880 - f1_m: 0.8238 - val_loss: 0.2394 - val_f1_m: 0.9241\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2595 - f1_m: 0.8950 - val_loss: 0.2176 - val_f1_m: 0.9241\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2343 - f1_m: 0.9150 - val_loss: 0.1973 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2119 - f1_m: 0.9287 - val_loss: 0.1850 - val_f1_m: 0.9286\n",
      "0.9287499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 674us/sample - loss: 0.6574 - f1_m: 0.7987 - val_loss: 0.6396 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6071 - f1_m: 0.7987 - val_loss: 0.6017 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5646 - f1_m: 0.7987 - val_loss: 0.5727 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5335 - f1_m: 0.7987 - val_loss: 0.5537 - val_f1_m: 0.7545\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5111 - f1_m: 0.7987 - val_loss: 0.5407 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4958 - f1_m: 0.7987 - val_loss: 0.5276 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4808 - f1_m: 0.7987 - val_loss: 0.5115 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4638 - f1_m: 0.7987 - val_loss: 0.4923 - val_f1_m: 0.7411\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4449 - f1_m: 0.7987 - val_loss: 0.4698 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4229 - f1_m: 0.7987 - val_loss: 0.4457 - val_f1_m: 0.7679\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3992 - f1_m: 0.7987 - val_loss: 0.4195 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3741 - f1_m: 0.7987 - val_loss: 0.3900 - val_f1_m: 0.7545\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3489 - f1_m: 0.7987 - val_loss: 0.3611 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3194 - f1_m: 0.7987 - val_loss: 0.3331 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2910 - f1_m: 0.7987 - val_loss: 0.2955 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2626 - f1_m: 0.8712 - val_loss: 0.2667 - val_f1_m: 0.8393\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2372 - f1_m: 0.9025 - val_loss: 0.2400 - val_f1_m: 0.9152\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2150 - f1_m: 0.9100 - val_loss: 0.2181 - val_f1_m: 0.9330\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.1960 - f1_m: 0.9287 - val_loss: 0.1952 - val_f1_m: 0.9330\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.1820 - f1_m: 0.9375 - val_loss: 0.1840 - val_f1_m: 0.9330\n",
      "0.9375\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 670us/sample - loss: 0.6597 - f1_m: 0.7875 - val_loss: 0.6275 - val_f1_m: 0.8348\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6131 - f1_m: 0.7875 - val_loss: 0.5782 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5749 - f1_m: 0.7875 - val_loss: 0.5401 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5493 - f1_m: 0.7875 - val_loss: 0.5143 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5343 - f1_m: 0.7875 - val_loss: 0.4994 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5243 - f1_m: 0.7875 - val_loss: 0.4899 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5169 - f1_m: 0.7875 - val_loss: 0.4812 - val_f1_m: 0.8348\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5097 - f1_m: 0.7875 - val_loss: 0.4736 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5012 - f1_m: 0.7875 - val_loss: 0.4640 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4919 - f1_m: 0.7875 - val_loss: 0.4539 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4819 - f1_m: 0.7875 - val_loss: 0.4440 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4699 - f1_m: 0.7875 - val_loss: 0.4315 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.4566 - f1_m: 0.7875 - val_loss: 0.4172 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4413 - f1_m: 0.7875 - val_loss: 0.4015 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4235 - f1_m: 0.7875 - val_loss: 0.3839 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4036 - f1_m: 0.7875 - val_loss: 0.3641 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3821 - f1_m: 0.7875 - val_loss: 0.3427 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3589 - f1_m: 0.7875 - val_loss: 0.3201 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3350 - f1_m: 0.7875 - val_loss: 0.2965 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3106 - f1_m: 0.7862 - val_loss: 0.2743 - val_f1_m: 0.8170\n",
      "0.78624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 667us/sample - loss: 0.6573 - f1_m: 0.7950 - val_loss: 0.6320 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6077 - f1_m: 0.7950 - val_loss: 0.5869 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5636 - f1_m: 0.7950 - val_loss: 0.5519 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5346 - f1_m: 0.7950 - val_loss: 0.5311 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.5175 - f1_m: 0.7950 - val_loss: 0.5193 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5064 - f1_m: 0.7950 - val_loss: 0.5098 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4964 - f1_m: 0.7950 - val_loss: 0.4997 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4849 - f1_m: 0.7950 - val_loss: 0.4877 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4724 - f1_m: 0.7950 - val_loss: 0.4735 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4579 - f1_m: 0.7950 - val_loss: 0.4587 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4430 - f1_m: 0.7950 - val_loss: 0.4420 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4239 - f1_m: 0.7950 - val_loss: 0.4221 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4003 - f1_m: 0.7950 - val_loss: 0.3940 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3723 - f1_m: 0.7950 - val_loss: 0.3636 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3417 - f1_m: 0.7950 - val_loss: 0.3316 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3100 - f1_m: 0.7950 - val_loss: 0.2985 - val_f1_m: 0.7545\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2783 - f1_m: 0.8137 - val_loss: 0.2670 - val_f1_m: 0.8884\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2492 - f1_m: 0.8937 - val_loss: 0.2391 - val_f1_m: 0.9062\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2230 - f1_m: 0.9200 - val_loss: 0.2152 - val_f1_m: 0.9196\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2017 - f1_m: 0.9325 - val_loss: 0.1960 - val_f1_m: 0.9554\n",
      "0.93249995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 675us/sample - loss: 0.6564 - f1_m: 0.7937 - val_loss: 0.6326 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6067 - f1_m: 0.7937 - val_loss: 0.5873 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5633 - f1_m: 0.7937 - val_loss: 0.5544 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5358 - f1_m: 0.7937 - val_loss: 0.5338 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5185 - f1_m: 0.7937 - val_loss: 0.5210 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5069 - f1_m: 0.7937 - val_loss: 0.5105 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4960 - f1_m: 0.7937 - val_loss: 0.4979 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4833 - f1_m: 0.7937 - val_loss: 0.4839 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4688 - f1_m: 0.7937 - val_loss: 0.4684 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4534 - f1_m: 0.7937 - val_loss: 0.4533 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4363 - f1_m: 0.7937 - val_loss: 0.4346 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4176 - f1_m: 0.7937 - val_loss: 0.4149 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3961 - f1_m: 0.7937 - val_loss: 0.3928 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3725 - f1_m: 0.7937 - val_loss: 0.3683 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3485 - f1_m: 0.7937 - val_loss: 0.3437 - val_f1_m: 0.7589\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3214 - f1_m: 0.7937 - val_loss: 0.3160 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2962 - f1_m: 0.7937 - val_loss: 0.2914 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2713 - f1_m: 0.8462 - val_loss: 0.2680 - val_f1_m: 0.8705\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2487 - f1_m: 0.8988 - val_loss: 0.2495 - val_f1_m: 0.8616\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2276 - f1_m: 0.9137 - val_loss: 0.2302 - val_f1_m: 0.9286\n",
      "0.91374993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 690us/sample - loss: 0.6597 - f1_m: 0.7825 - val_loss: 0.6206 - val_f1_m: 0.8527\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6136 - f1_m: 0.7825 - val_loss: 0.5642 - val_f1_m: 0.8393\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5745 - f1_m: 0.7825 - val_loss: 0.5172 - val_f1_m: 0.8393\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5467 - f1_m: 0.7825 - val_loss: 0.4868 - val_f1_m: 0.8527\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5314 - f1_m: 0.7825 - val_loss: 0.4652 - val_f1_m: 0.8259\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5196 - f1_m: 0.7825 - val_loss: 0.4545 - val_f1_m: 0.8527\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5082 - f1_m: 0.7825 - val_loss: 0.4415 - val_f1_m: 0.8527\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4925 - f1_m: 0.7825 - val_loss: 0.4244 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4733 - f1_m: 0.7825 - val_loss: 0.4029 - val_f1_m: 0.8259\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4516 - f1_m: 0.7825 - val_loss: 0.3826 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4286 - f1_m: 0.7825 - val_loss: 0.3657 - val_f1_m: 0.8393\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4005 - f1_m: 0.7825 - val_loss: 0.3345 - val_f1_m: 0.8393\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3705 - f1_m: 0.7825 - val_loss: 0.3079 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3386 - f1_m: 0.7825 - val_loss: 0.2834 - val_f1_m: 0.8393\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3059 - f1_m: 0.7825 - val_loss: 0.2526 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2742 - f1_m: 0.8550 - val_loss: 0.2290 - val_f1_m: 0.9062\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2461 - f1_m: 0.9075 - val_loss: 0.2069 - val_f1_m: 0.9107\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2212 - f1_m: 0.9175 - val_loss: 0.1889 - val_f1_m: 0.9241\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2031 - f1_m: 0.9287 - val_loss: 0.1766 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1882 - f1_m: 0.9300 - val_loss: 0.1659 - val_f1_m: 0.9420\n",
      "0.92999995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 677us/sample - loss: 0.6562 - f1_m: 0.8025 - val_loss: 0.6413 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6045 - f1_m: 0.8025 - val_loss: 0.6039 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5581 - f1_m: 0.8025 - val_loss: 0.5781 - val_f1_m: 0.7545\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5256 - f1_m: 0.8025 - val_loss: 0.5671 - val_f1_m: 0.7545\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5088 - f1_m: 0.8025 - val_loss: 0.5602 - val_f1_m: 0.7143\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4964 - f1_m: 0.8025 - val_loss: 0.5506 - val_f1_m: 0.7411\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4858 - f1_m: 0.8025 - val_loss: 0.5424 - val_f1_m: 0.7411\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4741 - f1_m: 0.8025 - val_loss: 0.5253 - val_f1_m: 0.7411\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4567 - f1_m: 0.8025 - val_loss: 0.5046 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4377 - f1_m: 0.8025 - val_loss: 0.4835 - val_f1_m: 0.7277\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4156 - f1_m: 0.8025 - val_loss: 0.4580 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3912 - f1_m: 0.8025 - val_loss: 0.4289 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3652 - f1_m: 0.8025 - val_loss: 0.3958 - val_f1_m: 0.7545\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3359 - f1_m: 0.8025 - val_loss: 0.3613 - val_f1_m: 0.7411\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3068 - f1_m: 0.8025 - val_loss: 0.3270 - val_f1_m: 0.7545\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2787 - f1_m: 0.8025 - val_loss: 0.2988 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2506 - f1_m: 0.8637 - val_loss: 0.2585 - val_f1_m: 0.9018\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2262 - f1_m: 0.9025 - val_loss: 0.2327 - val_f1_m: 0.8973\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2059 - f1_m: 0.9300 - val_loss: 0.2092 - val_f1_m: 0.9241\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1900 - f1_m: 0.9312 - val_loss: 0.1864 - val_f1_m: 0.9598\n",
      "0.93125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 708us/sample - loss: 0.6594 - f1_m: 0.7875 - val_loss: 0.6281 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.6129 - f1_m: 0.7875 - val_loss: 0.5751 - val_f1_m: 0.8348\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5701 - f1_m: 0.7875 - val_loss: 0.5342 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5418 - f1_m: 0.7875 - val_loss: 0.5082 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5267 - f1_m: 0.7875 - val_loss: 0.4921 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5168 - f1_m: 0.7875 - val_loss: 0.4810 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5078 - f1_m: 0.7875 - val_loss: 0.4717 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4974 - f1_m: 0.7875 - val_loss: 0.4595 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4843 - f1_m: 0.7875 - val_loss: 0.4455 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4710 - f1_m: 0.7875 - val_loss: 0.4296 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4537 - f1_m: 0.7875 - val_loss: 0.4099 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4305 - f1_m: 0.7875 - val_loss: 0.3852 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4039 - f1_m: 0.7875 - val_loss: 0.3576 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3746 - f1_m: 0.7875 - val_loss: 0.3282 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3443 - f1_m: 0.7875 - val_loss: 0.2967 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3131 - f1_m: 0.7875 - val_loss: 0.2669 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2835 - f1_m: 0.8212 - val_loss: 0.2377 - val_f1_m: 0.9018\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2571 - f1_m: 0.8837 - val_loss: 0.2112 - val_f1_m: 0.9420\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2345 - f1_m: 0.9112 - val_loss: 0.1887 - val_f1_m: 0.9420\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2154 - f1_m: 0.9175 - val_loss: 0.1704 - val_f1_m: 0.9464\n",
      "0.9175\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 737us/sample - loss: 0.6606 - f1_m: 0.7850 - val_loss: 0.6243 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6137 - f1_m: 0.7850 - val_loss: 0.5699 - val_f1_m: 0.8437\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5723 - f1_m: 0.7850 - val_loss: 0.5274 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5460 - f1_m: 0.7850 - val_loss: 0.4988 - val_f1_m: 0.8437\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5302 - f1_m: 0.7850 - val_loss: 0.4839 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5191 - f1_m: 0.7850 - val_loss: 0.4708 - val_f1_m: 0.8304\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5093 - f1_m: 0.7850 - val_loss: 0.4607 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4968 - f1_m: 0.7850 - val_loss: 0.4468 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4826 - f1_m: 0.7850 - val_loss: 0.4343 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4674 - f1_m: 0.7850 - val_loss: 0.4180 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4467 - f1_m: 0.7850 - val_loss: 0.3975 - val_f1_m: 0.8304\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4220 - f1_m: 0.7850 - val_loss: 0.3765 - val_f1_m: 0.8304\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3954 - f1_m: 0.7850 - val_loss: 0.3533 - val_f1_m: 0.8437\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3656 - f1_m: 0.7850 - val_loss: 0.3289 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3333 - f1_m: 0.7850 - val_loss: 0.3041 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3036 - f1_m: 0.7850 - val_loss: 0.2831 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2742 - f1_m: 0.8612 - val_loss: 0.2605 - val_f1_m: 0.8259\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.2489 - f1_m: 0.9012 - val_loss: 0.2437 - val_f1_m: 0.8839\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2252 - f1_m: 0.9050 - val_loss: 0.2308 - val_f1_m: 0.8839\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2085 - f1_m: 0.9300 - val_loss: 0.2231 - val_f1_m: 0.8393\n",
      "0.93\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 681us/sample - loss: 0.6548 - f1_m: 0.7975 - val_loss: 0.6332 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6053 - f1_m: 0.7975 - val_loss: 0.5893 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5594 - f1_m: 0.7975 - val_loss: 0.5584 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5296 - f1_m: 0.7975 - val_loss: 0.5410 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5117 - f1_m: 0.7975 - val_loss: 0.5308 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4995 - f1_m: 0.7975 - val_loss: 0.5219 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4877 - f1_m: 0.7975 - val_loss: 0.5085 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4708 - f1_m: 0.7975 - val_loss: 0.4887 - val_f1_m: 0.7589\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4501 - f1_m: 0.7975 - val_loss: 0.4682 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4273 - f1_m: 0.7975 - val_loss: 0.4444 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4023 - f1_m: 0.7975 - val_loss: 0.4189 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3744 - f1_m: 0.7975 - val_loss: 0.3893 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3447 - f1_m: 0.7975 - val_loss: 0.3607 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3132 - f1_m: 0.7975 - val_loss: 0.3286 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2819 - f1_m: 0.8025 - val_loss: 0.2981 - val_f1_m: 0.8348\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2511 - f1_m: 0.8887 - val_loss: 0.2718 - val_f1_m: 0.8705\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2241 - f1_m: 0.9137 - val_loss: 0.2518 - val_f1_m: 0.8393\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2016 - f1_m: 0.9300 - val_loss: 0.2328 - val_f1_m: 0.8929\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.1836 - f1_m: 0.9350 - val_loss: 0.2206 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1694 - f1_m: 0.9450 - val_loss: 0.2109 - val_f1_m: 0.9286\n",
      "0.945\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 715us/sample - loss: 0.6579 - f1_m: 0.7875 - val_loss: 0.6234 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6116 - f1_m: 0.7887 - val_loss: 0.5705 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5683 - f1_m: 0.7887 - val_loss: 0.5294 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5401 - f1_m: 0.7887 - val_loss: 0.5036 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5234 - f1_m: 0.7887 - val_loss: 0.4894 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5121 - f1_m: 0.7887 - val_loss: 0.4791 - val_f1_m: 0.8304\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5006 - f1_m: 0.7887 - val_loss: 0.4692 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4883 - f1_m: 0.7887 - val_loss: 0.4571 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4736 - f1_m: 0.7887 - val_loss: 0.4431 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4578 - f1_m: 0.7887 - val_loss: 0.4283 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4400 - f1_m: 0.7887 - val_loss: 0.4113 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4191 - f1_m: 0.7887 - val_loss: 0.3904 - val_f1_m: 0.8304\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3931 - f1_m: 0.7887 - val_loss: 0.3632 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3613 - f1_m: 0.7887 - val_loss: 0.3327 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3270 - f1_m: 0.7887 - val_loss: 0.3021 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2944 - f1_m: 0.7887 - val_loss: 0.2738 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2645 - f1_m: 0.8812 - val_loss: 0.2488 - val_f1_m: 0.8750\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2385 - f1_m: 0.9050 - val_loss: 0.2276 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2167 - f1_m: 0.9175 - val_loss: 0.2132 - val_f1_m: 0.9420\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1999 - f1_m: 0.9225 - val_loss: 0.2009 - val_f1_m: 0.9241\n",
      "0.9225\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6573 - f1_m: 0.7887 - val_loss: 0.6270 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6099 - f1_m: 0.7887 - val_loss: 0.5785 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5696 - f1_m: 0.7887 - val_loss: 0.5372 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5407 - f1_m: 0.7887 - val_loss: 0.5076 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5226 - f1_m: 0.7887 - val_loss: 0.4904 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5101 - f1_m: 0.7887 - val_loss: 0.4771 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4978 - f1_m: 0.7887 - val_loss: 0.4628 - val_f1_m: 0.8304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4820 - f1_m: 0.7887 - val_loss: 0.4437 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4629 - f1_m: 0.7887 - val_loss: 0.4249 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4415 - f1_m: 0.7887 - val_loss: 0.4005 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4170 - f1_m: 0.7887 - val_loss: 0.3737 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3900 - f1_m: 0.7887 - val_loss: 0.3441 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3596 - f1_m: 0.7887 - val_loss: 0.3124 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3279 - f1_m: 0.7887 - val_loss: 0.2796 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2956 - f1_m: 0.7887 - val_loss: 0.2452 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2626 - f1_m: 0.8650 - val_loss: 0.2174 - val_f1_m: 0.9643\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2349 - f1_m: 0.9100 - val_loss: 0.1859 - val_f1_m: 0.9643\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2098 - f1_m: 0.9225 - val_loss: 0.1646 - val_f1_m: 0.9687\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1902 - f1_m: 0.9425 - val_loss: 0.1442 - val_f1_m: 0.9688\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1767 - f1_m: 0.9387 - val_loss: 0.1308 - val_f1_m: 0.9732\n",
      "0.9387499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 742us/sample - loss: 0.6565 - f1_m: 0.8025 - val_loss: 0.6424 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6074 - f1_m: 0.8025 - val_loss: 0.6060 - val_f1_m: 0.7411\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5616 - f1_m: 0.8025 - val_loss: 0.5823 - val_f1_m: 0.7411\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5314 - f1_m: 0.8025 - val_loss: 0.5706 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5121 - f1_m: 0.8025 - val_loss: 0.5623 - val_f1_m: 0.7545\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5017 - f1_m: 0.8025 - val_loss: 0.5567 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4908 - f1_m: 0.8025 - val_loss: 0.5452 - val_f1_m: 0.7545\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4805 - f1_m: 0.8025 - val_loss: 0.5342 - val_f1_m: 0.7545\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4687 - f1_m: 0.8025 - val_loss: 0.5196 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4547 - f1_m: 0.8025 - val_loss: 0.5024 - val_f1_m: 0.7545\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4398 - f1_m: 0.8025 - val_loss: 0.4859 - val_f1_m: 0.7545\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4235 - f1_m: 0.8025 - val_loss: 0.4653 - val_f1_m: 0.7411\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4045 - f1_m: 0.8025 - val_loss: 0.4417 - val_f1_m: 0.7411\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3835 - f1_m: 0.8025 - val_loss: 0.4149 - val_f1_m: 0.7679\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3570 - f1_m: 0.8025 - val_loss: 0.3789 - val_f1_m: 0.7545\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3272 - f1_m: 0.8025 - val_loss: 0.3409 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2969 - f1_m: 0.8025 - val_loss: 0.3052 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2691 - f1_m: 0.8287 - val_loss: 0.2755 - val_f1_m: 0.8348\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2462 - f1_m: 0.8788 - val_loss: 0.2449 - val_f1_m: 0.8839\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2237 - f1_m: 0.9075 - val_loss: 0.2192 - val_f1_m: 0.9196\n",
      "0.9074999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 678us/sample - loss: 0.6599 - f1_m: 0.7850 - val_loss: 0.6250 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6128 - f1_m: 0.7850 - val_loss: 0.5736 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5753 - f1_m: 0.7850 - val_loss: 0.5306 - val_f1_m: 0.8437\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5469 - f1_m: 0.7850 - val_loss: 0.5015 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5275 - f1_m: 0.7850 - val_loss: 0.4825 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5123 - f1_m: 0.7850 - val_loss: 0.4645 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4969 - f1_m: 0.7850 - val_loss: 0.4471 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4790 - f1_m: 0.7850 - val_loss: 0.4292 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4578 - f1_m: 0.7850 - val_loss: 0.4078 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4343 - f1_m: 0.7850 - val_loss: 0.3850 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4111 - f1_m: 0.7850 - val_loss: 0.3611 - val_f1_m: 0.8437\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3843 - f1_m: 0.7850 - val_loss: 0.3370 - val_f1_m: 0.8304\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3567 - f1_m: 0.7850 - val_loss: 0.3140 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3296 - f1_m: 0.7850 - val_loss: 0.2897 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2999 - f1_m: 0.8025 - val_loss: 0.2632 - val_f1_m: 0.8750\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2742 - f1_m: 0.8850 - val_loss: 0.2408 - val_f1_m: 0.8661\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2498 - f1_m: 0.8962 - val_loss: 0.2221 - val_f1_m: 0.8973\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2297 - f1_m: 0.9100 - val_loss: 0.2055 - val_f1_m: 0.9018\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2143 - f1_m: 0.9112 - val_loss: 0.1930 - val_f1_m: 0.9375\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2014 - f1_m: 0.9250 - val_loss: 0.1830 - val_f1_m: 0.9375\n",
      "0.925\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 665us/sample - loss: 0.6584 - f1_m: 0.7937 - val_loss: 0.6314 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6101 - f1_m: 0.7937 - val_loss: 0.5860 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5674 - f1_m: 0.7937 - val_loss: 0.5509 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5393 - f1_m: 0.7937 - val_loss: 0.5283 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5199 - f1_m: 0.7937 - val_loss: 0.5167 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5078 - f1_m: 0.7937 - val_loss: 0.5062 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4980 - f1_m: 0.7937 - val_loss: 0.4952 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4853 - f1_m: 0.7937 - val_loss: 0.4823 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4682 - f1_m: 0.7937 - val_loss: 0.4655 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4496 - f1_m: 0.7937 - val_loss: 0.4462 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4285 - f1_m: 0.7937 - val_loss: 0.4241 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4037 - f1_m: 0.7937 - val_loss: 0.3989 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3763 - f1_m: 0.7937 - val_loss: 0.3708 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3460 - f1_m: 0.7937 - val_loss: 0.3415 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3152 - f1_m: 0.7937 - val_loss: 0.3110 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2850 - f1_m: 0.8112 - val_loss: 0.2841 - val_f1_m: 0.8705\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2568 - f1_m: 0.8788 - val_loss: 0.2591 - val_f1_m: 0.8705\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2326 - f1_m: 0.9062 - val_loss: 0.2395 - val_f1_m: 0.8929\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2127 - f1_m: 0.9162 - val_loss: 0.2263 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.1988 - f1_m: 0.9275 - val_loss: 0.2116 - val_f1_m: 0.9152\n",
      "0.9275\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 672us/sample - loss: 0.6581 - f1_m: 0.7975 - val_loss: 0.6390 - val_f1_m: 0.7455\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6048 - f1_m: 0.7975 - val_loss: 0.5970 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5588 - f1_m: 0.7975 - val_loss: 0.5674 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5297 - f1_m: 0.7975 - val_loss: 0.5515 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5136 - f1_m: 0.7975 - val_loss: 0.5417 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5035 - f1_m: 0.7975 - val_loss: 0.5336 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4945 - f1_m: 0.7975 - val_loss: 0.5221 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4839 - f1_m: 0.7975 - val_loss: 0.5121 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4713 - f1_m: 0.7975 - val_loss: 0.4973 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4573 - f1_m: 0.7975 - val_loss: 0.4817 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4420 - f1_m: 0.7975 - val_loss: 0.4664 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4249 - f1_m: 0.7975 - val_loss: 0.4475 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4059 - f1_m: 0.7975 - val_loss: 0.4278 - val_f1_m: 0.7723\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3847 - f1_m: 0.7975 - val_loss: 0.4043 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3609 - f1_m: 0.7975 - val_loss: 0.3788 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3364 - f1_m: 0.7975 - val_loss: 0.3534 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3106 - f1_m: 0.7975 - val_loss: 0.3259 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2838 - f1_m: 0.7975 - val_loss: 0.3010 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3075 - f1_m: 0.78 - 0s 61us/sample - loss: 0.2588 - f1_m: 0.8925 - val_loss: 0.2808 - val_f1_m: 0.8393\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2366 - f1_m: 0.9025 - val_loss: 0.2571 - val_f1_m: 0.8795\n",
      "0.9024999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6572 - f1_m: 0.7925 - val_loss: 0.6314 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6082 - f1_m: 0.7925 - val_loss: 0.5842 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5641 - f1_m: 0.7925 - val_loss: 0.5483 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5355 - f1_m: 0.7925 - val_loss: 0.5274 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5194 - f1_m: 0.7925 - val_loss: 0.5146 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5086 - f1_m: 0.7925 - val_loss: 0.5042 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4985 - f1_m: 0.7925 - val_loss: 0.4930 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4863 - f1_m: 0.7925 - val_loss: 0.4796 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4726 - f1_m: 0.7925 - val_loss: 0.4652 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4578 - f1_m: 0.7925 - val_loss: 0.4496 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4404 - f1_m: 0.7925 - val_loss: 0.4317 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4212 - f1_m: 0.7925 - val_loss: 0.4111 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.3994 - f1_m: 0.7925 - val_loss: 0.3896 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3745 - f1_m: 0.7925 - val_loss: 0.3635 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3473 - f1_m: 0.7925 - val_loss: 0.3386 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3201 - f1_m: 0.7925 - val_loss: 0.3111 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2915 - f1_m: 0.7925 - val_loss: 0.2860 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2637 - f1_m: 0.8787 - val_loss: 0.2612 - val_f1_m: 0.8795\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2373 - f1_m: 0.9125 - val_loss: 0.2394 - val_f1_m: 0.8973\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2142 - f1_m: 0.9413 - val_loss: 0.2203 - val_f1_m: 0.8884\n",
      "0.94125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6559 - f1_m: 0.8062 - val_loss: 0.6459 - val_f1_m: 0.7098\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6042 - f1_m: 0.8075 - val_loss: 0.6137 - val_f1_m: 0.7366\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5560 - f1_m: 0.8075 - val_loss: 0.5947 - val_f1_m: 0.7232\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5229 - f1_m: 0.8075 - val_loss: 0.5893 - val_f1_m: 0.7232\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5040 - f1_m: 0.8075 - val_loss: 0.5877 - val_f1_m: 0.7366\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4919 - f1_m: 0.8075 - val_loss: 0.5816 - val_f1_m: 0.7366\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4818 - f1_m: 0.8075 - val_loss: 0.5742 - val_f1_m: 0.7500\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4705 - f1_m: 0.8075 - val_loss: 0.5637 - val_f1_m: 0.7366\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4582 - f1_m: 0.8075 - val_loss: 0.5471 - val_f1_m: 0.7366\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4406 - f1_m: 0.8075 - val_loss: 0.5259 - val_f1_m: 0.7634\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4198 - f1_m: 0.8075 - val_loss: 0.5055 - val_f1_m: 0.7098\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3971 - f1_m: 0.8075 - val_loss: 0.4801 - val_f1_m: 0.7500\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3737 - f1_m: 0.8075 - val_loss: 0.4571 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3478 - f1_m: 0.8075 - val_loss: 0.4315 - val_f1_m: 0.7232\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3203 - f1_m: 0.8075 - val_loss: 0.3923 - val_f1_m: 0.7232\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2932 - f1_m: 0.8075 - val_loss: 0.3617 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2656 - f1_m: 0.8062 - val_loss: 0.3287 - val_f1_m: 0.8304\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2424 - f1_m: 0.8837 - val_loss: 0.3049 - val_f1_m: 0.8259\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2223 - f1_m: 0.9187 - val_loss: 0.2852 - val_f1_m: 0.8304\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2032 - f1_m: 0.9225 - val_loss: 0.2604 - val_f1_m: 0.8705\n",
      "0.9224999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 677us/sample - loss: 0.6568 - f1_m: 0.7987 - val_loss: 0.6376 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6069 - f1_m: 0.7987 - val_loss: 0.5971 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5633 - f1_m: 0.7987 - val_loss: 0.5680 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5341 - f1_m: 0.7987 - val_loss: 0.5521 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5141 - f1_m: 0.7987 - val_loss: 0.5416 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5015 - f1_m: 0.7987 - val_loss: 0.5321 - val_f1_m: 0.7545\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4895 - f1_m: 0.7987 - val_loss: 0.5189 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4746 - f1_m: 0.7987 - val_loss: 0.5009 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4557 - f1_m: 0.7987 - val_loss: 0.4799 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4349 - f1_m: 0.7987 - val_loss: 0.4569 - val_f1_m: 0.7679\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4110 - f1_m: 0.7987 - val_loss: 0.4294 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3841 - f1_m: 0.7987 - val_loss: 0.3991 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3554 - f1_m: 0.7987 - val_loss: 0.3660 - val_f1_m: 0.7411\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3255 - f1_m: 0.7987 - val_loss: 0.3317 - val_f1_m: 0.7679\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2965 - f1_m: 0.7987 - val_loss: 0.2973 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2649 - f1_m: 0.8475 - val_loss: 0.2669 - val_f1_m: 0.8616\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2395 - f1_m: 0.9013 - val_loss: 0.2387 - val_f1_m: 0.9018\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2150 - f1_m: 0.9162 - val_loss: 0.2155 - val_f1_m: 0.9152\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1963 - f1_m: 0.9300 - val_loss: 0.1955 - val_f1_m: 0.9241\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1811 - f1_m: 0.9325 - val_loss: 0.1810 - val_f1_m: 0.9464\n",
      "0.93249995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 675us/sample - loss: 0.6570 - f1_m: 0.7950 - val_loss: 0.6322 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6078 - f1_m: 0.7950 - val_loss: 0.5863 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5646 - f1_m: 0.7950 - val_loss: 0.5508 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5347 - f1_m: 0.7950 - val_loss: 0.5306 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5176 - f1_m: 0.7950 - val_loss: 0.5187 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5068 - f1_m: 0.7950 - val_loss: 0.5089 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4962 - f1_m: 0.7950 - val_loss: 0.4958 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4821 - f1_m: 0.7950 - val_loss: 0.4792 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4644 - f1_m: 0.7950 - val_loss: 0.4608 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4449 - f1_m: 0.7950 - val_loss: 0.4386 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4236 - f1_m: 0.7950 - val_loss: 0.4142 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3999 - f1_m: 0.7950 - val_loss: 0.3866 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3751 - f1_m: 0.7950 - val_loss: 0.3616 - val_f1_m: 0.7545\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3457 - f1_m: 0.7950 - val_loss: 0.3261 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3166 - f1_m: 0.7950 - val_loss: 0.2985 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2903 - f1_m: 0.7975 - val_loss: 0.2637 - val_f1_m: 0.8884\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2656 - f1_m: 0.8712 - val_loss: 0.2373 - val_f1_m: 0.9196\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2428 - f1_m: 0.8787 - val_loss: 0.2143 - val_f1_m: 0.9152\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2249 - f1_m: 0.9100 - val_loss: 0.1952 - val_f1_m: 0.9554\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2104 - f1_m: 0.9125 - val_loss: 0.1840 - val_f1_m: 0.9420\n",
      "0.9125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 675us/sample - loss: 0.6581 - f1_m: 0.7850 - val_loss: 0.6247 - val_f1_m: 0.8437\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6105 - f1_m: 0.7850 - val_loss: 0.5729 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5733 - f1_m: 0.7850 - val_loss: 0.5261 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5436 - f1_m: 0.7850 - val_loss: 0.5011 - val_f1_m: 0.8437\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5282 - f1_m: 0.7850 - val_loss: 0.4813 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5167 - f1_m: 0.7850 - val_loss: 0.4680 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5057 - f1_m: 0.7850 - val_loss: 0.4542 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4921 - f1_m: 0.7850 - val_loss: 0.4395 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4769 - f1_m: 0.7850 - val_loss: 0.4223 - val_f1_m: 0.8437\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4611 - f1_m: 0.7850 - val_loss: 0.4039 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4395 - f1_m: 0.7850 - val_loss: 0.3786 - val_f1_m: 0.8304\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4130 - f1_m: 0.7850 - val_loss: 0.3510 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3850 - f1_m: 0.7850 - val_loss: 0.3207 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3533 - f1_m: 0.7850 - val_loss: 0.2877 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3197 - f1_m: 0.7850 - val_loss: 0.2560 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2875 - f1_m: 0.8112 - val_loss: 0.2236 - val_f1_m: 0.9018\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2575 - f1_m: 0.8875 - val_loss: 0.1934 - val_f1_m: 0.9598\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2309 - f1_m: 0.9087 - val_loss: 0.1670 - val_f1_m: 0.9643\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2097 - f1_m: 0.9175 - val_loss: 0.1474 - val_f1_m: 0.9821\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.1942 - f1_m: 0.9275 - val_loss: 0.1276 - val_f1_m: 0.9821\n",
      "0.92749995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 682us/sample - loss: 0.6574 - f1_m: 0.7912 - val_loss: 0.6278 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6097 - f1_m: 0.7912 - val_loss: 0.5790 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5668 - f1_m: 0.7912 - val_loss: 0.5407 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5383 - f1_m: 0.7912 - val_loss: 0.5168 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5206 - f1_m: 0.7912 - val_loss: 0.5034 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5112 - f1_m: 0.7912 - val_loss: 0.4917 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4985 - f1_m: 0.7912 - val_loss: 0.4820 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4867 - f1_m: 0.7912 - val_loss: 0.4668 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4690 - f1_m: 0.7912 - val_loss: 0.4476 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4491 - f1_m: 0.7912 - val_loss: 0.4259 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4267 - f1_m: 0.7912 - val_loss: 0.4017 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4008 - f1_m: 0.7912 - val_loss: 0.3768 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3730 - f1_m: 0.7912 - val_loss: 0.3468 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3430 - f1_m: 0.7912 - val_loss: 0.3148 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3106 - f1_m: 0.7912 - val_loss: 0.2835 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2778 - f1_m: 0.8187 - val_loss: 0.2557 - val_f1_m: 0.9152\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2483 - f1_m: 0.9037 - val_loss: 0.2247 - val_f1_m: 0.9330\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2204 - f1_m: 0.9225 - val_loss: 0.1993 - val_f1_m: 0.9375\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.1969 - f1_m: 0.9375 - val_loss: 0.1794 - val_f1_m: 0.9509\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1789 - f1_m: 0.9450 - val_loss: 0.1643 - val_f1_m: 0.9643\n",
      "0.945\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 684us/sample - loss: 0.6592 - f1_m: 0.7762 - val_loss: 0.6114 - val_f1_m: 0.8616\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6136 - f1_m: 0.7762 - val_loss: 0.5486 - val_f1_m: 0.8616\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5745 - f1_m: 0.7762 - val_loss: 0.4949 - val_f1_m: 0.8750\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5495 - f1_m: 0.7762 - val_loss: 0.4602 - val_f1_m: 0.8482\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5357 - f1_m: 0.7762 - val_loss: 0.4360 - val_f1_m: 0.8482\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5248 - f1_m: 0.7762 - val_loss: 0.4264 - val_f1_m: 0.8616\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5133 - f1_m: 0.7762 - val_loss: 0.4160 - val_f1_m: 0.8750\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5001 - f1_m: 0.7762 - val_loss: 0.4025 - val_f1_m: 0.8750\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4857 - f1_m: 0.7762 - val_loss: 0.3875 - val_f1_m: 0.8750\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4696 - f1_m: 0.7762 - val_loss: 0.3701 - val_f1_m: 0.8482\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4509 - f1_m: 0.7762 - val_loss: 0.3509 - val_f1_m: 0.8482\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4293 - f1_m: 0.7762 - val_loss: 0.3351 - val_f1_m: 0.8616\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4063 - f1_m: 0.7762 - val_loss: 0.3228 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3800 - f1_m: 0.7762 - val_loss: 0.2967 - val_f1_m: 0.8348\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3519 - f1_m: 0.7762 - val_loss: 0.2690 - val_f1_m: 0.8750\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3224 - f1_m: 0.7762 - val_loss: 0.2521 - val_f1_m: 0.8750\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2940 - f1_m: 0.8025 - val_loss: 0.2318 - val_f1_m: 0.9018\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2686 - f1_m: 0.8875 - val_loss: 0.2180 - val_f1_m: 0.9152\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2449 - f1_m: 0.9037 - val_loss: 0.2008 - val_f1_m: 0.9330\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2255 - f1_m: 0.9200 - val_loss: 0.1892 - val_f1_m: 0.9241\n",
      "0.92\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 687us/sample - loss: 0.6598 - f1_m: 0.7805 - val_loss: 0.6174 - val_f1_m: 0.8437\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6134 - f1_m: 0.7812 - val_loss: 0.5561 - val_f1_m: 0.8571\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5729 - f1_m: 0.7812 - val_loss: 0.5089 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5483 - f1_m: 0.7812 - val_loss: 0.4782 - val_f1_m: 0.8437\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5332 - f1_m: 0.7812 - val_loss: 0.4595 - val_f1_m: 0.8437\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5217 - f1_m: 0.7812 - val_loss: 0.4467 - val_f1_m: 0.8571\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5105 - f1_m: 0.7812 - val_loss: 0.4328 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4970 - f1_m: 0.7812 - val_loss: 0.4191 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4805 - f1_m: 0.7812 - val_loss: 0.4032 - val_f1_m: 0.8437\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4622 - f1_m: 0.7812 - val_loss: 0.3828 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4404 - f1_m: 0.7812 - val_loss: 0.3627 - val_f1_m: 0.8304\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4150 - f1_m: 0.7812 - val_loss: 0.3398 - val_f1_m: 0.8571\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3878 - f1_m: 0.7812 - val_loss: 0.3143 - val_f1_m: 0.8437\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3573 - f1_m: 0.7812 - val_loss: 0.2866 - val_f1_m: 0.8437\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3260 - f1_m: 0.7812 - val_loss: 0.2615 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2953 - f1_m: 0.8100 - val_loss: 0.2373 - val_f1_m: 0.9018\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2666 - f1_m: 0.8837 - val_loss: 0.2144 - val_f1_m: 0.8839\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2430 - f1_m: 0.9012 - val_loss: 0.1954 - val_f1_m: 0.9241\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2227 - f1_m: 0.9150 - val_loss: 0.1810 - val_f1_m: 0.9420\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2076 - f1_m: 0.9237 - val_loss: 0.1675 - val_f1_m: 0.9420\n",
      "0.9237499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 682us/sample - loss: 0.6574 - f1_m: 0.7912 - val_loss: 0.6276 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6079 - f1_m: 0.7925 - val_loss: 0.5791 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5649 - f1_m: 0.7925 - val_loss: 0.5416 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5374 - f1_m: 0.7925 - val_loss: 0.5187 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5188 - f1_m: 0.7925 - val_loss: 0.5061 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5064 - f1_m: 0.7925 - val_loss: 0.4950 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4945 - f1_m: 0.7925 - val_loss: 0.4825 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4811 - f1_m: 0.7925 - val_loss: 0.4687 - val_f1_m: 0.7500\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4486 - f1_m: 0.81 - 0s 60us/sample - loss: 0.4650 - f1_m: 0.7925 - val_loss: 0.4529 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4483 - f1_m: 0.7925 - val_loss: 0.4342 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4287 - f1_m: 0.7925 - val_loss: 0.4138 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4074 - f1_m: 0.7925 - val_loss: 0.3910 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3835 - f1_m: 0.7925 - val_loss: 0.3639 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3549 - f1_m: 0.7925 - val_loss: 0.3362 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3257 - f1_m: 0.7925 - val_loss: 0.3062 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.2939 - f1_m: 0.7925 - val_loss: 0.2736 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2638 - f1_m: 0.8875 - val_loss: 0.2449 - val_f1_m: 0.8973\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2361 - f1_m: 0.9012 - val_loss: 0.2212 - val_f1_m: 0.9286\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2141 - f1_m: 0.9250 - val_loss: 0.2000 - val_f1_m: 0.9464\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1950 - f1_m: 0.9325 - val_loss: 0.1855 - val_f1_m: 0.9464\n",
      "0.93249995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 669us/sample - loss: 0.6585 - f1_m: 0.7937 - val_loss: 0.6315 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6105 - f1_m: 0.7937 - val_loss: 0.5859 - val_f1_m: 0.7589\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5687 - f1_m: 0.7937 - val_loss: 0.5502 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5374 - f1_m: 0.7937 - val_loss: 0.5300 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5202 - f1_m: 0.7937 - val_loss: 0.5173 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5057 - f1_m: 0.7937 - val_loss: 0.5076 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4933 - f1_m: 0.7937 - val_loss: 0.4965 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4790 - f1_m: 0.7937 - val_loss: 0.4837 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4642 - f1_m: 0.7937 - val_loss: 0.4710 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4480 - f1_m: 0.7937 - val_loss: 0.4565 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4300 - f1_m: 0.7937 - val_loss: 0.4404 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4097 - f1_m: 0.7937 - val_loss: 0.4218 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3866 - f1_m: 0.7937 - val_loss: 0.4018 - val_f1_m: 0.7589\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3612 - f1_m: 0.7937 - val_loss: 0.3796 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3348 - f1_m: 0.7937 - val_loss: 0.3576 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3072 - f1_m: 0.7937 - val_loss: 0.3341 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2806 - f1_m: 0.7950 - val_loss: 0.3148 - val_f1_m: 0.7634\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2568 - f1_m: 0.8712 - val_loss: 0.2935 - val_f1_m: 0.8393\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2365 - f1_m: 0.9112 - val_loss: 0.2804 - val_f1_m: 0.8393\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2166 - f1_m: 0.9212 - val_loss: 0.2661 - val_f1_m: 0.8527\n",
      "0.9212499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 682us/sample - loss: 0.6564 - f1_m: 0.8012 - val_loss: 0.6427 - val_f1_m: 0.7723\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6044 - f1_m: 0.8012 - val_loss: 0.6049 - val_f1_m: 0.7589\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5579 - f1_m: 0.8012 - val_loss: 0.5794 - val_f1_m: 0.7455\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5277 - f1_m: 0.8012 - val_loss: 0.5670 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5126 - f1_m: 0.8012 - val_loss: 0.5592 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5021 - f1_m: 0.8012 - val_loss: 0.5505 - val_f1_m: 0.7589\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4934 - f1_m: 0.8012 - val_loss: 0.5415 - val_f1_m: 0.7589\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4836 - f1_m: 0.8012 - val_loss: 0.5271 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4714 - f1_m: 0.8012 - val_loss: 0.5133 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4588 - f1_m: 0.8012 - val_loss: 0.4995 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4450 - f1_m: 0.8012 - val_loss: 0.4852 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4299 - f1_m: 0.8012 - val_loss: 0.4644 - val_f1_m: 0.7321\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4126 - f1_m: 0.8012 - val_loss: 0.4431 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3937 - f1_m: 0.8012 - val_loss: 0.4194 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3732 - f1_m: 0.8012 - val_loss: 0.3944 - val_f1_m: 0.7187\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3514 - f1_m: 0.8012 - val_loss: 0.3651 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3296 - f1_m: 0.8012 - val_loss: 0.3408 - val_f1_m: 0.7589\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3076 - f1_m: 0.8012 - val_loss: 0.3106 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2859 - f1_m: 0.8012 - val_loss: 0.2871 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2674 - f1_m: 0.8487 - val_loss: 0.2628 - val_f1_m: 0.8571\n",
      "0.84874994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 680us/sample - loss: 0.6574 - f1_m: 0.7925 - val_loss: 0.6298 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6083 - f1_m: 0.7925 - val_loss: 0.5820 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5663 - f1_m: 0.7925 - val_loss: 0.5449 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5399 - f1_m: 0.7925 - val_loss: 0.5206 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5229 - f1_m: 0.7925 - val_loss: 0.5094 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5129 - f1_m: 0.7925 - val_loss: 0.5000 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5051 - f1_m: 0.7925 - val_loss: 0.4907 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4945 - f1_m: 0.7925 - val_loss: 0.4801 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4811 - f1_m: 0.7925 - val_loss: 0.4651 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4655 - f1_m: 0.7925 - val_loss: 0.4479 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4470 - f1_m: 0.7925 - val_loss: 0.4260 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4262 - f1_m: 0.7925 - val_loss: 0.4039 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4037 - f1_m: 0.7925 - val_loss: 0.3790 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3781 - f1_m: 0.7925 - val_loss: 0.3525 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3513 - f1_m: 0.7925 - val_loss: 0.3199 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3231 - f1_m: 0.7925 - val_loss: 0.2902 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2963 - f1_m: 0.8037 - val_loss: 0.2642 - val_f1_m: 0.9241\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2720 - f1_m: 0.8625 - val_loss: 0.2363 - val_f1_m: 0.9152\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2524 - f1_m: 0.8750 - val_loss: 0.2219 - val_f1_m: 0.9464\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2360 - f1_m: 0.8975 - val_loss: 0.1988 - val_f1_m: 0.9152\n",
      "0.8974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 681us/sample - loss: 0.6571 - f1_m: 0.7912 - val_loss: 0.6283 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6079 - f1_m: 0.7912 - val_loss: 0.5795 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5666 - f1_m: 0.7912 - val_loss: 0.5414 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5394 - f1_m: 0.7912 - val_loss: 0.5184 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5233 - f1_m: 0.7912 - val_loss: 0.5060 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5131 - f1_m: 0.7912 - val_loss: 0.4962 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5032 - f1_m: 0.7912 - val_loss: 0.4863 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4923 - f1_m: 0.7912 - val_loss: 0.4752 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4808 - f1_m: 0.7912 - val_loss: 0.4624 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4670 - f1_m: 0.7912 - val_loss: 0.4495 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4513 - f1_m: 0.7912 - val_loss: 0.4335 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4349 - f1_m: 0.7912 - val_loss: 0.4182 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4152 - f1_m: 0.7912 - val_loss: 0.3978 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3941 - f1_m: 0.7912 - val_loss: 0.3779 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3716 - f1_m: 0.7912 - val_loss: 0.3557 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3475 - f1_m: 0.7912 - val_loss: 0.3328 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3234 - f1_m: 0.7912 - val_loss: 0.3113 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2994 - f1_m: 0.7912 - val_loss: 0.2887 - val_f1_m: 0.8571\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2763 - f1_m: 0.8562 - val_loss: 0.2694 - val_f1_m: 0.8616\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2567 - f1_m: 0.8850 - val_loss: 0.2531 - val_f1_m: 0.8750\n",
      "0.885\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 692us/sample - loss: 0.6571 - f1_m: 0.7987 - val_loss: 0.6369 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6058 - f1_m: 0.7987 - val_loss: 0.5952 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5616 - f1_m: 0.7987 - val_loss: 0.5643 - val_f1_m: 0.7545\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5310 - f1_m: 0.7987 - val_loss: 0.5487 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5141 - f1_m: 0.7987 - val_loss: 0.5388 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5024 - f1_m: 0.7987 - val_loss: 0.5298 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4931 - f1_m: 0.7987 - val_loss: 0.5194 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4817 - f1_m: 0.7987 - val_loss: 0.5076 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4687 - f1_m: 0.7987 - val_loss: 0.4936 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4539 - f1_m: 0.7987 - val_loss: 0.4775 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4377 - f1_m: 0.7987 - val_loss: 0.4599 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4200 - f1_m: 0.7987 - val_loss: 0.4389 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3996 - f1_m: 0.7987 - val_loss: 0.4176 - val_f1_m: 0.7545\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3766 - f1_m: 0.7987 - val_loss: 0.3899 - val_f1_m: 0.7679\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3521 - f1_m: 0.7987 - val_loss: 0.3626 - val_f1_m: 0.7679\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3256 - f1_m: 0.7987 - val_loss: 0.3307 - val_f1_m: 0.7679\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2991 - f1_m: 0.7987 - val_loss: 0.3023 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2720 - f1_m: 0.8287 - val_loss: 0.2741 - val_f1_m: 0.8616\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2487 - f1_m: 0.8887 - val_loss: 0.2481 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2255 - f1_m: 0.9050 - val_loss: 0.2260 - val_f1_m: 0.9196\n",
      "0.9049999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 675us/sample - loss: 0.6580 - f1_m: 0.7962 - val_loss: 0.6355 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6065 - f1_m: 0.7962 - val_loss: 0.5928 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5632 - f1_m: 0.7962 - val_loss: 0.5601 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5340 - f1_m: 0.7962 - val_loss: 0.5417 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5167 - f1_m: 0.7962 - val_loss: 0.5305 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5056 - f1_m: 0.7962 - val_loss: 0.5208 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4948 - f1_m: 0.7962 - val_loss: 0.5093 - val_f1_m: 0.7500\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4831 - f1_m: 0.7962 - val_loss: 0.4968 - val_f1_m: 0.7500\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4695 - f1_m: 0.7962 - val_loss: 0.4818 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4545 - f1_m: 0.7962 - val_loss: 0.4672 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4384 - f1_m: 0.7962 - val_loss: 0.4493 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4203 - f1_m: 0.7962 - val_loss: 0.4292 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3998 - f1_m: 0.7962 - val_loss: 0.4105 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3762 - f1_m: 0.7962 - val_loss: 0.3815 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3515 - f1_m: 0.7962 - val_loss: 0.3553 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3252 - f1_m: 0.7962 - val_loss: 0.3272 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2986 - f1_m: 0.7962 - val_loss: 0.3007 - val_f1_m: 0.7500\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2732 - f1_m: 0.8262 - val_loss: 0.2749 - val_f1_m: 0.8661\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2493 - f1_m: 0.8875 - val_loss: 0.2541 - val_f1_m: 0.8705\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2289 - f1_m: 0.9000 - val_loss: 0.2339 - val_f1_m: 0.9196\n",
      "0.8999999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 705us/sample - loss: 0.6613 - f1_m: 0.7825 - val_loss: 0.6227 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6136 - f1_m: 0.7825 - val_loss: 0.5674 - val_f1_m: 0.8527\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5745 - f1_m: 0.7825 - val_loss: 0.5177 - val_f1_m: 0.8393\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5472 - f1_m: 0.7825 - val_loss: 0.4899 - val_f1_m: 0.8527\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5326 - f1_m: 0.7825 - val_loss: 0.4714 - val_f1_m: 0.8527\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5221 - f1_m: 0.7825 - val_loss: 0.4594 - val_f1_m: 0.8527\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5114 - f1_m: 0.7825 - val_loss: 0.4468 - val_f1_m: 0.8393\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4997 - f1_m: 0.7825 - val_loss: 0.4355 - val_f1_m: 0.8527\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4870 - f1_m: 0.7825 - val_loss: 0.4196 - val_f1_m: 0.8259\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4724 - f1_m: 0.7825 - val_loss: 0.4052 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4570 - f1_m: 0.7825 - val_loss: 0.3884 - val_f1_m: 0.8393\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4394 - f1_m: 0.7825 - val_loss: 0.3721 - val_f1_m: 0.8527\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4176 - f1_m: 0.7825 - val_loss: 0.3505 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3923 - f1_m: 0.7825 - val_loss: 0.3228 - val_f1_m: 0.8393\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3601 - f1_m: 0.7825 - val_loss: 0.2960 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3288 - f1_m: 0.7825 - val_loss: 0.2721 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2974 - f1_m: 0.7962 - val_loss: 0.2442 - val_f1_m: 0.9018\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2689 - f1_m: 0.8800 - val_loss: 0.2197 - val_f1_m: 0.9018\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2441 - f1_m: 0.9000 - val_loss: 0.2017 - val_f1_m: 0.9420\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2245 - f1_m: 0.9162 - val_loss: 0.1864 - val_f1_m: 0.9196\n",
      "0.91625\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 680us/sample - loss: 0.6552 - f1_m: 0.8062 - val_loss: 0.6451 - val_f1_m: 0.7277\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6006 - f1_m: 0.8062 - val_loss: 0.6114 - val_f1_m: 0.7545\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5538 - f1_m: 0.8062 - val_loss: 0.5904 - val_f1_m: 0.7545\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5223 - f1_m: 0.8062 - val_loss: 0.5827 - val_f1_m: 0.7143\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5054 - f1_m: 0.8062 - val_loss: 0.5785 - val_f1_m: 0.7411\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4939 - f1_m: 0.8062 - val_loss: 0.5717 - val_f1_m: 0.7545\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4837 - f1_m: 0.8062 - val_loss: 0.5610 - val_f1_m: 0.7411\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4728 - f1_m: 0.8062 - val_loss: 0.5474 - val_f1_m: 0.7545\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4606 - f1_m: 0.8062 - val_loss: 0.5336 - val_f1_m: 0.7411\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4460 - f1_m: 0.8062 - val_loss: 0.5164 - val_f1_m: 0.7009\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4307 - f1_m: 0.8062 - val_loss: 0.4982 - val_f1_m: 0.7411\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4131 - f1_m: 0.8062 - val_loss: 0.4769 - val_f1_m: 0.7545\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3931 - f1_m: 0.8062 - val_loss: 0.4512 - val_f1_m: 0.7545\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3709 - f1_m: 0.8062 - val_loss: 0.4247 - val_f1_m: 0.7545\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3468 - f1_m: 0.8062 - val_loss: 0.3947 - val_f1_m: 0.7277\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3221 - f1_m: 0.8062 - val_loss: 0.3625 - val_f1_m: 0.7277\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2956 - f1_m: 0.8062 - val_loss: 0.3325 - val_f1_m: 0.7277\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2692 - f1_m: 0.8050 - val_loss: 0.3015 - val_f1_m: 0.8705\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2455 - f1_m: 0.8987 - val_loss: 0.2726 - val_f1_m: 0.8929\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2218 - f1_m: 0.9162 - val_loss: 0.2494 - val_f1_m: 0.9420\n",
      "0.91624993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6586 - f1_m: 0.7950 - val_loss: 0.6337 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.6090 - f1_m: 0.7950 - val_loss: 0.5886 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5652 - f1_m: 0.7950 - val_loss: 0.5532 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5348 - f1_m: 0.7950 - val_loss: 0.5338 - val_f1_m: 0.7545\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5178 - f1_m: 0.7950 - val_loss: 0.5216 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5069 - f1_m: 0.7950 - val_loss: 0.5117 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4972 - f1_m: 0.7950 - val_loss: 0.5014 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4851 - f1_m: 0.7950 - val_loss: 0.4889 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4714 - f1_m: 0.7950 - val_loss: 0.4721 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4529 - f1_m: 0.7950 - val_loss: 0.4516 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4324 - f1_m: 0.7950 - val_loss: 0.4285 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4086 - f1_m: 0.7950 - val_loss: 0.4020 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3821 - f1_m: 0.7950 - val_loss: 0.3725 - val_f1_m: 0.7679\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3534 - f1_m: 0.7950 - val_loss: 0.3406 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3222 - f1_m: 0.7950 - val_loss: 0.3093 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2917 - f1_m: 0.7950 - val_loss: 0.2769 - val_f1_m: 0.7679\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2625 - f1_m: 0.8687 - val_loss: 0.2474 - val_f1_m: 0.9286\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2352 - f1_m: 0.8975 - val_loss: 0.2204 - val_f1_m: 0.9330\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2132 - f1_m: 0.9075 - val_loss: 0.2005 - val_f1_m: 0.9420\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.1961 - f1_m: 0.9375 - val_loss: 0.1838 - val_f1_m: 0.9554\n",
      "0.93749994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 678us/sample - loss: 0.6595 - f1_m: 0.7887 - val_loss: 0.6256 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6117 - f1_m: 0.7887 - val_loss: 0.5762 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5702 - f1_m: 0.7887 - val_loss: 0.5325 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5409 - f1_m: 0.7887 - val_loss: 0.5048 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5237 - f1_m: 0.7887 - val_loss: 0.4892 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5111 - f1_m: 0.7887 - val_loss: 0.4768 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4991 - f1_m: 0.7887 - val_loss: 0.4637 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4848 - f1_m: 0.7887 - val_loss: 0.4494 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4697 - f1_m: 0.7887 - val_loss: 0.4335 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4533 - f1_m: 0.7887 - val_loss: 0.4155 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4348 - f1_m: 0.7887 - val_loss: 0.3956 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4123 - f1_m: 0.7887 - val_loss: 0.3734 - val_f1_m: 0.8036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3876 - f1_m: 0.7887 - val_loss: 0.3448 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.3542 - f1_m: 0.7887 - val_loss: 0.3114 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3201 - f1_m: 0.7887 - val_loss: 0.2764 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2861 - f1_m: 0.7900 - val_loss: 0.2449 - val_f1_m: 0.8616\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2537 - f1_m: 0.8862 - val_loss: 0.2162 - val_f1_m: 0.9464\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2245 - f1_m: 0.9275 - val_loss: 0.1890 - val_f1_m: 0.9330\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.1997 - f1_m: 0.9413 - val_loss: 0.1685 - val_f1_m: 0.9554\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1807 - f1_m: 0.9475 - val_loss: 0.1514 - val_f1_m: 0.9598\n",
      "0.9475\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 696us/sample - loss: 0.6584 - f1_m: 0.7875 - val_loss: 0.6235 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6116 - f1_m: 0.7875 - val_loss: 0.5723 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5706 - f1_m: 0.7875 - val_loss: 0.5299 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5417 - f1_m: 0.7875 - val_loss: 0.5005 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5249 - f1_m: 0.7875 - val_loss: 0.4854 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5140 - f1_m: 0.7875 - val_loss: 0.4744 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5030 - f1_m: 0.7875 - val_loss: 0.4638 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4906 - f1_m: 0.7875 - val_loss: 0.4515 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4760 - f1_m: 0.7875 - val_loss: 0.4371 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4605 - f1_m: 0.7875 - val_loss: 0.4242 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4434 - f1_m: 0.7875 - val_loss: 0.4061 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4233 - f1_m: 0.7875 - val_loss: 0.3889 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3995 - f1_m: 0.7875 - val_loss: 0.3702 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3736 - f1_m: 0.7875 - val_loss: 0.3464 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3455 - f1_m: 0.7875 - val_loss: 0.3259 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3164 - f1_m: 0.7875 - val_loss: 0.3023 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2866 - f1_m: 0.8062 - val_loss: 0.2819 - val_f1_m: 0.8393\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2599 - f1_m: 0.8875 - val_loss: 0.2655 - val_f1_m: 0.8750\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2344 - f1_m: 0.9037 - val_loss: 0.2522 - val_f1_m: 0.8884\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2128 - f1_m: 0.9300 - val_loss: 0.2433 - val_f1_m: 0.9062\n",
      "0.93\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 669us/sample - loss: 0.6569 - f1_m: 0.7937 - val_loss: 0.6302 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6073 - f1_m: 0.7937 - val_loss: 0.5836 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5658 - f1_m: 0.7937 - val_loss: 0.5480 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5355 - f1_m: 0.7937 - val_loss: 0.5277 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5184 - f1_m: 0.7937 - val_loss: 0.5149 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5063 - f1_m: 0.7937 - val_loss: 0.5042 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4950 - f1_m: 0.7937 - val_loss: 0.4926 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4819 - f1_m: 0.7937 - val_loss: 0.4794 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4669 - f1_m: 0.7937 - val_loss: 0.4652 - val_f1_m: 0.7455\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4518 - f1_m: 0.7937 - val_loss: 0.4494 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4335 - f1_m: 0.7937 - val_loss: 0.4313 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4149 - f1_m: 0.7937 - val_loss: 0.4107 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3932 - f1_m: 0.7937 - val_loss: 0.3882 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3671 - f1_m: 0.7937 - val_loss: 0.3642 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3408 - f1_m: 0.7937 - val_loss: 0.3380 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3131 - f1_m: 0.7937 - val_loss: 0.3113 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2852 - f1_m: 0.8000 - val_loss: 0.2861 - val_f1_m: 0.8705\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2590 - f1_m: 0.8837 - val_loss: 0.2610 - val_f1_m: 0.8348\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2342 - f1_m: 0.9050 - val_loss: 0.2403 - val_f1_m: 0.9152\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2139 - f1_m: 0.9150 - val_loss: 0.2247 - val_f1_m: 0.9286\n",
      "0.9149999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 681us/sample - loss: 0.6580 - f1_m: 0.7925 - val_loss: 0.6315 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6087 - f1_m: 0.7925 - val_loss: 0.5841 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5647 - f1_m: 0.7925 - val_loss: 0.5488 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5388 - f1_m: 0.7925 - val_loss: 0.5255 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5211 - f1_m: 0.7925 - val_loss: 0.5125 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5098 - f1_m: 0.7925 - val_loss: 0.5019 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4997 - f1_m: 0.7925 - val_loss: 0.4909 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4871 - f1_m: 0.7925 - val_loss: 0.4782 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4741 - f1_m: 0.7925 - val_loss: 0.4642 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4596 - f1_m: 0.7925 - val_loss: 0.4500 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.4434 - f1_m: 0.7925 - val_loss: 0.4329 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4250 - f1_m: 0.7925 - val_loss: 0.4139 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4045 - f1_m: 0.7925 - val_loss: 0.3938 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3817 - f1_m: 0.7925 - val_loss: 0.3696 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3566 - f1_m: 0.7925 - val_loss: 0.3455 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3305 - f1_m: 0.7925 - val_loss: 0.3198 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3053 - f1_m: 0.7925 - val_loss: 0.2944 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2796 - f1_m: 0.8275 - val_loss: 0.2733 - val_f1_m: 0.8616\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2553 - f1_m: 0.8812 - val_loss: 0.2511 - val_f1_m: 0.8884\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2347 - f1_m: 0.8975 - val_loss: 0.2342 - val_f1_m: 0.9018\n",
      "0.8975\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 702us/sample - loss: 0.6570 - f1_m: 0.7987 - val_loss: 0.6371 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6079 - f1_m: 0.7987 - val_loss: 0.5969 - val_f1_m: 0.7545\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5651 - f1_m: 0.7987 - val_loss: 0.5660 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5336 - f1_m: 0.7987 - val_loss: 0.5463 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5115 - f1_m: 0.7987 - val_loss: 0.5326 - val_f1_m: 0.7545\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4954 - f1_m: 0.7987 - val_loss: 0.5190 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4791 - f1_m: 0.7987 - val_loss: 0.5024 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4609 - f1_m: 0.7987 - val_loss: 0.4820 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4403 - f1_m: 0.7987 - val_loss: 0.4588 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4166 - f1_m: 0.7987 - val_loss: 0.4331 - val_f1_m: 0.7545\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3919 - f1_m: 0.7987 - val_loss: 0.4065 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3653 - f1_m: 0.7987 - val_loss: 0.3768 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3368 - f1_m: 0.7987 - val_loss: 0.3456 - val_f1_m: 0.7679\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3058 - f1_m: 0.7987 - val_loss: 0.3107 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2741 - f1_m: 0.8100 - val_loss: 0.2767 - val_f1_m: 0.8527\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2443 - f1_m: 0.8875 - val_loss: 0.2432 - val_f1_m: 0.9107\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2163 - f1_m: 0.9287 - val_loss: 0.2152 - val_f1_m: 0.9286\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.1935 - f1_m: 0.9400 - val_loss: 0.1928 - val_f1_m: 0.9509\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.1756 - f1_m: 0.9388 - val_loss: 0.1731 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.1628 - f1_m: 0.9488 - val_loss: 0.1585 - val_f1_m: 0.9598\n",
      "0.94875\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 683us/sample - loss: 0.6578 - f1_m: 0.7850 - val_loss: 0.6204 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6132 - f1_m: 0.7850 - val_loss: 0.5673 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5751 - f1_m: 0.7850 - val_loss: 0.5271 - val_f1_m: 0.8437\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5487 - f1_m: 0.7850 - val_loss: 0.4992 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.5318 - f1_m: 0.7850 - val_loss: 0.4797 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5192 - f1_m: 0.7850 - val_loss: 0.4681 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5074 - f1_m: 0.7850 - val_loss: 0.4554 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4949 - f1_m: 0.7850 - val_loss: 0.4437 - val_f1_m: 0.8437\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4801 - f1_m: 0.7850 - val_loss: 0.4298 - val_f1_m: 0.8437\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4629 - f1_m: 0.7850 - val_loss: 0.4132 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4447 - f1_m: 0.7850 - val_loss: 0.3968 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4251 - f1_m: 0.7850 - val_loss: 0.3776 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4030 - f1_m: 0.7850 - val_loss: 0.3577 - val_f1_m: 0.8437\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3785 - f1_m: 0.7850 - val_loss: 0.3363 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3525 - f1_m: 0.7850 - val_loss: 0.3153 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3264 - f1_m: 0.7850 - val_loss: 0.2916 - val_f1_m: 0.8437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2988 - f1_m: 0.7850 - val_loss: 0.2709 - val_f1_m: 0.8482\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2734 - f1_m: 0.8662 - val_loss: 0.2524 - val_f1_m: 0.8795\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2496 - f1_m: 0.9087 - val_loss: 0.2333 - val_f1_m: 0.9062\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2290 - f1_m: 0.9150 - val_loss: 0.2192 - val_f1_m: 0.9152\n",
      "0.915\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6569 - f1_m: 0.7912 - val_loss: 0.6294 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6076 - f1_m: 0.7912 - val_loss: 0.5816 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5667 - f1_m: 0.7912 - val_loss: 0.5424 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5379 - f1_m: 0.7912 - val_loss: 0.5209 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5216 - f1_m: 0.7912 - val_loss: 0.5080 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5106 - f1_m: 0.7912 - val_loss: 0.4978 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5005 - f1_m: 0.7912 - val_loss: 0.4875 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4893 - f1_m: 0.7912 - val_loss: 0.4750 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4755 - f1_m: 0.7912 - val_loss: 0.4607 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4606 - f1_m: 0.7912 - val_loss: 0.4465 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4454 - f1_m: 0.7912 - val_loss: 0.4288 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4266 - f1_m: 0.7912 - val_loss: 0.4098 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4061 - f1_m: 0.7912 - val_loss: 0.3882 - val_f1_m: 0.7679\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3836 - f1_m: 0.7912 - val_loss: 0.3659 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3577 - f1_m: 0.7912 - val_loss: 0.3419 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3314 - f1_m: 0.7912 - val_loss: 0.3171 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3045 - f1_m: 0.7912 - val_loss: 0.2920 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2785 - f1_m: 0.8312 - val_loss: 0.2690 - val_f1_m: 0.8527\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2548 - f1_m: 0.8900 - val_loss: 0.2476 - val_f1_m: 0.8884\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2330 - f1_m: 0.9050 - val_loss: 0.2292 - val_f1_m: 0.9196\n",
      "0.9049999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 673us/sample - loss: 0.6564 - f1_m: 0.8037 - val_loss: 0.6447 - val_f1_m: 0.7500\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6032 - f1_m: 0.8037 - val_loss: 0.6105 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5592 - f1_m: 0.8037 - val_loss: 0.5870 - val_f1_m: 0.7500\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5263 - f1_m: 0.8037 - val_loss: 0.5771 - val_f1_m: 0.7098\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5100 - f1_m: 0.8037 - val_loss: 0.5706 - val_f1_m: 0.7366\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4974 - f1_m: 0.8037 - val_loss: 0.5617 - val_f1_m: 0.7366\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4847 - f1_m: 0.8037 - val_loss: 0.5472 - val_f1_m: 0.7500\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4696 - f1_m: 0.8037 - val_loss: 0.5262 - val_f1_m: 0.7500\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4521 - f1_m: 0.8037 - val_loss: 0.5081 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4325 - f1_m: 0.8037 - val_loss: 0.4896 - val_f1_m: 0.7500\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4109 - f1_m: 0.8037 - val_loss: 0.4612 - val_f1_m: 0.7500\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3857 - f1_m: 0.8037 - val_loss: 0.4354 - val_f1_m: 0.7366\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3586 - f1_m: 0.8037 - val_loss: 0.4000 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3288 - f1_m: 0.8037 - val_loss: 0.3689 - val_f1_m: 0.7500\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2989 - f1_m: 0.8037 - val_loss: 0.3354 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2675 - f1_m: 0.8075 - val_loss: 0.2988 - val_f1_m: 0.8705\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2412 - f1_m: 0.9050 - val_loss: 0.2720 - val_f1_m: 0.8482\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2148 - f1_m: 0.9200 - val_loss: 0.2458 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.1949 - f1_m: 0.9425 - val_loss: 0.2264 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.1790 - f1_m: 0.9425 - val_loss: 0.2140 - val_f1_m: 0.9152\n",
      "0.9425\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 676us/sample - loss: 0.6603 - f1_m: 0.7875 - val_loss: 0.6274 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6119 - f1_m: 0.7875 - val_loss: 0.5764 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5693 - f1_m: 0.7875 - val_loss: 0.5336 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5414 - f1_m: 0.7875 - val_loss: 0.5062 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5255 - f1_m: 0.7875 - val_loss: 0.4901 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5156 - f1_m: 0.7875 - val_loss: 0.4786 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5055 - f1_m: 0.7875 - val_loss: 0.4677 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4943 - f1_m: 0.7875 - val_loss: 0.4554 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4819 - f1_m: 0.7875 - val_loss: 0.4426 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4683 - f1_m: 0.7875 - val_loss: 0.4273 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.4530 - f1_m: 0.7875 - val_loss: 0.4098 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4358 - f1_m: 0.7875 - val_loss: 0.3907 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4172 - f1_m: 0.7875 - val_loss: 0.3698 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.3946 - f1_m: 0.7875 - val_loss: 0.3480 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3703 - f1_m: 0.7875 - val_loss: 0.3260 - val_f1_m: 0.8348\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.3446 - f1_m: 0.7875 - val_loss: 0.2981 - val_f1_m: 0.7679\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3176 - f1_m: 0.7875 - val_loss: 0.2756 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2910 - f1_m: 0.8225 - val_loss: 0.2487 - val_f1_m: 0.9196\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2651 - f1_m: 0.8925 - val_loss: 0.2282 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2427 - f1_m: 0.9075 - val_loss: 0.2055 - val_f1_m: 0.9241\n",
      "0.9074999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 690us/sample - loss: 0.6580 - f1_m: 0.7962 - val_loss: 0.6368 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6070 - f1_m: 0.7962 - val_loss: 0.5940 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5637 - f1_m: 0.7962 - val_loss: 0.5640 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5361 - f1_m: 0.7962 - val_loss: 0.5474 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5208 - f1_m: 0.7962 - val_loss: 0.5387 - val_f1_m: 0.7634\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5121 - f1_m: 0.7962 - val_loss: 0.5326 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5054 - f1_m: 0.7962 - val_loss: 0.5272 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4991 - f1_m: 0.7962 - val_loss: 0.5205 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4903 - f1_m: 0.7962 - val_loss: 0.5073 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4760 - f1_m: 0.7962 - val_loss: 0.4926 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4603 - f1_m: 0.7962 - val_loss: 0.4760 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4421 - f1_m: 0.7962 - val_loss: 0.4564 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4210 - f1_m: 0.7962 - val_loss: 0.4340 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3966 - f1_m: 0.7962 - val_loss: 0.4097 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3707 - f1_m: 0.7962 - val_loss: 0.3821 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3424 - f1_m: 0.7962 - val_loss: 0.3530 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3133 - f1_m: 0.7962 - val_loss: 0.3242 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2845 - f1_m: 0.7937 - val_loss: 0.2986 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2577 - f1_m: 0.8800 - val_loss: 0.2738 - val_f1_m: 0.8348\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2339 - f1_m: 0.9025 - val_loss: 0.2513 - val_f1_m: 0.8750\n",
      "0.9024999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 689us/sample - loss: 0.6577 - f1_m: 0.7912 - val_loss: 0.6283 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6081 - f1_m: 0.7912 - val_loss: 0.5802 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5669 - f1_m: 0.7912 - val_loss: 0.5409 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5381 - f1_m: 0.7912 - val_loss: 0.5177 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5208 - f1_m: 0.7912 - val_loss: 0.5029 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5083 - f1_m: 0.7912 - val_loss: 0.4913 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4960 - f1_m: 0.7912 - val_loss: 0.4795 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4828 - f1_m: 0.7912 - val_loss: 0.4657 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4692 - f1_m: 0.7912 - val_loss: 0.4504 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4515 - f1_m: 0.7912 - val_loss: 0.4333 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4294 - f1_m: 0.7912 - val_loss: 0.4089 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4015 - f1_m: 0.7912 - val_loss: 0.3804 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3704 - f1_m: 0.7912 - val_loss: 0.3526 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3383 - f1_m: 0.7912 - val_loss: 0.3204 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3050 - f1_m: 0.7912 - val_loss: 0.2909 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2725 - f1_m: 0.8362 - val_loss: 0.2643 - val_f1_m: 0.9196\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2423 - f1_m: 0.9050 - val_loss: 0.2391 - val_f1_m: 0.9330\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 0.2179 - f1_m: 0.9250 - val_loss: 0.2173 - val_f1_m: 0.9196\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.1948 - f1_m: 0.9350 - val_loss: 0.2051 - val_f1_m: 0.9062\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1794 - f1_m: 0.9413 - val_loss: 0.1919 - val_f1_m: 0.9062\n",
      "0.94125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 684us/sample - loss: 0.6584 - f1_m: 0.7887 - val_loss: 0.6266 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6098 - f1_m: 0.7900 - val_loss: 0.5763 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5685 - f1_m: 0.7900 - val_loss: 0.5341 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5401 - f1_m: 0.7900 - val_loss: 0.5096 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5232 - f1_m: 0.7900 - val_loss: 0.4949 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5119 - f1_m: 0.7900 - val_loss: 0.4837 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5012 - f1_m: 0.7900 - val_loss: 0.4728 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4886 - f1_m: 0.7900 - val_loss: 0.4596 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4723 - f1_m: 0.7900 - val_loss: 0.4411 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4513 - f1_m: 0.7900 - val_loss: 0.4182 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4274 - f1_m: 0.7900 - val_loss: 0.3952 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4015 - f1_m: 0.7900 - val_loss: 0.3682 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3727 - f1_m: 0.7900 - val_loss: 0.3429 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3415 - f1_m: 0.7900 - val_loss: 0.3122 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3096 - f1_m: 0.7900 - val_loss: 0.2832 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2770 - f1_m: 0.8375 - val_loss: 0.2568 - val_f1_m: 0.8973\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2472 - f1_m: 0.8937 - val_loss: 0.2349 - val_f1_m: 0.8884\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2219 - f1_m: 0.9212 - val_loss: 0.2167 - val_f1_m: 0.9152\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2007 - f1_m: 0.9325 - val_loss: 0.2037 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1848 - f1_m: 0.9388 - val_loss: 0.1954 - val_f1_m: 0.9062\n",
      "0.93875\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 791us/sample - loss: 0.6604 - f1_m: 0.7862 - val_loss: 0.6278 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.6111 - f1_m: 0.7875 - val_loss: 0.5771 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5676 - f1_m: 0.7875 - val_loss: 0.5342 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5416 - f1_m: 0.7875 - val_loss: 0.5060 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5250 - f1_m: 0.7875 - val_loss: 0.4929 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5149 - f1_m: 0.7875 - val_loss: 0.4802 - val_f1_m: 0.8348\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5056 - f1_m: 0.7875 - val_loss: 0.4694 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4943 - f1_m: 0.7875 - val_loss: 0.4572 - val_f1_m: 0.8348\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4661 - f1_m: 0.81 - 0s 58us/sample - loss: 0.4817 - f1_m: 0.7875 - val_loss: 0.4430 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4677 - f1_m: 0.7875 - val_loss: 0.4275 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4526 - f1_m: 0.7875 - val_loss: 0.4110 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4343 - f1_m: 0.7875 - val_loss: 0.3924 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4130 - f1_m: 0.7875 - val_loss: 0.3714 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3900 - f1_m: 0.7875 - val_loss: 0.3482 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3649 - f1_m: 0.7875 - val_loss: 0.3259 - val_f1_m: 0.8348\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3391 - f1_m: 0.7875 - val_loss: 0.2976 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3119 - f1_m: 0.7875 - val_loss: 0.2729 - val_f1_m: 0.8348\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2849 - f1_m: 0.8312 - val_loss: 0.2470 - val_f1_m: 0.9062\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2596 - f1_m: 0.8913 - val_loss: 0.2249 - val_f1_m: 0.8750\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2367 - f1_m: 0.9000 - val_loss: 0.2050 - val_f1_m: 0.9241\n",
      "0.8999999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 686us/sample - loss: 0.6579 - f1_m: 0.7912 - val_loss: 0.6319 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6073 - f1_m: 0.7925 - val_loss: 0.5849 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5646 - f1_m: 0.7925 - val_loss: 0.5487 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5366 - f1_m: 0.7925 - val_loss: 0.5274 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5202 - f1_m: 0.7925 - val_loss: 0.5146 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5089 - f1_m: 0.7925 - val_loss: 0.5044 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4980 - f1_m: 0.7925 - val_loss: 0.4932 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4865 - f1_m: 0.7925 - val_loss: 0.4817 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4736 - f1_m: 0.7925 - val_loss: 0.4678 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4591 - f1_m: 0.7925 - val_loss: 0.4538 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4436 - f1_m: 0.7925 - val_loss: 0.4374 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4256 - f1_m: 0.7925 - val_loss: 0.4190 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4046 - f1_m: 0.7925 - val_loss: 0.3967 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3762 - f1_m: 0.7925 - val_loss: 0.3688 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3468 - f1_m: 0.7925 - val_loss: 0.3401 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.3157 - f1_m: 0.7925 - val_loss: 0.3142 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2865 - f1_m: 0.8012 - val_loss: 0.2880 - val_f1_m: 0.8348\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2590 - f1_m: 0.8825 - val_loss: 0.2656 - val_f1_m: 0.8705\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2338 - f1_m: 0.9050 - val_loss: 0.2457 - val_f1_m: 0.8929\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2127 - f1_m: 0.9275 - val_loss: 0.2314 - val_f1_m: 0.8929\n",
      "0.92749995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 678us/sample - loss: 0.6613 - f1_m: 0.7775 - val_loss: 0.6178 - val_f1_m: 0.8527\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6153 - f1_m: 0.7787 - val_loss: 0.5602 - val_f1_m: 0.8661\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5766 - f1_m: 0.7787 - val_loss: 0.5097 - val_f1_m: 0.8661\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5504 - f1_m: 0.7787 - val_loss: 0.4758 - val_f1_m: 0.8393\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5351 - f1_m: 0.7787 - val_loss: 0.4567 - val_f1_m: 0.8661\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5244 - f1_m: 0.7787 - val_loss: 0.4432 - val_f1_m: 0.8527\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5136 - f1_m: 0.7787 - val_loss: 0.4307 - val_f1_m: 0.8661\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5008 - f1_m: 0.7787 - val_loss: 0.4177 - val_f1_m: 0.8527\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4873 - f1_m: 0.7787 - val_loss: 0.4035 - val_f1_m: 0.8661\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4720 - f1_m: 0.7787 - val_loss: 0.3885 - val_f1_m: 0.8661\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4552 - f1_m: 0.7787 - val_loss: 0.3736 - val_f1_m: 0.8527\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4353 - f1_m: 0.7787 - val_loss: 0.3563 - val_f1_m: 0.8661\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4139 - f1_m: 0.7787 - val_loss: 0.3372 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3888 - f1_m: 0.7787 - val_loss: 0.3168 - val_f1_m: 0.8393\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3614 - f1_m: 0.7787 - val_loss: 0.2942 - val_f1_m: 0.8661\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3336 - f1_m: 0.7787 - val_loss: 0.2713 - val_f1_m: 0.8661\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3063 - f1_m: 0.7875 - val_loss: 0.2486 - val_f1_m: 0.8304\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2776 - f1_m: 0.8687 - val_loss: 0.2274 - val_f1_m: 0.8884\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2530 - f1_m: 0.9025 - val_loss: 0.2083 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2315 - f1_m: 0.9162 - val_loss: 0.1913 - val_f1_m: 0.9196\n",
      "0.91624993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 682us/sample - loss: 0.6590 - f1_m: 0.7925 - val_loss: 0.6300 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6086 - f1_m: 0.7937 - val_loss: 0.5839 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5640 - f1_m: 0.7937 - val_loss: 0.5471 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5359 - f1_m: 0.7937 - val_loss: 0.5249 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5187 - f1_m: 0.7937 - val_loss: 0.5140 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5092 - f1_m: 0.7937 - val_loss: 0.5047 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4996 - f1_m: 0.7937 - val_loss: 0.4954 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4886 - f1_m: 0.7937 - val_loss: 0.4843 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4762 - f1_m: 0.7937 - val_loss: 0.4701 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4599 - f1_m: 0.7937 - val_loss: 0.4529 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4407 - f1_m: 0.7937 - val_loss: 0.4310 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4178 - f1_m: 0.7937 - val_loss: 0.4066 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3922 - f1_m: 0.7937 - val_loss: 0.3792 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3659 - f1_m: 0.7937 - val_loss: 0.3509 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3352 - f1_m: 0.7937 - val_loss: 0.3196 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3052 - f1_m: 0.7937 - val_loss: 0.2882 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2765 - f1_m: 0.8400 - val_loss: 0.2594 - val_f1_m: 0.8884\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2494 - f1_m: 0.8912 - val_loss: 0.2345 - val_f1_m: 0.9018\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2278 - f1_m: 0.9100 - val_loss: 0.2134 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2093 - f1_m: 0.9112 - val_loss: 0.1994 - val_f1_m: 0.9464\n",
      "0.91124994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 683us/sample - loss: 0.6581 - f1_m: 0.7900 - val_loss: 0.6319 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.6088 - f1_m: 0.7925 - val_loss: 0.5866 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5676 - f1_m: 0.7925 - val_loss: 0.5487 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5388 - f1_m: 0.7925 - val_loss: 0.5265 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5210 - f1_m: 0.7925 - val_loss: 0.5136 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5104 - f1_m: 0.7925 - val_loss: 0.5038 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5007 - f1_m: 0.7925 - val_loss: 0.4937 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4904 - f1_m: 0.7925 - val_loss: 0.4808 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4757 - f1_m: 0.7925 - val_loss: 0.4638 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4581 - f1_m: 0.7925 - val_loss: 0.4453 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4390 - f1_m: 0.7925 - val_loss: 0.4248 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4162 - f1_m: 0.7925 - val_loss: 0.3987 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3899 - f1_m: 0.7925 - val_loss: 0.3717 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3629 - f1_m: 0.7925 - val_loss: 0.3433 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3336 - f1_m: 0.7925 - val_loss: 0.3113 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3028 - f1_m: 0.7925 - val_loss: 0.2809 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2742 - f1_m: 0.8287 - val_loss: 0.2505 - val_f1_m: 0.8661\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2483 - f1_m: 0.8887 - val_loss: 0.2241 - val_f1_m: 0.9018\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2268 - f1_m: 0.9150 - val_loss: 0.2016 - val_f1_m: 0.9241\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2087 - f1_m: 0.9262 - val_loss: 0.1841 - val_f1_m: 0.9420\n",
      "0.9262499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 695us/sample - loss: 0.6578 - f1_m: 0.7912 - val_loss: 0.6272 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6085 - f1_m: 0.7912 - val_loss: 0.5778 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5653 - f1_m: 0.7912 - val_loss: 0.5391 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5387 - f1_m: 0.7912 - val_loss: 0.5167 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5216 - f1_m: 0.7912 - val_loss: 0.5037 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5110 - f1_m: 0.7912 - val_loss: 0.4936 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5009 - f1_m: 0.7912 - val_loss: 0.4833 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4889 - f1_m: 0.7912 - val_loss: 0.4699 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4726 - f1_m: 0.7912 - val_loss: 0.4533 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4536 - f1_m: 0.7912 - val_loss: 0.4344 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4330 - f1_m: 0.7912 - val_loss: 0.4132 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4084 - f1_m: 0.7912 - val_loss: 0.3891 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3809 - f1_m: 0.7912 - val_loss: 0.3626 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3508 - f1_m: 0.7912 - val_loss: 0.3383 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3189 - f1_m: 0.7912 - val_loss: 0.3050 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2861 - f1_m: 0.8075 - val_loss: 0.2779 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2558 - f1_m: 0.8837 - val_loss: 0.2536 - val_f1_m: 0.8705\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2278 - f1_m: 0.9137 - val_loss: 0.2331 - val_f1_m: 0.9018\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2045 - f1_m: 0.9300 - val_loss: 0.2182 - val_f1_m: 0.8839\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.1861 - f1_m: 0.9413 - val_loss: 0.2067 - val_f1_m: 0.8973\n",
      "0.94125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 681us/sample - loss: 0.6584 - f1_m: 0.7937 - val_loss: 0.6322 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6084 - f1_m: 0.7937 - val_loss: 0.5864 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5673 - f1_m: 0.7937 - val_loss: 0.5505 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5387 - f1_m: 0.7937 - val_loss: 0.5303 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5223 - f1_m: 0.7937 - val_loss: 0.5173 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5108 - f1_m: 0.7937 - val_loss: 0.5065 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5001 - f1_m: 0.7937 - val_loss: 0.4949 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4881 - f1_m: 0.7937 - val_loss: 0.4828 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4755 - f1_m: 0.7937 - val_loss: 0.4702 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4617 - f1_m: 0.7937 - val_loss: 0.4557 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4466 - f1_m: 0.7937 - val_loss: 0.4393 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4289 - f1_m: 0.7937 - val_loss: 0.4198 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4103 - f1_m: 0.7937 - val_loss: 0.3998 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3876 - f1_m: 0.7937 - val_loss: 0.3788 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3641 - f1_m: 0.7937 - val_loss: 0.3515 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3401 - f1_m: 0.7937 - val_loss: 0.3283 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3133 - f1_m: 0.7937 - val_loss: 0.3020 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2883 - f1_m: 0.7975 - val_loss: 0.2768 - val_f1_m: 0.8705\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2642 - f1_m: 0.8550 - val_loss: 0.2603 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2449 - f1_m: 0.8962 - val_loss: 0.2378 - val_f1_m: 0.8839\n",
      "0.89624995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 697us/sample - loss: 0.6566 - f1_m: 0.7975 - val_loss: 0.6355 - val_f1_m: 0.7545\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6024 - f1_m: 0.7987 - val_loss: 0.5940 - val_f1_m: 0.7545\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5580 - f1_m: 0.7987 - val_loss: 0.5638 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5273 - f1_m: 0.7987 - val_loss: 0.5497 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5112 - f1_m: 0.7987 - val_loss: 0.5407 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5002 - f1_m: 0.7987 - val_loss: 0.5323 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4900 - f1_m: 0.7987 - val_loss: 0.5219 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4787 - f1_m: 0.7987 - val_loss: 0.5075 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4657 - f1_m: 0.7987 - val_loss: 0.4911 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.4460 - f1_m: 0.7987 - val_loss: 0.4663 - val_f1_m: 0.7679\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4231 - f1_m: 0.7987 - val_loss: 0.4418 - val_f1_m: 0.7545\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3980 - f1_m: 0.7987 - val_loss: 0.4105 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3701 - f1_m: 0.7987 - val_loss: 0.3786 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3410 - f1_m: 0.7987 - val_loss: 0.3466 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3089 - f1_m: 0.7987 - val_loss: 0.3070 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2776 - f1_m: 0.8050 - val_loss: 0.2727 - val_f1_m: 0.8437\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2496 - f1_m: 0.8887 - val_loss: 0.2415 - val_f1_m: 0.8929\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2248 - f1_m: 0.9100 - val_loss: 0.2185 - val_f1_m: 0.9152\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2042 - f1_m: 0.9225 - val_loss: 0.1921 - val_f1_m: 0.9330\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.1882 - f1_m: 0.9325 - val_loss: 0.1773 - val_f1_m: 0.9241\n",
      "0.9325\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6580 - f1_m: 0.7887 - val_loss: 0.6263 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6078 - f1_m: 0.7887 - val_loss: 0.5743 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5666 - f1_m: 0.7887 - val_loss: 0.5319 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5375 - f1_m: 0.7887 - val_loss: 0.5078 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5220 - f1_m: 0.7887 - val_loss: 0.4929 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5108 - f1_m: 0.7887 - val_loss: 0.4822 - val_f1_m: 0.8304\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5002 - f1_m: 0.7887 - val_loss: 0.4713 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4881 - f1_m: 0.7887 - val_loss: 0.4590 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4740 - f1_m: 0.7887 - val_loss: 0.4444 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4572 - f1_m: 0.7887 - val_loss: 0.4279 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4392 - f1_m: 0.7887 - val_loss: 0.4130 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4188 - f1_m: 0.7887 - val_loss: 0.3921 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3953 - f1_m: 0.7887 - val_loss: 0.3708 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3704 - f1_m: 0.7887 - val_loss: 0.3487 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.3429 - f1_m: 0.7887 - val_loss: 0.3266 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3144 - f1_m: 0.7887 - val_loss: 0.3061 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2850 - f1_m: 0.8162 - val_loss: 0.2791 - val_f1_m: 0.8661\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2589 - f1_m: 0.8850 - val_loss: 0.2634 - val_f1_m: 0.8973\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2355 - f1_m: 0.8975 - val_loss: 0.2483 - val_f1_m: 0.8929\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2127 - f1_m: 0.9187 - val_loss: 0.2346 - val_f1_m: 0.9152\n",
      "0.9187499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 690us/sample - loss: 0.6595 - f1_m: 0.7868 - val_loss: 0.6271 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.6105 - f1_m: 0.7875 - val_loss: 0.5758 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5698 - f1_m: 0.7875 - val_loss: 0.5325 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5417 - f1_m: 0.7875 - val_loss: 0.5086 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5267 - f1_m: 0.7875 - val_loss: 0.4929 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5159 - f1_m: 0.7875 - val_loss: 0.4816 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5068 - f1_m: 0.7875 - val_loss: 0.4705 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4965 - f1_m: 0.7875 - val_loss: 0.4592 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4832 - f1_m: 0.7875 - val_loss: 0.4463 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4696 - f1_m: 0.7875 - val_loss: 0.4313 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4546 - f1_m: 0.7875 - val_loss: 0.4152 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4366 - f1_m: 0.7875 - val_loss: 0.3972 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4161 - f1_m: 0.7875 - val_loss: 0.3765 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3932 - f1_m: 0.7875 - val_loss: 0.3539 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3682 - f1_m: 0.7875 - val_loss: 0.3313 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3428 - f1_m: 0.7875 - val_loss: 0.3060 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3163 - f1_m: 0.7875 - val_loss: 0.2815 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2902 - f1_m: 0.8162 - val_loss: 0.2588 - val_f1_m: 0.8750\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2662 - f1_m: 0.8837 - val_loss: 0.2382 - val_f1_m: 0.8884\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2462 - f1_m: 0.8925 - val_loss: 0.2199 - val_f1_m: 0.8795\n",
      "0.8924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6577 - f1_m: 0.8000 - val_loss: 0.6365 - val_f1_m: 0.7500\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.6054 - f1_m: 0.8000 - val_loss: 0.5957 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5596 - f1_m: 0.8000 - val_loss: 0.5651 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5289 - f1_m: 0.8000 - val_loss: 0.5496 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5116 - f1_m: 0.8000 - val_loss: 0.5404 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4996 - f1_m: 0.8000 - val_loss: 0.5323 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4891 - f1_m: 0.8000 - val_loss: 0.5219 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4760 - f1_m: 0.8000 - val_loss: 0.5067 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4573 - f1_m: 0.8000 - val_loss: 0.4864 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4364 - f1_m: 0.8000 - val_loss: 0.4652 - val_f1_m: 0.7500\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4144 - f1_m: 0.8000 - val_loss: 0.4391 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3880 - f1_m: 0.8000 - val_loss: 0.4121 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3599 - f1_m: 0.8000 - val_loss: 0.3802 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3306 - f1_m: 0.8000 - val_loss: 0.3474 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2993 - f1_m: 0.8000 - val_loss: 0.3132 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2703 - f1_m: 0.8062 - val_loss: 0.2859 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2424 - f1_m: 0.8912 - val_loss: 0.2556 - val_f1_m: 0.8750\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2194 - f1_m: 0.9137 - val_loss: 0.2316 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1991 - f1_m: 0.9237 - val_loss: 0.2089 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.1851 - f1_m: 0.9275 - val_loss: 0.1948 - val_f1_m: 0.9107\n",
      "0.92749995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 679us/sample - loss: 0.6607 - f1_m: 0.7862 - val_loss: 0.6255 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6149 - f1_m: 0.7862 - val_loss: 0.5761 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5759 - f1_m: 0.7862 - val_loss: 0.5320 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5462 - f1_m: 0.7862 - val_loss: 0.5018 - val_f1_m: 0.8393\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5283 - f1_m: 0.7862 - val_loss: 0.4839 - val_f1_m: 0.8259\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5161 - f1_m: 0.7862 - val_loss: 0.4717 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5054 - f1_m: 0.7862 - val_loss: 0.4597 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4929 - f1_m: 0.7862 - val_loss: 0.4469 - val_f1_m: 0.8393\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4781 - f1_m: 0.7862 - val_loss: 0.4325 - val_f1_m: 0.8259\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4633 - f1_m: 0.7862 - val_loss: 0.4187 - val_f1_m: 0.8259\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4471 - f1_m: 0.7862 - val_loss: 0.3989 - val_f1_m: 0.8393\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4233 - f1_m: 0.7862 - val_loss: 0.3766 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3961 - f1_m: 0.7862 - val_loss: 0.3516 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3658 - f1_m: 0.7862 - val_loss: 0.3253 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3335 - f1_m: 0.7862 - val_loss: 0.2951 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3009 - f1_m: 0.7862 - val_loss: 0.2683 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2691 - f1_m: 0.8625 - val_loss: 0.2424 - val_f1_m: 0.8795\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2406 - f1_m: 0.9075 - val_loss: 0.2204 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2158 - f1_m: 0.9275 - val_loss: 0.2061 - val_f1_m: 0.9196\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1951 - f1_m: 0.9450 - val_loss: 0.1899 - val_f1_m: 0.9330\n",
      "0.945\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 678us/sample - loss: 0.6566 - f1_m: 0.7900 - val_loss: 0.6260 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6081 - f1_m: 0.7900 - val_loss: 0.5763 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5673 - f1_m: 0.7900 - val_loss: 0.5363 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5391 - f1_m: 0.7900 - val_loss: 0.5115 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5230 - f1_m: 0.7900 - val_loss: 0.4958 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5115 - f1_m: 0.7900 - val_loss: 0.4845 - val_f1_m: 0.8259\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4999 - f1_m: 0.7900 - val_loss: 0.4728 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4866 - f1_m: 0.7900 - val_loss: 0.4589 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4726 - f1_m: 0.7900 - val_loss: 0.4444 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4584 - f1_m: 0.7900 - val_loss: 0.4302 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4418 - f1_m: 0.7900 - val_loss: 0.4095 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4215 - f1_m: 0.7900 - val_loss: 0.3915 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3996 - f1_m: 0.7900 - val_loss: 0.3663 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3763 - f1_m: 0.7900 - val_loss: 0.3427 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3510 - f1_m: 0.7900 - val_loss: 0.3165 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3230 - f1_m: 0.7900 - val_loss: 0.2910 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2974 - f1_m: 0.7900 - val_loss: 0.2638 - val_f1_m: 0.8259\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2715 - f1_m: 0.8600 - val_loss: 0.2441 - val_f1_m: 0.9286\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2486 - f1_m: 0.8988 - val_loss: 0.2211 - val_f1_m: 0.9375\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2300 - f1_m: 0.9112 - val_loss: 0.2111 - val_f1_m: 0.9241\n",
      "0.91124994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 692us/sample - loss: 0.6597 - f1_m: 0.7900 - val_loss: 0.6275 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6110 - f1_m: 0.7900 - val_loss: 0.5777 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5674 - f1_m: 0.7900 - val_loss: 0.5370 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5379 - f1_m: 0.7900 - val_loss: 0.5113 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5211 - f1_m: 0.7900 - val_loss: 0.4964 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5094 - f1_m: 0.7900 - val_loss: 0.4843 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4985 - f1_m: 0.7900 - val_loss: 0.4727 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4870 - f1_m: 0.7900 - val_loss: 0.4588 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4725 - f1_m: 0.7900 - val_loss: 0.4444 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4576 - f1_m: 0.7900 - val_loss: 0.4278 - val_f1_m: 0.8259\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4404 - f1_m: 0.7900 - val_loss: 0.4096 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4210 - f1_m: 0.7900 - val_loss: 0.3887 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3988 - f1_m: 0.7900 - val_loss: 0.3645 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3739 - f1_m: 0.7900 - val_loss: 0.3380 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3463 - f1_m: 0.7900 - val_loss: 0.3115 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3181 - f1_m: 0.7900 - val_loss: 0.2815 - val_f1_m: 0.8125\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2892 - f1_m: 0.7912 - val_loss: 0.2524 - val_f1_m: 0.9018\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2617 - f1_m: 0.8837 - val_loss: 0.2272 - val_f1_m: 0.9420\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2367 - f1_m: 0.8988 - val_loss: 0.2049 - val_f1_m: 0.9509\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2151 - f1_m: 0.9162 - val_loss: 0.1843 - val_f1_m: 0.9554\n",
      "0.91625\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 677us/sample - loss: 0.6586 - f1_m: 0.7875 - val_loss: 0.6283 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6094 - f1_m: 0.7875 - val_loss: 0.5764 - val_f1_m: 0.8348\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5685 - f1_m: 0.7875 - val_loss: 0.5350 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5411 - f1_m: 0.7875 - val_loss: 0.5096 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5245 - f1_m: 0.7875 - val_loss: 0.4930 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5135 - f1_m: 0.7875 - val_loss: 0.4804 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5020 - f1_m: 0.7875 - val_loss: 0.4667 - val_f1_m: 0.8348\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4894 - f1_m: 0.7875 - val_loss: 0.4534 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4748 - f1_m: 0.7875 - val_loss: 0.4380 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4589 - f1_m: 0.7875 - val_loss: 0.4202 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4405 - f1_m: 0.7875 - val_loss: 0.4006 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4199 - f1_m: 0.7875 - val_loss: 0.3789 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3967 - f1_m: 0.7875 - val_loss: 0.3553 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3689 - f1_m: 0.7875 - val_loss: 0.3282 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3406 - f1_m: 0.7875 - val_loss: 0.3005 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3113 - f1_m: 0.7875 - val_loss: 0.2720 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2818 - f1_m: 0.8137 - val_loss: 0.2441 - val_f1_m: 0.8839\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2544 - f1_m: 0.8962 - val_loss: 0.2183 - val_f1_m: 0.9286\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2286 - f1_m: 0.9212 - val_loss: 0.1963 - val_f1_m: 0.9464\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2081 - f1_m: 0.9400 - val_loss: 0.1773 - val_f1_m: 0.9554\n",
      "0.93999994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 666us/sample - loss: 0.6577 - f1_m: 0.7887 - val_loss: 0.6262 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6091 - f1_m: 0.7887 - val_loss: 0.5742 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5669 - f1_m: 0.7887 - val_loss: 0.5346 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5398 - f1_m: 0.7887 - val_loss: 0.5107 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5246 - f1_m: 0.7887 - val_loss: 0.4953 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5141 - f1_m: 0.7887 - val_loss: 0.4847 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5045 - f1_m: 0.7887 - val_loss: 0.4733 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4928 - f1_m: 0.7887 - val_loss: 0.4605 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4798 - f1_m: 0.7887 - val_loss: 0.4459 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4657 - f1_m: 0.7887 - val_loss: 0.4303 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4502 - f1_m: 0.7887 - val_loss: 0.4130 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4325 - f1_m: 0.7887 - val_loss: 0.3939 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4125 - f1_m: 0.7887 - val_loss: 0.3711 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3896 - f1_m: 0.7887 - val_loss: 0.3477 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3663 - f1_m: 0.7887 - val_loss: 0.3223 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3405 - f1_m: 0.7887 - val_loss: 0.2959 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3144 - f1_m: 0.7887 - val_loss: 0.2704 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2894 - f1_m: 0.8150 - val_loss: 0.2442 - val_f1_m: 0.9062\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2681 - f1_m: 0.8825 - val_loss: 0.2242 - val_f1_m: 0.8929\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2456 - f1_m: 0.8862 - val_loss: 0.2040 - val_f1_m: 0.9464\n",
      "0.8862499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 668us/sample - loss: 0.6565 - f1_m: 0.7975 - val_loss: 0.6335 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6069 - f1_m: 0.7975 - val_loss: 0.5916 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5644 - f1_m: 0.7975 - val_loss: 0.5603 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5348 - f1_m: 0.7975 - val_loss: 0.5438 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5191 - f1_m: 0.7975 - val_loss: 0.5349 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5096 - f1_m: 0.7975 - val_loss: 0.5293 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5029 - f1_m: 0.7975 - val_loss: 0.5243 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4970 - f1_m: 0.7975 - val_loss: 0.5185 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4901 - f1_m: 0.7975 - val_loss: 0.5104 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4816 - f1_m: 0.7975 - val_loss: 0.5014 - val_f1_m: 0.7455\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4727 - f1_m: 0.7975 - val_loss: 0.4926 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4620 - f1_m: 0.7975 - val_loss: 0.4811 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4507 - f1_m: 0.7975 - val_loss: 0.4693 - val_f1_m: 0.7723\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4375 - f1_m: 0.7975 - val_loss: 0.4528 - val_f1_m: 0.7455\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4213 - f1_m: 0.7975 - val_loss: 0.4355 - val_f1_m: 0.7589\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4038 - f1_m: 0.7975 - val_loss: 0.4158 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3848 - f1_m: 0.7975 - val_loss: 0.3935 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3635 - f1_m: 0.7975 - val_loss: 0.3694 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3411 - f1_m: 0.7975 - val_loss: 0.3431 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3172 - f1_m: 0.7975 - val_loss: 0.3175 - val_f1_m: 0.7857\n",
      "0.7974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 680us/sample - loss: 0.6557 - f1_m: 0.8012 - val_loss: 0.6382 - val_f1_m: 0.7455\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6030 - f1_m: 0.8012 - val_loss: 0.5989 - val_f1_m: 0.7589\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5591 - f1_m: 0.8012 - val_loss: 0.5704 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5261 - f1_m: 0.8012 - val_loss: 0.5588 - val_f1_m: 0.7589\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5100 - f1_m: 0.8012 - val_loss: 0.5515 - val_f1_m: 0.7589\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4994 - f1_m: 0.8012 - val_loss: 0.5453 - val_f1_m: 0.7187\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4908 - f1_m: 0.8012 - val_loss: 0.5374 - val_f1_m: 0.7589\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4810 - f1_m: 0.8012 - val_loss: 0.5242 - val_f1_m: 0.7321\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4704 - f1_m: 0.8012 - val_loss: 0.5111 - val_f1_m: 0.7589\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4572 - f1_m: 0.8012 - val_loss: 0.4987 - val_f1_m: 0.7455\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4437 - f1_m: 0.8012 - val_loss: 0.4844 - val_f1_m: 0.7321\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4284 - f1_m: 0.8012 - val_loss: 0.4672 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4119 - f1_m: 0.8012 - val_loss: 0.4448 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3930 - f1_m: 0.8012 - val_loss: 0.4224 - val_f1_m: 0.7455\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3724 - f1_m: 0.8012 - val_loss: 0.3976 - val_f1_m: 0.7589\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3474 - f1_m: 0.8012 - val_loss: 0.3635 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3185 - f1_m: 0.8012 - val_loss: 0.3287 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2905 - f1_m: 0.8012 - val_loss: 0.2969 - val_f1_m: 0.7455\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2644 - f1_m: 0.8487 - val_loss: 0.2638 - val_f1_m: 0.8571\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2426 - f1_m: 0.8787 - val_loss: 0.2367 - val_f1_m: 0.9420\n",
      "0.8787499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 705us/sample - loss: 0.6568 - f1_m: 0.8062 - val_loss: 0.6469 - val_f1_m: 0.7545\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6043 - f1_m: 0.8062 - val_loss: 0.6156 - val_f1_m: 0.7277\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5592 - f1_m: 0.8062 - val_loss: 0.5965 - val_f1_m: 0.7143\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5288 - f1_m: 0.8062 - val_loss: 0.5892 - val_f1_m: 0.7411\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5117 - f1_m: 0.8062 - val_loss: 0.5868 - val_f1_m: 0.7143\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5013 - f1_m: 0.8062 - val_loss: 0.5821 - val_f1_m: 0.7411\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4942 - f1_m: 0.8062 - val_loss: 0.5802 - val_f1_m: 0.7143\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4878 - f1_m: 0.8062 - val_loss: 0.5720 - val_f1_m: 0.7411\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4807 - f1_m: 0.8062 - val_loss: 0.5650 - val_f1_m: 0.7411\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4722 - f1_m: 0.8062 - val_loss: 0.5530 - val_f1_m: 0.7545\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4635 - f1_m: 0.8062 - val_loss: 0.5445 - val_f1_m: 0.7545\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4536 - f1_m: 0.8062 - val_loss: 0.5308 - val_f1_m: 0.7411\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4421 - f1_m: 0.8062 - val_loss: 0.5189 - val_f1_m: 0.7277\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4302 - f1_m: 0.8062 - val_loss: 0.5048 - val_f1_m: 0.7545\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4148 - f1_m: 0.8062 - val_loss: 0.4839 - val_f1_m: 0.7277\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3981 - f1_m: 0.8062 - val_loss: 0.4610 - val_f1_m: 0.7545\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3806 - f1_m: 0.8062 - val_loss: 0.4354 - val_f1_m: 0.7277\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3594 - f1_m: 0.8062 - val_loss: 0.4102 - val_f1_m: 0.7545\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3379 - f1_m: 0.8062 - val_loss: 0.3822 - val_f1_m: 0.7545\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3163 - f1_m: 0.8062 - val_loss: 0.3510 - val_f1_m: 0.7679\n",
      "0.8062499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 684us/sample - loss: 0.6609 - f1_m: 0.7862 - val_loss: 0.6275 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6144 - f1_m: 0.7862 - val_loss: 0.5788 - val_f1_m: 0.8393\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5761 - f1_m: 0.7862 - val_loss: 0.5374 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5483 - f1_m: 0.7862 - val_loss: 0.5079 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5302 - f1_m: 0.7862 - val_loss: 0.4892 - val_f1_m: 0.8393\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5162 - f1_m: 0.7862 - val_loss: 0.4731 - val_f1_m: 0.8393\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5025 - f1_m: 0.7862 - val_loss: 0.4585 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4879 - f1_m: 0.7862 - val_loss: 0.4435 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4703 - f1_m: 0.7862 - val_loss: 0.4268 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4506 - f1_m: 0.7862 - val_loss: 0.4096 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4294 - f1_m: 0.7862 - val_loss: 0.3893 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4061 - f1_m: 0.7862 - val_loss: 0.3678 - val_f1_m: 0.8259\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3817 - f1_m: 0.7862 - val_loss: 0.3458 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3547 - f1_m: 0.7862 - val_loss: 0.3217 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3266 - f1_m: 0.7862 - val_loss: 0.2988 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.2983 - f1_m: 0.7862 - val_loss: 0.2757 - val_f1_m: 0.8661\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2712 - f1_m: 0.8625 - val_loss: 0.2583 - val_f1_m: 0.8973\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2481 - f1_m: 0.8925 - val_loss: 0.2421 - val_f1_m: 0.9018\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2278 - f1_m: 0.9212 - val_loss: 0.2236 - val_f1_m: 0.8705\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2119 - f1_m: 0.9225 - val_loss: 0.2179 - val_f1_m: 0.8839\n",
      "0.9224999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 682us/sample - loss: 0.6601 - f1_m: 0.7850 - val_loss: 0.6250 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6126 - f1_m: 0.7862 - val_loss: 0.5734 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5717 - f1_m: 0.7862 - val_loss: 0.5286 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5431 - f1_m: 0.7862 - val_loss: 0.5004 - val_f1_m: 0.8393\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5266 - f1_m: 0.7862 - val_loss: 0.4850 - val_f1_m: 0.8393\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5154 - f1_m: 0.7862 - val_loss: 0.4737 - val_f1_m: 0.8393\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5054 - f1_m: 0.7862 - val_loss: 0.4621 - val_f1_m: 0.8393\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4941 - f1_m: 0.7862 - val_loss: 0.4512 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4794 - f1_m: 0.7862 - val_loss: 0.4377 - val_f1_m: 0.8259\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4645 - f1_m: 0.7862 - val_loss: 0.4238 - val_f1_m: 0.8259\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4478 - f1_m: 0.7862 - val_loss: 0.4073 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4298 - f1_m: 0.7862 - val_loss: 0.3909 - val_f1_m: 0.8393\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4080 - f1_m: 0.7862 - val_loss: 0.3707 - val_f1_m: 0.8393\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3839 - f1_m: 0.7862 - val_loss: 0.3504 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3593 - f1_m: 0.7862 - val_loss: 0.3274 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3321 - f1_m: 0.7862 - val_loss: 0.3047 - val_f1_m: 0.8393\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3045 - f1_m: 0.7862 - val_loss: 0.2825 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2792 - f1_m: 0.8512 - val_loss: 0.2627 - val_f1_m: 0.8437\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2563 - f1_m: 0.8875 - val_loss: 0.2439 - val_f1_m: 0.8304\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2352 - f1_m: 0.9025 - val_loss: 0.2292 - val_f1_m: 0.9018\n",
      "0.9024999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 692us/sample - loss: 0.6583 - f1_m: 0.7850 - val_loss: 0.6228 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6106 - f1_m: 0.7862 - val_loss: 0.5711 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5729 - f1_m: 0.7862 - val_loss: 0.5300 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5463 - f1_m: 0.7862 - val_loss: 0.5027 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5295 - f1_m: 0.7862 - val_loss: 0.4861 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5176 - f1_m: 0.7862 - val_loss: 0.4740 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5068 - f1_m: 0.7862 - val_loss: 0.4624 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4955 - f1_m: 0.7862 - val_loss: 0.4502 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4822 - f1_m: 0.7862 - val_loss: 0.4368 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4669 - f1_m: 0.7862 - val_loss: 0.4210 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4488 - f1_m: 0.7862 - val_loss: 0.4014 - val_f1_m: 0.8393\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4301 - f1_m: 0.7862 - val_loss: 0.3819 - val_f1_m: 0.8393\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4101 - f1_m: 0.7862 - val_loss: 0.3621 - val_f1_m: 0.8393\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3872 - f1_m: 0.7862 - val_loss: 0.3419 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3649 - f1_m: 0.7862 - val_loss: 0.3197 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3396 - f1_m: 0.7862 - val_loss: 0.3000 - val_f1_m: 0.8393\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3144 - f1_m: 0.7862 - val_loss: 0.2748 - val_f1_m: 0.8259\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2910 - f1_m: 0.8175 - val_loss: 0.2554 - val_f1_m: 0.8884\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2671 - f1_m: 0.8787 - val_loss: 0.2358 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2470 - f1_m: 0.9012 - val_loss: 0.2187 - val_f1_m: 0.8839\n",
      "0.90124995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 682us/sample - loss: 0.6590 - f1_m: 0.7837 - val_loss: 0.6235 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6116 - f1_m: 0.7837 - val_loss: 0.5708 - val_f1_m: 0.8482\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5726 - f1_m: 0.7837 - val_loss: 0.5254 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5430 - f1_m: 0.7837 - val_loss: 0.4948 - val_f1_m: 0.8482\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5267 - f1_m: 0.7837 - val_loss: 0.4734 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5099 - f1_m: 0.7837 - val_loss: 0.4574 - val_f1_m: 0.8348\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4946 - f1_m: 0.7837 - val_loss: 0.4401 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4773 - f1_m: 0.7837 - val_loss: 0.4224 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4569 - f1_m: 0.7837 - val_loss: 0.4027 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4332 - f1_m: 0.7837 - val_loss: 0.3794 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4093 - f1_m: 0.7837 - val_loss: 0.3564 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3823 - f1_m: 0.7837 - val_loss: 0.3317 - val_f1_m: 0.8482\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3535 - f1_m: 0.7837 - val_loss: 0.3072 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3237 - f1_m: 0.7837 - val_loss: 0.2820 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2939 - f1_m: 0.8100 - val_loss: 0.2590 - val_f1_m: 0.8884\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2649 - f1_m: 0.8825 - val_loss: 0.2381 - val_f1_m: 0.8929\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2392 - f1_m: 0.9037 - val_loss: 0.2195 - val_f1_m: 0.9018\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2176 - f1_m: 0.9237 - val_loss: 0.2061 - val_f1_m: 0.9330\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1996 - f1_m: 0.9300 - val_loss: 0.1961 - val_f1_m: 0.9241\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1867 - f1_m: 0.9400 - val_loss: 0.1866 - val_f1_m: 0.9062\n",
      "0.94\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 697us/sample - loss: 0.6591 - f1_m: 0.7800 - val_loss: 0.6169 - val_f1_m: 0.8348\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6145 - f1_m: 0.7800 - val_loss: 0.5562 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5754 - f1_m: 0.7800 - val_loss: 0.5099 - val_f1_m: 0.8616\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5494 - f1_m: 0.7800 - val_loss: 0.4789 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5352 - f1_m: 0.7800 - val_loss: 0.4582 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.5229 - f1_m: 0.7800 - val_loss: 0.4452 - val_f1_m: 0.8348\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5116 - f1_m: 0.7800 - val_loss: 0.4327 - val_f1_m: 0.8348\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4980 - f1_m: 0.7800 - val_loss: 0.4203 - val_f1_m: 0.8482\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4843 - f1_m: 0.7800 - val_loss: 0.4039 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4691 - f1_m: 0.7800 - val_loss: 0.3903 - val_f1_m: 0.8482\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4518 - f1_m: 0.7800 - val_loss: 0.3727 - val_f1_m: 0.8616\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4321 - f1_m: 0.7800 - val_loss: 0.3554 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4111 - f1_m: 0.7800 - val_loss: 0.3327 - val_f1_m: 0.8482\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.3860 - f1_m: 0.7800 - val_loss: 0.3123 - val_f1_m: 0.8348\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3602 - f1_m: 0.7800 - val_loss: 0.2900 - val_f1_m: 0.8616\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.3326 - f1_m: 0.7800 - val_loss: 0.2674 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3065 - f1_m: 0.7875 - val_loss: 0.2459 - val_f1_m: 0.8750\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.2815 - f1_m: 0.8675 - val_loss: 0.2247 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.2597 - f1_m: 0.8925 - val_loss: 0.2057 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2390 - f1_m: 0.9037 - val_loss: 0.1919 - val_f1_m: 0.9286\n",
      "0.90374994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 686us/sample - loss: 0.6588 - f1_m: 0.7887 - val_loss: 0.6278 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6107 - f1_m: 0.7887 - val_loss: 0.5799 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5704 - f1_m: 0.7887 - val_loss: 0.5415 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5412 - f1_m: 0.7887 - val_loss: 0.5145 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5222 - f1_m: 0.7887 - val_loss: 0.4950 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5056 - f1_m: 0.7887 - val_loss: 0.4787 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4896 - f1_m: 0.7887 - val_loss: 0.4611 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4718 - f1_m: 0.7887 - val_loss: 0.4420 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4506 - f1_m: 0.7887 - val_loss: 0.4185 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4275 - f1_m: 0.7887 - val_loss: 0.3952 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4027 - f1_m: 0.7887 - val_loss: 0.3711 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3759 - f1_m: 0.7887 - val_loss: 0.3452 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3491 - f1_m: 0.7887 - val_loss: 0.3181 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3197 - f1_m: 0.7887 - val_loss: 0.2920 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2923 - f1_m: 0.8162 - val_loss: 0.2679 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2656 - f1_m: 0.8725 - val_loss: 0.2456 - val_f1_m: 0.9062\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2428 - f1_m: 0.9000 - val_loss: 0.2269 - val_f1_m: 0.9107\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.2230 - f1_m: 0.9100 - val_loss: 0.2108 - val_f1_m: 0.9152\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2076 - f1_m: 0.9225 - val_loss: 0.1992 - val_f1_m: 0.9152\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1950 - f1_m: 0.9275 - val_loss: 0.1896 - val_f1_m: 0.9196\n",
      "0.9275\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 681us/sample - loss: 0.6573 - f1_m: 0.7975 - val_loss: 0.6364 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6065 - f1_m: 0.7975 - val_loss: 0.5949 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5627 - f1_m: 0.7975 - val_loss: 0.5644 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5317 - f1_m: 0.7975 - val_loss: 0.5491 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5159 - f1_m: 0.7975 - val_loss: 0.5401 - val_f1_m: 0.7455\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5057 - f1_m: 0.7975 - val_loss: 0.5328 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4971 - f1_m: 0.7975 - val_loss: 0.5235 - val_f1_m: 0.7321\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4873 - f1_m: 0.7975 - val_loss: 0.5124 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4760 - f1_m: 0.7975 - val_loss: 0.4993 - val_f1_m: 0.7589\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4631 - f1_m: 0.7975 - val_loss: 0.4834 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4499 - f1_m: 0.7975 - val_loss: 0.4684 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4334 - f1_m: 0.7975 - val_loss: 0.4511 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4155 - f1_m: 0.7975 - val_loss: 0.4312 - val_f1_m: 0.7723\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3955 - f1_m: 0.7975 - val_loss: 0.4073 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3738 - f1_m: 0.7975 - val_loss: 0.3805 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3505 - f1_m: 0.7975 - val_loss: 0.3545 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3276 - f1_m: 0.7975 - val_loss: 0.3271 - val_f1_m: 0.7589\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3044 - f1_m: 0.7975 - val_loss: 0.3026 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2814 - f1_m: 0.8312 - val_loss: 0.2760 - val_f1_m: 0.8259\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2604 - f1_m: 0.8787 - val_loss: 0.2504 - val_f1_m: 0.9018\n",
      "0.8787499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 677us/sample - loss: 0.6583 - f1_m: 0.7812 - val_loss: 0.6206 - val_f1_m: 0.8437\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6118 - f1_m: 0.7812 - val_loss: 0.5640 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5728 - f1_m: 0.7812 - val_loss: 0.5156 - val_f1_m: 0.8571\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5472 - f1_m: 0.7812 - val_loss: 0.4834 - val_f1_m: 0.8437\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5306 - f1_m: 0.7812 - val_loss: 0.4654 - val_f1_m: 0.8437\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5196 - f1_m: 0.7812 - val_loss: 0.4499 - val_f1_m: 0.8571\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5080 - f1_m: 0.7812 - val_loss: 0.4380 - val_f1_m: 0.8571\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4949 - f1_m: 0.7812 - val_loss: 0.4229 - val_f1_m: 0.8571\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4805 - f1_m: 0.7812 - val_loss: 0.4063 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4654 - f1_m: 0.7812 - val_loss: 0.3919 - val_f1_m: 0.8437\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4468 - f1_m: 0.7812 - val_loss: 0.3716 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4259 - f1_m: 0.7812 - val_loss: 0.3527 - val_f1_m: 0.8571\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4024 - f1_m: 0.7812 - val_loss: 0.3287 - val_f1_m: 0.8571\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3766 - f1_m: 0.7812 - val_loss: 0.3043 - val_f1_m: 0.8437\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3485 - f1_m: 0.7812 - val_loss: 0.2796 - val_f1_m: 0.8437\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3207 - f1_m: 0.7812 - val_loss: 0.2547 - val_f1_m: 0.8437\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2926 - f1_m: 0.8075 - val_loss: 0.2330 - val_f1_m: 0.9196\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2667 - f1_m: 0.8875 - val_loss: 0.2125 - val_f1_m: 0.9420\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2437 - f1_m: 0.9012 - val_loss: 0.1929 - val_f1_m: 0.9375\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2240 - f1_m: 0.9212 - val_loss: 0.1766 - val_f1_m: 0.9554\n",
      "0.92125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 693us/sample - loss: 0.6572 - f1_m: 0.7887 - val_loss: 0.6288 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6094 - f1_m: 0.7887 - val_loss: 0.5788 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5680 - f1_m: 0.7887 - val_loss: 0.5382 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5405 - f1_m: 0.7887 - val_loss: 0.5137 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5235 - f1_m: 0.7887 - val_loss: 0.5005 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5136 - f1_m: 0.7887 - val_loss: 0.4887 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5036 - f1_m: 0.7887 - val_loss: 0.4788 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4927 - f1_m: 0.7887 - val_loss: 0.4665 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4796 - f1_m: 0.7887 - val_loss: 0.4520 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4653 - f1_m: 0.7887 - val_loss: 0.4370 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4489 - f1_m: 0.7887 - val_loss: 0.4205 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4310 - f1_m: 0.7887 - val_loss: 0.4026 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4096 - f1_m: 0.7887 - val_loss: 0.3821 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3881 - f1_m: 0.7887 - val_loss: 0.3618 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3628 - f1_m: 0.7887 - val_loss: 0.3359 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3350 - f1_m: 0.7887 - val_loss: 0.3114 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3075 - f1_m: 0.7887 - val_loss: 0.2868 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2796 - f1_m: 0.8200 - val_loss: 0.2637 - val_f1_m: 0.8750\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2547 - f1_m: 0.8900 - val_loss: 0.2428 - val_f1_m: 0.8795\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2320 - f1_m: 0.9100 - val_loss: 0.2246 - val_f1_m: 0.9062\n",
      "0.9099999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 709us/sample - loss: 0.6609 - f1_m: 0.7837 - val_loss: 0.6229 - val_f1_m: 0.8348\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6148 - f1_m: 0.7837 - val_loss: 0.5691 - val_f1_m: 0.8482\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.5762 - f1_m: 0.7837 - val_loss: 0.5253 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5485 - f1_m: 0.7837 - val_loss: 0.4979 - val_f1_m: 0.8482\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5337 - f1_m: 0.7837 - val_loss: 0.4786 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5224 - f1_m: 0.7837 - val_loss: 0.4659 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5123 - f1_m: 0.7837 - val_loss: 0.4550 - val_f1_m: 0.8482\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5007 - f1_m: 0.7837 - val_loss: 0.4428 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4867 - f1_m: 0.7837 - val_loss: 0.4263 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4720 - f1_m: 0.7837 - val_loss: 0.4104 - val_f1_m: 0.8482\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4535 - f1_m: 0.7837 - val_loss: 0.3878 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4278 - f1_m: 0.7837 - val_loss: 0.3630 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3988 - f1_m: 0.7837 - val_loss: 0.3347 - val_f1_m: 0.8482\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3685 - f1_m: 0.7837 - val_loss: 0.3081 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3359 - f1_m: 0.7837 - val_loss: 0.2765 - val_f1_m: 0.8482\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3041 - f1_m: 0.7850 - val_loss: 0.2473 - val_f1_m: 0.8527\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2734 - f1_m: 0.8637 - val_loss: 0.2213 - val_f1_m: 0.8884\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2478 - f1_m: 0.9062 - val_loss: 0.1989 - val_f1_m: 0.9152\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2264 - f1_m: 0.9125 - val_loss: 0.1784 - val_f1_m: 0.9509\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2086 - f1_m: 0.9187 - val_loss: 0.1633 - val_f1_m: 0.9375\n",
      "0.91875\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 695us/sample - loss: 0.6576 - f1_m: 0.7875 - val_loss: 0.6246 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6097 - f1_m: 0.7875 - val_loss: 0.5740 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5693 - f1_m: 0.7875 - val_loss: 0.5304 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5406 - f1_m: 0.7875 - val_loss: 0.5036 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5242 - f1_m: 0.7875 - val_loss: 0.4882 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5138 - f1_m: 0.7875 - val_loss: 0.4772 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5040 - f1_m: 0.7875 - val_loss: 0.4656 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4938 - f1_m: 0.7875 - val_loss: 0.4545 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4790 - f1_m: 0.7875 - val_loss: 0.4370 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4609 - f1_m: 0.7875 - val_loss: 0.4170 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4405 - f1_m: 0.7875 - val_loss: 0.3954 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4161 - f1_m: 0.7875 - val_loss: 0.3699 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3897 - f1_m: 0.7875 - val_loss: 0.3429 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3607 - f1_m: 0.7875 - val_loss: 0.3139 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3310 - f1_m: 0.7875 - val_loss: 0.2836 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3006 - f1_m: 0.7875 - val_loss: 0.2548 - val_f1_m: 0.8750\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2721 - f1_m: 0.8750 - val_loss: 0.2278 - val_f1_m: 0.8839\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2474 - f1_m: 0.9025 - val_loss: 0.2045 - val_f1_m: 0.9062\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2261 - f1_m: 0.9137 - val_loss: 0.1859 - val_f1_m: 0.9509\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2098 - f1_m: 0.9212 - val_loss: 0.1706 - val_f1_m: 0.9509\n",
      "0.9212499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 694us/sample - loss: 0.6573 - f1_m: 0.7950 - val_loss: 0.6344 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6078 - f1_m: 0.7950 - val_loss: 0.5904 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5638 - f1_m: 0.7950 - val_loss: 0.5577 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5334 - f1_m: 0.7950 - val_loss: 0.5395 - val_f1_m: 0.7411\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5172 - f1_m: 0.7950 - val_loss: 0.5280 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5065 - f1_m: 0.7950 - val_loss: 0.5180 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4971 - f1_m: 0.7950 - val_loss: 0.5081 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4863 - f1_m: 0.7950 - val_loss: 0.4950 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4745 - f1_m: 0.7950 - val_loss: 0.4801 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4603 - f1_m: 0.7950 - val_loss: 0.4638 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4439 - f1_m: 0.7950 - val_loss: 0.4430 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4219 - f1_m: 0.7950 - val_loss: 0.4177 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3969 - f1_m: 0.7950 - val_loss: 0.3887 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3689 - f1_m: 0.7950 - val_loss: 0.3585 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3395 - f1_m: 0.7950 - val_loss: 0.3276 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3109 - f1_m: 0.7950 - val_loss: 0.2956 - val_f1_m: 0.7411\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2821 - f1_m: 0.8062 - val_loss: 0.2635 - val_f1_m: 0.8571\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2556 - f1_m: 0.8887 - val_loss: 0.2378 - val_f1_m: 0.8750\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2330 - f1_m: 0.9050 - val_loss: 0.2133 - val_f1_m: 0.9464\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2159 - f1_m: 0.9200 - val_loss: 0.1955 - val_f1_m: 0.9464\n",
      "0.92\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 680us/sample - loss: 0.6600 - f1_m: 0.7825 - val_loss: 0.6216 - val_f1_m: 0.8393\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6122 - f1_m: 0.7825 - val_loss: 0.5653 - val_f1_m: 0.8527\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5714 - f1_m: 0.7825 - val_loss: 0.5198 - val_f1_m: 0.8393\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5456 - f1_m: 0.7825 - val_loss: 0.4906 - val_f1_m: 0.8393\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5308 - f1_m: 0.7825 - val_loss: 0.4719 - val_f1_m: 0.8527\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5217 - f1_m: 0.7825 - val_loss: 0.4603 - val_f1_m: 0.8393\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5106 - f1_m: 0.7825 - val_loss: 0.4518 - val_f1_m: 0.8393\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4994 - f1_m: 0.7825 - val_loss: 0.4385 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4862 - f1_m: 0.7825 - val_loss: 0.4258 - val_f1_m: 0.8259\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4714 - f1_m: 0.7825 - val_loss: 0.4108 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4550 - f1_m: 0.7825 - val_loss: 0.3947 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4361 - f1_m: 0.7825 - val_loss: 0.3779 - val_f1_m: 0.8393\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4140 - f1_m: 0.7825 - val_loss: 0.3576 - val_f1_m: 0.8393\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3901 - f1_m: 0.7825 - val_loss: 0.3375 - val_f1_m: 0.8393\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3640 - f1_m: 0.7825 - val_loss: 0.3174 - val_f1_m: 0.8527\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3375 - f1_m: 0.7825 - val_loss: 0.2970 - val_f1_m: 0.8393\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3100 - f1_m: 0.7825 - val_loss: 0.2730 - val_f1_m: 0.8259\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2846 - f1_m: 0.8300 - val_loss: 0.2580 - val_f1_m: 0.8973\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2597 - f1_m: 0.8862 - val_loss: 0.2361 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2402 - f1_m: 0.8987 - val_loss: 0.2213 - val_f1_m: 0.8929\n",
      "0.89874995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 683us/sample - loss: 0.6584 - f1_m: 0.7950 - val_loss: 0.6326 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6083 - f1_m: 0.7950 - val_loss: 0.5853 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5629 - f1_m: 0.7950 - val_loss: 0.5505 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5324 - f1_m: 0.7950 - val_loss: 0.5306 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5161 - f1_m: 0.7950 - val_loss: 0.5189 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5043 - f1_m: 0.7950 - val_loss: 0.5094 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4935 - f1_m: 0.7950 - val_loss: 0.4993 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4818 - f1_m: 0.7950 - val_loss: 0.4872 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4693 - f1_m: 0.7950 - val_loss: 0.4727 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4543 - f1_m: 0.7950 - val_loss: 0.4582 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4384 - f1_m: 0.7950 - val_loss: 0.4416 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4205 - f1_m: 0.7950 - val_loss: 0.4227 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4005 - f1_m: 0.7950 - val_loss: 0.4000 - val_f1_m: 0.7679\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3764 - f1_m: 0.7950 - val_loss: 0.3760 - val_f1_m: 0.7679\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3505 - f1_m: 0.7950 - val_loss: 0.3487 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3225 - f1_m: 0.7950 - val_loss: 0.3200 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2938 - f1_m: 0.7950 - val_loss: 0.2908 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2647 - f1_m: 0.8537 - val_loss: 0.2626 - val_f1_m: 0.9152\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2334 - f1_m: 0.9150 - val_loss: 0.2297 - val_f1_m: 0.9241\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2049 - f1_m: 0.9262 - val_loss: 0.2062 - val_f1_m: 0.9375\n",
      "0.9262499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6581 - f1_m: 0.7975 - val_loss: 0.6346 - val_f1_m: 0.7723\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6065 - f1_m: 0.7975 - val_loss: 0.5912 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5644 - f1_m: 0.7975 - val_loss: 0.5597 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5350 - f1_m: 0.7975 - val_loss: 0.5416 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5171 - f1_m: 0.7975 - val_loss: 0.5300 - val_f1_m: 0.7589\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5049 - f1_m: 0.7975 - val_loss: 0.5203 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4927 - f1_m: 0.7975 - val_loss: 0.5084 - val_f1_m: 0.7589\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4794 - f1_m: 0.7975 - val_loss: 0.4965 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4648 - f1_m: 0.7975 - val_loss: 0.4818 - val_f1_m: 0.7589\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4498 - f1_m: 0.7975 - val_loss: 0.4653 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4309 - f1_m: 0.7975 - val_loss: 0.4442 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4093 - f1_m: 0.7975 - val_loss: 0.4202 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3852 - f1_m: 0.7975 - val_loss: 0.3928 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3593 - f1_m: 0.7975 - val_loss: 0.3642 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3302 - f1_m: 0.7975 - val_loss: 0.3333 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3019 - f1_m: 0.7975 - val_loss: 0.3018 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2739 - f1_m: 0.8162 - val_loss: 0.2729 - val_f1_m: 0.8795\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2493 - f1_m: 0.8775 - val_loss: 0.2455 - val_f1_m: 0.8973\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2295 - f1_m: 0.9050 - val_loss: 0.2232 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2112 - f1_m: 0.9175 - val_loss: 0.2047 - val_f1_m: 0.9286\n",
      "0.9174999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 683us/sample - loss: 0.6595 - f1_m: 0.7887 - val_loss: 0.6277 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.6095 - f1_m: 0.7900 - val_loss: 0.5766 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5676 - f1_m: 0.7900 - val_loss: 0.5381 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5403 - f1_m: 0.7900 - val_loss: 0.5152 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5255 - f1_m: 0.7900 - val_loss: 0.5024 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5142 - f1_m: 0.7900 - val_loss: 0.4932 - val_f1_m: 0.8259\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5048 - f1_m: 0.7900 - val_loss: 0.4833 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4935 - f1_m: 0.7900 - val_loss: 0.4728 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4809 - f1_m: 0.7900 - val_loss: 0.4596 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4660 - f1_m: 0.7900 - val_loss: 0.4454 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4496 - f1_m: 0.7900 - val_loss: 0.4295 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4312 - f1_m: 0.7900 - val_loss: 0.4120 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4115 - f1_m: 0.7900 - val_loss: 0.3929 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3887 - f1_m: 0.7900 - val_loss: 0.3725 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3641 - f1_m: 0.7900 - val_loss: 0.3505 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3389 - f1_m: 0.7900 - val_loss: 0.3284 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3134 - f1_m: 0.7900 - val_loss: 0.3067 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2886 - f1_m: 0.8187 - val_loss: 0.2849 - val_f1_m: 0.8527\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2656 - f1_m: 0.8675 - val_loss: 0.2666 - val_f1_m: 0.8795\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2456 - f1_m: 0.8937 - val_loss: 0.2510 - val_f1_m: 0.8348\n",
      "0.89374995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 696us/sample - loss: 0.6571 - f1_m: 0.7925 - val_loss: 0.6298 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6073 - f1_m: 0.7925 - val_loss: 0.5847 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5677 - f1_m: 0.7925 - val_loss: 0.5469 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5368 - f1_m: 0.7925 - val_loss: 0.5252 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5208 - f1_m: 0.7925 - val_loss: 0.5113 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5096 - f1_m: 0.7925 - val_loss: 0.5018 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5006 - f1_m: 0.7925 - val_loss: 0.4924 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4900 - f1_m: 0.7925 - val_loss: 0.4804 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4777 - f1_m: 0.7925 - val_loss: 0.4670 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4637 - f1_m: 0.7925 - val_loss: 0.4524 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4489 - f1_m: 0.7925 - val_loss: 0.4367 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4321 - f1_m: 0.7925 - val_loss: 0.4180 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4125 - f1_m: 0.7925 - val_loss: 0.3973 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3915 - f1_m: 0.7925 - val_loss: 0.3742 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3672 - f1_m: 0.7925 - val_loss: 0.3493 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3413 - f1_m: 0.7925 - val_loss: 0.3235 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3154 - f1_m: 0.7925 - val_loss: 0.2974 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2891 - f1_m: 0.8025 - val_loss: 0.2732 - val_f1_m: 0.8884\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2654 - f1_m: 0.8712 - val_loss: 0.2518 - val_f1_m: 0.8884\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2443 - f1_m: 0.8950 - val_loss: 0.2343 - val_f1_m: 0.9018\n",
      "0.8949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 695us/sample - loss: 0.6593 - f1_m: 0.7875 - val_loss: 0.6250 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6122 - f1_m: 0.7875 - val_loss: 0.5749 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5720 - f1_m: 0.7875 - val_loss: 0.5332 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5436 - f1_m: 0.7875 - val_loss: 0.5049 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5229 - f1_m: 0.7875 - val_loss: 0.4835 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5064 - f1_m: 0.7875 - val_loss: 0.4681 - val_f1_m: 0.8348\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4899 - f1_m: 0.7875 - val_loss: 0.4504 - val_f1_m: 0.8348\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4705 - f1_m: 0.7875 - val_loss: 0.4319 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.4499 - f1_m: 0.7875 - val_loss: 0.4101 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4247 - f1_m: 0.7875 - val_loss: 0.3880 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3989 - f1_m: 0.7875 - val_loss: 0.3647 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3710 - f1_m: 0.7875 - val_loss: 0.3402 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3414 - f1_m: 0.7875 - val_loss: 0.3158 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3104 - f1_m: 0.7875 - val_loss: 0.2876 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2783 - f1_m: 0.8087 - val_loss: 0.2602 - val_f1_m: 0.8616\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2472 - f1_m: 0.9125 - val_loss: 0.2369 - val_f1_m: 0.8884\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2204 - f1_m: 0.9287 - val_loss: 0.2177 - val_f1_m: 0.9107\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1987 - f1_m: 0.9425 - val_loss: 0.2034 - val_f1_m: 0.8973\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1819 - f1_m: 0.9425 - val_loss: 0.1921 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.1703 - f1_m: 0.9437 - val_loss: 0.1854 - val_f1_m: 0.9196\n",
      "0.9437499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6586 - f1_m: 0.7930 - val_loss: 0.6325 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6090 - f1_m: 0.7937 - val_loss: 0.5859 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5650 - f1_m: 0.7937 - val_loss: 0.5502 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5358 - f1_m: 0.7937 - val_loss: 0.5296 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5189 - f1_m: 0.7937 - val_loss: 0.5182 - val_f1_m: 0.7455\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5083 - f1_m: 0.7937 - val_loss: 0.5090 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4984 - f1_m: 0.7937 - val_loss: 0.4990 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4872 - f1_m: 0.7937 - val_loss: 0.4865 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4724 - f1_m: 0.7937 - val_loss: 0.4684 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4534 - f1_m: 0.7937 - val_loss: 0.4483 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4312 - f1_m: 0.7937 - val_loss: 0.4252 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4071 - f1_m: 0.7937 - val_loss: 0.3984 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3786 - f1_m: 0.7937 - val_loss: 0.3690 - val_f1_m: 0.7723\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3496 - f1_m: 0.7937 - val_loss: 0.3386 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3203 - f1_m: 0.7937 - val_loss: 0.3087 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2900 - f1_m: 0.7937 - val_loss: 0.2797 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2635 - f1_m: 0.8787 - val_loss: 0.2548 - val_f1_m: 0.8571\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2399 - f1_m: 0.9013 - val_loss: 0.2321 - val_f1_m: 0.9018\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2219 - f1_m: 0.9112 - val_loss: 0.2120 - val_f1_m: 0.9241\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2060 - f1_m: 0.9187 - val_loss: 0.1972 - val_f1_m: 0.9241\n",
      "0.91875\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 677us/sample - loss: 0.6594 - f1_m: 0.7875 - val_loss: 0.6280 - val_f1_m: 0.8348\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.6123 - f1_m: 0.7875 - val_loss: 0.5764 - val_f1_m: 0.8348\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5704 - f1_m: 0.7875 - val_loss: 0.5360 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5421 - f1_m: 0.7875 - val_loss: 0.5089 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5260 - f1_m: 0.7875 - val_loss: 0.4922 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5149 - f1_m: 0.7875 - val_loss: 0.4800 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5032 - f1_m: 0.7875 - val_loss: 0.4674 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4910 - f1_m: 0.7875 - val_loss: 0.4548 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4771 - f1_m: 0.7875 - val_loss: 0.4399 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4619 - f1_m: 0.7875 - val_loss: 0.4247 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4449 - f1_m: 0.7875 - val_loss: 0.4073 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4259 - f1_m: 0.7875 - val_loss: 0.3883 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4032 - f1_m: 0.7875 - val_loss: 0.3672 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3790 - f1_m: 0.7875 - val_loss: 0.3443 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3531 - f1_m: 0.7875 - val_loss: 0.3209 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3257 - f1_m: 0.7875 - val_loss: 0.2965 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3007 - f1_m: 0.7862 - val_loss: 0.2740 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2748 - f1_m: 0.8562 - val_loss: 0.2522 - val_f1_m: 0.8661\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2510 - f1_m: 0.8862 - val_loss: 0.2346 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2320 - f1_m: 0.9037 - val_loss: 0.2187 - val_f1_m: 0.9018\n",
      "0.90374994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 680us/sample - loss: 0.6607 - f1_m: 0.7825 - val_loss: 0.6198 - val_f1_m: 0.8393\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6136 - f1_m: 0.7825 - val_loss: 0.5615 - val_f1_m: 0.8393\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5748 - f1_m: 0.7825 - val_loss: 0.5118 - val_f1_m: 0.8527\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5470 - f1_m: 0.7825 - val_loss: 0.4834 - val_f1_m: 0.8393\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5314 - f1_m: 0.7825 - val_loss: 0.4656 - val_f1_m: 0.8393\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5206 - f1_m: 0.7825 - val_loss: 0.4532 - val_f1_m: 0.8527\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5109 - f1_m: 0.7825 - val_loss: 0.4426 - val_f1_m: 0.8527\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4984 - f1_m: 0.7825 - val_loss: 0.4290 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4851 - f1_m: 0.7825 - val_loss: 0.4158 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4700 - f1_m: 0.7825 - val_loss: 0.3987 - val_f1_m: 0.8393\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4506 - f1_m: 0.7825 - val_loss: 0.3783 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4254 - f1_m: 0.7825 - val_loss: 0.3532 - val_f1_m: 0.8393\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3978 - f1_m: 0.7825 - val_loss: 0.3268 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3661 - f1_m: 0.7825 - val_loss: 0.2989 - val_f1_m: 0.8527\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3343 - f1_m: 0.7825 - val_loss: 0.2674 - val_f1_m: 0.8393\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3000 - f1_m: 0.7850 - val_loss: 0.2399 - val_f1_m: 0.9062\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2670 - f1_m: 0.8825 - val_loss: 0.2125 - val_f1_m: 0.9152\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2381 - f1_m: 0.9200 - val_loss: 0.1883 - val_f1_m: 0.9241\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2130 - f1_m: 0.9312 - val_loss: 0.1698 - val_f1_m: 0.9196\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.1958 - f1_m: 0.9312 - val_loss: 0.1544 - val_f1_m: 0.9330\n",
      "0.9312499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 683us/sample - loss: 0.6586 - f1_m: 0.7912 - val_loss: 0.6323 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6088 - f1_m: 0.7912 - val_loss: 0.5864 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5666 - f1_m: 0.7912 - val_loss: 0.5488 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5386 - f1_m: 0.7912 - val_loss: 0.5270 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5247 - f1_m: 0.7912 - val_loss: 0.5135 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5125 - f1_m: 0.7912 - val_loss: 0.5037 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5021 - f1_m: 0.7912 - val_loss: 0.4927 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4920 - f1_m: 0.7912 - val_loss: 0.4803 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4781 - f1_m: 0.7912 - val_loss: 0.4670 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4638 - f1_m: 0.7912 - val_loss: 0.4525 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4481 - f1_m: 0.7912 - val_loss: 0.4371 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4299 - f1_m: 0.7912 - val_loss: 0.4181 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4093 - f1_m: 0.7912 - val_loss: 0.3988 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3861 - f1_m: 0.7912 - val_loss: 0.3751 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3608 - f1_m: 0.7912 - val_loss: 0.3524 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3343 - f1_m: 0.7912 - val_loss: 0.3268 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3076 - f1_m: 0.7912 - val_loss: 0.3033 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2813 - f1_m: 0.8200 - val_loss: 0.2790 - val_f1_m: 0.8616\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2569 - f1_m: 0.8900 - val_loss: 0.2563 - val_f1_m: 0.8929\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2351 - f1_m: 0.9100 - val_loss: 0.2386 - val_f1_m: 0.8839\n",
      "0.91\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 680us/sample - loss: 0.6556 - f1_m: 0.7975 - val_loss: 0.6353 - val_f1_m: 0.7455\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6054 - f1_m: 0.7975 - val_loss: 0.5935 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5603 - f1_m: 0.7975 - val_loss: 0.5629 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5305 - f1_m: 0.7975 - val_loss: 0.5456 - val_f1_m: 0.7589\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5130 - f1_m: 0.7975 - val_loss: 0.5347 - val_f1_m: 0.7589\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5021 - f1_m: 0.7975 - val_loss: 0.5258 - val_f1_m: 0.7455\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4915 - f1_m: 0.7975 - val_loss: 0.5153 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4809 - f1_m: 0.7975 - val_loss: 0.5012 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4671 - f1_m: 0.7975 - val_loss: 0.4855 - val_f1_m: 0.7455\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4518 - f1_m: 0.7975 - val_loss: 0.4697 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4360 - f1_m: 0.7975 - val_loss: 0.4511 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4173 - f1_m: 0.7975 - val_loss: 0.4313 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3968 - f1_m: 0.7975 - val_loss: 0.4068 - val_f1_m: 0.7723\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3714 - f1_m: 0.7975 - val_loss: 0.3765 - val_f1_m: 0.7589\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3417 - f1_m: 0.7975 - val_loss: 0.3428 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3117 - f1_m: 0.7975 - val_loss: 0.3122 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2814 - f1_m: 0.7975 - val_loss: 0.2765 - val_f1_m: 0.8661\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2534 - f1_m: 0.8875 - val_loss: 0.2522 - val_f1_m: 0.8839\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2313 - f1_m: 0.9025 - val_loss: 0.2283 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2094 - f1_m: 0.9125 - val_loss: 0.2056 - val_f1_m: 0.9062\n",
      "0.9125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 731us/sample - loss: 0.6603 - f1_m: 0.7912 - val_loss: 0.6315 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6113 - f1_m: 0.7912 - val_loss: 0.5831 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5674 - f1_m: 0.7912 - val_loss: 0.5449 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5400 - f1_m: 0.7912 - val_loss: 0.5190 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5214 - f1_m: 0.7912 - val_loss: 0.5048 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5093 - f1_m: 0.7912 - val_loss: 0.4928 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4973 - f1_m: 0.7912 - val_loss: 0.4787 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4811 - f1_m: 0.7912 - val_loss: 0.4608 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4623 - f1_m: 0.7912 - val_loss: 0.4402 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4405 - f1_m: 0.7912 - val_loss: 0.4183 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4156 - f1_m: 0.7912 - val_loss: 0.3902 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3868 - f1_m: 0.7912 - val_loss: 0.3610 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3571 - f1_m: 0.7912 - val_loss: 0.3292 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3232 - f1_m: 0.7912 - val_loss: 0.2972 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2898 - f1_m: 0.7912 - val_loss: 0.2683 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2583 - f1_m: 0.8787 - val_loss: 0.2378 - val_f1_m: 0.9018\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2294 - f1_m: 0.9125 - val_loss: 0.2134 - val_f1_m: 0.9241\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2057 - f1_m: 0.9362 - val_loss: 0.1930 - val_f1_m: 0.9375\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.1865 - f1_m: 0.9413 - val_loss: 0.1784 - val_f1_m: 0.9420\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.1725 - f1_m: 0.9450 - val_loss: 0.1670 - val_f1_m: 0.9286\n",
      "0.945\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6577 - f1_m: 0.7987 - val_loss: 0.6382 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6071 - f1_m: 0.7987 - val_loss: 0.5971 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5624 - f1_m: 0.7987 - val_loss: 0.5684 - val_f1_m: 0.7545\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5326 - f1_m: 0.7987 - val_loss: 0.5545 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5149 - f1_m: 0.7987 - val_loss: 0.5451 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5033 - f1_m: 0.7987 - val_loss: 0.5371 - val_f1_m: 0.7545\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4931 - f1_m: 0.7987 - val_loss: 0.5263 - val_f1_m: 0.7545\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4818 - f1_m: 0.7987 - val_loss: 0.5121 - val_f1_m: 0.7545\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4693 - f1_m: 0.7987 - val_loss: 0.4969 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4554 - f1_m: 0.7987 - val_loss: 0.4826 - val_f1_m: 0.7545\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4400 - f1_m: 0.7987 - val_loss: 0.4640 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4230 - f1_m: 0.7987 - val_loss: 0.4429 - val_f1_m: 0.7411\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4045 - f1_m: 0.7987 - val_loss: 0.4206 - val_f1_m: 0.7545\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3824 - f1_m: 0.7987 - val_loss: 0.3945 - val_f1_m: 0.7679\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3616 - f1_m: 0.7987 - val_loss: 0.3684 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3369 - f1_m: 0.7987 - val_loss: 0.3407 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3126 - f1_m: 0.7987 - val_loss: 0.3107 - val_f1_m: 0.7411\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2913 - f1_m: 0.7987 - val_loss: 0.2909 - val_f1_m: 0.7545\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2676 - f1_m: 0.8600 - val_loss: 0.2572 - val_f1_m: 0.8750\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2473 - f1_m: 0.8950 - val_loss: 0.2365 - val_f1_m: 0.9018\n",
      "0.895\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 680us/sample - loss: 0.6584 - f1_m: 0.7962 - val_loss: 0.6335 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6095 - f1_m: 0.7962 - val_loss: 0.5892 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5670 - f1_m: 0.7962 - val_loss: 0.5554 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5364 - f1_m: 0.7962 - val_loss: 0.5362 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5190 - f1_m: 0.7962 - val_loss: 0.5234 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5058 - f1_m: 0.7962 - val_loss: 0.5126 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4941 - f1_m: 0.7962 - val_loss: 0.5002 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4807 - f1_m: 0.7962 - val_loss: 0.4876 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4660 - f1_m: 0.7962 - val_loss: 0.4723 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4503 - f1_m: 0.7962 - val_loss: 0.4528 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4277 - f1_m: 0.7962 - val_loss: 0.4271 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4017 - f1_m: 0.7962 - val_loss: 0.3966 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3728 - f1_m: 0.7962 - val_loss: 0.3665 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3416 - f1_m: 0.7962 - val_loss: 0.3311 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3092 - f1_m: 0.7962 - val_loss: 0.2943 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2766 - f1_m: 0.8175 - val_loss: 0.2603 - val_f1_m: 0.8705\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2464 - f1_m: 0.8913 - val_loss: 0.2285 - val_f1_m: 0.9241\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2204 - f1_m: 0.9237 - val_loss: 0.2008 - val_f1_m: 0.9509\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.1979 - f1_m: 0.9362 - val_loss: 0.1792 - val_f1_m: 0.9598\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.1791 - f1_m: 0.9475 - val_loss: 0.1629 - val_f1_m: 0.9643\n",
      "0.9475\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 683us/sample - loss: 0.6605 - f1_m: 0.7800 - val_loss: 0.6203 - val_f1_m: 0.8616\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6148 - f1_m: 0.7800 - val_loss: 0.5622 - val_f1_m: 0.8616\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5754 - f1_m: 0.7800 - val_loss: 0.5135 - val_f1_m: 0.8616\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5500 - f1_m: 0.7800 - val_loss: 0.4791 - val_f1_m: 0.8482\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5347 - f1_m: 0.7800 - val_loss: 0.4582 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5226 - f1_m: 0.7800 - val_loss: 0.4440 - val_f1_m: 0.8348\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5107 - f1_m: 0.7800 - val_loss: 0.4294 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4967 - f1_m: 0.7800 - val_loss: 0.4155 - val_f1_m: 0.8616\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4796 - f1_m: 0.7800 - val_loss: 0.3968 - val_f1_m: 0.8482\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4593 - f1_m: 0.7800 - val_loss: 0.3751 - val_f1_m: 0.8482\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4366 - f1_m: 0.7800 - val_loss: 0.3523 - val_f1_m: 0.8482\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4102 - f1_m: 0.7800 - val_loss: 0.3274 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3806 - f1_m: 0.7800 - val_loss: 0.3025 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3497 - f1_m: 0.7800 - val_loss: 0.2717 - val_f1_m: 0.8482\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3180 - f1_m: 0.7800 - val_loss: 0.2459 - val_f1_m: 0.8348\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2874 - f1_m: 0.8225 - val_loss: 0.2238 - val_f1_m: 0.9420\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2581 - f1_m: 0.8987 - val_loss: 0.2032 - val_f1_m: 0.9375\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2336 - f1_m: 0.9125 - val_loss: 0.1814 - val_f1_m: 0.9241\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2160 - f1_m: 0.9162 - val_loss: 0.1691 - val_f1_m: 0.9509\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1987 - f1_m: 0.9287 - val_loss: 0.1599 - val_f1_m: 0.9375\n",
      "0.92875\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 686us/sample - loss: 0.6571 - f1_m: 0.7925 - val_loss: 0.6278 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6087 - f1_m: 0.7925 - val_loss: 0.5804 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5671 - f1_m: 0.7925 - val_loss: 0.5405 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5373 - f1_m: 0.7925 - val_loss: 0.5183 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5216 - f1_m: 0.7925 - val_loss: 0.5051 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5100 - f1_m: 0.7925 - val_loss: 0.4957 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4996 - f1_m: 0.7925 - val_loss: 0.4851 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4871 - f1_m: 0.7925 - val_loss: 0.4736 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4732 - f1_m: 0.7925 - val_loss: 0.4605 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4578 - f1_m: 0.7925 - val_loss: 0.4449 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4412 - f1_m: 0.7925 - val_loss: 0.4274 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4217 - f1_m: 0.7925 - val_loss: 0.4083 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3998 - f1_m: 0.7925 - val_loss: 0.3873 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3762 - f1_m: 0.7925 - val_loss: 0.3625 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3502 - f1_m: 0.7925 - val_loss: 0.3369 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3239 - f1_m: 0.7925 - val_loss: 0.3137 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2979 - f1_m: 0.7925 - val_loss: 0.2860 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2722 - f1_m: 0.8575 - val_loss: 0.2623 - val_f1_m: 0.8571\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2490 - f1_m: 0.8975 - val_loss: 0.2404 - val_f1_m: 0.8929\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2284 - f1_m: 0.9150 - val_loss: 0.2222 - val_f1_m: 0.8929\n",
      "0.9149999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 19s 24ms/sample - loss: 0.6574 - f1_m: 0.7900 - val_loss: 0.6283 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.6097 - f1_m: 0.7912 - val_loss: 0.5798 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5682 - f1_m: 0.7912 - val_loss: 0.5425 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.5411 - f1_m: 0.7912 - val_loss: 0.5177 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.5226 - f1_m: 0.7912 - val_loss: 0.5035 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5105 - f1_m: 0.7912 - val_loss: 0.4916 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4981 - f1_m: 0.7912 - val_loss: 0.4782 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4840 - f1_m: 0.7912 - val_loss: 0.4644 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4669 - f1_m: 0.7912 - val_loss: 0.4462 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4485 - f1_m: 0.7912 - val_loss: 0.4253 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4257 - f1_m: 0.7912 - val_loss: 0.4023 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4003 - f1_m: 0.7912 - val_loss: 0.3774 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3720 - f1_m: 0.7912 - val_loss: 0.3522 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3427 - f1_m: 0.7912 - val_loss: 0.3223 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3132 - f1_m: 0.7912 - val_loss: 0.2942 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.2827 - f1_m: 0.8200 - val_loss: 0.2695 - val_f1_m: 0.8929\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2556 - f1_m: 0.8825 - val_loss: 0.2471 - val_f1_m: 0.8839\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2332 - f1_m: 0.9013 - val_loss: 0.2310 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2142 - f1_m: 0.9112 - val_loss: 0.2193 - val_f1_m: 0.9062\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2014 - f1_m: 0.9262 - val_loss: 0.2090 - val_f1_m: 0.9107\n",
      "0.92625\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 703us/sample - loss: 0.6563 - f1_m: 0.7925 - val_loss: 0.6299 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6071 - f1_m: 0.7925 - val_loss: 0.5820 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5645 - f1_m: 0.7925 - val_loss: 0.5436 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5350 - f1_m: 0.7925 - val_loss: 0.5221 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5182 - f1_m: 0.7925 - val_loss: 0.5113 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5079 - f1_m: 0.7925 - val_loss: 0.5021 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4984 - f1_m: 0.7925 - val_loss: 0.4926 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4872 - f1_m: 0.7925 - val_loss: 0.4809 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4740 - f1_m: 0.7925 - val_loss: 0.4675 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4594 - f1_m: 0.7925 - val_loss: 0.4538 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4441 - f1_m: 0.7925 - val_loss: 0.4381 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4259 - f1_m: 0.7925 - val_loss: 0.4206 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4062 - f1_m: 0.7925 - val_loss: 0.4012 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3836 - f1_m: 0.7925 - val_loss: 0.3809 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3584 - f1_m: 0.7925 - val_loss: 0.3564 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3329 - f1_m: 0.7925 - val_loss: 0.3350 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3071 - f1_m: 0.7925 - val_loss: 0.3110 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2821 - f1_m: 0.7925 - val_loss: 0.2903 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2588 - f1_m: 0.8775 - val_loss: 0.2719 - val_f1_m: 0.8259\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2389 - f1_m: 0.9062 - val_loss: 0.2569 - val_f1_m: 0.8482\n",
      "0.90624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 687us/sample - loss: 0.6559 - f1_m: 0.7962 - val_loss: 0.6372 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6057 - f1_m: 0.7975 - val_loss: 0.5959 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5608 - f1_m: 0.7975 - val_loss: 0.5641 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5300 - f1_m: 0.7975 - val_loss: 0.5469 - val_f1_m: 0.7589\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5134 - f1_m: 0.7975 - val_loss: 0.5373 - val_f1_m: 0.7589\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5023 - f1_m: 0.7975 - val_loss: 0.5271 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4929 - f1_m: 0.7975 - val_loss: 0.5191 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4826 - f1_m: 0.7975 - val_loss: 0.5042 - val_f1_m: 0.7589\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4677 - f1_m: 0.7975 - val_loss: 0.4906 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4535 - f1_m: 0.7975 - val_loss: 0.4765 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4384 - f1_m: 0.7975 - val_loss: 0.4590 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4211 - f1_m: 0.7975 - val_loss: 0.4397 - val_f1_m: 0.7589\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4000 - f1_m: 0.7975 - val_loss: 0.4196 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3778 - f1_m: 0.7975 - val_loss: 0.3953 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3541 - f1_m: 0.7975 - val_loss: 0.3686 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3283 - f1_m: 0.7975 - val_loss: 0.3441 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3037 - f1_m: 0.7975 - val_loss: 0.3170 - val_f1_m: 0.7589\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2778 - f1_m: 0.8050 - val_loss: 0.2904 - val_f1_m: 0.8571\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2558 - f1_m: 0.8912 - val_loss: 0.2675 - val_f1_m: 0.8527\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2352 - f1_m: 0.8988 - val_loss: 0.2470 - val_f1_m: 0.8795\n",
      "0.89875\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 687us/sample - loss: 0.6587 - f1_m: 0.7862 - val_loss: 0.6207 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6114 - f1_m: 0.7862 - val_loss: 0.5663 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5702 - f1_m: 0.7862 - val_loss: 0.5206 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5421 - f1_m: 0.7862 - val_loss: 0.4912 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5257 - f1_m: 0.7862 - val_loss: 0.4758 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5146 - f1_m: 0.7862 - val_loss: 0.4651 - val_f1_m: 0.8259\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5018 - f1_m: 0.7862 - val_loss: 0.4514 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4852 - f1_m: 0.7862 - val_loss: 0.4333 - val_f1_m: 0.8393\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4664 - f1_m: 0.7862 - val_loss: 0.4146 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4458 - f1_m: 0.7862 - val_loss: 0.3953 - val_f1_m: 0.8259\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4221 - f1_m: 0.7862 - val_loss: 0.3716 - val_f1_m: 0.8393\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3947 - f1_m: 0.7862 - val_loss: 0.3472 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3659 - f1_m: 0.7862 - val_loss: 0.3246 - val_f1_m: 0.8393\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3349 - f1_m: 0.7862 - val_loss: 0.2942 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3050 - f1_m: 0.7862 - val_loss: 0.2684 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2732 - f1_m: 0.8662 - val_loss: 0.2456 - val_f1_m: 0.8884\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2454 - f1_m: 0.8975 - val_loss: 0.2290 - val_f1_m: 0.9062\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2216 - f1_m: 0.9162 - val_loss: 0.2161 - val_f1_m: 0.9330\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2024 - f1_m: 0.9312 - val_loss: 0.2026 - val_f1_m: 0.9330\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.1885 - f1_m: 0.9375 - val_loss: 0.1941 - val_f1_m: 0.9196\n",
      "0.9375\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 697us/sample - loss: 0.6589 - f1_m: 0.7962 - val_loss: 0.6335 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6061 - f1_m: 0.7962 - val_loss: 0.5886 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5636 - f1_m: 0.7962 - val_loss: 0.5546 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5338 - f1_m: 0.7962 - val_loss: 0.5369 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5174 - f1_m: 0.7962 - val_loss: 0.5263 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5056 - f1_m: 0.7962 - val_loss: 0.5173 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4949 - f1_m: 0.7962 - val_loss: 0.5069 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4834 - f1_m: 0.7962 - val_loss: 0.4951 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4696 - f1_m: 0.7962 - val_loss: 0.4800 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4535 - f1_m: 0.7962 - val_loss: 0.4642 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4366 - f1_m: 0.7962 - val_loss: 0.4458 - val_f1_m: 0.7500\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4170 - f1_m: 0.7962 - val_loss: 0.4238 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3943 - f1_m: 0.7962 - val_loss: 0.3985 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3652 - f1_m: 0.7962 - val_loss: 0.3663 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3327 - f1_m: 0.7962 - val_loss: 0.3311 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3002 - f1_m: 0.7962 - val_loss: 0.2966 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2682 - f1_m: 0.8262 - val_loss: 0.2644 - val_f1_m: 0.8795\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2392 - f1_m: 0.9075 - val_loss: 0.2367 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2150 - f1_m: 0.9175 - val_loss: 0.2113 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.1954 - f1_m: 0.9375 - val_loss: 0.1946 - val_f1_m: 0.9420\n",
      "0.9375\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 708us/sample - loss: 0.6574 - f1_m: 0.7925 - val_loss: 0.6315 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6069 - f1_m: 0.7937 - val_loss: 0.5854 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.5633 - f1_m: 0.7937 - val_loss: 0.5504 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5344 - f1_m: 0.7937 - val_loss: 0.5299 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5189 - f1_m: 0.7937 - val_loss: 0.5185 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5074 - f1_m: 0.7937 - val_loss: 0.5093 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4979 - f1_m: 0.7937 - val_loss: 0.4993 - val_f1_m: 0.7589\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4865 - f1_m: 0.7937 - val_loss: 0.4867 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.4733 - f1_m: 0.7937 - val_loss: 0.4719 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4581 - f1_m: 0.7937 - val_loss: 0.4567 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4426 - f1_m: 0.7937 - val_loss: 0.4409 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4234 - f1_m: 0.7937 - val_loss: 0.4201 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4022 - f1_m: 0.7937 - val_loss: 0.3988 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3775 - f1_m: 0.7937 - val_loss: 0.3721 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3460 - f1_m: 0.7937 - val_loss: 0.3403 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3133 - f1_m: 0.7937 - val_loss: 0.3104 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2816 - f1_m: 0.7962 - val_loss: 0.2829 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2517 - f1_m: 0.8975 - val_loss: 0.2585 - val_f1_m: 0.8527\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2257 - f1_m: 0.9100 - val_loss: 0.2387 - val_f1_m: 0.8884\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2048 - f1_m: 0.9237 - val_loss: 0.2245 - val_f1_m: 0.8929\n",
      "0.9237499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 688us/sample - loss: 0.6563 - f1_m: 0.7950 - val_loss: 0.6303 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6066 - f1_m: 0.7950 - val_loss: 0.5845 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5643 - f1_m: 0.7950 - val_loss: 0.5494 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5362 - f1_m: 0.7950 - val_loss: 0.5291 - val_f1_m: 0.7411\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5194 - f1_m: 0.7950 - val_loss: 0.5173 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5086 - f1_m: 0.7950 - val_loss: 0.5088 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4980 - f1_m: 0.7950 - val_loss: 0.4993 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4867 - f1_m: 0.7950 - val_loss: 0.4882 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4736 - f1_m: 0.7950 - val_loss: 0.4754 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4590 - f1_m: 0.7950 - val_loss: 0.4615 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4432 - f1_m: 0.7950 - val_loss: 0.4435 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4227 - f1_m: 0.7950 - val_loss: 0.4201 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3988 - f1_m: 0.7950 - val_loss: 0.3959 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3722 - f1_m: 0.7950 - val_loss: 0.3663 - val_f1_m: 0.7679\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3423 - f1_m: 0.7950 - val_loss: 0.3370 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3130 - f1_m: 0.7950 - val_loss: 0.3077 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2850 - f1_m: 0.8012 - val_loss: 0.2800 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2599 - f1_m: 0.8812 - val_loss: 0.2563 - val_f1_m: 0.8839\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2388 - f1_m: 0.9012 - val_loss: 0.2364 - val_f1_m: 0.8884\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2204 - f1_m: 0.9050 - val_loss: 0.2184 - val_f1_m: 0.9196\n",
      "0.9049999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 686us/sample - loss: 0.6572 - f1_m: 0.7829 - val_loss: 0.6170 - val_f1_m: 0.8348\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6111 - f1_m: 0.7837 - val_loss: 0.5616 - val_f1_m: 0.8348\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5717 - f1_m: 0.7837 - val_loss: 0.5157 - val_f1_m: 0.8482\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5453 - f1_m: 0.7837 - val_loss: 0.4869 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5302 - f1_m: 0.7837 - val_loss: 0.4697 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5175 - f1_m: 0.7837 - val_loss: 0.4569 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5058 - f1_m: 0.7837 - val_loss: 0.4449 - val_f1_m: 0.8348\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4919 - f1_m: 0.7837 - val_loss: 0.4322 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4773 - f1_m: 0.7837 - val_loss: 0.4179 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4609 - f1_m: 0.7837 - val_loss: 0.4036 - val_f1_m: 0.8482\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4416 - f1_m: 0.7837 - val_loss: 0.3849 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4199 - f1_m: 0.7837 - val_loss: 0.3649 - val_f1_m: 0.8482\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3957 - f1_m: 0.7837 - val_loss: 0.3456 - val_f1_m: 0.8482\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3693 - f1_m: 0.7837 - val_loss: 0.3239 - val_f1_m: 0.8348\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3414 - f1_m: 0.7837 - val_loss: 0.3044 - val_f1_m: 0.8348\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3139 - f1_m: 0.7837 - val_loss: 0.2812 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2865 - f1_m: 0.8325 - val_loss: 0.2624 - val_f1_m: 0.8527\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2607 - f1_m: 0.8850 - val_loss: 0.2458 - val_f1_m: 0.8884\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2374 - f1_m: 0.9025 - val_loss: 0.2315 - val_f1_m: 0.8884\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2187 - f1_m: 0.9187 - val_loss: 0.2219 - val_f1_m: 0.9062\n",
      "0.9187499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 702us/sample - loss: 0.6564 - f1_m: 0.7975 - val_loss: 0.6361 - val_f1_m: 0.7589\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6063 - f1_m: 0.7975 - val_loss: 0.5952 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5632 - f1_m: 0.7975 - val_loss: 0.5650 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5338 - f1_m: 0.7975 - val_loss: 0.5480 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5164 - f1_m: 0.7975 - val_loss: 0.5378 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5056 - f1_m: 0.7975 - val_loss: 0.5300 - val_f1_m: 0.7589\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4957 - f1_m: 0.7975 - val_loss: 0.5205 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4847 - f1_m: 0.7975 - val_loss: 0.5070 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4717 - f1_m: 0.7975 - val_loss: 0.4939 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4587 - f1_m: 0.7975 - val_loss: 0.4811 - val_f1_m: 0.7455\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4440 - f1_m: 0.7975 - val_loss: 0.4650 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4285 - f1_m: 0.7975 - val_loss: 0.4486 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4107 - f1_m: 0.7975 - val_loss: 0.4266 - val_f1_m: 0.7321\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3892 - f1_m: 0.7975 - val_loss: 0.4044 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3669 - f1_m: 0.7975 - val_loss: 0.3830 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3434 - f1_m: 0.7975 - val_loss: 0.3558 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3194 - f1_m: 0.7975 - val_loss: 0.3271 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2958 - f1_m: 0.7975 - val_loss: 0.3024 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2724 - f1_m: 0.8450 - val_loss: 0.2795 - val_f1_m: 0.8527\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2514 - f1_m: 0.8812 - val_loss: 0.2556 - val_f1_m: 0.8571\n",
      "0.8812499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 682us/sample - loss: 0.6565 - f1_m: 0.7925 - val_loss: 0.6321 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6081 - f1_m: 0.7925 - val_loss: 0.5868 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5647 - f1_m: 0.7925 - val_loss: 0.5501 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5364 - f1_m: 0.7925 - val_loss: 0.5272 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5192 - f1_m: 0.7925 - val_loss: 0.5149 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5086 - f1_m: 0.7925 - val_loss: 0.5045 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4998 - f1_m: 0.7925 - val_loss: 0.4935 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4877 - f1_m: 0.7925 - val_loss: 0.4801 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4711 - f1_m: 0.7925 - val_loss: 0.4612 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4531 - f1_m: 0.7925 - val_loss: 0.4430 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4328 - f1_m: 0.7925 - val_loss: 0.4210 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4086 - f1_m: 0.7925 - val_loss: 0.3966 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3824 - f1_m: 0.7925 - val_loss: 0.3698 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3541 - f1_m: 0.7925 - val_loss: 0.3425 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3251 - f1_m: 0.7925 - val_loss: 0.3146 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2937 - f1_m: 0.7925 - val_loss: 0.2834 - val_f1_m: 0.8125\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2653 - f1_m: 0.8662 - val_loss: 0.2564 - val_f1_m: 0.8884\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2393 - f1_m: 0.9025 - val_loss: 0.2372 - val_f1_m: 0.8705\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2168 - f1_m: 0.9112 - val_loss: 0.2158 - val_f1_m: 0.9152\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2000 - f1_m: 0.9237 - val_loss: 0.2010 - val_f1_m: 0.9330\n",
      "0.92375\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 677us/sample - loss: 0.6594 - f1_m: 0.7862 - val_loss: 0.6237 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6114 - f1_m: 0.7862 - val_loss: 0.5724 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5752 - f1_m: 0.7862 - val_loss: 0.5293 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5466 - f1_m: 0.7862 - val_loss: 0.4997 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5271 - f1_m: 0.7862 - val_loss: 0.4786 - val_f1_m: 0.8393\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5110 - f1_m: 0.7862 - val_loss: 0.4624 - val_f1_m: 0.8259\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4946 - f1_m: 0.7862 - val_loss: 0.4445 - val_f1_m: 0.8259\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4771 - f1_m: 0.7862 - val_loss: 0.4260 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4567 - f1_m: 0.7862 - val_loss: 0.4047 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4346 - f1_m: 0.7862 - val_loss: 0.3824 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4112 - f1_m: 0.7862 - val_loss: 0.3579 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3859 - f1_m: 0.7862 - val_loss: 0.3337 - val_f1_m: 0.8393\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3594 - f1_m: 0.7862 - val_loss: 0.3067 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3328 - f1_m: 0.7862 - val_loss: 0.2789 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3050 - f1_m: 0.7862 - val_loss: 0.2535 - val_f1_m: 0.8482\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2808 - f1_m: 0.8687 - val_loss: 0.2290 - val_f1_m: 0.9107\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2576 - f1_m: 0.8825 - val_loss: 0.2069 - val_f1_m: 0.9152\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2392 - f1_m: 0.9075 - val_loss: 0.1880 - val_f1_m: 0.9241\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2230 - f1_m: 0.9150 - val_loss: 0.1711 - val_f1_m: 0.9464\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2097 - f1_m: 0.9200 - val_loss: 0.1579 - val_f1_m: 0.9509\n",
      "0.9199999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 696us/sample - loss: 0.6589 - f1_m: 0.8000 - val_loss: 0.6404 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6073 - f1_m: 0.8000 - val_loss: 0.6020 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5612 - f1_m: 0.8000 - val_loss: 0.5724 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5291 - f1_m: 0.8000 - val_loss: 0.5567 - val_f1_m: 0.7500\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5102 - f1_m: 0.8000 - val_loss: 0.5468 - val_f1_m: 0.7500\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4986 - f1_m: 0.8000 - val_loss: 0.5390 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4874 - f1_m: 0.8000 - val_loss: 0.5278 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4763 - f1_m: 0.8000 - val_loss: 0.5120 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4609 - f1_m: 0.8000 - val_loss: 0.4972 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4455 - f1_m: 0.8000 - val_loss: 0.4822 - val_f1_m: 0.7634\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4286 - f1_m: 0.8000 - val_loss: 0.4634 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4077 - f1_m: 0.8000 - val_loss: 0.4368 - val_f1_m: 0.7500\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3797 - f1_m: 0.8000 - val_loss: 0.4050 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3488 - f1_m: 0.8000 - val_loss: 0.3700 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3164 - f1_m: 0.8000 - val_loss: 0.3360 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2837 - f1_m: 0.8000 - val_loss: 0.2977 - val_f1_m: 0.7500\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.2526 - f1_m: 0.8625 - val_loss: 0.2649 - val_f1_m: 0.8795\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2233 - f1_m: 0.9137 - val_loss: 0.2334 - val_f1_m: 0.9018\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1995 - f1_m: 0.9262 - val_loss: 0.2046 - val_f1_m: 0.9375\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1806 - f1_m: 0.9488 - val_loss: 0.1829 - val_f1_m: 0.9375\n",
      "0.94875\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 678us/sample - loss: 0.6572 - f1_m: 0.7950 - val_loss: 0.6322 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6067 - f1_m: 0.7950 - val_loss: 0.5870 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5631 - f1_m: 0.7950 - val_loss: 0.5512 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5330 - f1_m: 0.7950 - val_loss: 0.5310 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5167 - f1_m: 0.7950 - val_loss: 0.5190 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5056 - f1_m: 0.7950 - val_loss: 0.5090 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4950 - f1_m: 0.7950 - val_loss: 0.4979 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4831 - f1_m: 0.7950 - val_loss: 0.4847 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4685 - f1_m: 0.7950 - val_loss: 0.4713 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4542 - f1_m: 0.7950 - val_loss: 0.4563 - val_f1_m: 0.7679\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4380 - f1_m: 0.7950 - val_loss: 0.4393 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4193 - f1_m: 0.7950 - val_loss: 0.4193 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3988 - f1_m: 0.7950 - val_loss: 0.3972 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3757 - f1_m: 0.7950 - val_loss: 0.3724 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3507 - f1_m: 0.7950 - val_loss: 0.3477 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3244 - f1_m: 0.7950 - val_loss: 0.3231 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2996 - f1_m: 0.7950 - val_loss: 0.2972 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2745 - f1_m: 0.8212 - val_loss: 0.2744 - val_f1_m: 0.8795\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2521 - f1_m: 0.8862 - val_loss: 0.2539 - val_f1_m: 0.8884\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2324 - f1_m: 0.9025 - val_loss: 0.2373 - val_f1_m: 0.8929\n",
      "0.9024999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 691us/sample - loss: 0.6573 - f1_m: 0.7880 - val_loss: 0.6246 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6086 - f1_m: 0.7887 - val_loss: 0.5753 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5674 - f1_m: 0.7887 - val_loss: 0.5331 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5392 - f1_m: 0.7887 - val_loss: 0.5053 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5246 - f1_m: 0.7887 - val_loss: 0.4914 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5133 - f1_m: 0.7887 - val_loss: 0.4825 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5040 - f1_m: 0.7887 - val_loss: 0.4718 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4929 - f1_m: 0.7887 - val_loss: 0.4588 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4791 - f1_m: 0.7887 - val_loss: 0.4449 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4645 - f1_m: 0.7887 - val_loss: 0.4294 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4480 - f1_m: 0.7887 - val_loss: 0.4125 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4293 - f1_m: 0.7887 - val_loss: 0.3926 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4087 - f1_m: 0.7887 - val_loss: 0.3724 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3851 - f1_m: 0.7887 - val_loss: 0.3488 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3602 - f1_m: 0.7887 - val_loss: 0.3246 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3336 - f1_m: 0.7887 - val_loss: 0.3008 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3072 - f1_m: 0.7887 - val_loss: 0.2766 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2811 - f1_m: 0.8600 - val_loss: 0.2538 - val_f1_m: 0.8705\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2572 - f1_m: 0.8937 - val_loss: 0.2355 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2358 - f1_m: 0.9037 - val_loss: 0.2187 - val_f1_m: 0.9196\n",
      "0.90374994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 702us/sample - loss: 0.6592 - f1_m: 0.7962 - val_loss: 0.6350 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6090 - f1_m: 0.7962 - val_loss: 0.5905 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5645 - f1_m: 0.7962 - val_loss: 0.5572 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5349 - f1_m: 0.7962 - val_loss: 0.5376 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5182 - f1_m: 0.7962 - val_loss: 0.5269 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5073 - f1_m: 0.7962 - val_loss: 0.5180 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4977 - f1_m: 0.7962 - val_loss: 0.5082 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4861 - f1_m: 0.7962 - val_loss: 0.4958 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4729 - f1_m: 0.7962 - val_loss: 0.4833 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4588 - f1_m: 0.7962 - val_loss: 0.4695 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4437 - f1_m: 0.7962 - val_loss: 0.4528 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4263 - f1_m: 0.7962 - val_loss: 0.4341 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4063 - f1_m: 0.7962 - val_loss: 0.4123 - val_f1_m: 0.7500\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3840 - f1_m: 0.7962 - val_loss: 0.3874 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3601 - f1_m: 0.7962 - val_loss: 0.3612 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3343 - f1_m: 0.7962 - val_loss: 0.3335 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3095 - f1_m: 0.7962 - val_loss: 0.3051 - val_f1_m: 0.7634\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2837 - f1_m: 0.8050 - val_loss: 0.2788 - val_f1_m: 0.8571\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2603 - f1_m: 0.8825 - val_loss: 0.2530 - val_f1_m: 0.8705\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2393 - f1_m: 0.9013 - val_loss: 0.2314 - val_f1_m: 0.8929\n",
      "0.90125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 675us/sample - loss: 0.6589 - f1_m: 0.7900 - val_loss: 0.6292 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6098 - f1_m: 0.7900 - val_loss: 0.5805 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5693 - f1_m: 0.7900 - val_loss: 0.5419 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5397 - f1_m: 0.7900 - val_loss: 0.5154 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5210 - f1_m: 0.7900 - val_loss: 0.4962 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5061 - f1_m: 0.7900 - val_loss: 0.4814 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4912 - f1_m: 0.7900 - val_loss: 0.4647 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4751 - f1_m: 0.7900 - val_loss: 0.4465 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4560 - f1_m: 0.7900 - val_loss: 0.4246 - val_f1_m: 0.8259\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4331 - f1_m: 0.7900 - val_loss: 0.4004 - val_f1_m: 0.8259\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4084 - f1_m: 0.7900 - val_loss: 0.3745 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3820 - f1_m: 0.7900 - val_loss: 0.3469 - val_f1_m: 0.8259\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3543 - f1_m: 0.7900 - val_loss: 0.3175 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3256 - f1_m: 0.7900 - val_loss: 0.2883 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2967 - f1_m: 0.8000 - val_loss: 0.2587 - val_f1_m: 0.8884\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2693 - f1_m: 0.8712 - val_loss: 0.2319 - val_f1_m: 0.9152\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2444 - f1_m: 0.8937 - val_loss: 0.2102 - val_f1_m: 0.9464\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2240 - f1_m: 0.9137 - val_loss: 0.1903 - val_f1_m: 0.9554\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2057 - f1_m: 0.9212 - val_loss: 0.1735 - val_f1_m: 0.9554\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.1927 - f1_m: 0.9300 - val_loss: 0.1613 - val_f1_m: 0.9554\n",
      "0.93\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 684us/sample - loss: 0.6572 - f1_m: 0.7887 - val_loss: 0.6251 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6091 - f1_m: 0.7887 - val_loss: 0.5743 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5683 - f1_m: 0.7887 - val_loss: 0.5322 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5399 - f1_m: 0.7887 - val_loss: 0.5072 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5237 - f1_m: 0.7887 - val_loss: 0.4929 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5131 - f1_m: 0.7887 - val_loss: 0.4816 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5033 - f1_m: 0.7887 - val_loss: 0.4708 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4919 - f1_m: 0.7887 - val_loss: 0.4590 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4782 - f1_m: 0.7887 - val_loss: 0.4449 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4637 - f1_m: 0.7887 - val_loss: 0.4298 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4478 - f1_m: 0.7887 - val_loss: 0.4134 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4296 - f1_m: 0.7887 - val_loss: 0.3935 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4084 - f1_m: 0.7887 - val_loss: 0.3719 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3851 - f1_m: 0.7887 - val_loss: 0.3485 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3592 - f1_m: 0.7887 - val_loss: 0.3208 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3284 - f1_m: 0.7887 - val_loss: 0.2888 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2964 - f1_m: 0.7937 - val_loss: 0.2570 - val_f1_m: 0.8571\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2672 - f1_m: 0.8762 - val_loss: 0.2297 - val_f1_m: 0.8973\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2428 - f1_m: 0.8925 - val_loss: 0.2080 - val_f1_m: 0.9152\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2230 - f1_m: 0.9012 - val_loss: 0.1877 - val_f1_m: 0.9196\n",
      "0.90124995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 689us/sample - loss: 0.6576 - f1_m: 0.7975 - val_loss: 0.6365 - val_f1_m: 0.7589\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6052 - f1_m: 0.7975 - val_loss: 0.5943 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5612 - f1_m: 0.7975 - val_loss: 0.5626 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5313 - f1_m: 0.7975 - val_loss: 0.5460 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5144 - f1_m: 0.7975 - val_loss: 0.5356 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5032 - f1_m: 0.7975 - val_loss: 0.5262 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4928 - f1_m: 0.7975 - val_loss: 0.5138 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4806 - f1_m: 0.7975 - val_loss: 0.5003 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4667 - f1_m: 0.7975 - val_loss: 0.4844 - val_f1_m: 0.7455\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4518 - f1_m: 0.7975 - val_loss: 0.4679 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4351 - f1_m: 0.7975 - val_loss: 0.4481 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4160 - f1_m: 0.7975 - val_loss: 0.4253 - val_f1_m: 0.7589\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3944 - f1_m: 0.7975 - val_loss: 0.4032 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3704 - f1_m: 0.7975 - val_loss: 0.3695 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3384 - f1_m: 0.7975 - val_loss: 0.3359 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3092 - f1_m: 0.7975 - val_loss: 0.2980 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2772 - f1_m: 0.8162 - val_loss: 0.2648 - val_f1_m: 0.8750\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2497 - f1_m: 0.8875 - val_loss: 0.2337 - val_f1_m: 0.9330\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2260 - f1_m: 0.9150 - val_loss: 0.2091 - val_f1_m: 0.9241\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2067 - f1_m: 0.9250 - val_loss: 0.1895 - val_f1_m: 0.9464\n",
      "0.92499995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 677us/sample - loss: 0.6584 - f1_m: 0.7975 - val_loss: 0.6334 - val_f1_m: 0.7589\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6070 - f1_m: 0.7975 - val_loss: 0.5896 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5622 - f1_m: 0.7975 - val_loss: 0.5568 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5317 - f1_m: 0.7975 - val_loss: 0.5402 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5163 - f1_m: 0.7975 - val_loss: 0.5311 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5064 - f1_m: 0.7975 - val_loss: 0.5250 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4989 - f1_m: 0.7975 - val_loss: 0.5183 - val_f1_m: 0.7589\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4898 - f1_m: 0.7975 - val_loss: 0.5086 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4790 - f1_m: 0.7975 - val_loss: 0.4973 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4664 - f1_m: 0.7975 - val_loss: 0.4853 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4531 - f1_m: 0.7975 - val_loss: 0.4719 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4380 - f1_m: 0.7975 - val_loss: 0.4563 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4211 - f1_m: 0.7975 - val_loss: 0.4372 - val_f1_m: 0.7723\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4011 - f1_m: 0.7975 - val_loss: 0.4162 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3807 - f1_m: 0.7975 - val_loss: 0.3938 - val_f1_m: 0.7589\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3582 - f1_m: 0.7975 - val_loss: 0.3704 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3348 - f1_m: 0.7975 - val_loss: 0.3456 - val_f1_m: 0.7455\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3131 - f1_m: 0.7975 - val_loss: 0.3219 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2911 - f1_m: 0.7975 - val_loss: 0.3006 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2716 - f1_m: 0.8650 - val_loss: 0.2817 - val_f1_m: 0.8348\n",
      "0.86499995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6575 - f1_m: 0.7987 - val_loss: 0.6349 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6042 - f1_m: 0.7987 - val_loss: 0.5939 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5615 - f1_m: 0.7987 - val_loss: 0.5627 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5311 - f1_m: 0.7987 - val_loss: 0.5475 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5148 - f1_m: 0.7987 - val_loss: 0.5386 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5042 - f1_m: 0.7987 - val_loss: 0.5312 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4950 - f1_m: 0.7987 - val_loss: 0.5221 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4846 - f1_m: 0.7987 - val_loss: 0.5105 - val_f1_m: 0.7545\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4714 - f1_m: 0.7987 - val_loss: 0.4944 - val_f1_m: 0.7411\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4537 - f1_m: 0.7987 - val_loss: 0.4747 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4335 - f1_m: 0.7987 - val_loss: 0.4513 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4105 - f1_m: 0.7987 - val_loss: 0.4246 - val_f1_m: 0.7545\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3855 - f1_m: 0.7987 - val_loss: 0.3945 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3572 - f1_m: 0.7987 - val_loss: 0.3637 - val_f1_m: 0.7679\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3291 - f1_m: 0.7987 - val_loss: 0.3305 - val_f1_m: 0.7545\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3000 - f1_m: 0.7987 - val_loss: 0.2969 - val_f1_m: 0.7679\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2720 - f1_m: 0.8337 - val_loss: 0.2643 - val_f1_m: 0.8839\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2459 - f1_m: 0.8725 - val_loss: 0.2379 - val_f1_m: 0.9018\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2246 - f1_m: 0.9062 - val_loss: 0.2152 - val_f1_m: 0.9196\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2078 - f1_m: 0.9175 - val_loss: 0.1960 - val_f1_m: 0.9375\n",
      "0.9174999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 675us/sample - loss: 0.6559 - f1_m: 0.7887 - val_loss: 0.6254 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6075 - f1_m: 0.7887 - val_loss: 0.5712 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5636 - f1_m: 0.7887 - val_loss: 0.5320 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5372 - f1_m: 0.7887 - val_loss: 0.5066 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5229 - f1_m: 0.7887 - val_loss: 0.4934 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5134 - f1_m: 0.7887 - val_loss: 0.4827 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5054 - f1_m: 0.7887 - val_loss: 0.4719 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4950 - f1_m: 0.7887 - val_loss: 0.4608 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4843 - f1_m: 0.7887 - val_loss: 0.4472 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4704 - f1_m: 0.7887 - val_loss: 0.4337 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4554 - f1_m: 0.7887 - val_loss: 0.4147 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4391 - f1_m: 0.7887 - val_loss: 0.3958 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4201 - f1_m: 0.7887 - val_loss: 0.3734 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3985 - f1_m: 0.7887 - val_loss: 0.3508 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3762 - f1_m: 0.7887 - val_loss: 0.3240 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3509 - f1_m: 0.7887 - val_loss: 0.2958 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3277 - f1_m: 0.7887 - val_loss: 0.2679 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3028 - f1_m: 0.7837 - val_loss: 0.2419 - val_f1_m: 0.8125\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2800 - f1_m: 0.8375 - val_loss: 0.2197 - val_f1_m: 0.9196\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2607 - f1_m: 0.8825 - val_loss: 0.1956 - val_f1_m: 0.9241\n",
      "0.88249993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 692us/sample - loss: 0.6556 - f1_m: 0.8000 - val_loss: 0.6395 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6046 - f1_m: 0.8000 - val_loss: 0.6015 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5602 - f1_m: 0.8000 - val_loss: 0.5729 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5283 - f1_m: 0.8000 - val_loss: 0.5588 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5111 - f1_m: 0.8000 - val_loss: 0.5507 - val_f1_m: 0.7634\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4998 - f1_m: 0.8000 - val_loss: 0.5424 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4902 - f1_m: 0.8000 - val_loss: 0.5336 - val_f1_m: 0.7500\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4794 - f1_m: 0.8000 - val_loss: 0.5200 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4672 - f1_m: 0.8000 - val_loss: 0.5053 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4522 - f1_m: 0.8000 - val_loss: 0.4904 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4370 - f1_m: 0.8000 - val_loss: 0.4746 - val_f1_m: 0.7500\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4192 - f1_m: 0.8000 - val_loss: 0.4538 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3988 - f1_m: 0.8000 - val_loss: 0.4315 - val_f1_m: 0.7500\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3765 - f1_m: 0.8000 - val_loss: 0.4076 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3513 - f1_m: 0.8000 - val_loss: 0.3795 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3256 - f1_m: 0.8000 - val_loss: 0.3510 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2987 - f1_m: 0.8000 - val_loss: 0.3282 - val_f1_m: 0.7366\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2729 - f1_m: 0.8250 - val_loss: 0.2982 - val_f1_m: 0.8839\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2482 - f1_m: 0.8938 - val_loss: 0.2756 - val_f1_m: 0.8750\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2279 - f1_m: 0.9150 - val_loss: 0.2581 - val_f1_m: 0.8393\n",
      "0.9149999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 705us/sample - loss: 0.6561 - f1_m: 0.8025 - val_loss: 0.6397 - val_f1_m: 0.7545\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6050 - f1_m: 0.8025 - val_loss: 0.6032 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5604 - f1_m: 0.8025 - val_loss: 0.5764 - val_f1_m: 0.7411\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5276 - f1_m: 0.8025 - val_loss: 0.5643 - val_f1_m: 0.7411\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5101 - f1_m: 0.8025 - val_loss: 0.5584 - val_f1_m: 0.7411\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4986 - f1_m: 0.8025 - val_loss: 0.5511 - val_f1_m: 0.7411\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4897 - f1_m: 0.8025 - val_loss: 0.5453 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4796 - f1_m: 0.8025 - val_loss: 0.5304 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4688 - f1_m: 0.8025 - val_loss: 0.5164 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.4544 - f1_m: 0.8025 - val_loss: 0.5046 - val_f1_m: 0.7411\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4405 - f1_m: 0.8025 - val_loss: 0.4917 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4230 - f1_m: 0.8025 - val_loss: 0.4672 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4026 - f1_m: 0.8025 - val_loss: 0.4459 - val_f1_m: 0.7411\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3774 - f1_m: 0.8025 - val_loss: 0.4126 - val_f1_m: 0.7545\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3508 - f1_m: 0.8025 - val_loss: 0.3851 - val_f1_m: 0.7679\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3231 - f1_m: 0.8025 - val_loss: 0.3467 - val_f1_m: 0.7545\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2946 - f1_m: 0.8025 - val_loss: 0.3129 - val_f1_m: 0.7411\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2695 - f1_m: 0.8388 - val_loss: 0.2802 - val_f1_m: 0.8437\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.2458 - f1_m: 0.8925 - val_loss: 0.2608 - val_f1_m: 0.8304\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.2264 - f1_m: 0.9013 - val_loss: 0.2338 - val_f1_m: 0.8973\n",
      "0.90125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 679us/sample - loss: 0.6565 - f1_m: 0.7987 - val_loss: 0.6376 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6050 - f1_m: 0.7987 - val_loss: 0.5975 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5593 - f1_m: 0.7987 - val_loss: 0.5682 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5294 - f1_m: 0.7987 - val_loss: 0.5525 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5117 - f1_m: 0.7987 - val_loss: 0.5433 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4991 - f1_m: 0.7987 - val_loss: 0.5346 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4883 - f1_m: 0.7987 - val_loss: 0.5244 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4761 - f1_m: 0.7987 - val_loss: 0.5109 - val_f1_m: 0.7545\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4613 - f1_m: 0.7987 - val_loss: 0.4946 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4415 - f1_m: 0.7987 - val_loss: 0.4744 - val_f1_m: 0.7679\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4182 - f1_m: 0.7987 - val_loss: 0.4489 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3918 - f1_m: 0.7987 - val_loss: 0.4220 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3636 - f1_m: 0.7987 - val_loss: 0.3929 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3327 - f1_m: 0.7987 - val_loss: 0.3604 - val_f1_m: 0.7545\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3030 - f1_m: 0.7987 - val_loss: 0.3382 - val_f1_m: 0.7545\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2717 - f1_m: 0.8175 - val_loss: 0.3021 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2427 - f1_m: 0.8925 - val_loss: 0.2714 - val_f1_m: 0.8661\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2184 - f1_m: 0.9187 - val_loss: 0.2536 - val_f1_m: 0.8482\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.1978 - f1_m: 0.9275 - val_loss: 0.2327 - val_f1_m: 0.8795\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.1827 - f1_m: 0.9325 - val_loss: 0.2219 - val_f1_m: 0.8929\n",
      "0.93249995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 20s 25ms/sample - loss: 0.6583 - f1_m: 0.7962 - val_loss: 0.6361 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.6081 - f1_m: 0.7962 - val_loss: 0.5963 - val_f1_m: 0.7366\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.5670 - f1_m: 0.7962 - val_loss: 0.5640 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.5362 - f1_m: 0.7962 - val_loss: 0.5438 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5180 - f1_m: 0.7962 - val_loss: 0.5305 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5051 - f1_m: 0.7962 - val_loss: 0.5194 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4941 - f1_m: 0.7962 - val_loss: 0.5073 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4823 - f1_m: 0.7962 - val_loss: 0.4953 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4686 - f1_m: 0.7962 - val_loss: 0.4790 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4528 - f1_m: 0.7962 - val_loss: 0.4610 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4362 - f1_m: 0.7962 - val_loss: 0.4433 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4189 - f1_m: 0.7962 - val_loss: 0.4240 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3994 - f1_m: 0.7962 - val_loss: 0.4027 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4191 - f1_m: 0.75 - 0s 61us/sample - loss: 0.3791 - f1_m: 0.7962 - val_loss: 0.3790 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3577 - f1_m: 0.7962 - val_loss: 0.3538 - val_f1_m: 0.7500\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3345 - f1_m: 0.7962 - val_loss: 0.3287 - val_f1_m: 0.7500\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3129 - f1_m: 0.7962 - val_loss: 0.3097 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2957 - f1_m: 0.8025 - val_loss: 0.2819 - val_f1_m: 0.9018\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2719 - f1_m: 0.8500 - val_loss: 0.2597 - val_f1_m: 0.9330\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2525 - f1_m: 0.8925 - val_loss: 0.2400 - val_f1_m: 0.9241\n",
      "0.8924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 680us/sample - loss: 0.6593 - f1_m: 0.7900 - val_loss: 0.6296 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6107 - f1_m: 0.7900 - val_loss: 0.5834 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5712 - f1_m: 0.7900 - val_loss: 0.5436 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5398 - f1_m: 0.7900 - val_loss: 0.5205 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5240 - f1_m: 0.7900 - val_loss: 0.5060 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5130 - f1_m: 0.7900 - val_loss: 0.4956 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5029 - f1_m: 0.7900 - val_loss: 0.4850 - val_f1_m: 0.8259\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4915 - f1_m: 0.7900 - val_loss: 0.4715 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4781 - f1_m: 0.7900 - val_loss: 0.4574 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4641 - f1_m: 0.7900 - val_loss: 0.4428 - val_f1_m: 0.8259\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4490 - f1_m: 0.7900 - val_loss: 0.4260 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4309 - f1_m: 0.7900 - val_loss: 0.4079 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4107 - f1_m: 0.7900 - val_loss: 0.3886 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3876 - f1_m: 0.7900 - val_loss: 0.3651 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3633 - f1_m: 0.7900 - val_loss: 0.3436 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3378 - f1_m: 0.7900 - val_loss: 0.3190 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3118 - f1_m: 0.7900 - val_loss: 0.2966 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2862 - f1_m: 0.8250 - val_loss: 0.2775 - val_f1_m: 0.8571\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2625 - f1_m: 0.8675 - val_loss: 0.2582 - val_f1_m: 0.8571\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2417 - f1_m: 0.8950 - val_loss: 0.2426 - val_f1_m: 0.8750\n",
      "0.895\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 675us/sample - loss: 0.6581 - f1_m: 0.7925 - val_loss: 0.6299 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6085 - f1_m: 0.7925 - val_loss: 0.5815 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5653 - f1_m: 0.7925 - val_loss: 0.5453 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5376 - f1_m: 0.7925 - val_loss: 0.5234 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5207 - f1_m: 0.7925 - val_loss: 0.5105 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5106 - f1_m: 0.7925 - val_loss: 0.5000 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4997 - f1_m: 0.7925 - val_loss: 0.4897 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4891 - f1_m: 0.7925 - val_loss: 0.4778 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4762 - f1_m: 0.7925 - val_loss: 0.4637 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4615 - f1_m: 0.7925 - val_loss: 0.4484 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4452 - f1_m: 0.7925 - val_loss: 0.4308 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4266 - f1_m: 0.7925 - val_loss: 0.4102 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4056 - f1_m: 0.7925 - val_loss: 0.3875 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3821 - f1_m: 0.7925 - val_loss: 0.3628 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3564 - f1_m: 0.7925 - val_loss: 0.3360 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3291 - f1_m: 0.7925 - val_loss: 0.3095 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3030 - f1_m: 0.7925 - val_loss: 0.2821 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2757 - f1_m: 0.8362 - val_loss: 0.2552 - val_f1_m: 0.9018\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2512 - f1_m: 0.8887 - val_loss: 0.2326 - val_f1_m: 0.9152\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2293 - f1_m: 0.9150 - val_loss: 0.2124 - val_f1_m: 0.9241\n",
      "0.9149999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 680us/sample - loss: 0.6570 - f1_m: 0.7937 - val_loss: 0.6312 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.6070 - f1_m: 0.7937 - val_loss: 0.5845 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5626 - f1_m: 0.7937 - val_loss: 0.5496 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5352 - f1_m: 0.7937 - val_loss: 0.5284 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5175 - f1_m: 0.7937 - val_loss: 0.5168 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5071 - f1_m: 0.7937 - val_loss: 0.5075 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4971 - f1_m: 0.7937 - val_loss: 0.4973 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4859 - f1_m: 0.7937 - val_loss: 0.4849 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4728 - f1_m: 0.7937 - val_loss: 0.4707 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4586 - f1_m: 0.7937 - val_loss: 0.4561 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4431 - f1_m: 0.7937 - val_loss: 0.4391 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4252 - f1_m: 0.7937 - val_loss: 0.4203 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4049 - f1_m: 0.7937 - val_loss: 0.3996 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3822 - f1_m: 0.7937 - val_loss: 0.3761 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3587 - f1_m: 0.7937 - val_loss: 0.3517 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3335 - f1_m: 0.7937 - val_loss: 0.3260 - val_f1_m: 0.8125\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3071 - f1_m: 0.7937 - val_loss: 0.3013 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2815 - f1_m: 0.8200 - val_loss: 0.2764 - val_f1_m: 0.8661\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2565 - f1_m: 0.8912 - val_loss: 0.2555 - val_f1_m: 0.8750\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2352 - f1_m: 0.9000 - val_loss: 0.2357 - val_f1_m: 0.8929\n",
      "0.9\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 679us/sample - loss: 0.6593 - f1_m: 0.7937 - val_loss: 0.6344 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6083 - f1_m: 0.7937 - val_loss: 0.5873 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5629 - f1_m: 0.7937 - val_loss: 0.5518 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5338 - f1_m: 0.7937 - val_loss: 0.5312 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5177 - f1_m: 0.7937 - val_loss: 0.5188 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5065 - f1_m: 0.7937 - val_loss: 0.5088 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4966 - f1_m: 0.7937 - val_loss: 0.4979 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4846 - f1_m: 0.7937 - val_loss: 0.4861 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4716 - f1_m: 0.7937 - val_loss: 0.4717 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4560 - f1_m: 0.7937 - val_loss: 0.4566 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4392 - f1_m: 0.7937 - val_loss: 0.4397 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4201 - f1_m: 0.7937 - val_loss: 0.4202 - val_f1_m: 0.7589\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3987 - f1_m: 0.7937 - val_loss: 0.3984 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3752 - f1_m: 0.7937 - val_loss: 0.3755 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3499 - f1_m: 0.7937 - val_loss: 0.3506 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3230 - f1_m: 0.7937 - val_loss: 0.3275 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2969 - f1_m: 0.7937 - val_loss: 0.3008 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2705 - f1_m: 0.8537 - val_loss: 0.2779 - val_f1_m: 0.8393\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2450 - f1_m: 0.8937 - val_loss: 0.2577 - val_f1_m: 0.8750\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2198 - f1_m: 0.9137 - val_loss: 0.2375 - val_f1_m: 0.8795\n",
      "0.91374993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 682us/sample - loss: 0.6557 - f1_m: 0.7937 - val_loss: 0.6328 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6081 - f1_m: 0.7937 - val_loss: 0.5878 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5634 - f1_m: 0.7937 - val_loss: 0.5535 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5341 - f1_m: 0.7937 - val_loss: 0.5335 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.5165 - f1_m: 0.7937 - val_loss: 0.5226 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5062 - f1_m: 0.7937 - val_loss: 0.5133 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4966 - f1_m: 0.7937 - val_loss: 0.5037 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4866 - f1_m: 0.7937 - val_loss: 0.4904 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4724 - f1_m: 0.7937 - val_loss: 0.4761 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4582 - f1_m: 0.7937 - val_loss: 0.4611 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4444 - f1_m: 0.7937 - val_loss: 0.4450 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4249 - f1_m: 0.7937 - val_loss: 0.4264 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4049 - f1_m: 0.7937 - val_loss: 0.4047 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3821 - f1_m: 0.7937 - val_loss: 0.3817 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3573 - f1_m: 0.7937 - val_loss: 0.3577 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3322 - f1_m: 0.7937 - val_loss: 0.3321 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3059 - f1_m: 0.7937 - val_loss: 0.3063 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2801 - f1_m: 0.8187 - val_loss: 0.2834 - val_f1_m: 0.8884\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2571 - f1_m: 0.8825 - val_loss: 0.2625 - val_f1_m: 0.8795\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2366 - f1_m: 0.9025 - val_loss: 0.2441 - val_f1_m: 0.8973\n",
      "0.9024999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 712us/sample - loss: 0.6576 - f1_m: 0.7950 - val_loss: 0.6307 - val_f1_m: 0.7545\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6089 - f1_m: 0.7950 - val_loss: 0.5860 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5640 - f1_m: 0.7950 - val_loss: 0.5518 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5346 - f1_m: 0.7950 - val_loss: 0.5311 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5188 - f1_m: 0.7950 - val_loss: 0.5204 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5083 - f1_m: 0.7950 - val_loss: 0.5117 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4984 - f1_m: 0.7950 - val_loss: 0.5018 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4867 - f1_m: 0.7950 - val_loss: 0.4886 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4726 - f1_m: 0.7950 - val_loss: 0.4744 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4564 - f1_m: 0.7950 - val_loss: 0.4556 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4362 - f1_m: 0.7950 - val_loss: 0.4322 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4120 - f1_m: 0.7950 - val_loss: 0.4077 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3868 - f1_m: 0.7950 - val_loss: 0.3783 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3584 - f1_m: 0.7950 - val_loss: 0.3483 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3288 - f1_m: 0.7950 - val_loss: 0.3187 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2993 - f1_m: 0.7950 - val_loss: 0.2870 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2711 - f1_m: 0.8387 - val_loss: 0.2624 - val_f1_m: 0.9107\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2461 - f1_m: 0.8912 - val_loss: 0.2366 - val_f1_m: 0.9241\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2249 - f1_m: 0.9062 - val_loss: 0.2171 - val_f1_m: 0.9196\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2098 - f1_m: 0.9162 - val_loss: 0.2046 - val_f1_m: 0.9152\n",
      "0.91624993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 709us/sample - loss: 0.6556 - f1_m: 0.7937 - val_loss: 0.6288 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6067 - f1_m: 0.7937 - val_loss: 0.5821 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5654 - f1_m: 0.7937 - val_loss: 0.5468 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5368 - f1_m: 0.7937 - val_loss: 0.5270 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5207 - f1_m: 0.7937 - val_loss: 0.5153 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5104 - f1_m: 0.7937 - val_loss: 0.5061 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5011 - f1_m: 0.7937 - val_loss: 0.4967 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4907 - f1_m: 0.7937 - val_loss: 0.4854 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4791 - f1_m: 0.7937 - val_loss: 0.4728 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4656 - f1_m: 0.7937 - val_loss: 0.4589 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4514 - f1_m: 0.7937 - val_loss: 0.4433 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4352 - f1_m: 0.7937 - val_loss: 0.4248 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4171 - f1_m: 0.7937 - val_loss: 0.4045 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3957 - f1_m: 0.7937 - val_loss: 0.3814 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3734 - f1_m: 0.7937 - val_loss: 0.3563 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3488 - f1_m: 0.7937 - val_loss: 0.3322 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3251 - f1_m: 0.7937 - val_loss: 0.3049 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2999 - f1_m: 0.7937 - val_loss: 0.2786 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2761 - f1_m: 0.8562 - val_loss: 0.2548 - val_f1_m: 0.8839\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2548 - f1_m: 0.8800 - val_loss: 0.2328 - val_f1_m: 0.9152\n",
      "0.87999994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 705us/sample - loss: 0.6593 - f1_m: 0.7900 - val_loss: 0.6306 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6100 - f1_m: 0.7912 - val_loss: 0.5809 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5677 - f1_m: 0.7912 - val_loss: 0.5420 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5385 - f1_m: 0.7912 - val_loss: 0.5180 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5205 - f1_m: 0.7912 - val_loss: 0.5039 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5078 - f1_m: 0.7912 - val_loss: 0.4922 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4955 - f1_m: 0.7912 - val_loss: 0.4797 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4817 - f1_m: 0.7912 - val_loss: 0.4667 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4665 - f1_m: 0.7912 - val_loss: 0.4512 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4495 - f1_m: 0.7912 - val_loss: 0.4351 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4310 - f1_m: 0.7912 - val_loss: 0.4175 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4115 - f1_m: 0.7912 - val_loss: 0.3983 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3887 - f1_m: 0.7912 - val_loss: 0.3766 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3631 - f1_m: 0.7912 - val_loss: 0.3539 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3373 - f1_m: 0.7912 - val_loss: 0.3302 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3097 - f1_m: 0.7912 - val_loss: 0.3068 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2829 - f1_m: 0.8062 - val_loss: 0.2844 - val_f1_m: 0.8259\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2579 - f1_m: 0.8887 - val_loss: 0.2648 - val_f1_m: 0.8571\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2345 - f1_m: 0.9162 - val_loss: 0.2473 - val_f1_m: 0.8973\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2160 - f1_m: 0.9225 - val_loss: 0.2362 - val_f1_m: 0.8705\n",
      "0.9224999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 713us/sample - loss: 0.6575 - f1_m: 0.7937 - val_loss: 0.6306 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6078 - f1_m: 0.7937 - val_loss: 0.5846 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5635 - f1_m: 0.7937 - val_loss: 0.5487 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5337 - f1_m: 0.7937 - val_loss: 0.5294 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5178 - f1_m: 0.7937 - val_loss: 0.5179 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5080 - f1_m: 0.7937 - val_loss: 0.5092 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4995 - f1_m: 0.7937 - val_loss: 0.4996 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4903 - f1_m: 0.7937 - val_loss: 0.4876 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4779 - f1_m: 0.7937 - val_loss: 0.4735 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4635 - f1_m: 0.7937 - val_loss: 0.4566 - val_f1_m: 0.7455\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4453 - f1_m: 0.7937 - val_loss: 0.4345 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4237 - f1_m: 0.7937 - val_loss: 0.4100 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3995 - f1_m: 0.7937 - val_loss: 0.3834 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3736 - f1_m: 0.7937 - val_loss: 0.3536 - val_f1_m: 0.7455\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3447 - f1_m: 0.7937 - val_loss: 0.3225 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3164 - f1_m: 0.7937 - val_loss: 0.2917 - val_f1_m: 0.8125\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2880 - f1_m: 0.8075 - val_loss: 0.2614 - val_f1_m: 0.8661\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2626 - f1_m: 0.8725 - val_loss: 0.2348 - val_f1_m: 0.8929\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2397 - f1_m: 0.8937 - val_loss: 0.2116 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2218 - f1_m: 0.9112 - val_loss: 0.1934 - val_f1_m: 0.9420\n",
      "0.91124994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 690us/sample - loss: 0.6601 - f1_m: 0.7887 - val_loss: 0.6323 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6123 - f1_m: 0.7887 - val_loss: 0.5839 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5748 - f1_m: 0.7887 - val_loss: 0.5443 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5470 - f1_m: 0.7887 - val_loss: 0.5226 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5325 - f1_m: 0.7887 - val_loss: 0.5080 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5229 - f1_m: 0.7887 - val_loss: 0.4995 - val_f1_m: 0.8304\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5168 - f1_m: 0.7887 - val_loss: 0.4915 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5101 - f1_m: 0.7887 - val_loss: 0.4845 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5038 - f1_m: 0.7887 - val_loss: 0.4762 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4947 - f1_m: 0.7887 - val_loss: 0.4673 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4861 - f1_m: 0.7887 - val_loss: 0.4572 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.4761 - f1_m: 0.7887 - val_loss: 0.4462 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4637 - f1_m: 0.7887 - val_loss: 0.4326 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4501 - f1_m: 0.7887 - val_loss: 0.4168 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4317 - f1_m: 0.7887 - val_loss: 0.3938 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4047 - f1_m: 0.7887 - val_loss: 0.3713 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3771 - f1_m: 0.7887 - val_loss: 0.3427 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3487 - f1_m: 0.7887 - val_loss: 0.3120 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3196 - f1_m: 0.7887 - val_loss: 0.2884 - val_f1_m: 0.8304\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2946 - f1_m: 0.7987 - val_loss: 0.2602 - val_f1_m: 0.9107\n",
      "0.7987499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 698us/sample - loss: 0.6591 - f1_m: 0.7837 - val_loss: 0.6206 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6119 - f1_m: 0.7837 - val_loss: 0.5658 - val_f1_m: 0.8348\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5718 - f1_m: 0.7837 - val_loss: 0.5209 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5463 - f1_m: 0.7837 - val_loss: 0.4913 - val_f1_m: 0.8482\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5313 - f1_m: 0.7837 - val_loss: 0.4741 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5203 - f1_m: 0.7837 - val_loss: 0.4621 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5105 - f1_m: 0.7837 - val_loss: 0.4525 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4980 - f1_m: 0.7837 - val_loss: 0.4404 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4850 - f1_m: 0.7837 - val_loss: 0.4264 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4708 - f1_m: 0.7837 - val_loss: 0.4110 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4541 - f1_m: 0.7837 - val_loss: 0.3961 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4358 - f1_m: 0.7837 - val_loss: 0.3779 - val_f1_m: 0.8482\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4131 - f1_m: 0.7837 - val_loss: 0.3575 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3879 - f1_m: 0.7837 - val_loss: 0.3378 - val_f1_m: 0.8348\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3589 - f1_m: 0.7837 - val_loss: 0.3088 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3236 - f1_m: 0.7837 - val_loss: 0.2797 - val_f1_m: 0.8482\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2909 - f1_m: 0.8137 - val_loss: 0.2536 - val_f1_m: 0.8527\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2612 - f1_m: 0.8837 - val_loss: 0.2330 - val_f1_m: 0.8884\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2351 - f1_m: 0.9112 - val_loss: 0.2142 - val_f1_m: 0.9152\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2165 - f1_m: 0.9187 - val_loss: 0.2009 - val_f1_m: 0.9330\n",
      "0.9187499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 696us/sample - loss: 0.6567 - f1_m: 0.7912 - val_loss: 0.6272 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6098 - f1_m: 0.7912 - val_loss: 0.5770 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5660 - f1_m: 0.7912 - val_loss: 0.5397 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5375 - f1_m: 0.7912 - val_loss: 0.5157 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5209 - f1_m: 0.7912 - val_loss: 0.5015 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5095 - f1_m: 0.7912 - val_loss: 0.4911 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4984 - f1_m: 0.7912 - val_loss: 0.4802 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4602 - f1_m: 0.81 - 0s 61us/sample - loss: 0.4854 - f1_m: 0.7912 - val_loss: 0.4693 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4717 - f1_m: 0.7912 - val_loss: 0.4549 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4562 - f1_m: 0.7912 - val_loss: 0.4397 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4389 - f1_m: 0.7912 - val_loss: 0.4232 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4195 - f1_m: 0.7912 - val_loss: 0.4036 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3978 - f1_m: 0.7912 - val_loss: 0.3820 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3740 - f1_m: 0.7912 - val_loss: 0.3595 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3477 - f1_m: 0.7912 - val_loss: 0.3363 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3218 - f1_m: 0.7912 - val_loss: 0.3114 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2956 - f1_m: 0.7900 - val_loss: 0.2900 - val_f1_m: 0.8527\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2708 - f1_m: 0.8675 - val_loss: 0.2687 - val_f1_m: 0.8705\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2488 - f1_m: 0.8837 - val_loss: 0.2513 - val_f1_m: 0.8929\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2301 - f1_m: 0.9062 - val_loss: 0.2366 - val_f1_m: 0.9107\n",
      "0.90624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 697us/sample - loss: 0.6550 - f1_m: 0.7987 - val_loss: 0.6354 - val_f1_m: 0.7277\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6026 - f1_m: 0.7987 - val_loss: 0.5941 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5578 - f1_m: 0.7987 - val_loss: 0.5632 - val_f1_m: 0.7545\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5268 - f1_m: 0.7987 - val_loss: 0.5487 - val_f1_m: 0.7411\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5111 - f1_m: 0.7987 - val_loss: 0.5396 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5003 - f1_m: 0.7987 - val_loss: 0.5322 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4908 - f1_m: 0.7987 - val_loss: 0.5226 - val_f1_m: 0.7545\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4802 - f1_m: 0.7987 - val_loss: 0.5095 - val_f1_m: 0.7545\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4677 - f1_m: 0.7987 - val_loss: 0.4959 - val_f1_m: 0.7545\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4533 - f1_m: 0.7987 - val_loss: 0.4804 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4383 - f1_m: 0.7987 - val_loss: 0.4639 - val_f1_m: 0.7545\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4208 - f1_m: 0.7987 - val_loss: 0.4450 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4017 - f1_m: 0.7987 - val_loss: 0.4232 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3802 - f1_m: 0.7987 - val_loss: 0.4005 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3575 - f1_m: 0.7987 - val_loss: 0.3752 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3333 - f1_m: 0.7987 - val_loss: 0.3500 - val_f1_m: 0.7545\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3092 - f1_m: 0.7987 - val_loss: 0.3237 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2847 - f1_m: 0.8037 - val_loss: 0.2997 - val_f1_m: 0.8348\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2623 - f1_m: 0.8675 - val_loss: 0.2772 - val_f1_m: 0.8571\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2419 - f1_m: 0.8850 - val_loss: 0.2585 - val_f1_m: 0.8884\n",
      "0.88499993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 734us/sample - loss: 0.6578 - f1_m: 0.8037 - val_loss: 0.6418 - val_f1_m: 0.7634\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6058 - f1_m: 0.8037 - val_loss: 0.6055 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.5583 - f1_m: 0.8037 - val_loss: 0.5801 - val_f1_m: 0.7232\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5251 - f1_m: 0.8037 - val_loss: 0.5689 - val_f1_m: 0.7500\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5095 - f1_m: 0.8037 - val_loss: 0.5633 - val_f1_m: 0.7232\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4976 - f1_m: 0.8037 - val_loss: 0.5566 - val_f1_m: 0.7500\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4892 - f1_m: 0.8037 - val_loss: 0.5504 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4789 - f1_m: 0.8037 - val_loss: 0.5381 - val_f1_m: 0.7366\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4675 - f1_m: 0.8037 - val_loss: 0.5244 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4547 - f1_m: 0.8037 - val_loss: 0.5100 - val_f1_m: 0.7634\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4404 - f1_m: 0.8037 - val_loss: 0.4939 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4231 - f1_m: 0.8037 - val_loss: 0.4753 - val_f1_m: 0.7098\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4043 - f1_m: 0.8037 - val_loss: 0.4520 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3836 - f1_m: 0.8037 - val_loss: 0.4245 - val_f1_m: 0.7500\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3611 - f1_m: 0.8037 - val_loss: 0.3970 - val_f1_m: 0.7500\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3366 - f1_m: 0.8037 - val_loss: 0.3658 - val_f1_m: 0.7500\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3108 - f1_m: 0.8037 - val_loss: 0.3370 - val_f1_m: 0.7500\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2848 - f1_m: 0.8037 - val_loss: 0.3043 - val_f1_m: 0.7366\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2600 - f1_m: 0.8712 - val_loss: 0.2759 - val_f1_m: 0.8661\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2367 - f1_m: 0.9000 - val_loss: 0.2469 - val_f1_m: 0.9330\n",
      "0.8999999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 697us/sample - loss: 0.6583 - f1_m: 0.7805 - val_loss: 0.6180 - val_f1_m: 0.8437\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6129 - f1_m: 0.7812 - val_loss: 0.5594 - val_f1_m: 0.8571\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5728 - f1_m: 0.7812 - val_loss: 0.5120 - val_f1_m: 0.8437\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5473 - f1_m: 0.7812 - val_loss: 0.4804 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5328 - f1_m: 0.7812 - val_loss: 0.4602 - val_f1_m: 0.8571\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5228 - f1_m: 0.7812 - val_loss: 0.4487 - val_f1_m: 0.8571\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5132 - f1_m: 0.7812 - val_loss: 0.4376 - val_f1_m: 0.8571\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5013 - f1_m: 0.7812 - val_loss: 0.4268 - val_f1_m: 0.8437\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4883 - f1_m: 0.7812 - val_loss: 0.4113 - val_f1_m: 0.8571\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4741 - f1_m: 0.7812 - val_loss: 0.3958 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4580 - f1_m: 0.7812 - val_loss: 0.3782 - val_f1_m: 0.8571\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4393 - f1_m: 0.7812 - val_loss: 0.3598 - val_f1_m: 0.8571\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4180 - f1_m: 0.7812 - val_loss: 0.3430 - val_f1_m: 0.8437\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3958 - f1_m: 0.7812 - val_loss: 0.3185 - val_f1_m: 0.8437\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3698 - f1_m: 0.7812 - val_loss: 0.2925 - val_f1_m: 0.8437\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3432 - f1_m: 0.7812 - val_loss: 0.2720 - val_f1_m: 0.8571\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3167 - f1_m: 0.7812 - val_loss: 0.2587 - val_f1_m: 0.8125\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2920 - f1_m: 0.8475 - val_loss: 0.2241 - val_f1_m: 0.9286\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2685 - f1_m: 0.8737 - val_loss: 0.2111 - val_f1_m: 0.9375\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2475 - f1_m: 0.8950 - val_loss: 0.1949 - val_f1_m: 0.9509\n",
      "0.8949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 704us/sample - loss: 0.6585 - f1_m: 0.7850 - val_loss: 0.6195 - val_f1_m: 0.8437\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.6122 - f1_m: 0.7850 - val_loss: 0.5658 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5731 - f1_m: 0.7850 - val_loss: 0.5217 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5439 - f1_m: 0.7850 - val_loss: 0.4905 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5240 - f1_m: 0.7850 - val_loss: 0.4672 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5076 - f1_m: 0.7850 - val_loss: 0.4496 - val_f1_m: 0.8437\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4905 - f1_m: 0.7850 - val_loss: 0.4328 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4721 - f1_m: 0.7850 - val_loss: 0.4157 - val_f1_m: 0.8304\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4495 - f1_m: 0.7850 - val_loss: 0.3940 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4263 - f1_m: 0.7850 - val_loss: 0.3706 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4013 - f1_m: 0.7850 - val_loss: 0.3466 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3739 - f1_m: 0.7850 - val_loss: 0.3211 - val_f1_m: 0.8304\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3460 - f1_m: 0.7850 - val_loss: 0.2951 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3181 - f1_m: 0.7850 - val_loss: 0.2726 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2876 - f1_m: 0.8300 - val_loss: 0.2476 - val_f1_m: 0.8884\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2609 - f1_m: 0.8812 - val_loss: 0.2253 - val_f1_m: 0.9152\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2364 - f1_m: 0.9075 - val_loss: 0.2060 - val_f1_m: 0.9420\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2159 - f1_m: 0.9262 - val_loss: 0.1924 - val_f1_m: 0.9464\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.1998 - f1_m: 0.9350 - val_loss: 0.1768 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1853 - f1_m: 0.9412 - val_loss: 0.1705 - val_f1_m: 0.9330\n",
      "0.9412499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 691us/sample - loss: 0.6554 - f1_m: 0.7875 - val_loss: 0.6236 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6081 - f1_m: 0.7875 - val_loss: 0.5717 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5672 - f1_m: 0.7875 - val_loss: 0.5289 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5385 - f1_m: 0.7875 - val_loss: 0.5033 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5227 - f1_m: 0.7875 - val_loss: 0.4872 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5120 - f1_m: 0.7875 - val_loss: 0.4768 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5014 - f1_m: 0.7875 - val_loss: 0.4647 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4889 - f1_m: 0.7875 - val_loss: 0.4528 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4742 - f1_m: 0.7875 - val_loss: 0.4365 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4584 - f1_m: 0.7875 - val_loss: 0.4197 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4408 - f1_m: 0.7875 - val_loss: 0.4013 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4211 - f1_m: 0.7875 - val_loss: 0.3815 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3987 - f1_m: 0.7875 - val_loss: 0.3608 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3744 - f1_m: 0.7875 - val_loss: 0.3368 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3482 - f1_m: 0.7875 - val_loss: 0.3131 - val_f1_m: 0.8348\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3211 - f1_m: 0.7875 - val_loss: 0.2872 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2937 - f1_m: 0.7925 - val_loss: 0.2632 - val_f1_m: 0.8482\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2675 - f1_m: 0.8812 - val_loss: 0.2418 - val_f1_m: 0.9062\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2433 - f1_m: 0.8963 - val_loss: 0.2218 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2217 - f1_m: 0.9137 - val_loss: 0.2052 - val_f1_m: 0.9062\n",
      "0.91374993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 712us/sample - loss: 0.6574 - f1_m: 0.7937 - val_loss: 0.6332 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6053 - f1_m: 0.7950 - val_loss: 0.5890 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5612 - f1_m: 0.7950 - val_loss: 0.5536 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5306 - f1_m: 0.7950 - val_loss: 0.5337 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5129 - f1_m: 0.7950 - val_loss: 0.5214 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5011 - f1_m: 0.7950 - val_loss: 0.5103 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4906 - f1_m: 0.7950 - val_loss: 0.4977 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4773 - f1_m: 0.7950 - val_loss: 0.4831 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4628 - f1_m: 0.7950 - val_loss: 0.4664 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4463 - f1_m: 0.7950 - val_loss: 0.4482 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4277 - f1_m: 0.7950 - val_loss: 0.4272 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4067 - f1_m: 0.7950 - val_loss: 0.4047 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3831 - f1_m: 0.7950 - val_loss: 0.3785 - val_f1_m: 0.7545\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3564 - f1_m: 0.7950 - val_loss: 0.3486 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3289 - f1_m: 0.7950 - val_loss: 0.3184 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2983 - f1_m: 0.7950 - val_loss: 0.2864 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2684 - f1_m: 0.8525 - val_loss: 0.2558 - val_f1_m: 0.9062\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2414 - f1_m: 0.9112 - val_loss: 0.2281 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2157 - f1_m: 0.9175 - val_loss: 0.2043 - val_f1_m: 0.9241\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1941 - f1_m: 0.9275 - val_loss: 0.1840 - val_f1_m: 0.9420\n",
      "0.92749995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 697us/sample - loss: 0.6618 - f1_m: 0.7887 - val_loss: 0.6286 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6140 - f1_m: 0.7887 - val_loss: 0.5785 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5718 - f1_m: 0.7887 - val_loss: 0.5371 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5430 - f1_m: 0.7887 - val_loss: 0.5119 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5257 - f1_m: 0.7887 - val_loss: 0.4953 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5141 - f1_m: 0.7887 - val_loss: 0.4829 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5018 - f1_m: 0.7887 - val_loss: 0.4705 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4883 - f1_m: 0.7887 - val_loss: 0.4565 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4739 - f1_m: 0.7887 - val_loss: 0.4415 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4577 - f1_m: 0.7887 - val_loss: 0.4234 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4361 - f1_m: 0.7887 - val_loss: 0.4002 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4101 - f1_m: 0.7887 - val_loss: 0.3738 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3815 - f1_m: 0.7887 - val_loss: 0.3440 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3493 - f1_m: 0.7887 - val_loss: 0.3132 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3152 - f1_m: 0.7887 - val_loss: 0.2805 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2813 - f1_m: 0.8137 - val_loss: 0.2515 - val_f1_m: 0.8839\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2490 - f1_m: 0.9012 - val_loss: 0.2231 - val_f1_m: 0.9420\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2212 - f1_m: 0.9187 - val_loss: 0.2011 - val_f1_m: 0.9375\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1978 - f1_m: 0.9362 - val_loss: 0.1835 - val_f1_m: 0.9375\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.1800 - f1_m: 0.9400 - val_loss: 0.1707 - val_f1_m: 0.9509\n",
      "0.94\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 687us/sample - loss: 0.6574 - f1_m: 0.7900 - val_loss: 0.6290 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6101 - f1_m: 0.7900 - val_loss: 0.5804 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5693 - f1_m: 0.7900 - val_loss: 0.5430 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5395 - f1_m: 0.7900 - val_loss: 0.5163 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5204 - f1_m: 0.7900 - val_loss: 0.4979 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5044 - f1_m: 0.7900 - val_loss: 0.4840 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4899 - f1_m: 0.7900 - val_loss: 0.4684 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4728 - f1_m: 0.7900 - val_loss: 0.4512 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4535 - f1_m: 0.7900 - val_loss: 0.4310 - val_f1_m: 0.8259\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4297 - f1_m: 0.7900 - val_loss: 0.4091 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4048 - f1_m: 0.7900 - val_loss: 0.3858 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3784 - f1_m: 0.7900 - val_loss: 0.3611 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3475 - f1_m: 0.7900 - val_loss: 0.3360 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3160 - f1_m: 0.7900 - val_loss: 0.3078 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2825 - f1_m: 0.8100 - val_loss: 0.2811 - val_f1_m: 0.9062\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2500 - f1_m: 0.9012 - val_loss: 0.2591 - val_f1_m: 0.8839\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2225 - f1_m: 0.9225 - val_loss: 0.2389 - val_f1_m: 0.8661\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.1985 - f1_m: 0.9312 - val_loss: 0.2274 - val_f1_m: 0.8929\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.1795 - f1_m: 0.9413 - val_loss: 0.2180 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1655 - f1_m: 0.9475 - val_loss: 0.2153 - val_f1_m: 0.8795\n",
      "0.9475\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 694us/sample - loss: 0.6585 - f1_m: 0.7912 - val_loss: 0.6306 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.6103 - f1_m: 0.7912 - val_loss: 0.5837 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5674 - f1_m: 0.7912 - val_loss: 0.5465 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5400 - f1_m: 0.7912 - val_loss: 0.5222 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5223 - f1_m: 0.7912 - val_loss: 0.5082 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5103 - f1_m: 0.7912 - val_loss: 0.4966 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4988 - f1_m: 0.7912 - val_loss: 0.4836 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4861 - f1_m: 0.7912 - val_loss: 0.4692 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4714 - f1_m: 0.7912 - val_loss: 0.4539 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4561 - f1_m: 0.7912 - val_loss: 0.4378 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4385 - f1_m: 0.7912 - val_loss: 0.4186 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4188 - f1_m: 0.7912 - val_loss: 0.3987 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3973 - f1_m: 0.7912 - val_loss: 0.3763 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4650 - f1_m: 0.68 - 0s 62us/sample - loss: 0.3741 - f1_m: 0.7912 - val_loss: 0.3498 - val_f1_m: 0.7679\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3466 - f1_m: 0.7912 - val_loss: 0.3231 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3192 - f1_m: 0.7912 - val_loss: 0.2964 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2922 - f1_m: 0.8000 - val_loss: 0.2738 - val_f1_m: 0.8973\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2674 - f1_m: 0.8725 - val_loss: 0.2462 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2429 - f1_m: 0.8950 - val_loss: 0.2251 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2221 - f1_m: 0.9125 - val_loss: 0.2061 - val_f1_m: 0.9464\n",
      "0.9125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 702us/sample - loss: 0.6571 - f1_m: 0.7900 - val_loss: 0.6272 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6086 - f1_m: 0.7900 - val_loss: 0.5771 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.5664 - f1_m: 0.7900 - val_loss: 0.5380 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5391 - f1_m: 0.7900 - val_loss: 0.5147 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5231 - f1_m: 0.7900 - val_loss: 0.5006 - val_f1_m: 0.8259\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5116 - f1_m: 0.7900 - val_loss: 0.4898 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5014 - f1_m: 0.7900 - val_loss: 0.4789 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4890 - f1_m: 0.7900 - val_loss: 0.4661 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4757 - f1_m: 0.7900 - val_loss: 0.4521 - val_f1_m: 0.8259\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4611 - f1_m: 0.7900 - val_loss: 0.4378 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4451 - f1_m: 0.7900 - val_loss: 0.4205 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4279 - f1_m: 0.7900 - val_loss: 0.4040 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4073 - f1_m: 0.7900 - val_loss: 0.3829 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3845 - f1_m: 0.7900 - val_loss: 0.3611 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3614 - f1_m: 0.7900 - val_loss: 0.3370 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3370 - f1_m: 0.7900 - val_loss: 0.3126 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3099 - f1_m: 0.7900 - val_loss: 0.2888 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2865 - f1_m: 0.8037 - val_loss: 0.2671 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.2629 - f1_m: 0.8750 - val_loss: 0.2455 - val_f1_m: 0.8661\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2431 - f1_m: 0.8963 - val_loss: 0.2281 - val_f1_m: 0.9152\n",
      "0.89625\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 691us/sample - loss: 0.6575 - f1_m: 0.7887 - val_loss: 0.6269 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6089 - f1_m: 0.7887 - val_loss: 0.5757 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5663 - f1_m: 0.7887 - val_loss: 0.5338 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5378 - f1_m: 0.7887 - val_loss: 0.5068 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5219 - f1_m: 0.7887 - val_loss: 0.4905 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5106 - f1_m: 0.7887 - val_loss: 0.4787 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4997 - f1_m: 0.7887 - val_loss: 0.4658 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4849 - f1_m: 0.7887 - val_loss: 0.4480 - val_f1_m: 0.8304\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4655 - f1_m: 0.7887 - val_loss: 0.4262 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4440 - f1_m: 0.7887 - val_loss: 0.4041 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4211 - f1_m: 0.7887 - val_loss: 0.3779 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3941 - f1_m: 0.7887 - val_loss: 0.3500 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3648 - f1_m: 0.7887 - val_loss: 0.3226 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3348 - f1_m: 0.7887 - val_loss: 0.2888 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3038 - f1_m: 0.7887 - val_loss: 0.2602 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2735 - f1_m: 0.8450 - val_loss: 0.2274 - val_f1_m: 0.9330\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2466 - f1_m: 0.8975 - val_loss: 0.2082 - val_f1_m: 0.9509\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2238 - f1_m: 0.9075 - val_loss: 0.1897 - val_f1_m: 0.9687\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2043 - f1_m: 0.9275 - val_loss: 0.1660 - val_f1_m: 0.9688\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.1895 - f1_m: 0.9312 - val_loss: 0.1525 - val_f1_m: 0.9554\n",
      "0.9312499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 762us/sample - loss: 0.6584 - f1_m: 0.7900 - val_loss: 0.6270 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.6098 - f1_m: 0.7900 - val_loss: 0.5771 - val_f1_m: 0.7589\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5685 - f1_m: 0.7900 - val_loss: 0.5360 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5402 - f1_m: 0.7900 - val_loss: 0.5106 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5237 - f1_m: 0.7900 - val_loss: 0.4953 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5123 - f1_m: 0.7900 - val_loss: 0.4840 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5005 - f1_m: 0.7900 - val_loss: 0.4725 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4878 - f1_m: 0.7900 - val_loss: 0.4592 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4732 - f1_m: 0.7900 - val_loss: 0.4440 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4577 - f1_m: 0.7900 - val_loss: 0.4278 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4402 - f1_m: 0.7900 - val_loss: 0.4087 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4206 - f1_m: 0.7900 - val_loss: 0.3876 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3986 - f1_m: 0.7900 - val_loss: 0.3660 - val_f1_m: 0.7723\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3749 - f1_m: 0.7900 - val_loss: 0.3401 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3490 - f1_m: 0.7900 - val_loss: 0.3133 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3228 - f1_m: 0.7900 - val_loss: 0.2862 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2985 - f1_m: 0.7900 - val_loss: 0.2608 - val_f1_m: 0.8125\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2744 - f1_m: 0.8650 - val_loss: 0.2369 - val_f1_m: 0.8750\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2520 - f1_m: 0.8850 - val_loss: 0.2153 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2339 - f1_m: 0.9062 - val_loss: 0.1969 - val_f1_m: 0.9286\n",
      "0.90624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 695us/sample - loss: 0.6587 - f1_m: 0.7900 - val_loss: 0.6280 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6089 - f1_m: 0.7900 - val_loss: 0.5770 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5676 - f1_m: 0.7900 - val_loss: 0.5362 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5400 - f1_m: 0.7900 - val_loss: 0.5118 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5230 - f1_m: 0.7900 - val_loss: 0.4979 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5112 - f1_m: 0.7900 - val_loss: 0.4859 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4999 - f1_m: 0.7900 - val_loss: 0.4733 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4870 - f1_m: 0.7900 - val_loss: 0.4598 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4724 - f1_m: 0.7900 - val_loss: 0.4434 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4566 - f1_m: 0.7900 - val_loss: 0.4270 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4391 - f1_m: 0.7900 - val_loss: 0.4079 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4197 - f1_m: 0.7900 - val_loss: 0.3864 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3984 - f1_m: 0.7900 - val_loss: 0.3645 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3746 - f1_m: 0.7900 - val_loss: 0.3398 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3486 - f1_m: 0.7900 - val_loss: 0.3107 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3226 - f1_m: 0.7900 - val_loss: 0.2846 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2974 - f1_m: 0.7950 - val_loss: 0.2587 - val_f1_m: 0.9107\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2715 - f1_m: 0.8675 - val_loss: 0.2321 - val_f1_m: 0.9196\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2493 - f1_m: 0.8863 - val_loss: 0.2109 - val_f1_m: 0.9509\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2288 - f1_m: 0.9087 - val_loss: 0.1902 - val_f1_m: 0.9420\n",
      "0.90874994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 684us/sample - loss: 0.6587 - f1_m: 0.7937 - val_loss: 0.6318 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6106 - f1_m: 0.7937 - val_loss: 0.5866 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5677 - f1_m: 0.7937 - val_loss: 0.5502 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5396 - f1_m: 0.7937 - val_loss: 0.5284 - val_f1_m: 0.7589\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5224 - f1_m: 0.7937 - val_loss: 0.5163 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5118 - f1_m: 0.7937 - val_loss: 0.5060 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5009 - f1_m: 0.7937 - val_loss: 0.4948 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4892 - f1_m: 0.7937 - val_loss: 0.4828 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4762 - f1_m: 0.7937 - val_loss: 0.4693 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4620 - f1_m: 0.7937 - val_loss: 0.4539 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4467 - f1_m: 0.7937 - val_loss: 0.4373 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4295 - f1_m: 0.7937 - val_loss: 0.4169 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4101 - f1_m: 0.7937 - val_loss: 0.3973 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.3881 - f1_m: 0.7937 - val_loss: 0.3718 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3647 - f1_m: 0.7937 - val_loss: 0.3463 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3393 - f1_m: 0.7937 - val_loss: 0.3182 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3130 - f1_m: 0.7937 - val_loss: 0.2922 - val_f1_m: 0.8125\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2875 - f1_m: 0.7962 - val_loss: 0.2672 - val_f1_m: 0.8795\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2639 - f1_m: 0.8812 - val_loss: 0.2432 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2432 - f1_m: 0.9000 - val_loss: 0.2235 - val_f1_m: 0.8973\n",
      "0.8999999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 689us/sample - loss: 0.6578 - f1_m: 0.7850 - val_loss: 0.6229 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6115 - f1_m: 0.7850 - val_loss: 0.5684 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5699 - f1_m: 0.7850 - val_loss: 0.5237 - val_f1_m: 0.8437\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5433 - f1_m: 0.7850 - val_loss: 0.4943 - val_f1_m: 0.8437\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5276 - f1_m: 0.7850 - val_loss: 0.4785 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5186 - f1_m: 0.7850 - val_loss: 0.4644 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5074 - f1_m: 0.7850 - val_loss: 0.4563 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4965 - f1_m: 0.7850 - val_loss: 0.4427 - val_f1_m: 0.8304\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4834 - f1_m: 0.7850 - val_loss: 0.4292 - val_f1_m: 0.8437\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4684 - f1_m: 0.7850 - val_loss: 0.4144 - val_f1_m: 0.8437\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4522 - f1_m: 0.7850 - val_loss: 0.3986 - val_f1_m: 0.8437\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4336 - f1_m: 0.7850 - val_loss: 0.3771 - val_f1_m: 0.8304\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4114 - f1_m: 0.7850 - val_loss: 0.3553 - val_f1_m: 0.8437\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3871 - f1_m: 0.7850 - val_loss: 0.3319 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3609 - f1_m: 0.7850 - val_loss: 0.3085 - val_f1_m: 0.8437\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3322 - f1_m: 0.7850 - val_loss: 0.2797 - val_f1_m: 0.8437\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3052 - f1_m: 0.7837 - val_loss: 0.2564 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2780 - f1_m: 0.8475 - val_loss: 0.2304 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2522 - f1_m: 0.9175 - val_loss: 0.2088 - val_f1_m: 0.9330\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2311 - f1_m: 0.9112 - val_loss: 0.1934 - val_f1_m: 0.9241\n",
      "0.91124994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 688us/sample - loss: 0.6599 - f1_m: 0.7850 - val_loss: 0.6218 - val_f1_m: 0.8437\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6117 - f1_m: 0.7850 - val_loss: 0.5687 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5719 - f1_m: 0.7850 - val_loss: 0.5210 - val_f1_m: 0.8437\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5458 - f1_m: 0.7850 - val_loss: 0.4928 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5297 - f1_m: 0.7850 - val_loss: 0.4771 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5194 - f1_m: 0.7850 - val_loss: 0.4648 - val_f1_m: 0.8437\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5089 - f1_m: 0.7850 - val_loss: 0.4533 - val_f1_m: 0.8437\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4965 - f1_m: 0.7850 - val_loss: 0.4423 - val_f1_m: 0.8304\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4824 - f1_m: 0.7850 - val_loss: 0.4284 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4680 - f1_m: 0.7850 - val_loss: 0.4122 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4510 - f1_m: 0.7850 - val_loss: 0.3956 - val_f1_m: 0.8304\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4325 - f1_m: 0.7850 - val_loss: 0.3782 - val_f1_m: 0.8437\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4112 - f1_m: 0.7850 - val_loss: 0.3582 - val_f1_m: 0.8437\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3876 - f1_m: 0.7850 - val_loss: 0.3367 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3636 - f1_m: 0.7850 - val_loss: 0.3135 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3367 - f1_m: 0.7850 - val_loss: 0.2893 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3115 - f1_m: 0.7850 - val_loss: 0.2671 - val_f1_m: 0.8304\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2859 - f1_m: 0.8150 - val_loss: 0.2458 - val_f1_m: 0.8884\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2634 - f1_m: 0.8775 - val_loss: 0.2270 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2427 - f1_m: 0.9075 - val_loss: 0.2064 - val_f1_m: 0.9286\n",
      "0.9074999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6559 - f1_m: 0.7912 - val_loss: 0.6286 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6075 - f1_m: 0.7912 - val_loss: 0.5813 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5669 - f1_m: 0.7912 - val_loss: 0.5463 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5377 - f1_m: 0.7912 - val_loss: 0.5220 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5184 - f1_m: 0.7912 - val_loss: 0.5055 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5045 - f1_m: 0.7912 - val_loss: 0.4908 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4909 - f1_m: 0.7912 - val_loss: 0.4754 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4748 - f1_m: 0.7912 - val_loss: 0.4575 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4567 - f1_m: 0.7912 - val_loss: 0.4363 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4344 - f1_m: 0.7912 - val_loss: 0.4111 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4073 - f1_m: 0.7912 - val_loss: 0.3807 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3777 - f1_m: 0.7912 - val_loss: 0.3484 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3448 - f1_m: 0.7912 - val_loss: 0.3133 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3095 - f1_m: 0.7912 - val_loss: 0.2770 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2755 - f1_m: 0.8412 - val_loss: 0.2430 - val_f1_m: 0.8973\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2457 - f1_m: 0.8888 - val_loss: 0.2143 - val_f1_m: 0.9018\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2206 - f1_m: 0.9150 - val_loss: 0.1914 - val_f1_m: 0.9286\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2025 - f1_m: 0.9150 - val_loss: 0.1753 - val_f1_m: 0.9420\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.1884 - f1_m: 0.9300 - val_loss: 0.1638 - val_f1_m: 0.9464\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1788 - f1_m: 0.9287 - val_loss: 0.1556 - val_f1_m: 0.9375\n",
      "0.9287499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 698us/sample - loss: 0.6582 - f1_m: 0.7900 - val_loss: 0.6266 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6098 - f1_m: 0.7900 - val_loss: 0.5757 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5679 - f1_m: 0.7900 - val_loss: 0.5353 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5409 - f1_m: 0.7900 - val_loss: 0.5118 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5254 - f1_m: 0.7900 - val_loss: 0.4978 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5148 - f1_m: 0.7900 - val_loss: 0.4865 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5051 - f1_m: 0.7900 - val_loss: 0.4768 - val_f1_m: 0.8259\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4941 - f1_m: 0.7900 - val_loss: 0.4648 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4810 - f1_m: 0.7900 - val_loss: 0.4524 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4670 - f1_m: 0.7900 - val_loss: 0.4364 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4511 - f1_m: 0.7900 - val_loss: 0.4190 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4332 - f1_m: 0.7900 - val_loss: 0.3985 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4129 - f1_m: 0.7900 - val_loss: 0.3764 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3905 - f1_m: 0.7900 - val_loss: 0.3519 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3664 - f1_m: 0.7900 - val_loss: 0.3250 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3396 - f1_m: 0.7900 - val_loss: 0.3019 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3128 - f1_m: 0.7900 - val_loss: 0.2681 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2854 - f1_m: 0.8275 - val_loss: 0.2407 - val_f1_m: 0.9062\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2620 - f1_m: 0.8862 - val_loss: 0.2152 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2385 - f1_m: 0.8913 - val_loss: 0.1925 - val_f1_m: 0.9375\n",
      "0.89125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 706us/sample - loss: 0.6561 - f1_m: 0.8025 - val_loss: 0.6393 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6048 - f1_m: 0.8025 - val_loss: 0.6005 - val_f1_m: 0.7411\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5575 - f1_m: 0.8025 - val_loss: 0.5758 - val_f1_m: 0.7545\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5264 - f1_m: 0.8025 - val_loss: 0.5626 - val_f1_m: 0.7411\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5079 - f1_m: 0.8025 - val_loss: 0.5544 - val_f1_m: 0.7411\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4968 - f1_m: 0.8025 - val_loss: 0.5460 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4854 - f1_m: 0.8025 - val_loss: 0.5363 - val_f1_m: 0.7411\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.4737 - f1_m: 0.8025 - val_loss: 0.5210 - val_f1_m: 0.7545\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4573 - f1_m: 0.8025 - val_loss: 0.5013 - val_f1_m: 0.7277\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4378 - f1_m: 0.8025 - val_loss: 0.4802 - val_f1_m: 0.7545\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4159 - f1_m: 0.8025 - val_loss: 0.4553 - val_f1_m: 0.7545\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3928 - f1_m: 0.8025 - val_loss: 0.4271 - val_f1_m: 0.7411\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3661 - f1_m: 0.8025 - val_loss: 0.3958 - val_f1_m: 0.7679\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3368 - f1_m: 0.8025 - val_loss: 0.3621 - val_f1_m: 0.7679\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3071 - f1_m: 0.8025 - val_loss: 0.3273 - val_f1_m: 0.7545\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2763 - f1_m: 0.8025 - val_loss: 0.2935 - val_f1_m: 0.7545\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2476 - f1_m: 0.8912 - val_loss: 0.2626 - val_f1_m: 0.8839\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2211 - f1_m: 0.9100 - val_loss: 0.2344 - val_f1_m: 0.9420\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1990 - f1_m: 0.9337 - val_loss: 0.2154 - val_f1_m: 0.9241\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.1815 - f1_m: 0.9388 - val_loss: 0.1943 - val_f1_m: 0.9375\n",
      "0.93875\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 695us/sample - loss: 0.6585 - f1_m: 0.7900 - val_loss: 0.6293 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6108 - f1_m: 0.7900 - val_loss: 0.5791 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5685 - f1_m: 0.7900 - val_loss: 0.5413 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5413 - f1_m: 0.7900 - val_loss: 0.5168 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5250 - f1_m: 0.7900 - val_loss: 0.5033 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5141 - f1_m: 0.7900 - val_loss: 0.4930 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5043 - f1_m: 0.7900 - val_loss: 0.4815 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4934 - f1_m: 0.7900 - val_loss: 0.4694 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4800 - f1_m: 0.7900 - val_loss: 0.4553 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4674 - f1_m: 0.7900 - val_loss: 0.4418 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4512 - f1_m: 0.7900 - val_loss: 0.4247 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4340 - f1_m: 0.7900 - val_loss: 0.4065 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4142 - f1_m: 0.7900 - val_loss: 0.3869 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3921 - f1_m: 0.7900 - val_loss: 0.3634 - val_f1_m: 0.7589\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3662 - f1_m: 0.7900 - val_loss: 0.3367 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3401 - f1_m: 0.7900 - val_loss: 0.3093 - val_f1_m: 0.8125\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3074 - f1_m: 0.7900 - val_loss: 0.2747 - val_f1_m: 0.8259\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2757 - f1_m: 0.8475 - val_loss: 0.2469 - val_f1_m: 0.9152\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2471 - f1_m: 0.8925 - val_loss: 0.2219 - val_f1_m: 0.9152\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2235 - f1_m: 0.9137 - val_loss: 0.2033 - val_f1_m: 0.9375\n",
      "0.91374993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 688us/sample - loss: 0.6584 - f1_m: 0.7862 - val_loss: 0.6239 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6093 - f1_m: 0.7875 - val_loss: 0.5715 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5687 - f1_m: 0.7875 - val_loss: 0.5282 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5406 - f1_m: 0.7875 - val_loss: 0.5025 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5243 - f1_m: 0.7875 - val_loss: 0.4875 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5136 - f1_m: 0.7875 - val_loss: 0.4774 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5025 - f1_m: 0.7875 - val_loss: 0.4657 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4905 - f1_m: 0.7875 - val_loss: 0.4541 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4759 - f1_m: 0.7875 - val_loss: 0.4396 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4616 - f1_m: 0.7875 - val_loss: 0.4250 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4437 - f1_m: 0.7875 - val_loss: 0.4085 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4238 - f1_m: 0.7875 - val_loss: 0.3902 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4011 - f1_m: 0.7875 - val_loss: 0.3711 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3764 - f1_m: 0.7875 - val_loss: 0.3484 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3482 - f1_m: 0.7875 - val_loss: 0.3251 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3200 - f1_m: 0.7875 - val_loss: 0.3020 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2910 - f1_m: 0.8075 - val_loss: 0.2806 - val_f1_m: 0.8527\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2611 - f1_m: 0.8737 - val_loss: 0.2589 - val_f1_m: 0.8482\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2334 - f1_m: 0.9137 - val_loss: 0.2417 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2098 - f1_m: 0.9325 - val_loss: 0.2277 - val_f1_m: 0.8884\n",
      "0.93249995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 692us/sample - loss: 0.6584 - f1_m: 0.7850 - val_loss: 0.6227 - val_f1_m: 0.8437\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6137 - f1_m: 0.7850 - val_loss: 0.5698 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5757 - f1_m: 0.7850 - val_loss: 0.5291 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5503 - f1_m: 0.7850 - val_loss: 0.5014 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5356 - f1_m: 0.7850 - val_loss: 0.4854 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5270 - f1_m: 0.7850 - val_loss: 0.4746 - val_f1_m: 0.8437\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5199 - f1_m: 0.7850 - val_loss: 0.4659 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5110 - f1_m: 0.7850 - val_loss: 0.4553 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4978 - f1_m: 0.7850 - val_loss: 0.4410 - val_f1_m: 0.8437\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4827 - f1_m: 0.7850 - val_loss: 0.4247 - val_f1_m: 0.8437\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4658 - f1_m: 0.7850 - val_loss: 0.4073 - val_f1_m: 0.8437\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4466 - f1_m: 0.7850 - val_loss: 0.3864 - val_f1_m: 0.8437\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4248 - f1_m: 0.7850 - val_loss: 0.3638 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4003 - f1_m: 0.7850 - val_loss: 0.3392 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3734 - f1_m: 0.7850 - val_loss: 0.3131 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3451 - f1_m: 0.7850 - val_loss: 0.2845 - val_f1_m: 0.8304\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3150 - f1_m: 0.7850 - val_loss: 0.2571 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2867 - f1_m: 0.8250 - val_loss: 0.2297 - val_f1_m: 0.8795\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2607 - f1_m: 0.8950 - val_loss: 0.2061 - val_f1_m: 0.9196\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2387 - f1_m: 0.9175 - val_loss: 0.1850 - val_f1_m: 0.9420\n",
      "0.9174999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 689us/sample - loss: 0.6574 - f1_m: 0.8000 - val_loss: 0.6375 - val_f1_m: 0.7634\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6052 - f1_m: 0.8000 - val_loss: 0.5968 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5574 - f1_m: 0.8000 - val_loss: 0.5684 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5285 - f1_m: 0.8000 - val_loss: 0.5536 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5116 - f1_m: 0.8000 - val_loss: 0.5462 - val_f1_m: 0.7634\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5008 - f1_m: 0.8000 - val_loss: 0.5377 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4919 - f1_m: 0.8000 - val_loss: 0.5289 - val_f1_m: 0.7500\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4820 - f1_m: 0.8000 - val_loss: 0.5177 - val_f1_m: 0.7500\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4704 - f1_m: 0.8000 - val_loss: 0.5044 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4570 - f1_m: 0.8000 - val_loss: 0.4896 - val_f1_m: 0.7500\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4429 - f1_m: 0.8000 - val_loss: 0.4732 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4266 - f1_m: 0.8000 - val_loss: 0.4542 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4096 - f1_m: 0.8000 - val_loss: 0.4321 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3881 - f1_m: 0.8000 - val_loss: 0.4094 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3658 - f1_m: 0.8000 - val_loss: 0.3822 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3420 - f1_m: 0.8000 - val_loss: 0.3548 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3177 - f1_m: 0.8000 - val_loss: 0.3245 - val_f1_m: 0.7232\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2939 - f1_m: 0.8000 - val_loss: 0.2982 - val_f1_m: 0.7634\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2710 - f1_m: 0.8475 - val_loss: 0.2719 - val_f1_m: 0.8661\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2505 - f1_m: 0.8775 - val_loss: 0.2456 - val_f1_m: 0.9152\n",
      "0.8775\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 694us/sample - loss: 0.6571 - f1_m: 0.7887 - val_loss: 0.6241 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6078 - f1_m: 0.7887 - val_loss: 0.5721 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5673 - f1_m: 0.7887 - val_loss: 0.5317 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5391 - f1_m: 0.7887 - val_loss: 0.5072 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5234 - f1_m: 0.7887 - val_loss: 0.4921 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5122 - f1_m: 0.7887 - val_loss: 0.4810 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5010 - f1_m: 0.7887 - val_loss: 0.4686 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4885 - f1_m: 0.7887 - val_loss: 0.4560 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4741 - f1_m: 0.7887 - val_loss: 0.4404 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4559 - f1_m: 0.7887 - val_loss: 0.4196 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4339 - f1_m: 0.7887 - val_loss: 0.3992 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4082 - f1_m: 0.7887 - val_loss: 0.3722 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3798 - f1_m: 0.7887 - val_loss: 0.3455 - val_f1_m: 0.7500\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3497 - f1_m: 0.7887 - val_loss: 0.3160 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3174 - f1_m: 0.7887 - val_loss: 0.2855 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2865 - f1_m: 0.7962 - val_loss: 0.2594 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2584 - f1_m: 0.8850 - val_loss: 0.2326 - val_f1_m: 0.8929\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2327 - f1_m: 0.9075 - val_loss: 0.2125 - val_f1_m: 0.9196\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2120 - f1_m: 0.9275 - val_loss: 0.1962 - val_f1_m: 0.9196\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.1967 - f1_m: 0.9337 - val_loss: 0.1842 - val_f1_m: 0.9330\n",
      "0.93375\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 682us/sample - loss: 0.6572 - f1_m: 0.7862 - val_loss: 0.6235 - val_f1_m: 0.8393\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6099 - f1_m: 0.7862 - val_loss: 0.5710 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5684 - f1_m: 0.7862 - val_loss: 0.5279 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5414 - f1_m: 0.7862 - val_loss: 0.5003 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5254 - f1_m: 0.7862 - val_loss: 0.4842 - val_f1_m: 0.8259\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5147 - f1_m: 0.7862 - val_loss: 0.4726 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5045 - f1_m: 0.7862 - val_loss: 0.4609 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4917 - f1_m: 0.7862 - val_loss: 0.4463 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4737 - f1_m: 0.7862 - val_loss: 0.4267 - val_f1_m: 0.8259\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4527 - f1_m: 0.7862 - val_loss: 0.4060 - val_f1_m: 0.8393\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4295 - f1_m: 0.7862 - val_loss: 0.3826 - val_f1_m: 0.8393\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4035 - f1_m: 0.7862 - val_loss: 0.3586 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3760 - f1_m: 0.7862 - val_loss: 0.3307 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3451 - f1_m: 0.7862 - val_loss: 0.3029 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3145 - f1_m: 0.7862 - val_loss: 0.2746 - val_f1_m: 0.8393\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2848 - f1_m: 0.8325 - val_loss: 0.2477 - val_f1_m: 0.8661\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2571 - f1_m: 0.8925 - val_loss: 0.2231 - val_f1_m: 0.9107\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2336 - f1_m: 0.9100 - val_loss: 0.2030 - val_f1_m: 0.8973\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2143 - f1_m: 0.9175 - val_loss: 0.1862 - val_f1_m: 0.9330\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2001 - f1_m: 0.9250 - val_loss: 0.1753 - val_f1_m: 0.9196\n",
      "0.925\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 730us/sample - loss: 0.6569 - f1_m: 0.7875 - val_loss: 0.6262 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6073 - f1_m: 0.7887 - val_loss: 0.5747 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5659 - f1_m: 0.7887 - val_loss: 0.5345 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5376 - f1_m: 0.7887 - val_loss: 0.5107 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5209 - f1_m: 0.7887 - val_loss: 0.4958 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5092 - f1_m: 0.7887 - val_loss: 0.4842 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4968 - f1_m: 0.7887 - val_loss: 0.4725 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4826 - f1_m: 0.7887 - val_loss: 0.4573 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4638 - f1_m: 0.7887 - val_loss: 0.4389 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4435 - f1_m: 0.7887 - val_loss: 0.4193 - val_f1_m: 0.8170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4178 - f1_m: 0.7887 - val_loss: 0.3967 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3893 - f1_m: 0.7887 - val_loss: 0.3712 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3588 - f1_m: 0.7887 - val_loss: 0.3457 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3257 - f1_m: 0.7887 - val_loss: 0.3199 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2933 - f1_m: 0.7887 - val_loss: 0.2970 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2618 - f1_m: 0.8737 - val_loss: 0.2742 - val_f1_m: 0.8527\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2326 - f1_m: 0.9250 - val_loss: 0.2564 - val_f1_m: 0.8795\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2079 - f1_m: 0.9312 - val_loss: 0.2432 - val_f1_m: 0.8571\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1884 - f1_m: 0.9438 - val_loss: 0.2350 - val_f1_m: 0.8616\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1736 - f1_m: 0.9550 - val_loss: 0.2315 - val_f1_m: 0.8839\n",
      "0.955\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 695us/sample - loss: 0.6574 - f1_m: 0.7812 - val_loss: 0.6195 - val_f1_m: 0.8437\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6116 - f1_m: 0.7812 - val_loss: 0.5635 - val_f1_m: 0.8571\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5743 - f1_m: 0.7812 - val_loss: 0.5186 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5519 - f1_m: 0.7812 - val_loss: 0.4886 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5380 - f1_m: 0.7812 - val_loss: 0.4755 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5297 - f1_m: 0.7812 - val_loss: 0.4648 - val_f1_m: 0.8304\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5232 - f1_m: 0.7812 - val_loss: 0.4564 - val_f1_m: 0.8437\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5160 - f1_m: 0.7812 - val_loss: 0.4468 - val_f1_m: 0.8571\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5041 - f1_m: 0.7812 - val_loss: 0.4353 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4898 - f1_m: 0.7812 - val_loss: 0.4202 - val_f1_m: 0.8437\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4733 - f1_m: 0.7812 - val_loss: 0.4042 - val_f1_m: 0.8437\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4537 - f1_m: 0.7812 - val_loss: 0.3858 - val_f1_m: 0.8437\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4319 - f1_m: 0.7812 - val_loss: 0.3662 - val_f1_m: 0.8437\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4073 - f1_m: 0.7812 - val_loss: 0.3426 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3783 - f1_m: 0.7812 - val_loss: 0.3206 - val_f1_m: 0.8437\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3493 - f1_m: 0.7812 - val_loss: 0.2956 - val_f1_m: 0.8304\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3195 - f1_m: 0.7812 - val_loss: 0.2727 - val_f1_m: 0.8437\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2923 - f1_m: 0.8262 - val_loss: 0.2510 - val_f1_m: 0.8393\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2674 - f1_m: 0.8837 - val_loss: 0.2319 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2449 - f1_m: 0.9000 - val_loss: 0.2192 - val_f1_m: 0.9196\n",
      "0.8999999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 714us/sample - loss: 0.6590 - f1_m: 0.7862 - val_loss: 0.6268 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6110 - f1_m: 0.7862 - val_loss: 0.5746 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5710 - f1_m: 0.7862 - val_loss: 0.5306 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5420 - f1_m: 0.7862 - val_loss: 0.5055 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5266 - f1_m: 0.7862 - val_loss: 0.4887 - val_f1_m: 0.8259\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5161 - f1_m: 0.7862 - val_loss: 0.4780 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5063 - f1_m: 0.7862 - val_loss: 0.4669 - val_f1_m: 0.8259\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4950 - f1_m: 0.7862 - val_loss: 0.4534 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4820 - f1_m: 0.7862 - val_loss: 0.4389 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4672 - f1_m: 0.7862 - val_loss: 0.4236 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4507 - f1_m: 0.7862 - val_loss: 0.4056 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4312 - f1_m: 0.7862 - val_loss: 0.3867 - val_f1_m: 0.8393\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4103 - f1_m: 0.7862 - val_loss: 0.3654 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3861 - f1_m: 0.7862 - val_loss: 0.3408 - val_f1_m: 0.8393\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3605 - f1_m: 0.7862 - val_loss: 0.3159 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3337 - f1_m: 0.7862 - val_loss: 0.2891 - val_f1_m: 0.8125\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3063 - f1_m: 0.7862 - val_loss: 0.2639 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2809 - f1_m: 0.8175 - val_loss: 0.2411 - val_f1_m: 0.9062\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2564 - f1_m: 0.8950 - val_loss: 0.2128 - val_f1_m: 0.8973\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2349 - f1_m: 0.8987 - val_loss: 0.1962 - val_f1_m: 0.9107\n",
      "0.89874995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 692us/sample - loss: 0.6589 - f1_m: 0.7912 - val_loss: 0.6314 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6118 - f1_m: 0.7912 - val_loss: 0.5840 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5681 - f1_m: 0.7912 - val_loss: 0.5467 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5395 - f1_m: 0.7912 - val_loss: 0.5219 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5215 - f1_m: 0.7912 - val_loss: 0.5081 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5106 - f1_m: 0.7912 - val_loss: 0.4960 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4997 - f1_m: 0.7912 - val_loss: 0.4841 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4875 - f1_m: 0.7912 - val_loss: 0.4695 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4730 - f1_m: 0.7912 - val_loss: 0.4537 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4576 - f1_m: 0.7912 - val_loss: 0.4370 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4399 - f1_m: 0.7912 - val_loss: 0.4182 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4198 - f1_m: 0.7912 - val_loss: 0.3963 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3976 - f1_m: 0.7912 - val_loss: 0.3716 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3711 - f1_m: 0.7912 - val_loss: 0.3415 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3399 - f1_m: 0.7912 - val_loss: 0.3088 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3070 - f1_m: 0.7912 - val_loss: 0.2740 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2748 - f1_m: 0.8212 - val_loss: 0.2407 - val_f1_m: 0.9107\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2454 - f1_m: 0.9075 - val_loss: 0.2121 - val_f1_m: 0.9196\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2204 - f1_m: 0.9200 - val_loss: 0.1877 - val_f1_m: 0.9420\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2008 - f1_m: 0.9400 - val_loss: 0.1689 - val_f1_m: 0.9286\n",
      "0.94\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 701us/sample - loss: 0.6591 - f1_m: 0.7912 - val_loss: 0.6312 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6094 - f1_m: 0.7912 - val_loss: 0.5836 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5662 - f1_m: 0.7912 - val_loss: 0.5441 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5382 - f1_m: 0.7912 - val_loss: 0.5201 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5215 - f1_m: 0.7912 - val_loss: 0.5077 - val_f1_m: 0.7545\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5116 - f1_m: 0.7912 - val_loss: 0.4974 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5020 - f1_m: 0.7912 - val_loss: 0.4870 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4907 - f1_m: 0.7912 - val_loss: 0.4746 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4779 - f1_m: 0.7912 - val_loss: 0.4602 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4634 - f1_m: 0.7912 - val_loss: 0.4451 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4474 - f1_m: 0.7912 - val_loss: 0.4278 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4292 - f1_m: 0.7912 - val_loss: 0.4084 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4090 - f1_m: 0.7912 - val_loss: 0.3861 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3850 - f1_m: 0.7912 - val_loss: 0.3617 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3601 - f1_m: 0.7912 - val_loss: 0.3351 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3332 - f1_m: 0.7912 - val_loss: 0.3069 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3043 - f1_m: 0.7912 - val_loss: 0.2799 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2778 - f1_m: 0.8225 - val_loss: 0.2518 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2512 - f1_m: 0.9050 - val_loss: 0.2274 - val_f1_m: 0.9152\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2287 - f1_m: 0.9125 - val_loss: 0.2052 - val_f1_m: 0.9509\n",
      "0.9125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 709us/sample - loss: 0.6561 - f1_m: 0.7962 - val_loss: 0.6336 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6059 - f1_m: 0.7962 - val_loss: 0.5908 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5621 - f1_m: 0.7962 - val_loss: 0.5585 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.5325 - f1_m: 0.7962 - val_loss: 0.5410 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5157 - f1_m: 0.7962 - val_loss: 0.5305 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5047 - f1_m: 0.7962 - val_loss: 0.5200 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4949 - f1_m: 0.7962 - val_loss: 0.5089 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4830 - f1_m: 0.7962 - val_loss: 0.4935 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4699 - f1_m: 0.7962 - val_loss: 0.4796 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4558 - f1_m: 0.7962 - val_loss: 0.4639 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4408 - f1_m: 0.7962 - val_loss: 0.4455 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4240 - f1_m: 0.7962 - val_loss: 0.4247 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4043 - f1_m: 0.7962 - val_loss: 0.4020 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3842 - f1_m: 0.7962 - val_loss: 0.3798 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3612 - f1_m: 0.7962 - val_loss: 0.3511 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3385 - f1_m: 0.7962 - val_loss: 0.3245 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3134 - f1_m: 0.7962 - val_loss: 0.2997 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2915 - f1_m: 0.7900 - val_loss: 0.2699 - val_f1_m: 0.8482\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2690 - f1_m: 0.8587 - val_loss: 0.2460 - val_f1_m: 0.9152\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2492 - f1_m: 0.8787 - val_loss: 0.2268 - val_f1_m: 0.9330\n",
      "0.8787499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 695us/sample - loss: 0.6583 - f1_m: 0.7962 - val_loss: 0.6340 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6067 - f1_m: 0.7962 - val_loss: 0.5888 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5649 - f1_m: 0.7962 - val_loss: 0.5557 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5356 - f1_m: 0.7962 - val_loss: 0.5385 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5185 - f1_m: 0.7962 - val_loss: 0.5274 - val_f1_m: 0.7500\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5064 - f1_m: 0.7962 - val_loss: 0.5172 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4943 - f1_m: 0.7962 - val_loss: 0.5042 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4796 - f1_m: 0.7962 - val_loss: 0.4889 - val_f1_m: 0.7500\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4627 - f1_m: 0.7962 - val_loss: 0.4699 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4428 - f1_m: 0.7962 - val_loss: 0.4494 - val_f1_m: 0.7634\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4216 - f1_m: 0.7962 - val_loss: 0.4257 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3968 - f1_m: 0.7962 - val_loss: 0.3998 - val_f1_m: 0.7500\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3696 - f1_m: 0.7962 - val_loss: 0.3723 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3409 - f1_m: 0.7962 - val_loss: 0.3404 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3107 - f1_m: 0.7962 - val_loss: 0.3148 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2809 - f1_m: 0.8212 - val_loss: 0.2817 - val_f1_m: 0.8616\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2538 - f1_m: 0.8837 - val_loss: 0.2563 - val_f1_m: 0.9062\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2293 - f1_m: 0.9112 - val_loss: 0.2380 - val_f1_m: 0.9196\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2094 - f1_m: 0.9225 - val_loss: 0.2205 - val_f1_m: 0.9062\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1941 - f1_m: 0.9287 - val_loss: 0.2115 - val_f1_m: 0.9196\n",
      "0.92875\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 693us/sample - loss: 0.6562 - f1_m: 0.8037 - val_loss: 0.6416 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6056 - f1_m: 0.8037 - val_loss: 0.6070 - val_f1_m: 0.7634\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5606 - f1_m: 0.8037 - val_loss: 0.5810 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5292 - f1_m: 0.8037 - val_loss: 0.5693 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5105 - f1_m: 0.8037 - val_loss: 0.5644 - val_f1_m: 0.7500\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4980 - f1_m: 0.8037 - val_loss: 0.5569 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4882 - f1_m: 0.8037 - val_loss: 0.5473 - val_f1_m: 0.7500\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4774 - f1_m: 0.8037 - val_loss: 0.5353 - val_f1_m: 0.7500\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4642 - f1_m: 0.8037 - val_loss: 0.5195 - val_f1_m: 0.7232\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4509 - f1_m: 0.8037 - val_loss: 0.5067 - val_f1_m: 0.7366\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4353 - f1_m: 0.8037 - val_loss: 0.4893 - val_f1_m: 0.7500\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4187 - f1_m: 0.8037 - val_loss: 0.4683 - val_f1_m: 0.7366\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4001 - f1_m: 0.8037 - val_loss: 0.4460 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3796 - f1_m: 0.8037 - val_loss: 0.4202 - val_f1_m: 0.7366\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3570 - f1_m: 0.8037 - val_loss: 0.3937 - val_f1_m: 0.7366\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3349 - f1_m: 0.8037 - val_loss: 0.3701 - val_f1_m: 0.7500\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3109 - f1_m: 0.8037 - val_loss: 0.3356 - val_f1_m: 0.7366\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2880 - f1_m: 0.8037 - val_loss: 0.3050 - val_f1_m: 0.7634\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2668 - f1_m: 0.8287 - val_loss: 0.2801 - val_f1_m: 0.8437\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2478 - f1_m: 0.8762 - val_loss: 0.2571 - val_f1_m: 0.8705\n",
      "0.8762499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 686us/sample - loss: 0.6594 - f1_m: 0.7875 - val_loss: 0.6282 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6106 - f1_m: 0.7875 - val_loss: 0.5795 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5718 - f1_m: 0.7875 - val_loss: 0.5404 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5429 - f1_m: 0.7875 - val_loss: 0.5134 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5238 - f1_m: 0.7875 - val_loss: 0.4929 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5082 - f1_m: 0.7875 - val_loss: 0.4758 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4923 - f1_m: 0.7875 - val_loss: 0.4588 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4752 - f1_m: 0.7875 - val_loss: 0.4398 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4549 - f1_m: 0.7875 - val_loss: 0.4196 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4327 - f1_m: 0.7875 - val_loss: 0.3967 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4084 - f1_m: 0.7875 - val_loss: 0.3731 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3826 - f1_m: 0.7875 - val_loss: 0.3479 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3537 - f1_m: 0.7875 - val_loss: 0.3203 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3239 - f1_m: 0.7875 - val_loss: 0.2929 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2939 - f1_m: 0.7900 - val_loss: 0.2653 - val_f1_m: 0.8571\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2652 - f1_m: 0.8775 - val_loss: 0.2401 - val_f1_m: 0.8929\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2379 - f1_m: 0.9125 - val_loss: 0.2164 - val_f1_m: 0.9196\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2146 - f1_m: 0.9187 - val_loss: 0.2003 - val_f1_m: 0.9420\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1995 - f1_m: 0.9388 - val_loss: 0.1832 - val_f1_m: 0.9420\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.1817 - f1_m: 0.9450 - val_loss: 0.1715 - val_f1_m: 0.9420\n",
      "0.94499993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 694us/sample - loss: 0.6577 - f1_m: 0.8012 - val_loss: 0.6405 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6052 - f1_m: 0.8012 - val_loss: 0.6012 - val_f1_m: 0.7455\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5582 - f1_m: 0.8012 - val_loss: 0.5750 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5267 - f1_m: 0.8012 - val_loss: 0.5628 - val_f1_m: 0.7321\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5089 - f1_m: 0.8012 - val_loss: 0.5557 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4981 - f1_m: 0.8012 - val_loss: 0.5479 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4887 - f1_m: 0.8012 - val_loss: 0.5392 - val_f1_m: 0.7187\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4782 - f1_m: 0.8012 - val_loss: 0.5279 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4665 - f1_m: 0.8012 - val_loss: 0.5123 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4519 - f1_m: 0.8012 - val_loss: 0.4956 - val_f1_m: 0.7455\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4359 - f1_m: 0.8012 - val_loss: 0.4785 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4187 - f1_m: 0.8012 - val_loss: 0.4572 - val_f1_m: 0.7455\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3992 - f1_m: 0.8012 - val_loss: 0.4331 - val_f1_m: 0.7589\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3774 - f1_m: 0.8012 - val_loss: 0.4078 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3538 - f1_m: 0.8012 - val_loss: 0.3814 - val_f1_m: 0.7589\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3277 - f1_m: 0.8012 - val_loss: 0.3513 - val_f1_m: 0.7455\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3018 - f1_m: 0.8012 - val_loss: 0.3219 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2768 - f1_m: 0.8112 - val_loss: 0.2910 - val_f1_m: 0.8616\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2533 - f1_m: 0.8812 - val_loss: 0.2691 - val_f1_m: 0.8661\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2333 - f1_m: 0.9012 - val_loss: 0.2515 - val_f1_m: 0.8661\n",
      "0.90124995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 810us/sample - loss: 0.6589 - f1_m: 0.7850 - val_loss: 0.6225 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6133 - f1_m: 0.7850 - val_loss: 0.5711 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5764 - f1_m: 0.7850 - val_loss: 0.5304 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5490 - f1_m: 0.7850 - val_loss: 0.5026 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5319 - f1_m: 0.7850 - val_loss: 0.4835 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5175 - f1_m: 0.7850 - val_loss: 0.4704 - val_f1_m: 0.8437\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5047 - f1_m: 0.7850 - val_loss: 0.4556 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4909 - f1_m: 0.7850 - val_loss: 0.4415 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4752 - f1_m: 0.7850 - val_loss: 0.4241 - val_f1_m: 0.8437\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4564 - f1_m: 0.7850 - val_loss: 0.4078 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4373 - f1_m: 0.7850 - val_loss: 0.3881 - val_f1_m: 0.8304\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4167 - f1_m: 0.7850 - val_loss: 0.3687 - val_f1_m: 0.8304\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3936 - f1_m: 0.7850 - val_loss: 0.3472 - val_f1_m: 0.8437\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3692 - f1_m: 0.7850 - val_loss: 0.3263 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3431 - f1_m: 0.7850 - val_loss: 0.3024 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3172 - f1_m: 0.7850 - val_loss: 0.2793 - val_f1_m: 0.8304\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2919 - f1_m: 0.8225 - val_loss: 0.2623 - val_f1_m: 0.9062\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2672 - f1_m: 0.8800 - val_loss: 0.2391 - val_f1_m: 0.8839\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2446 - f1_m: 0.9025 - val_loss: 0.2256 - val_f1_m: 0.9152\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2268 - f1_m: 0.9200 - val_loss: 0.2075 - val_f1_m: 0.9286\n",
      "0.9199999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6545 - f1_m: 0.7962 - val_loss: 0.6335 - val_f1_m: 0.7589\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6031 - f1_m: 0.7975 - val_loss: 0.5912 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5623 - f1_m: 0.7975 - val_loss: 0.5628 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5346 - f1_m: 0.7975 - val_loss: 0.5480 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5202 - f1_m: 0.7975 - val_loss: 0.5405 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5109 - f1_m: 0.7975 - val_loss: 0.5346 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5044 - f1_m: 0.7975 - val_loss: 0.5295 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4982 - f1_m: 0.7975 - val_loss: 0.5231 - val_f1_m: 0.7589\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4914 - f1_m: 0.7975 - val_loss: 0.5155 - val_f1_m: 0.7455\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4830 - f1_m: 0.7975 - val_loss: 0.5065 - val_f1_m: 0.7321\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4737 - f1_m: 0.7975 - val_loss: 0.4975 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4638 - f1_m: 0.7975 - val_loss: 0.4870 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4519 - f1_m: 0.7975 - val_loss: 0.4729 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4379 - f1_m: 0.7975 - val_loss: 0.4572 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4215 - f1_m: 0.7975 - val_loss: 0.4380 - val_f1_m: 0.7589\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4023 - f1_m: 0.7975 - val_loss: 0.4172 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3806 - f1_m: 0.7975 - val_loss: 0.3891 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3486 - f1_m: 0.7975 - val_loss: 0.3518 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3145 - f1_m: 0.7975 - val_loss: 0.3177 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2837 - f1_m: 0.8012 - val_loss: 0.2849 - val_f1_m: 0.8393\n",
      "0.8012499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 689us/sample - loss: 0.6600 - f1_m: 0.7837 - val_loss: 0.6199 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6136 - f1_m: 0.7837 - val_loss: 0.5646 - val_f1_m: 0.8348\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5747 - f1_m: 0.7837 - val_loss: 0.5158 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5461 - f1_m: 0.7837 - val_loss: 0.4842 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5297 - f1_m: 0.7837 - val_loss: 0.4671 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5200 - f1_m: 0.7837 - val_loss: 0.4561 - val_f1_m: 0.8348\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5086 - f1_m: 0.7837 - val_loss: 0.4455 - val_f1_m: 0.8348\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4968 - f1_m: 0.7837 - val_loss: 0.4354 - val_f1_m: 0.8482\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4825 - f1_m: 0.7837 - val_loss: 0.4206 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4669 - f1_m: 0.7837 - val_loss: 0.4014 - val_f1_m: 0.8482\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4449 - f1_m: 0.7837 - val_loss: 0.3804 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4210 - f1_m: 0.7837 - val_loss: 0.3557 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3932 - f1_m: 0.7837 - val_loss: 0.3303 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3632 - f1_m: 0.7837 - val_loss: 0.3051 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3321 - f1_m: 0.7837 - val_loss: 0.2763 - val_f1_m: 0.8348\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3016 - f1_m: 0.7837 - val_loss: 0.2503 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2729 - f1_m: 0.8662 - val_loss: 0.2268 - val_f1_m: 0.9018\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2455 - f1_m: 0.9012 - val_loss: 0.2058 - val_f1_m: 0.9286\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2235 - f1_m: 0.9137 - val_loss: 0.1893 - val_f1_m: 0.9330\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2066 - f1_m: 0.9237 - val_loss: 0.1756 - val_f1_m: 0.9196\n",
      "0.9237499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 685us/sample - loss: 0.6589 - f1_m: 0.7925 - val_loss: 0.6321 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.6094 - f1_m: 0.7925 - val_loss: 0.5876 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5698 - f1_m: 0.7925 - val_loss: 0.5518 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5400 - f1_m: 0.7925 - val_loss: 0.5288 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5206 - f1_m: 0.7925 - val_loss: 0.5129 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5063 - f1_m: 0.7925 - val_loss: 0.4986 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4912 - f1_m: 0.7925 - val_loss: 0.4829 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4755 - f1_m: 0.7925 - val_loss: 0.4657 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4575 - f1_m: 0.7925 - val_loss: 0.4457 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4356 - f1_m: 0.7925 - val_loss: 0.4224 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4136 - f1_m: 0.7925 - val_loss: 0.3989 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3888 - f1_m: 0.7925 - val_loss: 0.3732 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3624 - f1_m: 0.7925 - val_loss: 0.3466 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3361 - f1_m: 0.7925 - val_loss: 0.3197 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3087 - f1_m: 0.7925 - val_loss: 0.2931 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2817 - f1_m: 0.8112 - val_loss: 0.2684 - val_f1_m: 0.8705\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2579 - f1_m: 0.8925 - val_loss: 0.2456 - val_f1_m: 0.9286\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2344 - f1_m: 0.9050 - val_loss: 0.2285 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2163 - f1_m: 0.9225 - val_loss: 0.2102 - val_f1_m: 0.9375\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2005 - f1_m: 0.9237 - val_loss: 0.2002 - val_f1_m: 0.9375\n",
      "0.9237499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 709us/sample - loss: 0.6565 - f1_m: 0.7987 - val_loss: 0.6364 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6036 - f1_m: 0.7987 - val_loss: 0.5959 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5582 - f1_m: 0.7987 - val_loss: 0.5650 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5286 - f1_m: 0.7987 - val_loss: 0.5493 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5118 - f1_m: 0.7987 - val_loss: 0.5401 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5023 - f1_m: 0.7987 - val_loss: 0.5335 - val_f1_m: 0.7545\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4933 - f1_m: 0.7987 - val_loss: 0.5214 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4831 - f1_m: 0.7987 - val_loss: 0.5092 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4706 - f1_m: 0.7987 - val_loss: 0.4954 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4567 - f1_m: 0.7987 - val_loss: 0.4793 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4417 - f1_m: 0.7987 - val_loss: 0.4623 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4247 - f1_m: 0.7987 - val_loss: 0.4414 - val_f1_m: 0.7545\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4061 - f1_m: 0.7987 - val_loss: 0.4171 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3843 - f1_m: 0.7987 - val_loss: 0.3924 - val_f1_m: 0.7545\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3618 - f1_m: 0.7987 - val_loss: 0.3641 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3366 - f1_m: 0.7987 - val_loss: 0.3328 - val_f1_m: 0.7545\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3107 - f1_m: 0.7987 - val_loss: 0.3032 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2866 - f1_m: 0.7950 - val_loss: 0.2717 - val_f1_m: 0.8571\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2621 - f1_m: 0.8675 - val_loss: 0.2434 - val_f1_m: 0.9196\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2410 - f1_m: 0.8862 - val_loss: 0.2190 - val_f1_m: 0.9554\n",
      "0.8862499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 702us/sample - loss: 0.6575 - f1_m: 0.7975 - val_loss: 0.6365 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6085 - f1_m: 0.7975 - val_loss: 0.5953 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5660 - f1_m: 0.7975 - val_loss: 0.5664 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5369 - f1_m: 0.7975 - val_loss: 0.5453 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5146 - f1_m: 0.7975 - val_loss: 0.5320 - val_f1_m: 0.7589\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4999 - f1_m: 0.7975 - val_loss: 0.5186 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4855 - f1_m: 0.7975 - val_loss: 0.5048 - val_f1_m: 0.7455\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4697 - f1_m: 0.7975 - val_loss: 0.4873 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4518 - f1_m: 0.7975 - val_loss: 0.4668 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4304 - f1_m: 0.7975 - val_loss: 0.4423 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4067 - f1_m: 0.7975 - val_loss: 0.4172 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3821 - f1_m: 0.7975 - val_loss: 0.3942 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3571 - f1_m: 0.7975 - val_loss: 0.3630 - val_f1_m: 0.7589\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3296 - f1_m: 0.7975 - val_loss: 0.3326 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3004 - f1_m: 0.7975 - val_loss: 0.3037 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2714 - f1_m: 0.8412 - val_loss: 0.2707 - val_f1_m: 0.8527\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2463 - f1_m: 0.8825 - val_loss: 0.2434 - val_f1_m: 0.8839\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2233 - f1_m: 0.9037 - val_loss: 0.2216 - val_f1_m: 0.9152\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2053 - f1_m: 0.9200 - val_loss: 0.2024 - val_f1_m: 0.9420\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 60us/sample - loss: 0.1920 - f1_m: 0.9312 - val_loss: 0.1895 - val_f1_m: 0.9420\n",
      "0.93125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 715us/sample - loss: 0.6587 - f1_m: 0.7937 - val_loss: 0.6327 - val_f1_m: 0.7723\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6087 - f1_m: 0.7937 - val_loss: 0.5858 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5642 - f1_m: 0.7937 - val_loss: 0.5506 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5359 - f1_m: 0.7937 - val_loss: 0.5284 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5179 - f1_m: 0.7937 - val_loss: 0.5156 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5061 - f1_m: 0.7937 - val_loss: 0.5045 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4942 - f1_m: 0.7937 - val_loss: 0.4924 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4818 - f1_m: 0.7937 - val_loss: 0.4789 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4663 - f1_m: 0.7937 - val_loss: 0.4630 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4496 - f1_m: 0.7937 - val_loss: 0.4457 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4311 - f1_m: 0.7937 - val_loss: 0.4261 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4092 - f1_m: 0.7937 - val_loss: 0.4016 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3814 - f1_m: 0.7937 - val_loss: 0.3713 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3495 - f1_m: 0.7937 - val_loss: 0.3390 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3163 - f1_m: 0.7937 - val_loss: 0.3078 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2814 - f1_m: 0.7937 - val_loss: 0.2762 - val_f1_m: 0.8571\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2500 - f1_m: 0.9000 - val_loss: 0.2474 - val_f1_m: 0.8973\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.2215 - f1_m: 0.9175 - val_loss: 0.2241 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1975 - f1_m: 0.9350 - val_loss: 0.2066 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.1789 - f1_m: 0.9475 - val_loss: 0.1950 - val_f1_m: 0.9152\n",
      "0.9475\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 715us/sample - loss: 0.6581 - f1_m: 0.7900 - val_loss: 0.6286 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6092 - f1_m: 0.7900 - val_loss: 0.5801 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5657 - f1_m: 0.7900 - val_loss: 0.5417 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5394 - f1_m: 0.7900 - val_loss: 0.5164 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5228 - f1_m: 0.7900 - val_loss: 0.5014 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5118 - f1_m: 0.7900 - val_loss: 0.4897 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5017 - f1_m: 0.7900 - val_loss: 0.4781 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4891 - f1_m: 0.7900 - val_loss: 0.4647 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4734 - f1_m: 0.7900 - val_loss: 0.4447 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4534 - f1_m: 0.7900 - val_loss: 0.4235 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4314 - f1_m: 0.7900 - val_loss: 0.3992 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4058 - f1_m: 0.7900 - val_loss: 0.3718 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3774 - f1_m: 0.7900 - val_loss: 0.3417 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3465 - f1_m: 0.7900 - val_loss: 0.3102 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3147 - f1_m: 0.7900 - val_loss: 0.2778 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2837 - f1_m: 0.8175 - val_loss: 0.2472 - val_f1_m: 0.8839\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2545 - f1_m: 0.8887 - val_loss: 0.2197 - val_f1_m: 0.8839\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2301 - f1_m: 0.9150 - val_loss: 0.1960 - val_f1_m: 0.9420\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2095 - f1_m: 0.9225 - val_loss: 0.1793 - val_f1_m: 0.9643\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1936 - f1_m: 0.9337 - val_loss: 0.1638 - val_f1_m: 0.9464\n",
      "0.9337499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 690us/sample - loss: 0.6578 - f1_m: 0.7962 - val_loss: 0.6355 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6081 - f1_m: 0.7962 - val_loss: 0.5914 - val_f1_m: 0.7634\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5628 - f1_m: 0.7962 - val_loss: 0.5586 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5315 - f1_m: 0.7962 - val_loss: 0.5393 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5138 - f1_m: 0.7962 - val_loss: 0.5275 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5024 - f1_m: 0.7962 - val_loss: 0.5165 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4913 - f1_m: 0.7962 - val_loss: 0.5048 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4794 - f1_m: 0.7962 - val_loss: 0.4905 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4652 - f1_m: 0.7962 - val_loss: 0.4743 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4495 - f1_m: 0.7962 - val_loss: 0.4579 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4326 - f1_m: 0.7962 - val_loss: 0.4381 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4145 - f1_m: 0.7962 - val_loss: 0.4184 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3931 - f1_m: 0.7962 - val_loss: 0.3922 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3690 - f1_m: 0.7962 - val_loss: 0.3690 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3450 - f1_m: 0.7962 - val_loss: 0.3372 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3175 - f1_m: 0.7962 - val_loss: 0.3094 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.2912 - f1_m: 0.7962 - val_loss: 0.2811 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2647 - f1_m: 0.8550 - val_loss: 0.2527 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2396 - f1_m: 0.9025 - val_loss: 0.2268 - val_f1_m: 0.9464\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2171 - f1_m: 0.9250 - val_loss: 0.2028 - val_f1_m: 0.9554\n",
      "0.925\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 702us/sample - loss: 0.6582 - f1_m: 0.7912 - val_loss: 0.6289 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6104 - f1_m: 0.7912 - val_loss: 0.5808 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5670 - f1_m: 0.7912 - val_loss: 0.5443 - val_f1_m: 0.7545\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5397 - f1_m: 0.7912 - val_loss: 0.5205 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5228 - f1_m: 0.7912 - val_loss: 0.5064 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5109 - f1_m: 0.7912 - val_loss: 0.4949 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4994 - f1_m: 0.7912 - val_loss: 0.4824 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4871 - f1_m: 0.7912 - val_loss: 0.4687 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4723 - f1_m: 0.7912 - val_loss: 0.4542 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4575 - f1_m: 0.7912 - val_loss: 0.4381 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4404 - f1_m: 0.7912 - val_loss: 0.4198 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4211 - f1_m: 0.7912 - val_loss: 0.3989 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3965 - f1_m: 0.7912 - val_loss: 0.3705 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3664 - f1_m: 0.7912 - val_loss: 0.3402 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3356 - f1_m: 0.7912 - val_loss: 0.3085 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3027 - f1_m: 0.7912 - val_loss: 0.2755 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2709 - f1_m: 0.8237 - val_loss: 0.2449 - val_f1_m: 0.8929\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2424 - f1_m: 0.9062 - val_loss: 0.2188 - val_f1_m: 0.9062\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2199 - f1_m: 0.9287 - val_loss: 0.1989 - val_f1_m: 0.9152\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1993 - f1_m: 0.9312 - val_loss: 0.1801 - val_f1_m: 0.9554\n",
      "0.9312499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 692us/sample - loss: 0.6584 - f1_m: 0.7962 - val_loss: 0.6335 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6084 - f1_m: 0.7962 - val_loss: 0.5876 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5636 - f1_m: 0.7962 - val_loss: 0.5526 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5339 - f1_m: 0.7962 - val_loss: 0.5327 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5171 - f1_m: 0.7962 - val_loss: 0.5220 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5064 - f1_m: 0.7962 - val_loss: 0.5137 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4967 - f1_m: 0.7962 - val_loss: 0.5046 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4854 - f1_m: 0.7962 - val_loss: 0.4938 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4729 - f1_m: 0.7962 - val_loss: 0.4810 - val_f1_m: 0.7366\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4596 - f1_m: 0.7962 - val_loss: 0.4669 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4410 - f1_m: 0.7962 - val_loss: 0.4451 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4188 - f1_m: 0.7962 - val_loss: 0.4196 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3930 - f1_m: 0.7962 - val_loss: 0.3924 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3665 - f1_m: 0.7962 - val_loss: 0.3629 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3366 - f1_m: 0.7962 - val_loss: 0.3344 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3075 - f1_m: 0.7962 - val_loss: 0.3020 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2783 - f1_m: 0.8075 - val_loss: 0.2744 - val_f1_m: 0.8705\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2533 - f1_m: 0.8812 - val_loss: 0.2483 - val_f1_m: 0.8839\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2294 - f1_m: 0.9100 - val_loss: 0.2286 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2116 - f1_m: 0.9225 - val_loss: 0.2112 - val_f1_m: 0.8929\n",
      "0.9225\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 698us/sample - loss: 0.6583 - f1_m: 0.7900 - val_loss: 0.6277 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6092 - f1_m: 0.7900 - val_loss: 0.5794 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5659 - f1_m: 0.7900 - val_loss: 0.5401 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5383 - f1_m: 0.7900 - val_loss: 0.5153 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5218 - f1_m: 0.7900 - val_loss: 0.5022 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5114 - f1_m: 0.7900 - val_loss: 0.4916 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5008 - f1_m: 0.7900 - val_loss: 0.4803 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4897 - f1_m: 0.7900 - val_loss: 0.4680 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4774 - f1_m: 0.7900 - val_loss: 0.4539 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4621 - f1_m: 0.7900 - val_loss: 0.4372 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4434 - f1_m: 0.7900 - val_loss: 0.4170 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4212 - f1_m: 0.7900 - val_loss: 0.3949 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3968 - f1_m: 0.7900 - val_loss: 0.3691 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3693 - f1_m: 0.7900 - val_loss: 0.3421 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3391 - f1_m: 0.7900 - val_loss: 0.3128 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3096 - f1_m: 0.7900 - val_loss: 0.2845 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2793 - f1_m: 0.8200 - val_loss: 0.2593 - val_f1_m: 0.8795\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2546 - f1_m: 0.8825 - val_loss: 0.2382 - val_f1_m: 0.9062\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2316 - f1_m: 0.9087 - val_loss: 0.2200 - val_f1_m: 0.8884\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2132 - f1_m: 0.9137 - val_loss: 0.2032 - val_f1_m: 0.9241\n",
      "0.91374993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 690us/sample - loss: 0.6569 - f1_m: 0.8000 - val_loss: 0.6381 - val_f1_m: 0.7634\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6055 - f1_m: 0.8000 - val_loss: 0.5975 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5606 - f1_m: 0.8000 - val_loss: 0.5685 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5309 - f1_m: 0.8000 - val_loss: 0.5547 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5141 - f1_m: 0.8000 - val_loss: 0.5466 - val_f1_m: 0.7500\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5040 - f1_m: 0.8000 - val_loss: 0.5394 - val_f1_m: 0.7366\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4951 - f1_m: 0.8000 - val_loss: 0.5310 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4855 - f1_m: 0.8000 - val_loss: 0.5190 - val_f1_m: 0.7500\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4581 - f1_m: 0.81 - 0s 63us/sample - loss: 0.4744 - f1_m: 0.8000 - val_loss: 0.5075 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4616 - f1_m: 0.8000 - val_loss: 0.4935 - val_f1_m: 0.7634\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4478 - f1_m: 0.8000 - val_loss: 0.4783 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4246 - f1_m: 0.81 - 0s 61us/sample - loss: 0.4325 - f1_m: 0.8000 - val_loss: 0.4600 - val_f1_m: 0.7232\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4146 - f1_m: 0.8000 - val_loss: 0.4388 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3946 - f1_m: 0.8000 - val_loss: 0.4162 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3733 - f1_m: 0.8000 - val_loss: 0.3900 - val_f1_m: 0.7500\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3491 - f1_m: 0.8000 - val_loss: 0.3630 - val_f1_m: 0.7500\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3250 - f1_m: 0.8000 - val_loss: 0.3359 - val_f1_m: 0.7500\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3007 - f1_m: 0.8000 - val_loss: 0.3104 - val_f1_m: 0.7366\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2765 - f1_m: 0.8212 - val_loss: 0.2833 - val_f1_m: 0.8661\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2566 - f1_m: 0.8838 - val_loss: 0.2654 - val_f1_m: 0.9330\n",
      "0.88375\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 695us/sample - loss: 0.6580 - f1_m: 0.7887 - val_loss: 0.6262 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6094 - f1_m: 0.7887 - val_loss: 0.5753 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5669 - f1_m: 0.7887 - val_loss: 0.5336 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5407 - f1_m: 0.7887 - val_loss: 0.5085 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5247 - f1_m: 0.7887 - val_loss: 0.4951 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5146 - f1_m: 0.7887 - val_loss: 0.4852 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5049 - f1_m: 0.7887 - val_loss: 0.4727 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4915 - f1_m: 0.7887 - val_loss: 0.4564 - val_f1_m: 0.8304\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4735 - f1_m: 0.7887 - val_loss: 0.4371 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4550 - f1_m: 0.7887 - val_loss: 0.4165 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4341 - f1_m: 0.7887 - val_loss: 0.3931 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4097 - f1_m: 0.7887 - val_loss: 0.3660 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3827 - f1_m: 0.7887 - val_loss: 0.3374 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3538 - f1_m: 0.7887 - val_loss: 0.3065 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3245 - f1_m: 0.7887 - val_loss: 0.2748 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2957 - f1_m: 0.8012 - val_loss: 0.2492 - val_f1_m: 0.8839\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2698 - f1_m: 0.8650 - val_loss: 0.2163 - val_f1_m: 0.9107\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1823 - f1_m: 0.93 - 0s 63us/sample - loss: 0.2451 - f1_m: 0.8888 - val_loss: 0.1925 - val_f1_m: 0.9420\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2268 - f1_m: 0.9150 - val_loss: 0.1725 - val_f1_m: 0.9687\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2128 - f1_m: 0.9225 - val_loss: 0.1556 - val_f1_m: 0.9554\n",
      "0.9225\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 691us/sample - loss: 0.6591 - f1_m: 0.7887 - val_loss: 0.6263 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6112 - f1_m: 0.7887 - val_loss: 0.5740 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5696 - f1_m: 0.7887 - val_loss: 0.5311 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5413 - f1_m: 0.7887 - val_loss: 0.5061 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5246 - f1_m: 0.7887 - val_loss: 0.4907 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5131 - f1_m: 0.7887 - val_loss: 0.4797 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5020 - f1_m: 0.7887 - val_loss: 0.4683 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4891 - f1_m: 0.7887 - val_loss: 0.4562 - val_f1_m: 0.8304\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4757 - f1_m: 0.7887 - val_loss: 0.4434 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4587 - f1_m: 0.7887 - val_loss: 0.4234 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4370 - f1_m: 0.7887 - val_loss: 0.4005 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4121 - f1_m: 0.7887 - val_loss: 0.3765 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3851 - f1_m: 0.7887 - val_loss: 0.3547 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3560 - f1_m: 0.7887 - val_loss: 0.3216 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3249 - f1_m: 0.7887 - val_loss: 0.2942 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2945 - f1_m: 0.7962 - val_loss: 0.2716 - val_f1_m: 0.9018\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2668 - f1_m: 0.8750 - val_loss: 0.2436 - val_f1_m: 0.8884\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2426 - f1_m: 0.8962 - val_loss: 0.2239 - val_f1_m: 0.9062\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2232 - f1_m: 0.9137 - val_loss: 0.2093 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2069 - f1_m: 0.9250 - val_loss: 0.1968 - val_f1_m: 0.9152\n",
      "0.925\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 717us/sample - loss: 0.6589 - f1_m: 0.7937 - val_loss: 0.6304 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6101 - f1_m: 0.7937 - val_loss: 0.5845 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5667 - f1_m: 0.7937 - val_loss: 0.5488 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5374 - f1_m: 0.7937 - val_loss: 0.5270 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5202 - f1_m: 0.7937 - val_loss: 0.5148 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5089 - f1_m: 0.7937 - val_loss: 0.5053 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4984 - f1_m: 0.7937 - val_loss: 0.4944 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4865 - f1_m: 0.7937 - val_loss: 0.4815 - val_f1_m: 0.7589\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4719 - f1_m: 0.7937 - val_loss: 0.4678 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4578 - f1_m: 0.7937 - val_loss: 0.4539 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4423 - f1_m: 0.7937 - val_loss: 0.4374 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4247 - f1_m: 0.7937 - val_loss: 0.4189 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4059 - f1_m: 0.7937 - val_loss: 0.3973 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3831 - f1_m: 0.7937 - val_loss: 0.3790 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.3607 - f1_m: 0.7937 - val_loss: 0.3503 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3313 - f1_m: 0.7937 - val_loss: 0.3200 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3018 - f1_m: 0.7937 - val_loss: 0.2927 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2753 - f1_m: 0.8450 - val_loss: 0.2657 - val_f1_m: 0.8839\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2520 - f1_m: 0.8812 - val_loss: 0.2432 - val_f1_m: 0.8973\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.2317 - f1_m: 0.8975 - val_loss: 0.2261 - val_f1_m: 0.8795\n",
      "0.8974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 691us/sample - loss: 0.6554 - f1_m: 0.8112 - val_loss: 0.6492 - val_f1_m: 0.7098\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6037 - f1_m: 0.8112 - val_loss: 0.6210 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5586 - f1_m: 0.8112 - val_loss: 0.6037 - val_f1_m: 0.7232\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5233 - f1_m: 0.8112 - val_loss: 0.5980 - val_f1_m: 0.6964\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5017 - f1_m: 0.8112 - val_loss: 0.5945 - val_f1_m: 0.6964\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4855 - f1_m: 0.8112 - val_loss: 0.5854 - val_f1_m: 0.7232\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4719 - f1_m: 0.8112 - val_loss: 0.5752 - val_f1_m: 0.7098\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4563 - f1_m: 0.8112 - val_loss: 0.5569 - val_f1_m: 0.7232\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4393 - f1_m: 0.8112 - val_loss: 0.5365 - val_f1_m: 0.7232\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4198 - f1_m: 0.8112 - val_loss: 0.5115 - val_f1_m: 0.6830\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3965 - f1_m: 0.8112 - val_loss: 0.4831 - val_f1_m: 0.7098\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3711 - f1_m: 0.8112 - val_loss: 0.4509 - val_f1_m: 0.7098\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3426 - f1_m: 0.8112 - val_loss: 0.4160 - val_f1_m: 0.7232\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3134 - f1_m: 0.8112 - val_loss: 0.3757 - val_f1_m: 0.7366\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2828 - f1_m: 0.8112 - val_loss: 0.3401 - val_f1_m: 0.7098\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2540 - f1_m: 0.8487 - val_loss: 0.3003 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2285 - f1_m: 0.9000 - val_loss: 0.2712 - val_f1_m: 0.8750\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2080 - f1_m: 0.9187 - val_loss: 0.2490 - val_f1_m: 0.8973\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1926 - f1_m: 0.9250 - val_loss: 0.2287 - val_f1_m: 0.9330\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1822 - f1_m: 0.9312 - val_loss: 0.2178 - val_f1_m: 0.9375\n",
      "0.93125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 706us/sample - loss: 0.6566 - f1_m: 0.8000 - val_loss: 0.6392 - val_f1_m: 0.7634\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.6061 - f1_m: 0.8000 - val_loss: 0.5990 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5601 - f1_m: 0.8000 - val_loss: 0.5710 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5288 - f1_m: 0.8000 - val_loss: 0.5567 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5106 - f1_m: 0.8000 - val_loss: 0.5466 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4989 - f1_m: 0.8000 - val_loss: 0.5391 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4886 - f1_m: 0.8000 - val_loss: 0.5276 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4763 - f1_m: 0.8000 - val_loss: 0.5123 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4593 - f1_m: 0.8000 - val_loss: 0.4894 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4395 - f1_m: 0.8000 - val_loss: 0.4666 - val_f1_m: 0.7366\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4170 - f1_m: 0.8000 - val_loss: 0.4413 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3916 - f1_m: 0.8000 - val_loss: 0.4126 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3650 - f1_m: 0.8000 - val_loss: 0.3784 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4068 - f1_m: 0.75 - 0s 61us/sample - loss: 0.3349 - f1_m: 0.8000 - val_loss: 0.3424 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3046 - f1_m: 0.8000 - val_loss: 0.3044 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2739 - f1_m: 0.8137 - val_loss: 0.2704 - val_f1_m: 0.8750\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.2468 - f1_m: 0.8962 - val_loss: 0.2394 - val_f1_m: 0.8973\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2216 - f1_m: 0.9137 - val_loss: 0.2096 - val_f1_m: 0.9643\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2008 - f1_m: 0.9287 - val_loss: 0.1872 - val_f1_m: 0.9509\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.1855 - f1_m: 0.9400 - val_loss: 0.1692 - val_f1_m: 0.9732\n",
      "0.94\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 705us/sample - loss: 0.6586 - f1_m: 0.7925 - val_loss: 0.6334 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6085 - f1_m: 0.7925 - val_loss: 0.5864 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5659 - f1_m: 0.7925 - val_loss: 0.5500 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5365 - f1_m: 0.7925 - val_loss: 0.5298 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5214 - f1_m: 0.7925 - val_loss: 0.5165 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5114 - f1_m: 0.7925 - val_loss: 0.5062 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5025 - f1_m: 0.7925 - val_loss: 0.4957 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4931 - f1_m: 0.7925 - val_loss: 0.4830 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4793 - f1_m: 0.7925 - val_loss: 0.4685 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4658 - f1_m: 0.7925 - val_loss: 0.4532 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4510 - f1_m: 0.7925 - val_loss: 0.4352 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4329 - f1_m: 0.7925 - val_loss: 0.4153 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4133 - f1_m: 0.7925 - val_loss: 0.3926 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3920 - f1_m: 0.7925 - val_loss: 0.3680 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3682 - f1_m: 0.7925 - val_loss: 0.3441 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3446 - f1_m: 0.7925 - val_loss: 0.3153 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3190 - f1_m: 0.7925 - val_loss: 0.2869 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2943 - f1_m: 0.7912 - val_loss: 0.2619 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2723 - f1_m: 0.8650 - val_loss: 0.2365 - val_f1_m: 0.9241\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2514 - f1_m: 0.8900 - val_loss: 0.2183 - val_f1_m: 0.8661\n",
      "0.8899999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 730us/sample - loss: 0.6584 - f1_m: 0.7962 - val_loss: 0.6344 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.6074 - f1_m: 0.7962 - val_loss: 0.5904 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5631 - f1_m: 0.7962 - val_loss: 0.5573 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5336 - f1_m: 0.7962 - val_loss: 0.5395 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5176 - f1_m: 0.7962 - val_loss: 0.5293 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5074 - f1_m: 0.7962 - val_loss: 0.5211 - val_f1_m: 0.7500\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4988 - f1_m: 0.7962 - val_loss: 0.5129 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4893 - f1_m: 0.7962 - val_loss: 0.5012 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4775 - f1_m: 0.7962 - val_loss: 0.4888 - val_f1_m: 0.7500\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4643 - f1_m: 0.7962 - val_loss: 0.4746 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4504 - f1_m: 0.7962 - val_loss: 0.4591 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4342 - f1_m: 0.7962 - val_loss: 0.4416 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.4162 - f1_m: 0.7962 - val_loss: 0.4209 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3937 - f1_m: 0.7962 - val_loss: 0.3926 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3663 - f1_m: 0.7962 - val_loss: 0.3617 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3377 - f1_m: 0.7962 - val_loss: 0.3284 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.3088 - f1_m: 0.7962 - val_loss: 0.2976 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.2819 - f1_m: 0.8225 - val_loss: 0.2668 - val_f1_m: 0.8750\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.2600 - f1_m: 0.8725 - val_loss: 0.2459 - val_f1_m: 0.8795\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.2385 - f1_m: 0.8887 - val_loss: 0.2183 - val_f1_m: 0.9375\n",
      "0.8887499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 718us/sample - loss: 0.6577 - f1_m: 0.7937 - val_loss: 0.6327 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6085 - f1_m: 0.7937 - val_loss: 0.5864 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5644 - f1_m: 0.7937 - val_loss: 0.5515 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5348 - f1_m: 0.7937 - val_loss: 0.5308 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5191 - f1_m: 0.7937 - val_loss: 0.5182 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5082 - f1_m: 0.7937 - val_loss: 0.5084 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4775 - f1_m: 0.81 - 0s 60us/sample - loss: 0.4990 - f1_m: 0.7937 - val_loss: 0.4980 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4880 - f1_m: 0.7937 - val_loss: 0.4856 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4762 - f1_m: 0.7937 - val_loss: 0.4709 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4610 - f1_m: 0.7937 - val_loss: 0.4548 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4453 - f1_m: 0.7937 - val_loss: 0.4374 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4276 - f1_m: 0.7937 - val_loss: 0.4168 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4065 - f1_m: 0.7937 - val_loss: 0.3907 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3780 - f1_m: 0.7937 - val_loss: 0.3575 - val_f1_m: 0.7589\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3458 - f1_m: 0.7937 - val_loss: 0.3236 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3141 - f1_m: 0.7937 - val_loss: 0.2906 - val_f1_m: 0.8125\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.2862 - f1_m: 0.7937 - val_loss: 0.2601 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2584 - f1_m: 0.8725 - val_loss: 0.2316 - val_f1_m: 0.9196\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2347 - f1_m: 0.8950 - val_loss: 0.2080 - val_f1_m: 0.9464\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2174 - f1_m: 0.9137 - val_loss: 0.1893 - val_f1_m: 0.9152\n",
      "0.91375\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 699us/sample - loss: 0.6585 - f1_m: 0.7937 - val_loss: 0.6341 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6093 - f1_m: 0.7937 - val_loss: 0.5895 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5658 - f1_m: 0.7937 - val_loss: 0.5544 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5366 - f1_m: 0.7937 - val_loss: 0.5336 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5199 - f1_m: 0.7937 - val_loss: 0.5208 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5093 - f1_m: 0.7937 - val_loss: 0.5098 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4983 - f1_m: 0.7937 - val_loss: 0.4981 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4856 - f1_m: 0.7937 - val_loss: 0.4847 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4729 - f1_m: 0.7937 - val_loss: 0.4722 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4587 - f1_m: 0.7937 - val_loss: 0.4574 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4446 - f1_m: 0.7937 - val_loss: 0.4420 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4264 - f1_m: 0.7937 - val_loss: 0.4240 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4077 - f1_m: 0.7937 - val_loss: 0.4022 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3855 - f1_m: 0.7937 - val_loss: 0.3818 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3618 - f1_m: 0.7937 - val_loss: 0.3555 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3373 - f1_m: 0.7937 - val_loss: 0.3309 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3122 - f1_m: 0.7937 - val_loss: 0.3047 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2876 - f1_m: 0.8000 - val_loss: 0.2776 - val_f1_m: 0.8527\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.2659 - f1_m: 0.8637 - val_loss: 0.2559 - val_f1_m: 0.8259\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2440 - f1_m: 0.8850 - val_loss: 0.2336 - val_f1_m: 0.9062\n",
      "0.88499993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 690us/sample - loss: 0.6562 - f1_m: 0.7925 - val_loss: 0.6282 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6066 - f1_m: 0.7925 - val_loss: 0.5799 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5628 - f1_m: 0.7925 - val_loss: 0.5421 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5345 - f1_m: 0.7925 - val_loss: 0.5200 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5187 - f1_m: 0.7925 - val_loss: 0.5082 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5087 - f1_m: 0.7925 - val_loss: 0.4991 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4989 - f1_m: 0.7925 - val_loss: 0.4899 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.5370 - f1_m: 0.75 - 0s 62us/sample - loss: 0.4889 - f1_m: 0.7925 - val_loss: 0.4788 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4987 - f1_m: 0.78 - 0s 63us/sample - loss: 0.4763 - f1_m: 0.7925 - val_loss: 0.4658 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4617 - f1_m: 0.7925 - val_loss: 0.4517 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4979 - f1_m: 0.75 - 0s 59us/sample - loss: 0.4462 - f1_m: 0.7925 - val_loss: 0.4357 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4287 - f1_m: 0.7925 - val_loss: 0.4180 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4098 - f1_m: 0.7925 - val_loss: 0.3988 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3875 - f1_m: 0.7925 - val_loss: 0.3767 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3639 - f1_m: 0.7925 - val_loss: 0.3534 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3395 - f1_m: 0.7925 - val_loss: 0.3319 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3158 - f1_m: 0.7925 - val_loss: 0.3059 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2921 - f1_m: 0.7837 - val_loss: 0.2837 - val_f1_m: 0.8482\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2669 - f1_m: 0.8637 - val_loss: 0.2633 - val_f1_m: 0.8839\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2459 - f1_m: 0.8887 - val_loss: 0.2451 - val_f1_m: 0.8795\n",
      "0.8887499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 700us/sample - loss: 0.6563 - f1_m: 0.7987 - val_loss: 0.6384 - val_f1_m: 0.7634\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6060 - f1_m: 0.8000 - val_loss: 0.6007 - val_f1_m: 0.7366\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5653 - f1_m: 0.8000 - val_loss: 0.5734 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5356 - f1_m: 0.8000 - val_loss: 0.5571 - val_f1_m: 0.7500\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5169 - f1_m: 0.8000 - val_loss: 0.5466 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5038 - f1_m: 0.8000 - val_loss: 0.5365 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4931 - f1_m: 0.8000 - val_loss: 0.5276 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4817 - f1_m: 0.8000 - val_loss: 0.5141 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4681 - f1_m: 0.8000 - val_loss: 0.5014 - val_f1_m: 0.7500\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4538 - f1_m: 0.8000 - val_loss: 0.4827 - val_f1_m: 0.7634\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4356 - f1_m: 0.8000 - val_loss: 0.4636 - val_f1_m: 0.7500\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4175 - f1_m: 0.8000 - val_loss: 0.4437 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3973 - f1_m: 0.8000 - val_loss: 0.4209 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3754 - f1_m: 0.8000 - val_loss: 0.3958 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3519 - f1_m: 0.8000 - val_loss: 0.3689 - val_f1_m: 0.7500\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3271 - f1_m: 0.8000 - val_loss: 0.3415 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3026 - f1_m: 0.8000 - val_loss: 0.3139 - val_f1_m: 0.7232\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2786 - f1_m: 0.8062 - val_loss: 0.2851 - val_f1_m: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2541 - f1_m: 0.8825 - val_loss: 0.2592 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2335 - f1_m: 0.9062 - val_loss: 0.2359 - val_f1_m: 0.9241\n",
      "0.90624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 687us/sample - loss: 0.6568 - f1_m: 0.8000 - val_loss: 0.6388 - val_f1_m: 0.7187\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6053 - f1_m: 0.8012 - val_loss: 0.6013 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5619 - f1_m: 0.8012 - val_loss: 0.5754 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.5309 - f1_m: 0.8012 - val_loss: 0.5603 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5125 - f1_m: 0.8012 - val_loss: 0.5528 - val_f1_m: 0.7589\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5004 - f1_m: 0.8012 - val_loss: 0.5442 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4909 - f1_m: 0.8012 - val_loss: 0.5335 - val_f1_m: 0.7321\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4796 - f1_m: 0.8012 - val_loss: 0.5218 - val_f1_m: 0.7455\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4672 - f1_m: 0.8012 - val_loss: 0.5085 - val_f1_m: 0.7321\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4530 - f1_m: 0.8012 - val_loss: 0.4929 - val_f1_m: 0.7455\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4365 - f1_m: 0.8012 - val_loss: 0.4736 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4190 - f1_m: 0.8012 - val_loss: 0.4533 - val_f1_m: 0.7589\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.3995 - f1_m: 0.8012 - val_loss: 0.4316 - val_f1_m: 0.7455\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3790 - f1_m: 0.8012 - val_loss: 0.4089 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3555 - f1_m: 0.8012 - val_loss: 0.3790 - val_f1_m: 0.7589\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3317 - f1_m: 0.8012 - val_loss: 0.3505 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3060 - f1_m: 0.8012 - val_loss: 0.3222 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2800 - f1_m: 0.8000 - val_loss: 0.2925 - val_f1_m: 0.8259\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2559 - f1_m: 0.8700 - val_loss: 0.2655 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2352 - f1_m: 0.9087 - val_loss: 0.2447 - val_f1_m: 0.8839\n",
      "0.90874994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 692us/sample - loss: 0.6568 - f1_m: 0.7962 - val_loss: 0.6327 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6078 - f1_m: 0.7962 - val_loss: 0.5901 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5660 - f1_m: 0.7962 - val_loss: 0.5591 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5382 - f1_m: 0.7962 - val_loss: 0.5377 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5173 - f1_m: 0.7962 - val_loss: 0.5241 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5027 - f1_m: 0.7962 - val_loss: 0.5098 - val_f1_m: 0.7500\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4884 - f1_m: 0.7962 - val_loss: 0.4950 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4729 - f1_m: 0.7962 - val_loss: 0.4776 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4545 - f1_m: 0.7962 - val_loss: 0.4559 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4338 - f1_m: 0.7962 - val_loss: 0.4330 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4115 - f1_m: 0.7962 - val_loss: 0.4097 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3893 - f1_m: 0.7962 - val_loss: 0.3830 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3639 - f1_m: 0.7962 - val_loss: 0.3538 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3378 - f1_m: 0.7962 - val_loss: 0.3240 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3112 - f1_m: 0.7962 - val_loss: 0.2950 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2859 - f1_m: 0.8262 - val_loss: 0.2660 - val_f1_m: 0.8571\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2618 - f1_m: 0.8725 - val_loss: 0.2397 - val_f1_m: 0.8929\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.2412 - f1_m: 0.8900 - val_loss: 0.2171 - val_f1_m: 0.9375\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2238 - f1_m: 0.9200 - val_loss: 0.1995 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2101 - f1_m: 0.9250 - val_loss: 0.1824 - val_f1_m: 0.9152\n",
      "0.92499995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 701us/sample - loss: 0.6561 - f1_m: 0.7900 - val_loss: 0.6276 - val_f1_m: 0.7723\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6076 - f1_m: 0.7900 - val_loss: 0.5770 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5631 - f1_m: 0.7900 - val_loss: 0.5409 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5358 - f1_m: 0.7900 - val_loss: 0.5164 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5193 - f1_m: 0.7900 - val_loss: 0.5023 - val_f1_m: 0.8259\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5081 - f1_m: 0.7900 - val_loss: 0.4911 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4975 - f1_m: 0.7900 - val_loss: 0.4792 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4864 - f1_m: 0.7900 - val_loss: 0.4657 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4718 - f1_m: 0.7900 - val_loss: 0.4498 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4564 - f1_m: 0.7900 - val_loss: 0.4327 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4378 - f1_m: 0.7900 - val_loss: 0.4132 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4173 - f1_m: 0.7900 - val_loss: 0.3918 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3942 - f1_m: 0.7900 - val_loss: 0.3673 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3672 - f1_m: 0.7900 - val_loss: 0.3320 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3306 - f1_m: 0.7900 - val_loss: 0.2977 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2946 - f1_m: 0.7875 - val_loss: 0.2628 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2598 - f1_m: 0.8612 - val_loss: 0.2299 - val_f1_m: 0.9286\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2291 - f1_m: 0.9112 - val_loss: 0.2013 - val_f1_m: 0.9464\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2037 - f1_m: 0.9312 - val_loss: 0.1774 - val_f1_m: 0.9732\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.1826 - f1_m: 0.9437 - val_loss: 0.1592 - val_f1_m: 0.9688\n",
      "0.9437499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 707us/sample - loss: 0.6560 - f1_m: 0.7962 - val_loss: 0.6362 - val_f1_m: 0.7634\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6088 - f1_m: 0.7962 - val_loss: 0.5957 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5671 - f1_m: 0.7962 - val_loss: 0.5675 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5398 - f1_m: 0.7962 - val_loss: 0.5458 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5213 - f1_m: 0.7962 - val_loss: 0.5327 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5083 - f1_m: 0.7962 - val_loss: 0.5210 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4966 - f1_m: 0.7962 - val_loss: 0.5081 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4843 - f1_m: 0.7962 - val_loss: 0.4945 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4703 - f1_m: 0.7962 - val_loss: 0.4778 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4537 - f1_m: 0.7962 - val_loss: 0.4589 - val_f1_m: 0.7366\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4359 - f1_m: 0.7962 - val_loss: 0.4403 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4172 - f1_m: 0.7962 - val_loss: 0.4189 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3961 - f1_m: 0.7962 - val_loss: 0.3950 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3731 - f1_m: 0.7962 - val_loss: 0.3687 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3490 - f1_m: 0.7962 - val_loss: 0.3408 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3235 - f1_m: 0.7962 - val_loss: 0.3130 - val_f1_m: 0.7500\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2963 - f1_m: 0.7962 - val_loss: 0.2832 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2713 - f1_m: 0.8625 - val_loss: 0.2573 - val_f1_m: 0.8929\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2486 - f1_m: 0.8875 - val_loss: 0.2324 - val_f1_m: 0.9464\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2265 - f1_m: 0.9187 - val_loss: 0.2099 - val_f1_m: 0.9330\n",
      "0.91875\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 706us/sample - loss: 0.6591 - f1_m: 0.7900 - val_loss: 0.6267 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.6094 - f1_m: 0.7900 - val_loss: 0.5769 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5699 - f1_m: 0.7900 - val_loss: 0.5356 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5417 - f1_m: 0.7900 - val_loss: 0.5122 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5255 - f1_m: 0.7900 - val_loss: 0.4994 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5155 - f1_m: 0.7900 - val_loss: 0.4891 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5061 - f1_m: 0.7900 - val_loss: 0.4793 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4954 - f1_m: 0.7900 - val_loss: 0.4682 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4832 - f1_m: 0.7900 - val_loss: 0.4553 - val_f1_m: 0.8259\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4689 - f1_m: 0.7900 - val_loss: 0.4389 - val_f1_m: 0.8259\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4505 - f1_m: 0.7900 - val_loss: 0.4187 - val_f1_m: 0.7321\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4278 - f1_m: 0.7900 - val_loss: 0.3961 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4023 - f1_m: 0.7900 - val_loss: 0.3686 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3754 - f1_m: 0.7900 - val_loss: 0.3409 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3457 - f1_m: 0.7900 - val_loss: 0.3129 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3151 - f1_m: 0.7900 - val_loss: 0.2833 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2861 - f1_m: 0.8112 - val_loss: 0.2595 - val_f1_m: 0.8839\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2605 - f1_m: 0.8837 - val_loss: 0.2333 - val_f1_m: 0.9152\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2362 - f1_m: 0.9075 - val_loss: 0.2129 - val_f1_m: 0.9330\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2165 - f1_m: 0.9125 - val_loss: 0.2005 - val_f1_m: 0.9375\n",
      "0.9125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 701us/sample - loss: 0.6592 - f1_m: 0.7862 - val_loss: 0.6264 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.6105 - f1_m: 0.7875 - val_loss: 0.5734 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5681 - f1_m: 0.7875 - val_loss: 0.5311 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5408 - f1_m: 0.7875 - val_loss: 0.5052 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5244 - f1_m: 0.7875 - val_loss: 0.4921 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5139 - f1_m: 0.7875 - val_loss: 0.4802 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5032 - f1_m: 0.7875 - val_loss: 0.4682 - val_f1_m: 0.8348\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4909 - f1_m: 0.7875 - val_loss: 0.4567 - val_f1_m: 0.8348\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4781 - f1_m: 0.7875 - val_loss: 0.4439 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4627 - f1_m: 0.7875 - val_loss: 0.4270 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4468 - f1_m: 0.7875 - val_loss: 0.4123 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4284 - f1_m: 0.7875 - val_loss: 0.3940 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4069 - f1_m: 0.7875 - val_loss: 0.3745 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3829 - f1_m: 0.7875 - val_loss: 0.3540 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3583 - f1_m: 0.7875 - val_loss: 0.3312 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3315 - f1_m: 0.7875 - val_loss: 0.3094 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3050 - f1_m: 0.7875 - val_loss: 0.2873 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2782 - f1_m: 0.8237 - val_loss: 0.2691 - val_f1_m: 0.8661\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2535 - f1_m: 0.8950 - val_loss: 0.2483 - val_f1_m: 0.8661\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2316 - f1_m: 0.9050 - val_loss: 0.2350 - val_f1_m: 0.9107\n",
      "0.9049999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 697us/sample - loss: 0.6578 - f1_m: 0.7812 - val_loss: 0.6178 - val_f1_m: 0.8437\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6114 - f1_m: 0.7812 - val_loss: 0.5612 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5736 - f1_m: 0.7812 - val_loss: 0.5114 - val_f1_m: 0.8437\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5478 - f1_m: 0.7812 - val_loss: 0.4799 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5322 - f1_m: 0.7812 - val_loss: 0.4611 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.5211 - f1_m: 0.7812 - val_loss: 0.4508 - val_f1_m: 0.8571\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5102 - f1_m: 0.7812 - val_loss: 0.4373 - val_f1_m: 0.8437\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4971 - f1_m: 0.7812 - val_loss: 0.4247 - val_f1_m: 0.8571\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4828 - f1_m: 0.7812 - val_loss: 0.4080 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4676 - f1_m: 0.7812 - val_loss: 0.3923 - val_f1_m: 0.8437\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4493 - f1_m: 0.7812 - val_loss: 0.3764 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4278 - f1_m: 0.7812 - val_loss: 0.3558 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4000 - f1_m: 0.7812 - val_loss: 0.3288 - val_f1_m: 0.8571\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3687 - f1_m: 0.7812 - val_loss: 0.3004 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3372 - f1_m: 0.7812 - val_loss: 0.2726 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3038 - f1_m: 0.7925 - val_loss: 0.2471 - val_f1_m: 0.9107\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2725 - f1_m: 0.8750 - val_loss: 0.2234 - val_f1_m: 0.9286\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2454 - f1_m: 0.8950 - val_loss: 0.2057 - val_f1_m: 0.8973\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2239 - f1_m: 0.9200 - val_loss: 0.1890 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2041 - f1_m: 0.9262 - val_loss: 0.1842 - val_f1_m: 0.9420\n",
      "0.9262499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 715us/sample - loss: 0.6610 - f1_m: 0.7812 - val_loss: 0.6212 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6159 - f1_m: 0.7812 - val_loss: 0.5668 - val_f1_m: 0.8437\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5780 - f1_m: 0.7812 - val_loss: 0.5199 - val_f1_m: 0.8571\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5504 - f1_m: 0.7812 - val_loss: 0.4857 - val_f1_m: 0.8571\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5298 - f1_m: 0.7812 - val_loss: 0.4641 - val_f1_m: 0.8571\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5129 - f1_m: 0.7812 - val_loss: 0.4447 - val_f1_m: 0.8437\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4948 - f1_m: 0.7812 - val_loss: 0.4236 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4753 - f1_m: 0.7812 - val_loss: 0.4039 - val_f1_m: 0.8437\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4527 - f1_m: 0.7812 - val_loss: 0.3834 - val_f1_m: 0.8437\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4291 - f1_m: 0.7812 - val_loss: 0.3592 - val_f1_m: 0.8571\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4032 - f1_m: 0.7812 - val_loss: 0.3347 - val_f1_m: 0.8437\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3741 - f1_m: 0.7812 - val_loss: 0.3150 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3443 - f1_m: 0.7812 - val_loss: 0.2841 - val_f1_m: 0.8571\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3141 - f1_m: 0.7812 - val_loss: 0.2593 - val_f1_m: 0.8437\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2836 - f1_m: 0.8500 - val_loss: 0.2375 - val_f1_m: 0.9018\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2539 - f1_m: 0.9050 - val_loss: 0.2174 - val_f1_m: 0.9375\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2285 - f1_m: 0.9200 - val_loss: 0.1996 - val_f1_m: 0.9420\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2069 - f1_m: 0.9325 - val_loss: 0.1868 - val_f1_m: 0.9286\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.1897 - f1_m: 0.9375 - val_loss: 0.1787 - val_f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.1763 - f1_m: 0.9437 - val_loss: 0.1643 - val_f1_m: 0.9286\n",
      "0.9437499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 692us/sample - loss: 0.6567 - f1_m: 0.7975 - val_loss: 0.6340 - val_f1_m: 0.7723\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6043 - f1_m: 0.7975 - val_loss: 0.5898 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5590 - f1_m: 0.7975 - val_loss: 0.5567 - val_f1_m: 0.7455\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5295 - f1_m: 0.7975 - val_loss: 0.5388 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5135 - f1_m: 0.7975 - val_loss: 0.5289 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5025 - f1_m: 0.7975 - val_loss: 0.5206 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4941 - f1_m: 0.7975 - val_loss: 0.5120 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.4828 - f1_m: 0.7975 - val_loss: 0.5005 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4703 - f1_m: 0.7975 - val_loss: 0.4864 - val_f1_m: 0.7589\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4564 - f1_m: 0.7975 - val_loss: 0.4724 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4408 - f1_m: 0.7975 - val_loss: 0.4560 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4241 - f1_m: 0.7975 - val_loss: 0.4373 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.4054 - f1_m: 0.7975 - val_loss: 0.4158 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3838 - f1_m: 0.7975 - val_loss: 0.3921 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3610 - f1_m: 0.7975 - val_loss: 0.3668 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3376 - f1_m: 0.7975 - val_loss: 0.3397 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3121 - f1_m: 0.7975 - val_loss: 0.3118 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2865 - f1_m: 0.7975 - val_loss: 0.2856 - val_f1_m: 0.7991\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2634 - f1_m: 0.8637 - val_loss: 0.2602 - val_f1_m: 0.8571\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2402 - f1_m: 0.9038 - val_loss: 0.2370 - val_f1_m: 0.9241\n",
      "0.90375\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 706us/sample - loss: 0.6576 - f1_m: 0.7975 - val_loss: 0.6350 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6045 - f1_m: 0.7975 - val_loss: 0.5898 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5587 - f1_m: 0.7975 - val_loss: 0.5569 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.5293 - f1_m: 0.7975 - val_loss: 0.5393 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5121 - f1_m: 0.7975 - val_loss: 0.5284 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5001 - f1_m: 0.7975 - val_loss: 0.5191 - val_f1_m: 0.7589\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4885 - f1_m: 0.7975 - val_loss: 0.5081 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4763 - f1_m: 0.7975 - val_loss: 0.4964 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4612 - f1_m: 0.7975 - val_loss: 0.4801 - val_f1_m: 0.7589\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4448 - f1_m: 0.7975 - val_loss: 0.4637 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4263 - f1_m: 0.7975 - val_loss: 0.4442 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4052 - f1_m: 0.7975 - val_loss: 0.4218 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3814 - f1_m: 0.7975 - val_loss: 0.3958 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3545 - f1_m: 0.7975 - val_loss: 0.3672 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3258 - f1_m: 0.7975 - val_loss: 0.3365 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2966 - f1_m: 0.7975 - val_loss: 0.3072 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2666 - f1_m: 0.8375 - val_loss: 0.2758 - val_f1_m: 0.8571\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2374 - f1_m: 0.9237 - val_loss: 0.2466 - val_f1_m: 0.8616\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2122 - f1_m: 0.9337 - val_loss: 0.2220 - val_f1_m: 0.9375\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.1896 - f1_m: 0.9525 - val_loss: 0.2007 - val_f1_m: 0.9375\n",
      "0.9524999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 706us/sample - loss: 0.6592 - f1_m: 0.7962 - val_loss: 0.6367 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6077 - f1_m: 0.7962 - val_loss: 0.5922 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5632 - f1_m: 0.7962 - val_loss: 0.5597 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5345 - f1_m: 0.7962 - val_loss: 0.5412 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5179 - f1_m: 0.7962 - val_loss: 0.5296 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5065 - f1_m: 0.7962 - val_loss: 0.5195 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4961 - f1_m: 0.7962 - val_loss: 0.5082 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4847 - f1_m: 0.7962 - val_loss: 0.4963 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4704 - f1_m: 0.7962 - val_loss: 0.4805 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4551 - f1_m: 0.7962 - val_loss: 0.4652 - val_f1_m: 0.7500\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4390 - f1_m: 0.7962 - val_loss: 0.4475 - val_f1_m: 0.7500\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4177 - f1_m: 0.7962 - val_loss: 0.4226 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3925 - f1_m: 0.7962 - val_loss: 0.3938 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3633 - f1_m: 0.7962 - val_loss: 0.3638 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3330 - f1_m: 0.7962 - val_loss: 0.3307 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3007 - f1_m: 0.7962 - val_loss: 0.2993 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2724 - f1_m: 0.8450 - val_loss: 0.2696 - val_f1_m: 0.8705\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2430 - f1_m: 0.8962 - val_loss: 0.2410 - val_f1_m: 0.8661\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2194 - f1_m: 0.9212 - val_loss: 0.2177 - val_f1_m: 0.8973\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2000 - f1_m: 0.9350 - val_loss: 0.1980 - val_f1_m: 0.9330\n",
      "0.935\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 704us/sample - loss: 0.6585 - f1_m: 0.7925 - val_loss: 0.6332 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.6096 - f1_m: 0.7937 - val_loss: 0.5861 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5659 - f1_m: 0.7937 - val_loss: 0.5518 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5366 - f1_m: 0.7937 - val_loss: 0.5320 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5210 - f1_m: 0.7937 - val_loss: 0.5194 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5098 - f1_m: 0.7937 - val_loss: 0.5098 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5001 - f1_m: 0.7937 - val_loss: 0.4986 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4867 - f1_m: 0.7937 - val_loss: 0.4835 - val_f1_m: 0.7589\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4702 - f1_m: 0.7937 - val_loss: 0.4646 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4511 - f1_m: 0.7937 - val_loss: 0.4442 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4295 - f1_m: 0.7937 - val_loss: 0.4208 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4062 - f1_m: 0.7937 - val_loss: 0.3955 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3792 - f1_m: 0.7937 - val_loss: 0.3660 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3521 - f1_m: 0.7937 - val_loss: 0.3370 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3218 - f1_m: 0.7937 - val_loss: 0.3051 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2939 - f1_m: 0.7950 - val_loss: 0.2747 - val_f1_m: 0.8571\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2668 - f1_m: 0.8662 - val_loss: 0.2494 - val_f1_m: 0.8795\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2442 - f1_m: 0.8887 - val_loss: 0.2255 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2242 - f1_m: 0.8937 - val_loss: 0.2072 - val_f1_m: 0.9375\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2104 - f1_m: 0.9225 - val_loss: 0.1928 - val_f1_m: 0.9509\n",
      "0.9225\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 693us/sample - loss: 0.6587 - f1_m: 0.7800 - val_loss: 0.6166 - val_f1_m: 0.8348\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6133 - f1_m: 0.7800 - val_loss: 0.5582 - val_f1_m: 0.8482\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5746 - f1_m: 0.7800 - val_loss: 0.5120 - val_f1_m: 0.8482\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5485 - f1_m: 0.7800 - val_loss: 0.4759 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5308 - f1_m: 0.7800 - val_loss: 0.4558 - val_f1_m: 0.8482\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5157 - f1_m: 0.7800 - val_loss: 0.4385 - val_f1_m: 0.8482\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5005 - f1_m: 0.7800 - val_loss: 0.4197 - val_f1_m: 0.8482\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4832 - f1_m: 0.7800 - val_loss: 0.4021 - val_f1_m: 0.8616\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4623 - f1_m: 0.7800 - val_loss: 0.3838 - val_f1_m: 0.8482\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4395 - f1_m: 0.7800 - val_loss: 0.3601 - val_f1_m: 0.8482\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4148 - f1_m: 0.7800 - val_loss: 0.3366 - val_f1_m: 0.8482\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3875 - f1_m: 0.7800 - val_loss: 0.3136 - val_f1_m: 0.8616\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3601 - f1_m: 0.7800 - val_loss: 0.2891 - val_f1_m: 0.8616\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3270 - f1_m: 0.7800 - val_loss: 0.2542 - val_f1_m: 0.8482\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2887 - f1_m: 0.8337 - val_loss: 0.2243 - val_f1_m: 0.9420\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2545 - f1_m: 0.9025 - val_loss: 0.1962 - val_f1_m: 0.9375\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2237 - f1_m: 0.9100 - val_loss: 0.1708 - val_f1_m: 0.9375\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2005 - f1_m: 0.9250 - val_loss: 0.1537 - val_f1_m: 0.9598\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.1830 - f1_m: 0.9337 - val_loss: 0.1432 - val_f1_m: 0.9554\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.1714 - f1_m: 0.9375 - val_loss: 0.1315 - val_f1_m: 0.9420\n",
      "0.93749994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 699us/sample - loss: 0.6589 - f1_m: 0.7887 - val_loss: 0.6273 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6101 - f1_m: 0.7887 - val_loss: 0.5770 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5688 - f1_m: 0.7887 - val_loss: 0.5358 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5405 - f1_m: 0.7887 - val_loss: 0.5121 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5249 - f1_m: 0.7887 - val_loss: 0.4975 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5138 - f1_m: 0.7887 - val_loss: 0.4858 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5029 - f1_m: 0.7887 - val_loss: 0.4750 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4905 - f1_m: 0.7887 - val_loss: 0.4614 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4764 - f1_m: 0.7887 - val_loss: 0.4474 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4621 - f1_m: 0.7887 - val_loss: 0.4327 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4455 - f1_m: 0.7887 - val_loss: 0.4162 - val_f1_m: 0.8304\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4272 - f1_m: 0.7887 - val_loss: 0.4008 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4088 - f1_m: 0.7887 - val_loss: 0.3786 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3832 - f1_m: 0.7887 - val_loss: 0.3566 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3573 - f1_m: 0.7887 - val_loss: 0.3349 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3310 - f1_m: 0.7887 - val_loss: 0.3083 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2971 - f1_m: 0.7925 - val_loss: 0.2806 - val_f1_m: 0.8571\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2639 - f1_m: 0.8637 - val_loss: 0.2551 - val_f1_m: 0.8661\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2363 - f1_m: 0.8937 - val_loss: 0.2410 - val_f1_m: 0.8705\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2161 - f1_m: 0.9262 - val_loss: 0.2249 - val_f1_m: 0.9196\n",
      "0.92625\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 707us/sample - loss: 0.6594 - f1_m: 0.8000 - val_loss: 0.6390 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6082 - f1_m: 0.8000 - val_loss: 0.6005 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5623 - f1_m: 0.8000 - val_loss: 0.5719 - val_f1_m: 0.7500\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5318 - f1_m: 0.8000 - val_loss: 0.5562 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5123 - f1_m: 0.8000 - val_loss: 0.5475 - val_f1_m: 0.7634\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5011 - f1_m: 0.8000 - val_loss: 0.5386 - val_f1_m: 0.7500\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4902 - f1_m: 0.8000 - val_loss: 0.5273 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4783 - f1_m: 0.8000 - val_loss: 0.5153 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4651 - f1_m: 0.8000 - val_loss: 0.4993 - val_f1_m: 0.7366\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4500 - f1_m: 0.8000 - val_loss: 0.4840 - val_f1_m: 0.7366\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4350 - f1_m: 0.8000 - val_loss: 0.4665 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4170 - f1_m: 0.8000 - val_loss: 0.4459 - val_f1_m: 0.7366\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3966 - f1_m: 0.8000 - val_loss: 0.4232 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3744 - f1_m: 0.8000 - val_loss: 0.3972 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3504 - f1_m: 0.8000 - val_loss: 0.3694 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3247 - f1_m: 0.8000 - val_loss: 0.3412 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2999 - f1_m: 0.8000 - val_loss: 0.3124 - val_f1_m: 0.7634\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2738 - f1_m: 0.7925 - val_loss: 0.2865 - val_f1_m: 0.8304\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2516 - f1_m: 0.8875 - val_loss: 0.2621 - val_f1_m: 0.8616\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2297 - f1_m: 0.9038 - val_loss: 0.2375 - val_f1_m: 0.9241\n",
      "0.90375\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 696us/sample - loss: 0.6573 - f1_m: 0.7925 - val_loss: 0.6307 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6065 - f1_m: 0.7925 - val_loss: 0.5851 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5648 - f1_m: 0.7925 - val_loss: 0.5466 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5372 - f1_m: 0.7925 - val_loss: 0.5249 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5207 - f1_m: 0.7925 - val_loss: 0.5136 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5111 - f1_m: 0.7925 - val_loss: 0.5035 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5021 - f1_m: 0.7925 - val_loss: 0.4934 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4921 - f1_m: 0.7925 - val_loss: 0.4819 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4808 - f1_m: 0.7925 - val_loss: 0.4689 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4679 - f1_m: 0.7925 - val_loss: 0.4546 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4538 - f1_m: 0.7925 - val_loss: 0.4384 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4382 - f1_m: 0.7925 - val_loss: 0.4209 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4192 - f1_m: 0.7925 - val_loss: 0.3986 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3989 - f1_m: 0.7925 - val_loss: 0.3755 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3763 - f1_m: 0.7925 - val_loss: 0.3516 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3533 - f1_m: 0.7925 - val_loss: 0.3220 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3278 - f1_m: 0.7925 - val_loss: 0.2937 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3031 - f1_m: 0.7925 - val_loss: 0.2667 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2795 - f1_m: 0.8137 - val_loss: 0.2397 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2588 - f1_m: 0.8750 - val_loss: 0.2156 - val_f1_m: 0.8929\n",
      "0.87499994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 713us/sample - loss: 0.6587 - f1_m: 0.7912 - val_loss: 0.6318 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6091 - f1_m: 0.7912 - val_loss: 0.5841 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5650 - f1_m: 0.7912 - val_loss: 0.5470 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5372 - f1_m: 0.7912 - val_loss: 0.5230 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5195 - f1_m: 0.7912 - val_loss: 0.5091 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5081 - f1_m: 0.7912 - val_loss: 0.4967 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4963 - f1_m: 0.7912 - val_loss: 0.4840 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4831 - f1_m: 0.7912 - val_loss: 0.4698 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4681 - f1_m: 0.7912 - val_loss: 0.4536 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4517 - f1_m: 0.7912 - val_loss: 0.4367 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4338 - f1_m: 0.7912 - val_loss: 0.4181 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4134 - f1_m: 0.7912 - val_loss: 0.3974 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3904 - f1_m: 0.7912 - val_loss: 0.3735 - val_f1_m: 0.7679\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3651 - f1_m: 0.7912 - val_loss: 0.3482 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3381 - f1_m: 0.7912 - val_loss: 0.3218 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3096 - f1_m: 0.7912 - val_loss: 0.2954 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2813 - f1_m: 0.8062 - val_loss: 0.2697 - val_f1_m: 0.8482\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2540 - f1_m: 0.9050 - val_loss: 0.2458 - val_f1_m: 0.8973\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2887 - f1_m: 0.87 - 0s 64us/sample - loss: 0.2306 - f1_m: 0.9125 - val_loss: 0.2252 - val_f1_m: 0.8884\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2090 - f1_m: 0.9275 - val_loss: 0.2078 - val_f1_m: 0.9375\n",
      "0.92749995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 695us/sample - loss: 0.6567 - f1_m: 0.7962 - val_loss: 0.6325 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6067 - f1_m: 0.7962 - val_loss: 0.5896 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5623 - f1_m: 0.7962 - val_loss: 0.5547 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5314 - f1_m: 0.7962 - val_loss: 0.5358 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5147 - f1_m: 0.7962 - val_loss: 0.5249 - val_f1_m: 0.7634\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5035 - f1_m: 0.7962 - val_loss: 0.5160 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4956 - f1_m: 0.7962 - val_loss: 0.5066 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4837 - f1_m: 0.7962 - val_loss: 0.4931 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4711 - f1_m: 0.7962 - val_loss: 0.4788 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4571 - f1_m: 0.7962 - val_loss: 0.4641 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4415 - f1_m: 0.7962 - val_loss: 0.4465 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4244 - f1_m: 0.7962 - val_loss: 0.4266 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4047 - f1_m: 0.7962 - val_loss: 0.4043 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3834 - f1_m: 0.7962 - val_loss: 0.3782 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3585 - f1_m: 0.7962 - val_loss: 0.3509 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3334 - f1_m: 0.7962 - val_loss: 0.3218 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3068 - f1_m: 0.7962 - val_loss: 0.2952 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2842 - f1_m: 0.8012 - val_loss: 0.2662 - val_f1_m: 0.8839\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2589 - f1_m: 0.8862 - val_loss: 0.2406 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2380 - f1_m: 0.9000 - val_loss: 0.2198 - val_f1_m: 0.8929\n",
      "0.8999999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 731us/sample - loss: 0.6590 - f1_m: 0.7887 - val_loss: 0.6275 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6084 - f1_m: 0.7887 - val_loss: 0.5765 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5686 - f1_m: 0.7887 - val_loss: 0.5354 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5409 - f1_m: 0.7887 - val_loss: 0.5120 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5251 - f1_m: 0.7887 - val_loss: 0.4984 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5144 - f1_m: 0.7887 - val_loss: 0.4873 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5048 - f1_m: 0.7887 - val_loss: 0.4774 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4937 - f1_m: 0.7887 - val_loss: 0.4650 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4809 - f1_m: 0.7887 - val_loss: 0.4517 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4665 - f1_m: 0.7887 - val_loss: 0.4367 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4507 - f1_m: 0.7887 - val_loss: 0.4203 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4322 - f1_m: 0.7887 - val_loss: 0.4019 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4112 - f1_m: 0.7887 - val_loss: 0.3814 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3878 - f1_m: 0.7887 - val_loss: 0.3586 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3628 - f1_m: 0.7887 - val_loss: 0.3347 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3363 - f1_m: 0.7887 - val_loss: 0.3104 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3090 - f1_m: 0.7887 - val_loss: 0.2855 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2827 - f1_m: 0.8237 - val_loss: 0.2622 - val_f1_m: 0.8884\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2575 - f1_m: 0.8937 - val_loss: 0.2395 - val_f1_m: 0.8571\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2335 - f1_m: 0.9100 - val_loss: 0.2182 - val_f1_m: 0.9330\n",
      "0.9099999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 730 samples, validate on 183 samples\n",
      "Epoch 1/20\n",
      "730/730 [==============================] - 1s 749us/sample - loss: 0.6607 - f1_m: 0.7770 - val_loss: 0.6436 - val_f1_m: 0.7606\n",
      "Epoch 2/20\n",
      "730/730 [==============================] - 0s 80us/sample - loss: 0.6209 - f1_m: 0.7754 - val_loss: 0.6085 - val_f1_m: 0.7586\n",
      "Epoch 3/20\n",
      "730/730 [==============================] - 0s 67us/sample - loss: 0.5868 - f1_m: 0.7767 - val_loss: 0.5834 - val_f1_m: 0.7545\n",
      "Epoch 4/20\n",
      "730/730 [==============================] - 0s 62us/sample - loss: 0.5615 - f1_m: 0.7754 - val_loss: 0.5667 - val_f1_m: 0.7647\n",
      "Epoch 5/20\n",
      "730/730 [==============================] - 0s 59us/sample - loss: 0.5460 - f1_m: 0.7767 - val_loss: 0.5548 - val_f1_m: 0.7708\n",
      "Epoch 6/20\n",
      "730/730 [==============================] - 0s 58us/sample - loss: 0.5339 - f1_m: 0.7763 - val_loss: 0.5456 - val_f1_m: 0.7627\n",
      "Epoch 7/20\n",
      "730/730 [==============================] - 0s 73us/sample - loss: 0.5244 - f1_m: 0.7773 - val_loss: 0.5357 - val_f1_m: 0.7606\n",
      "Epoch 8/20\n",
      "730/730 [==============================] - 0s 61us/sample - loss: 0.5142 - f1_m: 0.7760 - val_loss: 0.5253 - val_f1_m: 0.7586\n",
      "Epoch 9/20\n",
      "730/730 [==============================] - 0s 62us/sample - loss: 0.5031 - f1_m: 0.7773 - val_loss: 0.5118 - val_f1_m: 0.7668\n",
      "Epoch 10/20\n",
      "730/730 [==============================] - 0s 56us/sample - loss: 0.4900 - f1_m: 0.7760 - val_loss: 0.4970 - val_f1_m: 0.7606\n",
      "Epoch 11/20\n",
      "730/730 [==============================] - 0s 57us/sample - loss: 0.4743 - f1_m: 0.7754 - val_loss: 0.4794 - val_f1_m: 0.7586\n",
      "Epoch 12/20\n",
      "730/730 [==============================] - 0s 58us/sample - loss: 0.4581 - f1_m: 0.7773 - val_loss: 0.4616 - val_f1_m: 0.7606\n",
      "Epoch 13/20\n",
      "730/730 [==============================] - 0s 61us/sample - loss: 0.4413 - f1_m: 0.7757 - val_loss: 0.4411 - val_f1_m: 0.7545\n",
      "Epoch 14/20\n",
      "730/730 [==============================] - 0s 58us/sample - loss: 0.4206 - f1_m: 0.7757 - val_loss: 0.4180 - val_f1_m: 0.7606\n",
      "Epoch 15/20\n",
      "730/730 [==============================] - 0s 58us/sample - loss: 0.3982 - f1_m: 0.7767 - val_loss: 0.3923 - val_f1_m: 0.7606\n",
      "Epoch 16/20\n",
      "730/730 [==============================] - 0s 57us/sample - loss: 0.3745 - f1_m: 0.7767 - val_loss: 0.3653 - val_f1_m: 0.7586\n",
      "Epoch 17/20\n",
      "730/730 [==============================] - 0s 58us/sample - loss: 0.3501 - f1_m: 0.7773 - val_loss: 0.3370 - val_f1_m: 0.7647\n",
      "Epoch 18/20\n",
      "730/730 [==============================] - 0s 57us/sample - loss: 0.3246 - f1_m: 0.7767 - val_loss: 0.3082 - val_f1_m: 0.7586\n",
      "Epoch 19/20\n",
      "730/730 [==============================] - 0s 57us/sample - loss: 0.2982 - f1_m: 0.8187 - val_loss: 0.2790 - val_f1_m: 0.8897\n",
      "Epoch 20/20\n",
      "730/730 [==============================] - 0s 57us/sample - loss: 0.2749 - f1_m: 0.8809 - val_loss: 0.2521 - val_f1_m: 0.9022\n",
      "0.88085276\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "4\n",
      "88\n",
      "65\n",
      "14\n",
      "26\n",
      "9\n",
      "4\n",
      "4\n",
      "9\n",
      "3\n",
      "7\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "All Done\n"
     ]
    }
   ],
   "source": [
    "#the below code is for binary classification since MNSIT is a multi-class low-resolution image dataset. I am updating the code in the next cell.\n",
    "N=1000\n",
    "#Positive=Pos\n",
    "#Negative=Neg\n",
    "positiveN=int((Positive.shape[0]/dataset.shape[0])*N)\n",
    "negativeN=int(N-positiveN)\n",
    "print(positiveN, negativeN)\n",
    "#target variable\n",
    "#target_variable=\"default.payment.next.month\"\n",
    "df1=Positive.sample(positiveN)\n",
    "Positive.drop(df1.index, inplace=True)\n",
    "df2=Negative.sample(negativeN)\n",
    "Negative.drop(df2.index, inplace=True)\n",
    "test_data=df1.append(df2, ignore_index=True)\n",
    "test_data=test_data.sample(frac = 1) #This is to shuffel the training and testing data\n",
    "test_data=test_data.sample(frac = 1)\n",
    "test_data=test_data.sample(frac = 1)\n",
    "X_test=test_data.drop(columns=[target_variable])\n",
    "y_test=to_categorical(test_data[target_variable])\n",
    "\n",
    "# adding dense layer\n",
    "initial_model= get_initial_model(X_test.shape[1], 2)\n",
    "Models=[]\n",
    "val_acc=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "val_loss=[]\n",
    "train_loss=[]\n",
    "while Positive.empty==False and Negative.empty==False:\n",
    "  print(positiveN, negativeN)\n",
    "  df1=Positive.sample(min(positiveN, len(Positive)))\n",
    "  Positive.drop(df1.index, inplace=True)\n",
    "  df2=Negative.sample(min(negativeN, len(Negative)))\n",
    "  Negative.drop(df2.index, inplace=True)\n",
    "  train_data=df1.append(df2, ignore_index=True)\n",
    "  train_data=train_data.sample(frac = 1) #shuffel test data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel test data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel test data 3 times\n",
    "    \n",
    "  #all models have different initialization\n",
    "  # define the sequential model\n",
    "  \"\"\"initial_model = keras.Sequential()\n",
    "\n",
    "    # adding dense layer\n",
    "  initial_model.add(Dense(5, input_dim=X_test.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "  initial_model.add(Dense(10, activation='relu'))\n",
    "  initial_model.add(Dense(5, activation='relu'))\n",
    "\n",
    "    # adding dense layer with softmax activation/output layer\n",
    "  initial_model.add(Dense(2, activation='softmax'))\n",
    "  #initial_model.summary()\"\"\"\n",
    "  ann_model=get_initial_model(X_test.shape[1], 2) #same intial weights\n",
    "  ann_model.set_weights(initial_model.get_weights())\n",
    "  X_train=train_data.drop(columns=[target_variable])\n",
    "  #train_data[target_variable]=train_data[target_variable]-1 #only for skin_nonskin dataset\n",
    "  y_train=to_categorical(train_data[target_variable])\n",
    "  #print(y_train)\n",
    "  ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m]) # metrics=['accuracy']\n",
    "  history = ann_model.fit(X_train, y_train, epochs=20, validation_split=0.2, verbose=1)\n",
    "  print(history.history['f1_m'][-1])\n",
    "  ann_model.set_weights(update_weights(ann_model.get_weights()))\n",
    "  pred_test=ann_model.predict(X_test)\n",
    "  present=False\n",
    "  for i in range(len(Models)):\n",
    "    if (check_models(Models[i][0], ann_model.get_weights())):\n",
    "      print(\"if any\")\n",
    "      Models[i][1]=Models[i][1]+1\n",
    "      val_acc[i].append(history.history['val_f1_m'])\n",
    "      train_acc[i].append(history.history['f1_m'])\n",
    "      test_acc[i].append(f1_m(y_test, pred_test).numpy())\n",
    "      val_loss[i].append(history.history['val_loss'])\n",
    "      train_loss[i].append(history.history['loss'])\n",
    "      present=True\n",
    "      break\n",
    "  if present==False:\n",
    "    Models.append([ann_model.get_weights(), 1])\n",
    "    val_acc.append([history.history['val_f1_m']])\n",
    "    train_acc.append([history.history['f1_m']])\n",
    "    test_acc.append([f1_m(y_test, pred_test).numpy()])\n",
    "    val_loss.append([history.history['val_loss']])\n",
    "    train_loss.append([history.history['loss']])\n",
    "for i in range(len(Models)):\n",
    "  print(Models[i][1])\n",
    "print(\"All Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f87173b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "88\n",
      "65\n",
      "14\n",
      "26\n",
      "9\n",
      "4\n",
      "4\n",
      "9\n",
      "3\n",
      "7\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "17\n",
      "[[0.9319999, 0.92899996, 0.9229999, 0.92999995], [0.9269999, 0.9089999, 0.9139999, 0.91899997, 0.92499995, 0.92899996, 0.91899997, 0.92099994, 0.92999995, 0.9279999, 0.92899996, 0.93099993, 0.93099993, 0.91599995, 0.92899996, 0.9319999, 0.92999995, 0.92399997, 0.9179999, 0.92999995, 0.93099993, 0.92899996, 0.92599994, 0.92599994, 0.91699994, 0.93099993, 0.9229999, 0.93099993, 0.92199993, 0.9319999, 0.92199993, 0.9179999, 0.92999995, 0.92999995, 0.92899996, 0.91999996, 0.92599994, 0.91899997, 0.92999995, 0.92999995, 0.91199994, 0.92199993, 0.9319999, 0.91899997, 0.92499995, 0.934, 0.9229999, 0.92999995, 0.93099993, 0.92899996, 0.91899997, 0.92199993, 0.92099994, 0.92899996, 0.92899996, 0.90699995, 0.90599996, 0.9269999, 0.91699994, 0.90799993, 0.9279999, 0.92899996, 0.92999995, 0.92899996, 0.92499995, 0.92999995, 0.92199993, 0.9179999, 0.91899997, 0.91999996, 0.92899996, 0.91999996, 0.9279999, 0.9319999, 0.9269999, 0.9229999, 0.91899997, 0.93099993, 0.92399997, 0.92899996, 0.9179999, 0.90599996, 0.9179999, 0.93099993, 0.93099993, 0.92499995, 0.9319999, 0.92999995], [0.89299995, 0.9179999, 0.90499985, 0.9179999, 0.92499995, 0.9039999, 0.89399993, 0.9129999, 0.87299997, 0.9129999, 0.91499996, 0.91999996, 0.9229999, 0.92099994, 0.91899997, 0.91499996, 0.87799996, 0.89199996, 0.90199995, 0.90299994, 0.91699994, 0.90499985, 0.91899997, 0.90499985, 0.91499996, 0.90199995, 0.92099994, 0.92099994, 0.9179999, 0.91499996, 0.91499996, 0.91899997, 0.90299994, 0.8909999, 0.90599996, 0.90299994, 0.90199995, 0.90799993, 0.9139999, 0.8909999, 0.92499995, 0.88299996, 0.90699995, 0.8809999, 0.90299994, 0.90199995, 0.91699994, 0.8949999, 0.91499996, 0.90299994, 0.90299994, 0.91699994, 0.90699995, 0.89399993, 0.89199996, 0.90799993, 0.90199995, 0.8899999, 0.91599995, 0.89399993, 0.90799993, 0.9139999, 0.90799993, 0.8909999, 0.8909999], [0.90999997, 0.9269999, 0.91199994, 0.89799994, 0.9359999, 0.92599994, 0.91899997, 0.89799994, 0.90599996, 0.9129999, 0.92399997, 0.91999996, 0.9279999, 0.9319999], [0.91599995, 0.91899997, 0.90599996, 0.91699994, 0.9129999, 0.90099996, 0.92599994, 0.90699995, 0.9129999, 0.91699994, 0.92599994, 0.89599997, 0.92199993, 0.91599995, 0.89699996, 0.91899997, 0.92099994, 0.92599994, 0.934, 0.93099993, 0.92499995, 0.90599996, 0.9359999, 0.89799994, 0.91099995, 0.91099995], [0.9229999, 0.91899997, 0.91999996, 0.92099994, 0.9319999, 0.92999995, 0.92599994, 0.92199993, 0.92999995], [0.93099993, 0.92099994, 0.92099994, 0.93099993], [0.801, 0.75999993, 0.7929999, 0.7929999], [0.89799994, 0.92099994, 0.89799994, 0.88699996, 0.91599995, 0.91499996, 0.89199996, 0.89699996, 0.8949999], [0.92999995, 0.91999996, 0.92499995], [0.90799993, 0.93099993, 0.92099994, 0.92399997, 0.91999996, 0.8949999, 0.91899997], [0.92899996], [0.89799994, 0.90599996, 0.91699994], [0.92199993, 0.92199993, 0.90999997], [0.9269999], [0.87299997, 0.8529999], [0.9319999]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Models)):\n",
    "  print(Models[i][1])\n",
    "print(len(Models))\n",
    "#test_Acc = [i.numpy() for i in test_acc]\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c0f8934d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 88 65 14 26 9 4 4 9 3 7 1 3 3 1 2 1]\n",
      "[1 2 4 3 8]\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#this works for getting sorted recurrent models by frequency\n",
    "A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "print(np.array(Models).T[1])\n",
    "print(A)\n",
    "temp=list(np.array(Models)[A])\n",
    "print(temp[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "85627832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"\"\"\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#reducing the metrics lists to top 5 models only\n",
    "val_acc=list(np.array(val_acc)[A])\n",
    "test_acc=list(np.array(test_acc)[A])\n",
    "train_acc=list(np.array(train_acc)[A])\n",
    "val_loss=list(np.array(val_loss)[A])\n",
    "train_loss=list(np.array(train_loss)[A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "193c429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.27 ,  0.002,  0.24 ,  0.25 ,  0.31 ],\n",
      "       [ 0.05 , -0.01 ,  0.11 , -0.02 , -0.002],\n",
      "       [-0.34 , -0.05 , -0.38 , -0.28 , -0.39 ]], dtype=float32), array([ 0.16, -0.01,  0.11,  0.13,  0.16], dtype=float32), array([[ 0.34,  0.49,  0.29,  0.07,  0.99,  0.28, -0.18,  0.69,  0.16,\n",
      "         0.67],\n",
      "       [-0.56, -0.5 ,  0.6 , -0.02, -0.37,  0.6 , -0.48, -0.47, -0.01,\n",
      "        -0.05],\n",
      "       [ 0.91, -0.08, -0.93, -0.12,  0.41, -0.47, -0.38,  0.15, -0.47,\n",
      "        -0.52],\n",
      "       [-0.2 ,  0.78,  0.44, -0.6 ,  0.67, -0.47, -0.17,  0.81,  0.13,\n",
      "        -0.43],\n",
      "       [ 0.97,  0.96, -1.03, -0.44,  0.71,  0.41,  0.01,  0.62,  0.42,\n",
      "        -0.33]], dtype=float32), array([ 0.01,  0.05,  0.21,  0.16,  0.04, -0.02,  0.  ,  0.04, -0.09,\n",
      "        0.05], dtype=float32), array([[-0.18  , -0.02  ,  0.76  ,  0.72  , -0.0009],\n",
      "       [ 0.33  , -0.58  , -0.03  ,  0.28  ,  0.74  ],\n",
      "       [-0.54  ,  0.15  , -0.77  , -0.37  , -0.87  ],\n",
      "       [-0.63  , -0.59  , -0.64  , -0.41  , -0.23  ],\n",
      "       [ 0.03  , -0.35  ,  0.13  ,  0.3   ,  0.54  ],\n",
      "       [-0.22  ,  0.22  , -0.59  , -0.28  ,  0.27  ],\n",
      "       [-0.62  ,  0.41  , -0.48  , -0.25  , -0.61  ],\n",
      "       [-0.63  , -0.29  ,  0.81  ,  0.66  ,  0.18  ],\n",
      "       [ 0.48  , -0.26  ,  0.45  , -0.47  ,  0.42  ],\n",
      "       [ 0.53  ,  0.36  , -0.64  , -0.3   ,  0.15  ]], dtype=float32), array([-0.01,  0.  ,  0.08,  0.04,  0.06], dtype=float32), array([[ 0.77, -0.65],\n",
      "       [-0.2 , -0.88],\n",
      "       [-0.4 ,  0.75],\n",
      "       [-0.91,  1.18],\n",
      "       [-0.18,  0.86]], dtype=float32), array([-0.03,  0.03], dtype=float32)]\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "yhn tk\n",
      "12\n",
      "Done\n",
      "[array([[ 0.27 ,  0.005, -0.12 ,  0.31 ,  0.31 ],\n",
      "       [ 0.07 , -0.01 ,  0.12 ,  0.04 ,  0.03 ],\n",
      "       [-0.37 , -0.05 ,  0.43 , -0.31 , -0.4  ]], dtype=float32), array([ 0.13 , -0.01 , -0.005,  0.14 ,  0.15 ], dtype=float32), array([[ 0.26,  0.57,  0.5 ,  0.06,  1.02,  0.25, -0.18,  0.71,  0.16,\n",
      "         0.62],\n",
      "       [-0.56, -0.51,  0.61, -0.02, -0.37,  0.6 , -0.48, -0.47, -0.02,\n",
      "        -0.05],\n",
      "       [ 0.08, -0.75, -0.48, -0.07, -0.4 , -0.47, -0.38, -0.47, -0.45,\n",
      "        -0.54],\n",
      "       [-0.26,  0.89,  0.48, -0.6 ,  0.73, -0.5 , -0.17,  0.87,  0.13,\n",
      "        -0.48],\n",
      "       [ 0.9 ,  1.04, -0.69, -0.41,  0.73,  0.38,  0.01,  0.67,  0.42,\n",
      "        -0.38]], dtype=float32), array([-0.03,  0.18, -0.07,  0.  ,  0.07, -0.03,  0.  ,  0.08, -0.09,\n",
      "        0.  ], dtype=float32), array([[-0.2 , -0.02,  0.4 ,  0.41, -0.32],\n",
      "       [ 0.32, -0.58,  0.12,  0.46,  0.93],\n",
      "       [-0.53,  0.15, -0.3 ,  0.12, -0.4 ],\n",
      "       [-0.63, -0.59, -0.49, -0.21, -0.06],\n",
      "       [ 0.02, -0.35,  0.19,  0.38,  0.65],\n",
      "       [-0.21,  0.22, -0.58, -0.24,  0.28],\n",
      "       [-0.62,  0.41, -0.48, -0.25, -0.61],\n",
      "       [-0.64, -0.29,  0.89,  0.76,  0.3 ],\n",
      "       [ 0.49, -0.26,  0.47, -0.45,  0.46],\n",
      "       [ 0.53,  0.36, -0.62, -0.25,  0.2 ]], dtype=float32), array([-0.02,  0.  , -0.01, -0.01, -0.01], dtype=float32), array([[ 0.75, -0.63],\n",
      "       [-0.2 , -0.88],\n",
      "       [-0.32,  0.67],\n",
      "       [-0.94,  1.21],\n",
      "       [-0.3 ,  0.98]], dtype=float32), array([ 0.001, -0.001], dtype=float32)]\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "yhn tk\n",
      "15\n",
      "Done\n",
      "[array([[ 0.25  ,  0.004 ,  0.21  ,  0.24  ,  0.3   ],\n",
      "       [ 0.05  , -0.005 ,  0.12  , -0.02  ,  0.0006],\n",
      "       [-0.35  , -0.05  , -0.36  , -0.29  , -0.39  ]], dtype=float32), array([ 0.16, -0.01,  0.1 ,  0.14,  0.17], dtype=float32), array([[ 0.37,  0.51,  0.25,  0.02,  1.01,  0.28, -0.18,  0.7 ,  0.16,\n",
      "         0.6 ],\n",
      "       [-0.56, -0.5 ,  0.6 , -0.02, -0.37,  0.6 , -0.48, -0.47, -0.02,\n",
      "        -0.05],\n",
      "       [ 0.89, -0.09, -0.92, -0.19,  0.4 , -0.47, -0.38,  0.13, -0.46,\n",
      "        -0.55],\n",
      "       [-0.17,  0.8 ,  0.4 , -0.66,  0.69, -0.48, -0.17,  0.83,  0.13,\n",
      "        -0.5 ],\n",
      "       [ 0.97,  0.97, -1.04, -0.49,  0.71,  0.41,  0.01,  0.63,  0.42,\n",
      "        -0.39]], dtype=float32), array([ 0.02,  0.05,  0.21,  0.19,  0.04, -0.01,  0.  ,  0.05, -0.09,\n",
      "       -0.02], dtype=float32), array([[-0.19 , -0.02 ,  0.75 ,  0.7  , -0.01 ],\n",
      "       [ 0.33 , -0.58 , -0.002,  0.3  ,  0.77 ],\n",
      "       [-0.53 ,  0.15 , -0.74 , -0.35 , -0.85 ],\n",
      "       [-0.63 , -0.59 , -0.71 , -0.48 , -0.31 ],\n",
      "       [ 0.03 , -0.35 ,  0.15 ,  0.31 ,  0.56 ],\n",
      "       [-0.21 ,  0.22 , -0.59 , -0.29 ,  0.27 ],\n",
      "       [-0.62 ,  0.41 , -0.48 , -0.25 , -0.61 ],\n",
      "       [-0.63 , -0.29 ,  0.83 ,  0.68 ,  0.2  ],\n",
      "       [ 0.48 , -0.26 ,  0.44 , -0.48 ,  0.42 ],\n",
      "       [ 0.53 ,  0.36 , -0.61 , -0.24 ,  0.21 ]], dtype=float32), array([-0.01,  0.  ,  0.09,  0.04,  0.07], dtype=float32), array([[ 0.77, -0.65],\n",
      "       [-0.2 , -0.88],\n",
      "       [-0.41,  0.76],\n",
      "       [-0.92,  1.19],\n",
      "       [-0.2 ,  0.88]], dtype=float32), array([-0.03,  0.03], dtype=float32)]\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "yhn tk\n",
      "17\n",
      "Done\n",
      "[array([[ 0.29 ,  0.005, -0.05 ,  0.29 ,  0.32 ],\n",
      "       [ 0.07 , -0.01 ,  0.1  ,  0.01 ,  0.03 ],\n",
      "       [-0.4  , -0.05 ,  0.21 , -0.34 , -0.41 ]], dtype=float32), array([ 0.13  , -0.01  , -0.0004,  0.12  ,  0.15  ], dtype=float32), array([[ 0.36,  0.61,  0.44,  0.06,  1.1 ,  0.23, -0.18,  0.77,  0.15,\n",
      "         0.62],\n",
      "       [-0.56, -0.51,  0.61, -0.02, -0.37,  0.6 , -0.48, -0.47, -0.02,\n",
      "        -0.05],\n",
      "       [ 0.23, -0.6 , -0.45, -0.07, -0.21, -0.49, -0.38, -0.32, -0.46,\n",
      "        -0.54],\n",
      "       [-0.17,  0.9 ,  0.47, -0.6 ,  0.78, -0.52, -0.17,  0.89,  0.13,\n",
      "        -0.48],\n",
      "       [ 0.95,  1.05, -0.79, -0.41,  0.77,  0.35,  0.01,  0.67,  0.43,\n",
      "        -0.38]], dtype=float32), array([-0.06  ,  0.09  , -0.0006,  0.    ,  0.03  , -0.03  ,  0.    ,\n",
      "        0.05  , -0.09  ,  0.    ], dtype=float32), array([[-0.18, -0.02,  0.56,  0.56, -0.18],\n",
      "       [ 0.33, -0.58,  0.09,  0.42,  0.89],\n",
      "       [-0.53,  0.15, -0.34,  0.07, -0.44],\n",
      "       [-0.63, -0.59, -0.49, -0.21, -0.06],\n",
      "       [ 0.03, -0.35,  0.17,  0.35,  0.61],\n",
      "       [-0.21,  0.22, -0.57, -0.2 ,  0.3 ],\n",
      "       [-0.62,  0.41, -0.48, -0.25, -0.61],\n",
      "       [-0.63, -0.29,  0.88,  0.74,  0.27],\n",
      "       [ 0.48, -0.26,  0.46, -0.46,  0.44],\n",
      "       [ 0.53,  0.36, -0.62, -0.25,  0.2 ]], dtype=float32), array([-0.01 ,  0.   , -0.01 , -0.003, -0.01 ], dtype=float32), array([[ 0.77, -0.65],\n",
      "       [-0.2 , -0.88],\n",
      "       [-0.33,  0.68],\n",
      "       [-0.93,  1.2 ],\n",
      "       [-0.24,  0.92]], dtype=float32), array([-0.01,  0.01], dtype=float32)]\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "yhn tk\n",
      "5\n",
      "Done\n",
      "[array([[ 0.29 ,  0.004, -0.02 ,  0.29 ,  0.28 ],\n",
      "       [ 0.04 , -0.01 ,  0.02 , -0.02 ,  0.01 ],\n",
      "       [-0.4  , -0.05 , -0.004, -0.34 , -0.32 ]], dtype=float32), array([ 0.18, -0.01, -0.02,  0.16,  0.13], dtype=float32), array([[-0.09,  0.52,  0.43,  0.11,  1.07,  0.23, -0.27,  0.77,  0.71,\n",
      "         0.6 ],\n",
      "       [-0.56, -0.52,  0.61, -0.02, -0.37,  0.61, -0.48, -0.46, -0.02,\n",
      "        -0.05],\n",
      "       [ 0.36, -0.6 , -0.44, -0.07, -0.12, -0.48, -0.38, -0.27, -0.34,\n",
      "        -0.54],\n",
      "       [-0.52,  0.8 ,  0.44, -0.56,  0.74, -0.51, -0.26,  0.89,  0.58,\n",
      "        -0.5 ],\n",
      "       [ 0.39,  0.79, -0.68, -0.37,  0.58,  0.37, -0.07,  0.51,  0.95,\n",
      "        -0.4 ]], dtype=float32), array([-0.01,  0.07, -0.08,  0.15,  0.12, -0.03,  0.12,  0.08,  0.1 ,\n",
      "       -0.03], dtype=float32), array([[-0.19 , -0.02 ,  0.21 ,  0.21 , -0.53 ],\n",
      "       [ 0.28 , -0.58 , -0.02 , -0.005,  0.77 ],\n",
      "       [-0.56 ,  0.15 , -0.23 ,  0.07 , -0.34 ],\n",
      "       [-0.63 , -0.59 , -0.66 , -0.21 , -0.23 ],\n",
      "       [-0.02 , -0.35 ,  0.12 , -0.01 ,  0.56 ],\n",
      "       [-0.23 ,  0.22 , -0.55 , -0.3  ,  0.31 ],\n",
      "       [-0.62 ,  0.41 , -0.66 , -0.25 , -0.79 ],\n",
      "       [-0.68 , -0.29 ,  0.82 ,  0.38 ,  0.21 ],\n",
      "       [ 0.43 , -0.26 ,  0.62 , -0.64 ,  0.6  ],\n",
      "       [ 0.53 ,  0.36 , -0.6  , -0.25 ,  0.22 ]], dtype=float32), array([-0.03,  0.  ,  0.1 , -0.01,  0.1 ], dtype=float32), array([[ 0.73, -0.61],\n",
      "       [-0.2 , -0.88],\n",
      "       [-0.31,  0.66],\n",
      "       [-0.58,  0.85],\n",
      "       [-0.16,  0.84]], dtype=float32), array([-0.09,  0.09], dtype=float32)]\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "andr aara h\n",
      "yhn tk\n",
      "22\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "mean_model_weights=[]\n",
    "for i in range(5):\n",
    "    mean_model_weights.append(get_avg_weights(add_weights[i],X_test.shape[1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeff707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "171539/171539 [==============================] - 3s 18us/sample - loss: 0.2196 - accuracy: 0.7927\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.2190 - accuracy: 0.7919\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "171539/171539 [==============================] - 3s 18us/sample - loss: 0.2302 - accuracy: 0.7927\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 23us/sample - loss: 0.2295 - accuracy: 0.7919\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "171539/171539 [==============================] - 3s 19us/sample - loss: 0.2263 - accuracy: 0.7927\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.2257 - accuracy: 0.7919\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "171539/171539 [==============================] - 3s 20us/sample - loss: 0.2276 - accuracy: 0.7927\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.2269 - accuracy: 0.7919\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      " 95136/171539 [===============>..............] - ETA: 1s - loss: 0.3098 - accuracy: 0.7928"
     ]
    }
   ],
   "source": [
    "#mean models\n",
    "from sklearn.model_selection import train_test_split\n",
    "mean_models=[]\n",
    "mean_model_train_metrics=[]\n",
    "mean_model_loss=[]\n",
    "mean_model_acc=[]\n",
    "mean_model_test_metrics=[]\n",
    "mean_model_test_loss=[]\n",
    "mean_model_test_acc=[]\n",
    "y = to_categorical(dataset[target_variable])\n",
    "X = dataset.drop(columns=target_variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "for i in range(5):\n",
    "    init_model=get_initial_model(X_test.shape[1], 2)\n",
    "    init_model.set_weights(mean_model_weights[i])\n",
    "    mean_model_train_metrics.append(init_model.evaluate(X_train, y_train))\n",
    "    mean_model_loss.append(mean_model_train_metrics[i][0])\n",
    "    mean_model_acc.append(mean_model_train_metrics[i][1])\n",
    "    mean_model_test_metrics.append(init_model.evaluate(X_test, y_test))\n",
    "    mean_model_test_loss.append(mean_model_test_metrics[i][0])\n",
    "    mean_model_test_acc.append(mean_model_test_metrics[i][1])\n",
    "print(\"Done for model selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b29ec7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21983142676102038, 0.23032166993667214, 0.22653108226487761, 0.22775114739086574, 0.3101194851791345] [0.7919482, 0.7919482, 0.7919482, 0.7919482, 0.7919482]\n",
      "[0.2185741221189836, 0.22912102289909916, 0.2252313999101962, 0.22652762381742964, 0.30866479239732586] [0.793656, 0.793656, 0.793656, 0.793656, 0.793656]\n"
     ]
    }
   ],
   "source": [
    "print(mean_model_loss, mean_model_acc)\n",
    "print(mean_model_test_loss, mean_model_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7a5a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 137231 samples, validate on 34308 samples\n",
      "Epoch 1/20\n",
      "137231/137231 [==============================] - 8s 55us/sample - loss: 0.1337 - accuracy: 0.9493 - val_loss: 0.0717 - val_accuracy: 0.9789\n",
      "Epoch 2/20\n",
      "137231/137231 [==============================] - 7s 51us/sample - loss: 0.0490 - accuracy: 0.9854 - val_loss: 0.0237 - val_accuracy: 0.9948\n",
      "Epoch 3/20\n",
      "137231/137231 [==============================] - 7s 53us/sample - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0103 - val_accuracy: 0.9975\n",
      "Epoch 4/20\n",
      "137231/137231 [==============================] - 7s 53us/sample - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.0070 - val_accuracy: 0.9982\n",
      "Epoch 5/20\n",
      "137231/137231 [==============================] - 8s 55us/sample - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 6/20\n",
      "137231/137231 [==============================] - 7s 53us/sample - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.0059 - val_accuracy: 0.9986\n",
      "Epoch 7/20\n",
      "137231/137231 [==============================] - 8s 56us/sample - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
      "Epoch 8/20\n",
      "137231/137231 [==============================] - 8s 56us/sample - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.0087 - val_accuracy: 0.9978\n",
      "Epoch 9/20\n",
      "137231/137231 [==============================] - 7s 52us/sample - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0127 - val_accuracy: 0.9957\n",
      "Epoch 10/20\n",
      "137231/137231 [==============================] - 8s 60us/sample - loss: 0.0089 - accuracy: 0.9978 - val_loss: 0.0136 - val_accuracy: 0.9966\n",
      "Epoch 11/20\n",
      "137231/137231 [==============================] - 8s 61us/sample - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0066 - val_accuracy: 0.9985\n",
      "Epoch 12/20\n",
      "137231/137231 [==============================] - 8s 57us/sample - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0184 - val_accuracy: 0.9941\n",
      "Epoch 13/20\n",
      "137231/137231 [==============================] - 8s 58us/sample - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
      "Epoch 14/20\n",
      "137231/137231 [==============================] - 7s 54us/sample - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.0057 - val_accuracy: 0.9987\n",
      "Epoch 15/20\n",
      "137231/137231 [==============================] - 9s 66us/sample - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0087 - val_accuracy: 0.9983\n",
      "Epoch 16/20\n",
      "137231/137231 [==============================] - 9s 67us/sample - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0062 - val_accuracy: 0.9984\n",
      "Epoch 17/20\n",
      "137231/137231 [==============================] - 7s 52us/sample - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
      "Epoch 18/20\n",
      "137231/137231 [==============================] - 7s 52us/sample - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.0070 - val_accuracy: 0.9983\n",
      "Epoch 19/20\n",
      "137231/137231 [==============================] - 7s 52us/sample - loss: 0.0081 - accuracy: 0.9981 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "Epoch 20/20\n",
      "137231/137231 [==============================] - 7s 52us/sample - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0059 - val_accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "#benchmark model\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = to_categorical(dataset[target_variable])\n",
    "X = dataset.drop(columns=target_variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "ann_model=get_initial_model(X_test.shape[1], 2) #same intial weights\n",
    "ann_model.set_weights(initial_model.get_weights())\n",
    "history = ann_model.fit(X_train, y_train, epochs=20, validation_split=0.2, verbose=1)\n",
    "ann_model.set_weights(update_weights(ann_model.get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cfc802b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model=get_initial_model(X_test.shape[1], 2)\n",
    "saved_model.set_weights(initial_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "90b70da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.0065 - accuracy: 0.9986\n"
     ]
    }
   ],
   "source": [
    "#benchmark metrics\n",
    "benchmark_loss=history.history['loss']\n",
    "benchmark_val_loss=history.history['val_loss']\n",
    "benchmark_acc=history.history['accuracy']\n",
    "benchmark_val_acc=history.history['val_accuracy']\n",
    "benchmark_test_metrics=benchmark_model.evaluate(X_test, y_test)\n",
    "benchmark_test_loss=benchmark_test_metrics[0]\n",
    "benchmark_test_accuracy=benchmark_test_metrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7bdb0609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting graphs for loss and accuracies for the top 5 recurrent models:\n",
    "#plotting val_loss and loss for the models generated and the benchmark model.\n",
    "from random import randint\n",
    "import matplotlib.patches as mpatches\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "leg=[]\n",
    "for i in range(len(color)):\n",
    "    leg.append(mpatches.Patch(color=color[i], label=str(len(val_acc[i]))))\n",
    "n = len(val_acc)\n",
    "print(n)\n",
    "x_axis=np.arange(1, 21, 1)\n",
    "print(x_axis)\n",
    "for i in range(n):\n",
    "    for j in range(len(val_acc[i])):\n",
    "        plt.plot(x_axis,val_acc[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis, np.mean(val_acc[i], axis=0), color=color[i])\n",
    "#plt.xlim(-0.5,20.5)\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.plot(x_axis, benchmark_val_acc, color='black')\n",
    "plt.savefig(\"fig/Skin_NonSkin_F1_Val_20Epochs_10000.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f40dca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80249995, 0.80249995, 0.80249995, 0.80249995, 0.80249995, 0.80249995, 0.80249995, 0.80249995, 0.80249995, 0.80249995, 0.80249995, 0.80249995, 0.80249995, 0.80249995, 0.80249995, 0.80249995, 0.8474999, 0.89624995, 0.90874994, 0.9212499]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "0 0\n",
      "0 1\n",
      "1 0\n",
      "2 0\n",
      "2 1\n",
      "3 0\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "4 9\n",
      "4 10\n",
      "4 11\n",
      "4 12\n",
      "4 13\n",
      "4 14\n",
      "4 15\n",
      "4 16\n",
      "4 17\n",
      "4 18\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train accuracy \n",
    "from random import randint\n",
    "color = []\n",
    "print(train_acc[4][0])\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "x_axis=np.arange(1, 21, 1)\n",
    "print(x_axis)\n",
    "for i in range(n):\n",
    "    for j in range(len(train_acc[i])):\n",
    "        print(i,j)\n",
    "        plt.plot(x_axis,train_acc[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis,np.mean(train_acc[i], axis=0), color=color[i])\n",
    "plt.plot(x_axis,benchmark_acc, color='black')\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/Skin_NonSkin_F1_train_20Epochs_10000.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "172d1daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training loss\n",
    "from random import randint\n",
    "color = []\n",
    "n = len(train_loss)\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "for i in range(n):\n",
    "    for j in range(len(train_loss[i])):\n",
    "        plt.plot(x_axis,train_loss[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis,np.mean(train_loss[i], axis=0), color=color[i])\n",
    "plt.plot(x_axis,benchmark_loss, color='black')\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/Skin_NonSkin_loss_train_20Epochs_10000.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e8dfc90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#validation loss loss\n",
    "from random import randint\n",
    "color = []\n",
    "n = len(val_acc)\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "for i in range(n):\n",
    "    for j in range(len(train_loss[i])):\n",
    "        plt.plot(x_axis,val_loss[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis,np.mean(val_loss[i], axis=0), color=color[i])\n",
    "plt.plot(x_axis,benchmark_val_loss, color='black')\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/Skin_NonSkin_loss_val_20Epochs_10000.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bcdf5d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1748 - accuracy: 0.9346\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.1748 - accuracy: 0.9346\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1748 - accuracy: 0.9346\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1748 - accuracy: 0.9346\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1748 - accuracy: 0.9346\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1748 - accuracy: 0.9346\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1748 - accuracy: 0.9346\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1748 - accuracy: 0.9346\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1748 - accuracy: 0.9346\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.1748 - accuracy: 0.9346s - loss:\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.1748 - accuracy: 0.9346\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1748 - accuracy: 0.9346\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 20us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 24us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.1630 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1835 - accuracy: 0.9311s - loss: 0.1830 - accuracy: \n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 24us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 25us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 24us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1835 - accuracy: 0.9311\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1646 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.1646 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1646 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1646 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1646 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350s - loss: 0.1702 - accuracy: 0.93\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 26us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 26us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 25us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 24us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.1702 - accuracy: 0.9350\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 21us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 20us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 20us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1874 - accuracy: 0.9353\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1792 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1792 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 20us/sample - loss: 0.1792 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1792 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1792 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1651 - accuracy: 0.9344\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1671 - accuracy: 0.9356\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1671 - accuracy: 0.9356\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1671 - accuracy: 0.9356\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1671 - accuracy: 0.9356\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1671 - accuracy: 0.9356\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1671 - accuracy: 0.9356s -\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1671 - accuracy: 0.9356\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1671 - accuracy: 0.9356\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 26us/sample - loss: 0.1671 - accuracy: 0.9356\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 24us/sample - loss: 0.1671 - accuracy: 0.9356\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 25us/sample - loss: 0.1671 - accuracy: 0.9356\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1585 - accuracy: 0.9351s - loss: 0.1573 - ac\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1585 - accuracy: 0.9351s - loss: 0\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 26us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 29us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 24us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 21us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 20us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 21us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 22us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 22us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 24us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 25us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 20us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 22us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 23us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 19us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 22us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 24us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 28us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 26us/sample - loss: 0.1585 - accuracy: 0.9351\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 28us/sample - loss: 0.1636 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 26us/sample - loss: 0.1636 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 23us/sample - loss: 0.1636 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 22us/sample - loss: 0.1636 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73518/73518 [==============================] - 2s 23us/sample - loss: 0.1636 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 22us/sample - loss: 0.1636 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 21us/sample - loss: 0.1636 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1636 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1636 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 25us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 21us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 25us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 23us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 21us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 22us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 22us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 20us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 18us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 22us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 21us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 24us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 25us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 23us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 22us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 21us/sample - loss: 0.1587 - accuracy: 0.9357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 21us/sample - loss: 0.1671 - accuracy: 0.9335\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 24us/sample - loss: 0.1671 - accuracy: 0.9335\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 24us/sample - loss: 0.1671 - accuracy: 0.9335\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 23us/sample - loss: 0.1605 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 22us/sample - loss: 0.1605 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 22us/sample - loss: 0.1605 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 23us/sample - loss: 0.1605 - accuracy: 0.9354\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 2s 21us/sample - loss: 0.1605 - accuracy: 0.9354\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9b/5l977gy546s07hjrqj1tqdl80000gp/T/ipykernel_2206/2201997918.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mhigh_test_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_initial_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#same intial weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mhigh_test_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mhigh_test_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhigh_test_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#lets compute the accuracy for bigger test set 30% benchmark test data\n",
    "high_test_loss=[]\n",
    "high_test_f1=[]\n",
    "for i in range(len(add_weights)):\n",
    "    for j in range(len(add_weights[i])):\n",
    "        high_test_model=get_initial_model(X_test.shape[1], 2) #same intial weights\n",
    "        high_test_model.set_weights(Models[i][0])\n",
    "        high_test_metrics=high_test_model.evaluate(X_test,y_test)\n",
    "        if j == 0:\n",
    "            high_test_loss.append([high_test_metrics[0]])\n",
    "            high_test_f1.append([high_test_metrics[1]])\n",
    "        else:\n",
    "            high_test_loss[i].append(high_test_metrics[0])\n",
    "            high_test_f1[i].append(high_test_metrics[1])\n",
    "print(high_test_loss, high_test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802de1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_test_accs=list(np.array(high_test_f1)[A])\n",
    "print(high_test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5027d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for test accuracy plot\n",
    "#plot test accuracy of smaller test set\n",
    "benchmark_test_accs=[benchmark_test_accuracy]*n\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0.7, 1.1])\n",
    "for i in range(n):\n",
    "    plt.scatter([i]*len(test_acc[i]),test_acc[i], color=color[i], alpha=0.2)\n",
    "    plt.scatter(i,high_test_accs[i][0], color=color[i])\n",
    "plt.plot(benchmark_test_accs, color='black')\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/Skin_NonSkin_test_acc_20Epochs_1000.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2579da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for mean model accuracy and benchmark loss:\n",
    "n=5\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0.7, 0.85])\n",
    "for i in range(n):\n",
    "    plt.plot(i, mean_model_acc[i],'o',color=color[i])\n",
    "    plt.plot(i, mean_model_test_acc[i],'o', mfc='none',color=color[i])\n",
    "plt.plot([benchmark_acc[-1]]*n,color='black')\n",
    "plt.plot([benchmark_test_accuracy]*n,'-.',color='black')\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/SkinNonSkin_mean_model_results.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#done for now No need for MNSIT dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdd92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fdbdb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 793\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 604us/sample - loss: 0.6729 - f1_m: 0.7950 - val_loss: 0.6501 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6259 - f1_m: 0.7950 - val_loss: 0.6015 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5738 - f1_m: 0.7950 - val_loss: 0.5559 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5336 - f1_m: 0.7950 - val_loss: 0.5323 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5171 - f1_m: 0.7950 - val_loss: 0.5239 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5089 - f1_m: 0.7950 - val_loss: 0.5174 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5031 - f1_m: 0.7950 - val_loss: 0.5106 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4954 - f1_m: 0.7950 - val_loss: 0.5031 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4873 - f1_m: 0.7950 - val_loss: 0.4931 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4757 - f1_m: 0.7950 - val_loss: 0.4786 - val_f1_m: 0.7679\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4614 - f1_m: 0.7950 - val_loss: 0.4641 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4458 - f1_m: 0.7950 - val_loss: 0.4468 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4266 - f1_m: 0.7950 - val_loss: 0.4250 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4045 - f1_m: 0.7950 - val_loss: 0.3974 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3769 - f1_m: 0.7950 - val_loss: 0.3668 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3462 - f1_m: 0.7950 - val_loss: 0.3322 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3120 - f1_m: 0.7950 - val_loss: 0.2977 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2825 - f1_m: 0.7950 - val_loss: 0.2665 - val_f1_m: 0.7545\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2539 - f1_m: 0.7950 - val_loss: 0.2432 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2361 - f1_m: 0.7950 - val_loss: 0.2285 - val_f1_m: 0.7946\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 579us/sample - loss: 0.6736 - f1_m: 0.7817 - val_loss: 0.6427 - val_f1_m: 0.8393\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6294 - f1_m: 0.7825 - val_loss: 0.5823 - val_f1_m: 0.8527\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5818 - f1_m: 0.7825 - val_loss: 0.5180 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5468 - f1_m: 0.7825 - val_loss: 0.4763 - val_f1_m: 0.8527\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5301 - f1_m: 0.7825 - val_loss: 0.4625 - val_f1_m: 0.8393\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5228 - f1_m: 0.7825 - val_loss: 0.4526 - val_f1_m: 0.8259\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5148 - f1_m: 0.7825 - val_loss: 0.4467 - val_f1_m: 0.8393\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5043 - f1_m: 0.7825 - val_loss: 0.4364 - val_f1_m: 0.8527\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4933 - f1_m: 0.7825 - val_loss: 0.4261 - val_f1_m: 0.8259\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4764 - f1_m: 0.7825 - val_loss: 0.4129 - val_f1_m: 0.8527\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4569 - f1_m: 0.7825 - val_loss: 0.3914 - val_f1_m: 0.8527\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4319 - f1_m: 0.7825 - val_loss: 0.3650 - val_f1_m: 0.8527\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4018 - f1_m: 0.7825 - val_loss: 0.3373 - val_f1_m: 0.8393\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3697 - f1_m: 0.7825 - val_loss: 0.3079 - val_f1_m: 0.8393\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3408 - f1_m: 0.7825 - val_loss: 0.2787 - val_f1_m: 0.8527\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3130 - f1_m: 0.7825 - val_loss: 0.2550 - val_f1_m: 0.8393\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2868 - f1_m: 0.7825 - val_loss: 0.2325 - val_f1_m: 0.8259\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2628 - f1_m: 0.7825 - val_loss: 0.2126 - val_f1_m: 0.8393\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2409 - f1_m: 0.7825 - val_loss: 0.1975 - val_f1_m: 0.8259\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2262 - f1_m: 0.7912 - val_loss: 0.1854 - val_f1_m: 0.9241\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 592us/sample - loss: 0.6724 - f1_m: 0.7937 - val_loss: 0.6498 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6247 - f1_m: 0.7937 - val_loss: 0.5983 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5709 - f1_m: 0.7937 - val_loss: 0.5526 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5328 - f1_m: 0.7937 - val_loss: 0.5299 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5189 - f1_m: 0.7937 - val_loss: 0.5215 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5115 - f1_m: 0.7937 - val_loss: 0.5149 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5052 - f1_m: 0.7937 - val_loss: 0.5082 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4984 - f1_m: 0.7937 - val_loss: 0.5007 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4894 - f1_m: 0.7937 - val_loss: 0.4896 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4770 - f1_m: 0.7937 - val_loss: 0.4750 - val_f1_m: 0.7455\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4628 - f1_m: 0.7937 - val_loss: 0.4601 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4467 - f1_m: 0.7937 - val_loss: 0.4411 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4256 - f1_m: 0.7937 - val_loss: 0.4168 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4005 - f1_m: 0.7937 - val_loss: 0.3899 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3709 - f1_m: 0.7937 - val_loss: 0.3564 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3366 - f1_m: 0.7937 - val_loss: 0.3192 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2983 - f1_m: 0.7937 - val_loss: 0.2809 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2665 - f1_m: 0.7937 - val_loss: 0.2526 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2467 - f1_m: 0.7937 - val_loss: 0.2363 - val_f1_m: 0.7991\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2331 - f1_m: 0.7937 - val_loss: 0.2272 - val_f1_m: 0.8125\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.6744 - f1_m: 0.7887 - val_loss: 0.6487 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6277 - f1_m: 0.7887 - val_loss: 0.5922 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5764 - f1_m: 0.7887 - val_loss: 0.5367 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5374 - f1_m: 0.7887 - val_loss: 0.5052 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5208 - f1_m: 0.7887 - val_loss: 0.4926 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5128 - f1_m: 0.7887 - val_loss: 0.4852 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5060 - f1_m: 0.7887 - val_loss: 0.4773 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4964 - f1_m: 0.7887 - val_loss: 0.4665 - val_f1_m: 0.8304\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4868 - f1_m: 0.7887 - val_loss: 0.4553 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4742 - f1_m: 0.7887 - val_loss: 0.4421 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4612 - f1_m: 0.7887 - val_loss: 0.4268 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4441 - f1_m: 0.7887 - val_loss: 0.4071 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4220 - f1_m: 0.7887 - val_loss: 0.3817 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3943 - f1_m: 0.7887 - val_loss: 0.3522 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3664 - f1_m: 0.7887 - val_loss: 0.3213 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3363 - f1_m: 0.7887 - val_loss: 0.2904 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3075 - f1_m: 0.7887 - val_loss: 0.2617 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2812 - f1_m: 0.7887 - val_loss: 0.2345 - val_f1_m: 0.8304\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2573 - f1_m: 0.7887 - val_loss: 0.2120 - val_f1_m: 0.8304\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2391 - f1_m: 0.7887 - val_loss: 0.1967 - val_f1_m: 0.8036\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 610us/sample - loss: 0.6795 - f1_m: 0.7979 - val_loss: 0.6670 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6486 - f1_m: 0.7987 - val_loss: 0.6370 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6097 - f1_m: 0.7987 - val_loss: 0.6010 - val_f1_m: 0.7411\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5666 - f1_m: 0.7987 - val_loss: 0.5688 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5322 - f1_m: 0.7987 - val_loss: 0.5535 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5140 - f1_m: 0.7987 - val_loss: 0.5487 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5073 - f1_m: 0.7987 - val_loss: 0.5460 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5013 - f1_m: 0.7987 - val_loss: 0.5385 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4956 - f1_m: 0.7987 - val_loss: 0.5352 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4907 - f1_m: 0.7987 - val_loss: 0.5274 - val_f1_m: 0.7679\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4839 - f1_m: 0.7987 - val_loss: 0.5230 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4780 - f1_m: 0.7987 - val_loss: 0.5146 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4701 - f1_m: 0.7987 - val_loss: 0.5053 - val_f1_m: 0.7545\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4593 - f1_m: 0.7987 - val_loss: 0.4931 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4473 - f1_m: 0.7987 - val_loss: 0.4779 - val_f1_m: 0.7679\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4324 - f1_m: 0.7987 - val_loss: 0.4593 - val_f1_m: 0.7545\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4140 - f1_m: 0.7987 - val_loss: 0.4391 - val_f1_m: 0.7411\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3924 - f1_m: 0.7987 - val_loss: 0.4152 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3663 - f1_m: 0.7987 - val_loss: 0.3807 - val_f1_m: 0.7545\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3303 - f1_m: 0.7987 - val_loss: 0.3413 - val_f1_m: 0.7812\n",
      "0.7987499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 610us/sample - loss: 0.6732 - f1_m: 0.7925 - val_loss: 0.6489 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6265 - f1_m: 0.7925 - val_loss: 0.5983 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5759 - f1_m: 0.7925 - val_loss: 0.5468 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5354 - f1_m: 0.7925 - val_loss: 0.5172 - val_f1_m: 0.8036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5177 - f1_m: 0.7925 - val_loss: 0.5061 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5084 - f1_m: 0.7925 - val_loss: 0.4985 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5005 - f1_m: 0.7925 - val_loss: 0.4889 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4903 - f1_m: 0.7925 - val_loss: 0.4788 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4797 - f1_m: 0.7925 - val_loss: 0.4662 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4648 - f1_m: 0.7925 - val_loss: 0.4503 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4474 - f1_m: 0.7925 - val_loss: 0.4289 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4239 - f1_m: 0.7925 - val_loss: 0.4026 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3977 - f1_m: 0.7925 - val_loss: 0.3731 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3677 - f1_m: 0.7925 - val_loss: 0.3424 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3393 - f1_m: 0.7925 - val_loss: 0.3124 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3133 - f1_m: 0.7925 - val_loss: 0.2897 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2900 - f1_m: 0.7925 - val_loss: 0.2624 - val_f1_m: 0.7366\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2680 - f1_m: 0.7925 - val_loss: 0.2418 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2489 - f1_m: 0.7925 - val_loss: 0.2237 - val_f1_m: 0.7902\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2332 - f1_m: 0.7925 - val_loss: 0.2088 - val_f1_m: 0.8036\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 617us/sample - loss: 0.6729 - f1_m: 0.7880 - val_loss: 0.6466 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6285 - f1_m: 0.7887 - val_loss: 0.5928 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5774 - f1_m: 0.7887 - val_loss: 0.5392 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5410 - f1_m: 0.7887 - val_loss: 0.5056 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5235 - f1_m: 0.7887 - val_loss: 0.4934 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5157 - f1_m: 0.7887 - val_loss: 0.4836 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5062 - f1_m: 0.7887 - val_loss: 0.4754 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4956 - f1_m: 0.7887 - val_loss: 0.4643 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4840 - f1_m: 0.7887 - val_loss: 0.4523 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4703 - f1_m: 0.7887 - val_loss: 0.4386 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4550 - f1_m: 0.7887 - val_loss: 0.4218 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4328 - f1_m: 0.7887 - val_loss: 0.3982 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4058 - f1_m: 0.7887 - val_loss: 0.3704 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3756 - f1_m: 0.7887 - val_loss: 0.3419 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3460 - f1_m: 0.7887 - val_loss: 0.3163 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3169 - f1_m: 0.7887 - val_loss: 0.2898 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2904 - f1_m: 0.7887 - val_loss: 0.2727 - val_f1_m: 0.8304\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2673 - f1_m: 0.7887 - val_loss: 0.2536 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2451 - f1_m: 0.7887 - val_loss: 0.2338 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2287 - f1_m: 0.7887 - val_loss: 0.2228 - val_f1_m: 0.8036\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 610us/sample - loss: 0.6743 - f1_m: 0.7987 - val_loss: 0.6538 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6247 - f1_m: 0.7987 - val_loss: 0.6079 - val_f1_m: 0.7545\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5708 - f1_m: 0.7987 - val_loss: 0.5658 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5282 - f1_m: 0.7987 - val_loss: 0.5486 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5112 - f1_m: 0.7987 - val_loss: 0.5452 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5025 - f1_m: 0.7987 - val_loss: 0.5384 - val_f1_m: 0.7545\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4962 - f1_m: 0.7987 - val_loss: 0.5322 - val_f1_m: 0.7545\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4887 - f1_m: 0.7987 - val_loss: 0.5245 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4795 - f1_m: 0.7987 - val_loss: 0.5120 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4675 - f1_m: 0.7987 - val_loss: 0.5003 - val_f1_m: 0.7679\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4542 - f1_m: 0.7987 - val_loss: 0.4870 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4380 - f1_m: 0.7987 - val_loss: 0.4694 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4185 - f1_m: 0.7987 - val_loss: 0.4460 - val_f1_m: 0.7679\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3923 - f1_m: 0.7987 - val_loss: 0.4177 - val_f1_m: 0.7545\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3640 - f1_m: 0.7987 - val_loss: 0.3856 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3291 - f1_m: 0.7987 - val_loss: 0.3489 - val_f1_m: 0.7679\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2925 - f1_m: 0.7987 - val_loss: 0.3171 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2570 - f1_m: 0.7987 - val_loss: 0.2838 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2302 - f1_m: 0.7987 - val_loss: 0.2657 - val_f1_m: 0.7277\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2160 - f1_m: 0.7987 - val_loss: 0.2561 - val_f1_m: 0.7679\n",
      "0.7987499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 605us/sample - loss: 0.6785 - f1_m: 0.8000 - val_loss: 0.6671 - val_f1_m: 0.7366\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6467 - f1_m: 0.8000 - val_loss: 0.6366 - val_f1_m: 0.7634\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6065 - f1_m: 0.8000 - val_loss: 0.6021 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5631 - f1_m: 0.8000 - val_loss: 0.5728 - val_f1_m: 0.7500\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5305 - f1_m: 0.8000 - val_loss: 0.5601 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5139 - f1_m: 0.8000 - val_loss: 0.5555 - val_f1_m: 0.7500\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5063 - f1_m: 0.8000 - val_loss: 0.5515 - val_f1_m: 0.7366\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5006 - f1_m: 0.8000 - val_loss: 0.5456 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4951 - f1_m: 0.8000 - val_loss: 0.5393 - val_f1_m: 0.7500\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4895 - f1_m: 0.8000 - val_loss: 0.5344 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4834 - f1_m: 0.8000 - val_loss: 0.5275 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4763 - f1_m: 0.8000 - val_loss: 0.5180 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4683 - f1_m: 0.8000 - val_loss: 0.5072 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4563 - f1_m: 0.8000 - val_loss: 0.4929 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4423 - f1_m: 0.8000 - val_loss: 0.4758 - val_f1_m: 0.7500\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4258 - f1_m: 0.8000 - val_loss: 0.4582 - val_f1_m: 0.7500\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4056 - f1_m: 0.8000 - val_loss: 0.4317 - val_f1_m: 0.7634\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3806 - f1_m: 0.8000 - val_loss: 0.4015 - val_f1_m: 0.7500\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3462 - f1_m: 0.8000 - val_loss: 0.3640 - val_f1_m: 0.7634\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3107 - f1_m: 0.8000 - val_loss: 0.3241 - val_f1_m: 0.7634\n",
      "0.79999995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 577us/sample - loss: 0.6743 - f1_m: 0.7912 - val_loss: 0.6493 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6280 - f1_m: 0.7912 - val_loss: 0.5972 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5745 - f1_m: 0.7912 - val_loss: 0.5451 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5358 - f1_m: 0.7912 - val_loss: 0.5152 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5207 - f1_m: 0.7912 - val_loss: 0.5051 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5136 - f1_m: 0.7912 - val_loss: 0.4984 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5077 - f1_m: 0.7912 - val_loss: 0.4919 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5002 - f1_m: 0.7912 - val_loss: 0.4823 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4908 - f1_m: 0.7912 - val_loss: 0.4731 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4801 - f1_m: 0.7912 - val_loss: 0.4614 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4697 - f1_m: 0.7912 - val_loss: 0.4491 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4564 - f1_m: 0.7912 - val_loss: 0.4345 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4394 - f1_m: 0.7912 - val_loss: 0.4158 - val_f1_m: 0.7679\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4193 - f1_m: 0.7912 - val_loss: 0.3930 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3949 - f1_m: 0.7912 - val_loss: 0.3653 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3627 - f1_m: 0.7912 - val_loss: 0.3253 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3193 - f1_m: 0.7912 - val_loss: 0.2816 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2812 - f1_m: 0.7912 - val_loss: 0.2474 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2539 - f1_m: 0.7912 - val_loss: 0.2308 - val_f1_m: 0.7812\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2383 - f1_m: 0.7912 - val_loss: 0.2191 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 609us/sample - loss: 0.6730 - f1_m: 0.7862 - val_loss: 0.6433 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6273 - f1_m: 0.7862 - val_loss: 0.5840 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.5772 - f1_m: 0.7862 - val_loss: 0.5252 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5397 - f1_m: 0.7862 - val_loss: 0.4891 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5234 - f1_m: 0.7862 - val_loss: 0.4739 - val_f1_m: 0.8259\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5157 - f1_m: 0.7862 - val_loss: 0.4676 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5078 - f1_m: 0.7862 - val_loss: 0.4584 - val_f1_m: 0.8259\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4992 - f1_m: 0.7862 - val_loss: 0.4505 - val_f1_m: 0.8393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4874 - f1_m: 0.7862 - val_loss: 0.4392 - val_f1_m: 0.8393\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4737 - f1_m: 0.7862 - val_loss: 0.4260 - val_f1_m: 0.8393\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4566 - f1_m: 0.7862 - val_loss: 0.4072 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.4357 - f1_m: 0.7862 - val_loss: 0.3863 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.4096 - f1_m: 0.7862 - val_loss: 0.3611 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.3787 - f1_m: 0.7862 - val_loss: 0.3291 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.3400 - f1_m: 0.7862 - val_loss: 0.2957 - val_f1_m: 0.8393\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.3003 - f1_m: 0.7862 - val_loss: 0.2609 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.2637 - f1_m: 0.7862 - val_loss: 0.2345 - val_f1_m: 0.8125\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.2385 - f1_m: 0.7862 - val_loss: 0.2196 - val_f1_m: 0.8259\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.2234 - f1_m: 0.7862 - val_loss: 0.2062 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2138 - f1_m: 0.7862 - val_loss: 0.1981 - val_f1_m: 0.9018\n",
      "0.78624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 681us/sample - loss: 0.6790 - f1_m: 0.7925 - val_loss: 0.6637 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.6486 - f1_m: 0.7925 - val_loss: 0.6270 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.6089 - f1_m: 0.7925 - val_loss: 0.5858 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5662 - f1_m: 0.7925 - val_loss: 0.5461 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5373 - f1_m: 0.7925 - val_loss: 0.5243 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5235 - f1_m: 0.7925 - val_loss: 0.5152 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5169 - f1_m: 0.7925 - val_loss: 0.5094 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.5115 - f1_m: 0.7925 - val_loss: 0.5042 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5061 - f1_m: 0.7925 - val_loss: 0.4989 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5005 - f1_m: 0.7925 - val_loss: 0.4933 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4947 - f1_m: 0.7925 - val_loss: 0.4871 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4879 - f1_m: 0.7925 - val_loss: 0.4799 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4801 - f1_m: 0.7925 - val_loss: 0.4707 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4684 - f1_m: 0.7925 - val_loss: 0.4587 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.4553 - f1_m: 0.7925 - val_loss: 0.4437 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.4385 - f1_m: 0.7925 - val_loss: 0.4266 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.4191 - f1_m: 0.7925 - val_loss: 0.4061 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.3980 - f1_m: 0.7925 - val_loss: 0.3810 - val_f1_m: 0.7634\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.3654 - f1_m: 0.7925 - val_loss: 0.3462 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.3309 - f1_m: 0.7925 - val_loss: 0.3108 - val_f1_m: 0.7366\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 666us/sample - loss: 0.6733 - f1_m: 0.7837 - val_loss: 0.6435 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.6287 - f1_m: 0.7837 - val_loss: 0.5846 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5793 - f1_m: 0.7837 - val_loss: 0.5246 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5446 - f1_m: 0.7837 - val_loss: 0.4874 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5300 - f1_m: 0.7837 - val_loss: 0.4699 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5224 - f1_m: 0.7837 - val_loss: 0.4631 - val_f1_m: 0.8482\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5158 - f1_m: 0.7837 - val_loss: 0.4568 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5084 - f1_m: 0.7837 - val_loss: 0.4478 - val_f1_m: 0.8348\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4986 - f1_m: 0.7837 - val_loss: 0.4376 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4877 - f1_m: 0.7837 - val_loss: 0.4270 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.4765 - f1_m: 0.7837 - val_loss: 0.4133 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.4632 - f1_m: 0.7837 - val_loss: 0.3984 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.4448 - f1_m: 0.7837 - val_loss: 0.3791 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 0.4233 - f1_m: 0.7837 - val_loss: 0.3570 - val_f1_m: 0.8348\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.3966 - f1_m: 0.7837 - val_loss: 0.3253 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.3612 - f1_m: 0.7837 - val_loss: 0.2911 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.3224 - f1_m: 0.7837 - val_loss: 0.2572 - val_f1_m: 0.8348\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.2818 - f1_m: 0.7987 - val_loss: 0.2187 - val_f1_m: 0.9062\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.2451 - f1_m: 0.8812 - val_loss: 0.1889 - val_f1_m: 0.9330\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.2195 - f1_m: 0.9050 - val_loss: 0.1718 - val_f1_m: 0.9554\n",
      "0.9049999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 693us/sample - loss: 0.6798 - f1_m: 0.7925 - val_loss: 0.6642 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.6487 - f1_m: 0.7925 - val_loss: 0.6290 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.6105 - f1_m: 0.7925 - val_loss: 0.5854 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5678 - f1_m: 0.7925 - val_loss: 0.5486 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.5387 - f1_m: 0.7925 - val_loss: 0.5257 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5211 - f1_m: 0.7925 - val_loss: 0.5150 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5119 - f1_m: 0.7925 - val_loss: 0.5059 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5034 - f1_m: 0.7925 - val_loss: 0.4968 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4945 - f1_m: 0.7925 - val_loss: 0.4853 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.4824 - f1_m: 0.7925 - val_loss: 0.4743 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4694 - f1_m: 0.7925 - val_loss: 0.4609 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.4553 - f1_m: 0.7925 - val_loss: 0.4437 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.4341 - f1_m: 0.7925 - val_loss: 0.4197 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4083 - f1_m: 0.7925 - val_loss: 0.3909 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3795 - f1_m: 0.7925 - val_loss: 0.3593 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3483 - f1_m: 0.7925 - val_loss: 0.3306 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3210 - f1_m: 0.7925 - val_loss: 0.3036 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.2969 - f1_m: 0.7925 - val_loss: 0.2828 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2777 - f1_m: 0.7925 - val_loss: 0.2652 - val_f1_m: 0.7768\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2606 - f1_m: 0.7925 - val_loss: 0.2494 - val_f1_m: 0.8036\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 614us/sample - loss: 0.6763 - f1_m: 0.7850 - val_loss: 0.6473 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6298 - f1_m: 0.7850 - val_loss: 0.5907 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5857 - f1_m: 0.7850 - val_loss: 0.5341 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5503 - f1_m: 0.7850 - val_loss: 0.4992 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5324 - f1_m: 0.7850 - val_loss: 0.4828 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5211 - f1_m: 0.7850 - val_loss: 0.4688 - val_f1_m: 0.8437\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5081 - f1_m: 0.7850 - val_loss: 0.4544 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4938 - f1_m: 0.7850 - val_loss: 0.4383 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4766 - f1_m: 0.7850 - val_loss: 0.4214 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4562 - f1_m: 0.7850 - val_loss: 0.3992 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.4292 - f1_m: 0.7850 - val_loss: 0.3723 - val_f1_m: 0.8437\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3992 - f1_m: 0.7850 - val_loss: 0.3417 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3646 - f1_m: 0.7850 - val_loss: 0.3100 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3325 - f1_m: 0.7850 - val_loss: 0.2799 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.3060 - f1_m: 0.7850 - val_loss: 0.2586 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2840 - f1_m: 0.7850 - val_loss: 0.2416 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2629 - f1_m: 0.7850 - val_loss: 0.2250 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.2428 - f1_m: 0.7850 - val_loss: 0.2102 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.2300 - f1_m: 0.7850 - val_loss: 0.1984 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.2188 - f1_m: 0.8388 - val_loss: 0.1919 - val_f1_m: 0.9375\n",
      "0.83875\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 626us/sample - loss: 0.6803 - f1_m: 0.7800 - val_loss: 0.6591 - val_f1_m: 0.8348\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6518 - f1_m: 0.7800 - val_loss: 0.6173 - val_f1_m: 0.8482\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6155 - f1_m: 0.7800 - val_loss: 0.5639 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.5798 - f1_m: 0.7800 - val_loss: 0.5079 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5504 - f1_m: 0.7800 - val_loss: 0.4745 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.5372 - f1_m: 0.7800 - val_loss: 0.4565 - val_f1_m: 0.8482\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5293 - f1_m: 0.7800 - val_loss: 0.4456 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.5229 - f1_m: 0.7800 - val_loss: 0.4421 - val_f1_m: 0.8616\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.5166 - f1_m: 0.7800 - val_loss: 0.4332 - val_f1_m: 0.8482\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5100 - f1_m: 0.7800 - val_loss: 0.4275 - val_f1_m: 0.8482\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5026 - f1_m: 0.7800 - val_loss: 0.4198 - val_f1_m: 0.8616\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4936 - f1_m: 0.7800 - val_loss: 0.4119 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.4817 - f1_m: 0.7800 - val_loss: 0.4011 - val_f1_m: 0.8616\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4651 - f1_m: 0.7800 - val_loss: 0.3895 - val_f1_m: 0.8348\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4458 - f1_m: 0.7800 - val_loss: 0.3692 - val_f1_m: 0.8482\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4236 - f1_m: 0.7800 - val_loss: 0.3511 - val_f1_m: 0.8482\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.3968 - f1_m: 0.7800 - val_loss: 0.3179 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3577 - f1_m: 0.7800 - val_loss: 0.2868 - val_f1_m: 0.8616\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.3173 - f1_m: 0.7800 - val_loss: 0.2586 - val_f1_m: 0.8482\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2841 - f1_m: 0.7800 - val_loss: 0.2327 - val_f1_m: 0.8616\n",
      "0.7799999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 623us/sample - loss: 0.6785 - f1_m: 0.7925 - val_loss: 0.6632 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.6463 - f1_m: 0.7925 - val_loss: 0.6267 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6060 - f1_m: 0.7925 - val_loss: 0.5833 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5632 - f1_m: 0.7925 - val_loss: 0.5475 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5350 - f1_m: 0.7925 - val_loss: 0.5278 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5218 - f1_m: 0.7925 - val_loss: 0.5200 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5167 - f1_m: 0.7925 - val_loss: 0.5144 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5105 - f1_m: 0.7925 - val_loss: 0.5092 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5056 - f1_m: 0.7925 - val_loss: 0.5040 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5005 - f1_m: 0.7925 - val_loss: 0.4983 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4951 - f1_m: 0.7925 - val_loss: 0.4920 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4888 - f1_m: 0.7925 - val_loss: 0.4849 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4815 - f1_m: 0.7925 - val_loss: 0.4763 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4724 - f1_m: 0.7925 - val_loss: 0.4646 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4597 - f1_m: 0.7925 - val_loss: 0.4504 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4446 - f1_m: 0.7925 - val_loss: 0.4331 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4266 - f1_m: 0.7925 - val_loss: 0.4122 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4053 - f1_m: 0.7925 - val_loss: 0.3913 - val_f1_m: 0.7768\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3834 - f1_m: 0.7925 - val_loss: 0.3636 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.3475 - f1_m: 0.7925 - val_loss: 0.3245 - val_f1_m: 0.7902\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 627us/sample - loss: 0.6736 - f1_m: 0.7825 - val_loss: 0.6426 - val_f1_m: 0.8527\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.6281 - f1_m: 0.7825 - val_loss: 0.5801 - val_f1_m: 0.8527\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5801 - f1_m: 0.7825 - val_loss: 0.5190 - val_f1_m: 0.8527\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5457 - f1_m: 0.7825 - val_loss: 0.4785 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5314 - f1_m: 0.7825 - val_loss: 0.4602 - val_f1_m: 0.8259\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5226 - f1_m: 0.7825 - val_loss: 0.4512 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5147 - f1_m: 0.7825 - val_loss: 0.4432 - val_f1_m: 0.8527\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5042 - f1_m: 0.7825 - val_loss: 0.4311 - val_f1_m: 0.8393\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4914 - f1_m: 0.7825 - val_loss: 0.4209 - val_f1_m: 0.8527\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4772 - f1_m: 0.7825 - val_loss: 0.4049 - val_f1_m: 0.8527\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4606 - f1_m: 0.7825 - val_loss: 0.3880 - val_f1_m: 0.8527\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4388 - f1_m: 0.7825 - val_loss: 0.3658 - val_f1_m: 0.8527\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4130 - f1_m: 0.7825 - val_loss: 0.3399 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3813 - f1_m: 0.7825 - val_loss: 0.3102 - val_f1_m: 0.8527\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3402 - f1_m: 0.7825 - val_loss: 0.2685 - val_f1_m: 0.8393\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2978 - f1_m: 0.7825 - val_loss: 0.2353 - val_f1_m: 0.8527\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2680 - f1_m: 0.7825 - val_loss: 0.2126 - val_f1_m: 0.8527\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2485 - f1_m: 0.7825 - val_loss: 0.1976 - val_f1_m: 0.8527\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2322 - f1_m: 0.7825 - val_loss: 0.1865 - val_f1_m: 0.8259\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2224 - f1_m: 0.7825 - val_loss: 0.1796 - val_f1_m: 0.8527\n",
      "0.7824999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 623us/sample - loss: 0.6734 - f1_m: 0.7837 - val_loss: 0.6423 - val_f1_m: 0.8348\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6271 - f1_m: 0.7837 - val_loss: 0.5832 - val_f1_m: 0.8348\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5787 - f1_m: 0.7837 - val_loss: 0.5216 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5423 - f1_m: 0.7837 - val_loss: 0.4844 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5273 - f1_m: 0.7837 - val_loss: 0.4666 - val_f1_m: 0.8482\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5190 - f1_m: 0.7837 - val_loss: 0.4585 - val_f1_m: 0.8482\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5107 - f1_m: 0.7837 - val_loss: 0.4480 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5006 - f1_m: 0.7837 - val_loss: 0.4383 - val_f1_m: 0.8482\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4874 - f1_m: 0.7837 - val_loss: 0.4228 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4737 - f1_m: 0.7837 - val_loss: 0.4073 - val_f1_m: 0.8482\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4549 - f1_m: 0.7837 - val_loss: 0.3873 - val_f1_m: 0.8482\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4296 - f1_m: 0.7837 - val_loss: 0.3580 - val_f1_m: 0.8482\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4006 - f1_m: 0.7837 - val_loss: 0.3276 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3726 - f1_m: 0.7837 - val_loss: 0.2984 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3437 - f1_m: 0.7837 - val_loss: 0.2730 - val_f1_m: 0.8348\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3178 - f1_m: 0.7837 - val_loss: 0.2499 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2941 - f1_m: 0.7837 - val_loss: 0.2302 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2724 - f1_m: 0.7837 - val_loss: 0.2069 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2528 - f1_m: 0.7837 - val_loss: 0.1967 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2411 - f1_m: 0.7837 - val_loss: 0.1852 - val_f1_m: 0.9554\n",
      "0.78374994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 603us/sample - loss: 0.6718 - f1_m: 0.7975 - val_loss: 0.6524 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.6231 - f1_m: 0.7975 - val_loss: 0.6051 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5681 - f1_m: 0.7975 - val_loss: 0.5643 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5275 - f1_m: 0.7975 - val_loss: 0.5474 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5103 - f1_m: 0.7975 - val_loss: 0.5415 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5035 - f1_m: 0.7975 - val_loss: 0.5365 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4979 - f1_m: 0.7975 - val_loss: 0.5301 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4913 - f1_m: 0.7975 - val_loss: 0.5219 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4844 - f1_m: 0.7975 - val_loss: 0.5112 - val_f1_m: 0.7589\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4738 - f1_m: 0.7975 - val_loss: 0.4999 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4635 - f1_m: 0.7975 - val_loss: 0.4859 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4489 - f1_m: 0.7975 - val_loss: 0.4712 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4321 - f1_m: 0.7975 - val_loss: 0.4508 - val_f1_m: 0.7723\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4117 - f1_m: 0.7975 - val_loss: 0.4245 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3856 - f1_m: 0.7975 - val_loss: 0.3951 - val_f1_m: 0.7589\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3546 - f1_m: 0.7975 - val_loss: 0.3585 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3188 - f1_m: 0.7975 - val_loss: 0.3148 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2770 - f1_m: 0.7975 - val_loss: 0.2750 - val_f1_m: 0.7455\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2453 - f1_m: 0.7975 - val_loss: 0.2519 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2273 - f1_m: 0.7975 - val_loss: 0.2373 - val_f1_m: 0.7723\n",
      "0.7974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 580us/sample - loss: 0.6806 - f1_m: 0.7862 - val_loss: 0.6634 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6533 - f1_m: 0.7862 - val_loss: 0.6287 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6183 - f1_m: 0.7862 - val_loss: 0.5849 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5784 - f1_m: 0.7862 - val_loss: 0.5378 - val_f1_m: 0.8393\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5447 - f1_m: 0.7862 - val_loss: 0.5055 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5287 - f1_m: 0.7862 - val_loss: 0.4883 - val_f1_m: 0.8259\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5210 - f1_m: 0.7862 - val_loss: 0.4806 - val_f1_m: 0.8259\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5147 - f1_m: 0.7862 - val_loss: 0.4762 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5085 - f1_m: 0.7862 - val_loss: 0.4687 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5019 - f1_m: 0.7862 - val_loss: 0.4619 - val_f1_m: 0.8393\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4948 - f1_m: 0.7862 - val_loss: 0.4542 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4854 - f1_m: 0.7862 - val_loss: 0.4439 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4733 - f1_m: 0.7862 - val_loss: 0.4315 - val_f1_m: 0.8393\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4593 - f1_m: 0.7862 - val_loss: 0.4176 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4417 - f1_m: 0.7862 - val_loss: 0.3976 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4201 - f1_m: 0.7862 - val_loss: 0.3742 - val_f1_m: 0.8125\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3945 - f1_m: 0.7862 - val_loss: 0.3454 - val_f1_m: 0.8125\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3583 - f1_m: 0.7862 - val_loss: 0.3120 - val_f1_m: 0.7991\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3202 - f1_m: 0.7862 - val_loss: 0.2795 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2891 - f1_m: 0.7862 - val_loss: 0.2563 - val_f1_m: 0.8393\n",
      "0.78624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 597us/sample - loss: 0.6716 - f1_m: 0.7980 - val_loss: 0.6526 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6222 - f1_m: 0.7987 - val_loss: 0.6058 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5689 - f1_m: 0.7987 - val_loss: 0.5633 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5267 - f1_m: 0.7987 - val_loss: 0.5452 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5106 - f1_m: 0.7987 - val_loss: 0.5405 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5035 - f1_m: 0.7987 - val_loss: 0.5358 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4966 - f1_m: 0.7987 - val_loss: 0.5273 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4895 - f1_m: 0.7987 - val_loss: 0.5208 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4799 - f1_m: 0.7987 - val_loss: 0.5097 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4685 - f1_m: 0.7987 - val_loss: 0.4976 - val_f1_m: 0.7411\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4570 - f1_m: 0.7987 - val_loss: 0.4850 - val_f1_m: 0.7277\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4414 - f1_m: 0.7987 - val_loss: 0.4703 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4235 - f1_m: 0.7987 - val_loss: 0.4474 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4003 - f1_m: 0.7987 - val_loss: 0.4226 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3740 - f1_m: 0.7987 - val_loss: 0.3935 - val_f1_m: 0.7545\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3417 - f1_m: 0.7987 - val_loss: 0.3574 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3077 - f1_m: 0.7987 - val_loss: 0.3218 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2781 - f1_m: 0.7987 - val_loss: 0.2950 - val_f1_m: 0.7946\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2540 - f1_m: 0.7987 - val_loss: 0.2723 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2346 - f1_m: 0.7987 - val_loss: 0.2585 - val_f1_m: 0.7679\n",
      "0.7987499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 667us/sample - loss: 0.6712 - f1_m: 0.8017 - val_loss: 0.6549 - val_f1_m: 0.7411\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6209 - f1_m: 0.8025 - val_loss: 0.6121 - val_f1_m: 0.7545\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5673 - f1_m: 0.8025 - val_loss: 0.5752 - val_f1_m: 0.7545\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5249 - f1_m: 0.8025 - val_loss: 0.5620 - val_f1_m: 0.7143\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5071 - f1_m: 0.8025 - val_loss: 0.5596 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5001 - f1_m: 0.8025 - val_loss: 0.5527 - val_f1_m: 0.7277\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4944 - f1_m: 0.8025 - val_loss: 0.5468 - val_f1_m: 0.7545\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4870 - f1_m: 0.8025 - val_loss: 0.5383 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4784 - f1_m: 0.8025 - val_loss: 0.5304 - val_f1_m: 0.7545\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4685 - f1_m: 0.8025 - val_loss: 0.5182 - val_f1_m: 0.7411\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4584 - f1_m: 0.8025 - val_loss: 0.5071 - val_f1_m: 0.7545\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4465 - f1_m: 0.8025 - val_loss: 0.4955 - val_f1_m: 0.7545\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4323 - f1_m: 0.8025 - val_loss: 0.4779 - val_f1_m: 0.7679\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4139 - f1_m: 0.8025 - val_loss: 0.4526 - val_f1_m: 0.7411\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3907 - f1_m: 0.8025 - val_loss: 0.4231 - val_f1_m: 0.7545\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3650 - f1_m: 0.8025 - val_loss: 0.3965 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3392 - f1_m: 0.8025 - val_loss: 0.3701 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3146 - f1_m: 0.8025 - val_loss: 0.3414 - val_f1_m: 0.7545\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2919 - f1_m: 0.8025 - val_loss: 0.3142 - val_f1_m: 0.7277\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2702 - f1_m: 0.8025 - val_loss: 0.2913 - val_f1_m: 0.7411\n",
      "0.80249995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 583us/sample - loss: 0.6731 - f1_m: 0.7962 - val_loss: 0.6518 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6253 - f1_m: 0.7962 - val_loss: 0.6039 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5726 - f1_m: 0.7962 - val_loss: 0.5592 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5310 - f1_m: 0.7962 - val_loss: 0.5371 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5134 - f1_m: 0.7962 - val_loss: 0.5302 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5051 - f1_m: 0.7962 - val_loss: 0.5233 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4989 - f1_m: 0.7962 - val_loss: 0.5170 - val_f1_m: 0.7902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4904 - f1_m: 0.7962 - val_loss: 0.5074 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4807 - f1_m: 0.7962 - val_loss: 0.4964 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4683 - f1_m: 0.7962 - val_loss: 0.4837 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4544 - f1_m: 0.7962 - val_loss: 0.4684 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4385 - f1_m: 0.7962 - val_loss: 0.4498 - val_f1_m: 0.7500\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4166 - f1_m: 0.7962 - val_loss: 0.4262 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3916 - f1_m: 0.7962 - val_loss: 0.3992 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3615 - f1_m: 0.7962 - val_loss: 0.3676 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3267 - f1_m: 0.7962 - val_loss: 0.3321 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2902 - f1_m: 0.7962 - val_loss: 0.2978 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2573 - f1_m: 0.7962 - val_loss: 0.2726 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2340 - f1_m: 0.7962 - val_loss: 0.2561 - val_f1_m: 0.7768\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2199 - f1_m: 0.7962 - val_loss: 0.2458 - val_f1_m: 0.8036\n",
      "0.7962499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 586us/sample - loss: 0.6733 - f1_m: 0.7950 - val_loss: 0.6500 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6237 - f1_m: 0.7950 - val_loss: 0.6009 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5731 - f1_m: 0.7950 - val_loss: 0.5545 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5320 - f1_m: 0.7950 - val_loss: 0.5327 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5160 - f1_m: 0.7950 - val_loss: 0.5242 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5089 - f1_m: 0.7950 - val_loss: 0.5176 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5017 - f1_m: 0.7950 - val_loss: 0.5109 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4942 - f1_m: 0.7950 - val_loss: 0.5027 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4850 - f1_m: 0.7950 - val_loss: 0.4912 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4720 - f1_m: 0.7950 - val_loss: 0.4783 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4572 - f1_m: 0.7950 - val_loss: 0.4640 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4415 - f1_m: 0.7950 - val_loss: 0.4467 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4202 - f1_m: 0.7950 - val_loss: 0.4234 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3937 - f1_m: 0.7950 - val_loss: 0.3959 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3633 - f1_m: 0.7950 - val_loss: 0.3637 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.3285 - f1_m: 0.7950 - val_loss: 0.3268 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2857 - f1_m: 0.7950 - val_loss: 0.2822 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2479 - f1_m: 0.7950 - val_loss: 0.2557 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2268 - f1_m: 0.7950 - val_loss: 0.2397 - val_f1_m: 0.7679\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2139 - f1_m: 0.7950 - val_loss: 0.2302 - val_f1_m: 0.7946\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 620us/sample - loss: 0.6722 - f1_m: 0.8012 - val_loss: 0.6549 - val_f1_m: 0.7589\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.6227 - f1_m: 0.8012 - val_loss: 0.6109 - val_f1_m: 0.7589\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5694 - f1_m: 0.8012 - val_loss: 0.5731 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5274 - f1_m: 0.8012 - val_loss: 0.5587 - val_f1_m: 0.7455\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5115 - f1_m: 0.8012 - val_loss: 0.5563 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5029 - f1_m: 0.8012 - val_loss: 0.5503 - val_f1_m: 0.7589\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4966 - f1_m: 0.8012 - val_loss: 0.5439 - val_f1_m: 0.7589\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4899 - f1_m: 0.8012 - val_loss: 0.5358 - val_f1_m: 0.7455\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4818 - f1_m: 0.8012 - val_loss: 0.5256 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4725 - f1_m: 0.8012 - val_loss: 0.5126 - val_f1_m: 0.7321\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4578 - f1_m: 0.8012 - val_loss: 0.4977 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.4428 - f1_m: 0.8012 - val_loss: 0.4807 - val_f1_m: 0.7589\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4249 - f1_m: 0.8012 - val_loss: 0.4578 - val_f1_m: 0.7589\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4033 - f1_m: 0.8012 - val_loss: 0.4297 - val_f1_m: 0.7455\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3772 - f1_m: 0.8012 - val_loss: 0.4004 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3482 - f1_m: 0.8012 - val_loss: 0.3621 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3142 - f1_m: 0.8012 - val_loss: 0.3208 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2826 - f1_m: 0.8012 - val_loss: 0.2887 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2566 - f1_m: 0.8012 - val_loss: 0.2641 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2366 - f1_m: 0.8012 - val_loss: 0.2458 - val_f1_m: 0.7857\n",
      "0.8012499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 623us/sample - loss: 0.6788 - f1_m: 0.7942 - val_loss: 0.6649 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6477 - f1_m: 0.7950 - val_loss: 0.6321 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6084 - f1_m: 0.7950 - val_loss: 0.5940 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5660 - f1_m: 0.7950 - val_loss: 0.5594 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5342 - f1_m: 0.7950 - val_loss: 0.5400 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5182 - f1_m: 0.7950 - val_loss: 0.5329 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5117 - f1_m: 0.7950 - val_loss: 0.5279 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5067 - f1_m: 0.7950 - val_loss: 0.5221 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5013 - f1_m: 0.7950 - val_loss: 0.5169 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4960 - f1_m: 0.7950 - val_loss: 0.5110 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4904 - f1_m: 0.7950 - val_loss: 0.5047 - val_f1_m: 0.7545\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4844 - f1_m: 0.7950 - val_loss: 0.4975 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4770 - f1_m: 0.7950 - val_loss: 0.4873 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4671 - f1_m: 0.7950 - val_loss: 0.4771 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4560 - f1_m: 0.7950 - val_loss: 0.4631 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4435 - f1_m: 0.7950 - val_loss: 0.4463 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4272 - f1_m: 0.7950 - val_loss: 0.4287 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4072 - f1_m: 0.7950 - val_loss: 0.4044 - val_f1_m: 0.7946\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3862 - f1_m: 0.7950 - val_loss: 0.3803 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3597 - f1_m: 0.7950 - val_loss: 0.3492 - val_f1_m: 0.7679\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 631us/sample - loss: 0.6787 - f1_m: 0.7912 - val_loss: 0.6630 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6477 - f1_m: 0.7912 - val_loss: 0.6271 - val_f1_m: 0.7545\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6104 - f1_m: 0.7912 - val_loss: 0.5832 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5702 - f1_m: 0.7912 - val_loss: 0.5428 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5392 - f1_m: 0.7912 - val_loss: 0.5184 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5233 - f1_m: 0.7912 - val_loss: 0.5038 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5127 - f1_m: 0.7912 - val_loss: 0.4939 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5026 - f1_m: 0.7912 - val_loss: 0.4837 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4900 - f1_m: 0.7912 - val_loss: 0.4704 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4753 - f1_m: 0.7912 - val_loss: 0.4552 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4561 - f1_m: 0.7912 - val_loss: 0.4339 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4323 - f1_m: 0.7912 - val_loss: 0.4085 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4016 - f1_m: 0.7912 - val_loss: 0.3782 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3676 - f1_m: 0.7912 - val_loss: 0.3442 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3346 - f1_m: 0.7912 - val_loss: 0.3166 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3083 - f1_m: 0.7912 - val_loss: 0.2939 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2865 - f1_m: 0.7912 - val_loss: 0.2752 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2684 - f1_m: 0.7912 - val_loss: 0.2590 - val_f1_m: 0.7679\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2535 - f1_m: 0.7912 - val_loss: 0.2478 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2435 - f1_m: 0.7912 - val_loss: 0.2391 - val_f1_m: 0.7946\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 624us/sample - loss: 0.6794 - f1_m: 0.7850 - val_loss: 0.6601 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6505 - f1_m: 0.7850 - val_loss: 0.6199 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6134 - f1_m: 0.7850 - val_loss: 0.5731 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5751 - f1_m: 0.7850 - val_loss: 0.5255 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5476 - f1_m: 0.7850 - val_loss: 0.4937 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5329 - f1_m: 0.7850 - val_loss: 0.4801 - val_f1_m: 0.8304\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5257 - f1_m: 0.7850 - val_loss: 0.4718 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5194 - f1_m: 0.7850 - val_loss: 0.4667 - val_f1_m: 0.8437\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5137 - f1_m: 0.7850 - val_loss: 0.4598 - val_f1_m: 0.8437\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5077 - f1_m: 0.7850 - val_loss: 0.4540 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5014 - f1_m: 0.7850 - val_loss: 0.4459 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4936 - f1_m: 0.7850 - val_loss: 0.4400 - val_f1_m: 0.8304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4839 - f1_m: 0.7850 - val_loss: 0.4298 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4707 - f1_m: 0.7850 - val_loss: 0.4173 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4549 - f1_m: 0.7850 - val_loss: 0.4015 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4361 - f1_m: 0.7850 - val_loss: 0.3819 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4143 - f1_m: 0.7850 - val_loss: 0.3601 - val_f1_m: 0.8304\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3874 - f1_m: 0.7850 - val_loss: 0.3270 - val_f1_m: 0.8304\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3500 - f1_m: 0.7850 - val_loss: 0.2912 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3133 - f1_m: 0.7850 - val_loss: 0.2582 - val_f1_m: 0.7902\n",
      "0.7849999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 578us/sample - loss: 0.6753 - f1_m: 0.7937 - val_loss: 0.6518 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6271 - f1_m: 0.7937 - val_loss: 0.6028 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5779 - f1_m: 0.7937 - val_loss: 0.5568 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5386 - f1_m: 0.7937 - val_loss: 0.5292 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5195 - f1_m: 0.7937 - val_loss: 0.5173 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5099 - f1_m: 0.7937 - val_loss: 0.5090 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4992 - f1_m: 0.7937 - val_loss: 0.4955 - val_f1_m: 0.7321\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4856 - f1_m: 0.7937 - val_loss: 0.4827 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4713 - f1_m: 0.7937 - val_loss: 0.4666 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4529 - f1_m: 0.7937 - val_loss: 0.4474 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4301 - f1_m: 0.7937 - val_loss: 0.4218 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4019 - f1_m: 0.7937 - val_loss: 0.3921 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3694 - f1_m: 0.7937 - val_loss: 0.3587 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3364 - f1_m: 0.7937 - val_loss: 0.3310 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3077 - f1_m: 0.7937 - val_loss: 0.3028 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2830 - f1_m: 0.7937 - val_loss: 0.2829 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2625 - f1_m: 0.7937 - val_loss: 0.2628 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2435 - f1_m: 0.7937 - val_loss: 0.2455 - val_f1_m: 0.8125\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2289 - f1_m: 0.7937 - val_loss: 0.2316 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2164 - f1_m: 0.7937 - val_loss: 0.2226 - val_f1_m: 0.7723\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 577us/sample - loss: 0.6739 - f1_m: 0.7850 - val_loss: 0.6447 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6270 - f1_m: 0.7850 - val_loss: 0.5852 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5768 - f1_m: 0.7850 - val_loss: 0.5243 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5412 - f1_m: 0.7850 - val_loss: 0.4891 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5274 - f1_m: 0.7850 - val_loss: 0.4755 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5205 - f1_m: 0.7850 - val_loss: 0.4697 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5134 - f1_m: 0.7850 - val_loss: 0.4600 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5066 - f1_m: 0.7850 - val_loss: 0.4506 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4969 - f1_m: 0.7850 - val_loss: 0.4408 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4833 - f1_m: 0.7850 - val_loss: 0.4264 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4681 - f1_m: 0.7850 - val_loss: 0.4079 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4506 - f1_m: 0.7850 - val_loss: 0.3884 - val_f1_m: 0.8304\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4280 - f1_m: 0.7850 - val_loss: 0.3645 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3999 - f1_m: 0.7850 - val_loss: 0.3341 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3671 - f1_m: 0.7850 - val_loss: 0.2995 - val_f1_m: 0.8437\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3287 - f1_m: 0.7850 - val_loss: 0.2629 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2930 - f1_m: 0.7850 - val_loss: 0.2325 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2659 - f1_m: 0.7850 - val_loss: 0.2092 - val_f1_m: 0.8304\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2448 - f1_m: 0.7850 - val_loss: 0.1940 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2312 - f1_m: 0.7850 - val_loss: 0.1816 - val_f1_m: 0.8437\n",
      "0.7849999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 578us/sample - loss: 0.6715 - f1_m: 0.7950 - val_loss: 0.6513 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6272 - f1_m: 0.7950 - val_loss: 0.6063 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5767 - f1_m: 0.7950 - val_loss: 0.5608 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5355 - f1_m: 0.7950 - val_loss: 0.5361 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5170 - f1_m: 0.7950 - val_loss: 0.5277 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5103 - f1_m: 0.7950 - val_loss: 0.5218 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5037 - f1_m: 0.7950 - val_loss: 0.5143 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4949 - f1_m: 0.7950 - val_loss: 0.5038 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4855 - f1_m: 0.7950 - val_loss: 0.4925 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4728 - f1_m: 0.7950 - val_loss: 0.4770 - val_f1_m: 0.7679\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4574 - f1_m: 0.7950 - val_loss: 0.4599 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4382 - f1_m: 0.7950 - val_loss: 0.4387 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4156 - f1_m: 0.7950 - val_loss: 0.4124 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3881 - f1_m: 0.7950 - val_loss: 0.3813 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3589 - f1_m: 0.7950 - val_loss: 0.3532 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3326 - f1_m: 0.7950 - val_loss: 0.3287 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3097 - f1_m: 0.7950 - val_loss: 0.3073 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2907 - f1_m: 0.7950 - val_loss: 0.2852 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2702 - f1_m: 0.7950 - val_loss: 0.2698 - val_f1_m: 0.7812\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2537 - f1_m: 0.7950 - val_loss: 0.2495 - val_f1_m: 0.8080\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 573us/sample - loss: 0.6740 - f1_m: 0.7900 - val_loss: 0.6475 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.6264 - f1_m: 0.7900 - val_loss: 0.5938 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5774 - f1_m: 0.7900 - val_loss: 0.5413 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5397 - f1_m: 0.7900 - val_loss: 0.5120 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5238 - f1_m: 0.7900 - val_loss: 0.4992 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5163 - f1_m: 0.7900 - val_loss: 0.4918 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5100 - f1_m: 0.7900 - val_loss: 0.4859 - val_f1_m: 0.8259\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5014 - f1_m: 0.7900 - val_loss: 0.4757 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4904 - f1_m: 0.7900 - val_loss: 0.4663 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4790 - f1_m: 0.7900 - val_loss: 0.4542 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4660 - f1_m: 0.7900 - val_loss: 0.4402 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4504 - f1_m: 0.7900 - val_loss: 0.4237 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4304 - f1_m: 0.7900 - val_loss: 0.4019 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4068 - f1_m: 0.7900 - val_loss: 0.3766 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3794 - f1_m: 0.7900 - val_loss: 0.3468 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3450 - f1_m: 0.7900 - val_loss: 0.3115 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.3089 - f1_m: 0.7900 - val_loss: 0.2763 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2753 - f1_m: 0.7900 - val_loss: 0.2430 - val_f1_m: 0.7991\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2484 - f1_m: 0.7900 - val_loss: 0.2228 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2332 - f1_m: 0.7900 - val_loss: 0.2070 - val_f1_m: 0.7991\n",
      "0.7899999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 576us/sample - loss: 0.6786 - f1_m: 0.7875 - val_loss: 0.6607 - val_f1_m: 0.8348\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.6469 - f1_m: 0.7875 - val_loss: 0.6212 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6079 - f1_m: 0.7875 - val_loss: 0.5727 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5670 - f1_m: 0.7875 - val_loss: 0.5280 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5384 - f1_m: 0.7875 - val_loss: 0.5022 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5248 - f1_m: 0.7875 - val_loss: 0.4920 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.5188 - f1_m: 0.7875 - val_loss: 0.4847 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5126 - f1_m: 0.7875 - val_loss: 0.4792 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5070 - f1_m: 0.7875 - val_loss: 0.4724 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5013 - f1_m: 0.7875 - val_loss: 0.4678 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4944 - f1_m: 0.7875 - val_loss: 0.4605 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4873 - f1_m: 0.7875 - val_loss: 0.4526 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4779 - f1_m: 0.7875 - val_loss: 0.4437 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4654 - f1_m: 0.7875 - val_loss: 0.4310 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4496 - f1_m: 0.7875 - val_loss: 0.4136 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4310 - f1_m: 0.7875 - val_loss: 0.3944 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4104 - f1_m: 0.7875 - val_loss: 0.3726 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3862 - f1_m: 0.7875 - val_loss: 0.3452 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3506 - f1_m: 0.7875 - val_loss: 0.3105 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3131 - f1_m: 0.7875 - val_loss: 0.2804 - val_f1_m: 0.8080\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 575us/sample - loss: 0.6733 - f1_m: 0.7850 - val_loss: 0.6436 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.6269 - f1_m: 0.7850 - val_loss: 0.5825 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5757 - f1_m: 0.7850 - val_loss: 0.5218 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5413 - f1_m: 0.7850 - val_loss: 0.4853 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5249 - f1_m: 0.7850 - val_loss: 0.4741 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5173 - f1_m: 0.7850 - val_loss: 0.4643 - val_f1_m: 0.8437\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5107 - f1_m: 0.7850 - val_loss: 0.4568 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.5013 - f1_m: 0.7850 - val_loss: 0.4486 - val_f1_m: 0.8304\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4891 - f1_m: 0.7850 - val_loss: 0.4369 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4754 - f1_m: 0.7850 - val_loss: 0.4224 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4592 - f1_m: 0.7850 - val_loss: 0.4050 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4383 - f1_m: 0.7850 - val_loss: 0.3840 - val_f1_m: 0.8304\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4118 - f1_m: 0.7850 - val_loss: 0.3584 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3802 - f1_m: 0.7850 - val_loss: 0.3274 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3417 - f1_m: 0.7850 - val_loss: 0.2903 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2979 - f1_m: 0.7850 - val_loss: 0.2545 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2614 - f1_m: 0.7850 - val_loss: 0.2299 - val_f1_m: 0.8304\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2387 - f1_m: 0.7850 - val_loss: 0.2116 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2254 - f1_m: 0.7850 - val_loss: 0.2000 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2145 - f1_m: 0.8050 - val_loss: 0.1926 - val_f1_m: 0.9241\n",
      "0.80499995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 576us/sample - loss: 0.6706 - f1_m: 0.8075 - val_loss: 0.6579 - val_f1_m: 0.7098\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6205 - f1_m: 0.8075 - val_loss: 0.6193 - val_f1_m: 0.7366\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5625 - f1_m: 0.8075 - val_loss: 0.5899 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5182 - f1_m: 0.8075 - val_loss: 0.5866 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5005 - f1_m: 0.8075 - val_loss: 0.5883 - val_f1_m: 0.7366\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4930 - f1_m: 0.8075 - val_loss: 0.5855 - val_f1_m: 0.7366\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4865 - f1_m: 0.8075 - val_loss: 0.5792 - val_f1_m: 0.7366\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4802 - f1_m: 0.8075 - val_loss: 0.5720 - val_f1_m: 0.7500\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4730 - f1_m: 0.8075 - val_loss: 0.5618 - val_f1_m: 0.7500\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4630 - f1_m: 0.8075 - val_loss: 0.5522 - val_f1_m: 0.7366\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4517 - f1_m: 0.8075 - val_loss: 0.5351 - val_f1_m: 0.7232\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4388 - f1_m: 0.8075 - val_loss: 0.5224 - val_f1_m: 0.7500\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4235 - f1_m: 0.8075 - val_loss: 0.5030 - val_f1_m: 0.7232\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4048 - f1_m: 0.8075 - val_loss: 0.4760 - val_f1_m: 0.7366\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3816 - f1_m: 0.8075 - val_loss: 0.4470 - val_f1_m: 0.7366\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3546 - f1_m: 0.8075 - val_loss: 0.4099 - val_f1_m: 0.7366\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3240 - f1_m: 0.8075 - val_loss: 0.3707 - val_f1_m: 0.7232\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2886 - f1_m: 0.8075 - val_loss: 0.3293 - val_f1_m: 0.7366\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2566 - f1_m: 0.8075 - val_loss: 0.2958 - val_f1_m: 0.7500\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2347 - f1_m: 0.8075 - val_loss: 0.2802 - val_f1_m: 0.7366\n",
      "0.80749995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 574us/sample - loss: 0.6717 - f1_m: 0.7887 - val_loss: 0.6450 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.6227 - f1_m: 0.7887 - val_loss: 0.5886 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5743 - f1_m: 0.7887 - val_loss: 0.5344 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5393 - f1_m: 0.7887 - val_loss: 0.5054 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5251 - f1_m: 0.7887 - val_loss: 0.4929 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5170 - f1_m: 0.7887 - val_loss: 0.4862 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5100 - f1_m: 0.7887 - val_loss: 0.4788 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5026 - f1_m: 0.7887 - val_loss: 0.4700 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4934 - f1_m: 0.7887 - val_loss: 0.4588 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4804 - f1_m: 0.7887 - val_loss: 0.4459 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4662 - f1_m: 0.7887 - val_loss: 0.4301 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4500 - f1_m: 0.7887 - val_loss: 0.4119 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4293 - f1_m: 0.7887 - val_loss: 0.3898 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4046 - f1_m: 0.7887 - val_loss: 0.3625 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.3745 - f1_m: 0.7887 - val_loss: 0.3326 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.3413 - f1_m: 0.7887 - val_loss: 0.3021 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.3063 - f1_m: 0.7887 - val_loss: 0.2672 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.2727 - f1_m: 0.7887 - val_loss: 0.2359 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.2480 - f1_m: 0.7887 - val_loss: 0.2209 - val_f1_m: 0.8304\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.2330 - f1_m: 0.7887 - val_loss: 0.2076 - val_f1_m: 0.8036\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 583us/sample - loss: 0.6793 - f1_m: 0.7900 - val_loss: 0.6629 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6484 - f1_m: 0.7900 - val_loss: 0.6268 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.6114 - f1_m: 0.7900 - val_loss: 0.5839 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5692 - f1_m: 0.7900 - val_loss: 0.5459 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.5412 - f1_m: 0.7900 - val_loss: 0.5217 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.5256 - f1_m: 0.7900 - val_loss: 0.5109 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5182 - f1_m: 0.7900 - val_loss: 0.5040 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5131 - f1_m: 0.7900 - val_loss: 0.4978 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.5076 - f1_m: 0.7900 - val_loss: 0.4918 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.5023 - f1_m: 0.7900 - val_loss: 0.4855 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4964 - f1_m: 0.7900 - val_loss: 0.4782 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4901 - f1_m: 0.7900 - val_loss: 0.4703 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4814 - f1_m: 0.7900 - val_loss: 0.4588 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4709 - f1_m: 0.7900 - val_loss: 0.4459 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4577 - f1_m: 0.7900 - val_loss: 0.4301 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4419 - f1_m: 0.7900 - val_loss: 0.4106 - val_f1_m: 0.8125\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4227 - f1_m: 0.7900 - val_loss: 0.3877 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.3997 - f1_m: 0.7900 - val_loss: 0.3612 - val_f1_m: 0.8259\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.3726 - f1_m: 0.7900 - val_loss: 0.3331 - val_f1_m: 0.8259\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.3425 - f1_m: 0.7900 - val_loss: 0.2973 - val_f1_m: 0.7857\n",
      "0.7899999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 572us/sample - loss: 0.6712 - f1_m: 0.7997 - val_loss: 0.6541 - val_f1_m: 0.7589\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.6218 - f1_m: 0.8012 - val_loss: 0.6101 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.5689 - f1_m: 0.8012 - val_loss: 0.5730 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5263 - f1_m: 0.8012 - val_loss: 0.5606 - val_f1_m: 0.7321\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.5098 - f1_m: 0.8012 - val_loss: 0.5583 - val_f1_m: 0.7455\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.5012 - f1_m: 0.8012 - val_loss: 0.5523 - val_f1_m: 0.7455\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4945 - f1_m: 0.8012 - val_loss: 0.5444 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4879 - f1_m: 0.8012 - val_loss: 0.5381 - val_f1_m: 0.7589\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4782 - f1_m: 0.8012 - val_loss: 0.5231 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4662 - f1_m: 0.8012 - val_loss: 0.5097 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4528 - f1_m: 0.8012 - val_loss: 0.4970 - val_f1_m: 0.7455\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4375 - f1_m: 0.8012 - val_loss: 0.4783 - val_f1_m: 0.7589\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4198 - f1_m: 0.8012 - val_loss: 0.4581 - val_f1_m: 0.7589\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.3970 - f1_m: 0.8012 - val_loss: 0.4307 - val_f1_m: 0.7321\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.3707 - f1_m: 0.8012 - val_loss: 0.3987 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.3403 - f1_m: 0.8012 - val_loss: 0.3623 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.3070 - f1_m: 0.8012 - val_loss: 0.3260 - val_f1_m: 0.7589\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.2765 - f1_m: 0.8012 - val_loss: 0.2918 - val_f1_m: 0.7589\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 46us/sample - loss: 0.2470 - f1_m: 0.8012 - val_loss: 0.2682 - val_f1_m: 0.7589\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.2297 - f1_m: 0.8012 - val_loss: 0.2555 - val_f1_m: 0.7723\n",
      "0.8012499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 574us/sample - loss: 0.6783 - f1_m: 0.8055 - val_loss: 0.6692 - val_f1_m: 0.7545\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.6443 - f1_m: 0.8062 - val_loss: 0.6406 - val_f1_m: 0.7411\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.6004 - f1_m: 0.8062 - val_loss: 0.6090 - val_f1_m: 0.7143\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.5541 - f1_m: 0.8062 - val_loss: 0.5881 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.5211 - f1_m: 0.8062 - val_loss: 0.5853 - val_f1_m: 0.7411\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.5071 - f1_m: 0.8062 - val_loss: 0.5871 - val_f1_m: 0.7143\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.5007 - f1_m: 0.8062 - val_loss: 0.5837 - val_f1_m: 0.7411\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4954 - f1_m: 0.8062 - val_loss: 0.5793 - val_f1_m: 0.7277\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4905 - f1_m: 0.8062 - val_loss: 0.5727 - val_f1_m: 0.7545\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4854 - f1_m: 0.8062 - val_loss: 0.5676 - val_f1_m: 0.7277\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4803 - f1_m: 0.8062 - val_loss: 0.5623 - val_f1_m: 0.7545\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4745 - f1_m: 0.8062 - val_loss: 0.5598 - val_f1_m: 0.7411\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4676 - f1_m: 0.8062 - val_loss: 0.5496 - val_f1_m: 0.7143\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4606 - f1_m: 0.8062 - val_loss: 0.5357 - val_f1_m: 0.7545\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4505 - f1_m: 0.8062 - val_loss: 0.5231 - val_f1_m: 0.7545\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4373 - f1_m: 0.8062 - val_loss: 0.5067 - val_f1_m: 0.7411\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4215 - f1_m: 0.8062 - val_loss: 0.4869 - val_f1_m: 0.7277\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.4032 - f1_m: 0.8062 - val_loss: 0.4644 - val_f1_m: 0.7545\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.3829 - f1_m: 0.8062 - val_loss: 0.4417 - val_f1_m: 0.7277\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.3540 - f1_m: 0.8062 - val_loss: 0.4003 - val_f1_m: 0.7277\n",
      "0.8062499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 571us/sample - loss: 0.6712 - f1_m: 0.7962 - val_loss: 0.6503 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.6226 - f1_m: 0.7962 - val_loss: 0.6025 - val_f1_m: 0.7634\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5731 - f1_m: 0.7962 - val_loss: 0.5587 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5310 - f1_m: 0.7962 - val_loss: 0.5391 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.5146 - f1_m: 0.7962 - val_loss: 0.5320 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.5071 - f1_m: 0.7962 - val_loss: 0.5252 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.5007 - f1_m: 0.7962 - val_loss: 0.5186 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4936 - f1_m: 0.7962 - val_loss: 0.5104 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4844 - f1_m: 0.7962 - val_loss: 0.4985 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4736 - f1_m: 0.7962 - val_loss: 0.4857 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4618 - f1_m: 0.7962 - val_loss: 0.4721 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4464 - f1_m: 0.7962 - val_loss: 0.4542 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4279 - f1_m: 0.7962 - val_loss: 0.4315 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4044 - f1_m: 0.7962 - val_loss: 0.4045 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.3765 - f1_m: 0.7962 - val_loss: 0.3712 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.3452 - f1_m: 0.7962 - val_loss: 0.3344 - val_f1_m: 0.7500\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.3034 - f1_m: 0.7962 - val_loss: 0.2878 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.2670 - f1_m: 0.7962 - val_loss: 0.2558 - val_f1_m: 0.7768\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.2412 - f1_m: 0.7962 - val_loss: 0.2360 - val_f1_m: 0.7768\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.2257 - f1_m: 0.7962 - val_loss: 0.2237 - val_f1_m: 0.7634\n",
      "0.7962499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.6776 - f1_m: 0.7868 - val_loss: 0.6497 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6303 - f1_m: 0.7875 - val_loss: 0.5940 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5824 - f1_m: 0.7875 - val_loss: 0.5387 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5460 - f1_m: 0.7875 - val_loss: 0.5054 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5282 - f1_m: 0.7875 - val_loss: 0.4896 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5181 - f1_m: 0.7875 - val_loss: 0.4789 - val_f1_m: 0.8348\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5044 - f1_m: 0.7875 - val_loss: 0.4648 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4902 - f1_m: 0.7875 - val_loss: 0.4503 - val_f1_m: 0.8348\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4737 - f1_m: 0.7875 - val_loss: 0.4316 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4534 - f1_m: 0.7875 - val_loss: 0.4103 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4282 - f1_m: 0.7875 - val_loss: 0.3849 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3991 - f1_m: 0.7875 - val_loss: 0.3556 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3655 - f1_m: 0.7875 - val_loss: 0.3215 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3326 - f1_m: 0.7875 - val_loss: 0.2909 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3051 - f1_m: 0.7875 - val_loss: 0.2659 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2807 - f1_m: 0.7875 - val_loss: 0.2439 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2607 - f1_m: 0.7875 - val_loss: 0.2270 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2404 - f1_m: 0.7875 - val_loss: 0.2110 - val_f1_m: 0.8348\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2246 - f1_m: 0.7875 - val_loss: 0.1969 - val_f1_m: 0.8348\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2134 - f1_m: 0.8287 - val_loss: 0.1886 - val_f1_m: 0.9598\n",
      "0.8287499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 578us/sample - loss: 0.6728 - f1_m: 0.7987 - val_loss: 0.6542 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6233 - f1_m: 0.7987 - val_loss: 0.6087 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5682 - f1_m: 0.7987 - val_loss: 0.5684 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5293 - f1_m: 0.7987 - val_loss: 0.5516 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5127 - f1_m: 0.7987 - val_loss: 0.5468 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5052 - f1_m: 0.7987 - val_loss: 0.5393 - val_f1_m: 0.7411\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4973 - f1_m: 0.7987 - val_loss: 0.5339 - val_f1_m: 0.7143\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4900 - f1_m: 0.7987 - val_loss: 0.5253 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4803 - f1_m: 0.7987 - val_loss: 0.5143 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4695 - f1_m: 0.7987 - val_loss: 0.5031 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4571 - f1_m: 0.7987 - val_loss: 0.4913 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4427 - f1_m: 0.7987 - val_loss: 0.4753 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4246 - f1_m: 0.7987 - val_loss: 0.4545 - val_f1_m: 0.7545\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4028 - f1_m: 0.7987 - val_loss: 0.4303 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3742 - f1_m: 0.7987 - val_loss: 0.4006 - val_f1_m: 0.7545\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3409 - f1_m: 0.7987 - val_loss: 0.3581 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2928 - f1_m: 0.7987 - val_loss: 0.3130 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2555 - f1_m: 0.7987 - val_loss: 0.2849 - val_f1_m: 0.7545\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2324 - f1_m: 0.7987 - val_loss: 0.2670 - val_f1_m: 0.7812\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2179 - f1_m: 0.7987 - val_loss: 0.2563 - val_f1_m: 0.7679\n",
      "0.7987499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 581us/sample - loss: 0.6716 - f1_m: 0.7880 - val_loss: 0.6450 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6249 - f1_m: 0.7887 - val_loss: 0.5894 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5746 - f1_m: 0.7887 - val_loss: 0.5358 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5374 - f1_m: 0.7887 - val_loss: 0.5060 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5213 - f1_m: 0.7887 - val_loss: 0.4946 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5140 - f1_m: 0.7887 - val_loss: 0.4862 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5070 - f1_m: 0.7887 - val_loss: 0.4778 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4970 - f1_m: 0.7887 - val_loss: 0.4671 - val_f1_m: 0.8304\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4869 - f1_m: 0.7887 - val_loss: 0.4561 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4744 - f1_m: 0.7887 - val_loss: 0.4409 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4582 - f1_m: 0.7887 - val_loss: 0.4225 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4370 - f1_m: 0.7887 - val_loss: 0.3973 - val_f1_m: 0.8304\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4106 - f1_m: 0.7887 - val_loss: 0.3690 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3822 - f1_m: 0.7887 - val_loss: 0.3397 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3551 - f1_m: 0.7887 - val_loss: 0.3125 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3298 - f1_m: 0.7887 - val_loss: 0.2881 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3064 - f1_m: 0.7887 - val_loss: 0.2654 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2857 - f1_m: 0.7887 - val_loss: 0.2458 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2659 - f1_m: 0.7887 - val_loss: 0.2283 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2490 - f1_m: 0.7887 - val_loss: 0.2130 - val_f1_m: 0.8036\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 575us/sample - loss: 0.6726 - f1_m: 0.7987 - val_loss: 0.6544 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.6269 - f1_m: 0.7987 - val_loss: 0.6101 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5737 - f1_m: 0.7987 - val_loss: 0.5701 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5333 - f1_m: 0.7987 - val_loss: 0.5491 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5133 - f1_m: 0.7987 - val_loss: 0.5431 - val_f1_m: 0.7411\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5046 - f1_m: 0.7987 - val_loss: 0.5378 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4978 - f1_m: 0.7987 - val_loss: 0.5300 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4887 - f1_m: 0.7987 - val_loss: 0.5203 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4785 - f1_m: 0.7987 - val_loss: 0.5090 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4661 - f1_m: 0.7987 - val_loss: 0.4947 - val_f1_m: 0.7679\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4499 - f1_m: 0.7987 - val_loss: 0.4756 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4305 - f1_m: 0.7987 - val_loss: 0.4519 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4063 - f1_m: 0.7987 - val_loss: 0.4246 - val_f1_m: 0.7679\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3793 - f1_m: 0.7987 - val_loss: 0.3953 - val_f1_m: 0.7545\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3511 - f1_m: 0.7987 - val_loss: 0.3666 - val_f1_m: 0.7679\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3262 - f1_m: 0.7987 - val_loss: 0.3436 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3042 - f1_m: 0.7987 - val_loss: 0.3187 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2830 - f1_m: 0.7987 - val_loss: 0.2972 - val_f1_m: 0.7679\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2631 - f1_m: 0.7987 - val_loss: 0.2775 - val_f1_m: 0.7812\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2431 - f1_m: 0.7975 - val_loss: 0.2524 - val_f1_m: 0.8527\n",
      "0.7974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 576us/sample - loss: 0.6748 - f1_m: 0.7712 - val_loss: 0.6357 - val_f1_m: 0.8929\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6333 - f1_m: 0.7712 - val_loss: 0.5675 - val_f1_m: 0.8929\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5888 - f1_m: 0.7712 - val_loss: 0.4921 - val_f1_m: 0.8929\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5557 - f1_m: 0.7712 - val_loss: 0.4359 - val_f1_m: 0.8929\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5417 - f1_m: 0.7712 - val_loss: 0.4128 - val_f1_m: 0.8929\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5351 - f1_m: 0.7712 - val_loss: 0.4036 - val_f1_m: 0.8795\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5281 - f1_m: 0.7712 - val_loss: 0.3961 - val_f1_m: 0.8929\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5177 - f1_m: 0.7712 - val_loss: 0.3886 - val_f1_m: 0.8929\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5066 - f1_m: 0.7712 - val_loss: 0.3796 - val_f1_m: 0.8795\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4936 - f1_m: 0.7712 - val_loss: 0.3652 - val_f1_m: 0.8795\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4768 - f1_m: 0.7712 - val_loss: 0.3521 - val_f1_m: 0.8795\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4515 - f1_m: 0.7712 - val_loss: 0.3306 - val_f1_m: 0.8661\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4227 - f1_m: 0.7712 - val_loss: 0.2996 - val_f1_m: 0.8795\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3924 - f1_m: 0.7712 - val_loss: 0.2715 - val_f1_m: 0.8795\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3624 - f1_m: 0.7712 - val_loss: 0.2469 - val_f1_m: 0.8795\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3344 - f1_m: 0.7712 - val_loss: 0.2269 - val_f1_m: 0.8929\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3084 - f1_m: 0.7712 - val_loss: 0.2069 - val_f1_m: 0.8929\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2845 - f1_m: 0.7712 - val_loss: 0.1902 - val_f1_m: 0.8661\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2635 - f1_m: 0.7712 - val_loss: 0.1774 - val_f1_m: 0.8661\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2484 - f1_m: 0.7850 - val_loss: 0.1661 - val_f1_m: 0.8973\n",
      "0.785\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 578us/sample - loss: 0.6792 - f1_m: 0.7930 - val_loss: 0.6648 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.6475 - f1_m: 0.7937 - val_loss: 0.6304 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6084 - f1_m: 0.7937 - val_loss: 0.5892 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5656 - f1_m: 0.7937 - val_loss: 0.5546 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5343 - f1_m: 0.7937 - val_loss: 0.5353 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5214 - f1_m: 0.7937 - val_loss: 0.5273 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5146 - f1_m: 0.7937 - val_loss: 0.5213 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5090 - f1_m: 0.7937 - val_loss: 0.5154 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5040 - f1_m: 0.7937 - val_loss: 0.5096 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4989 - f1_m: 0.7937 - val_loss: 0.5033 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4932 - f1_m: 0.7937 - val_loss: 0.4968 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4869 - f1_m: 0.7937 - val_loss: 0.4891 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4794 - f1_m: 0.7937 - val_loss: 0.4796 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4695 - f1_m: 0.7937 - val_loss: 0.4665 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4574 - f1_m: 0.7937 - val_loss: 0.4518 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4432 - f1_m: 0.7937 - val_loss: 0.4352 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4254 - f1_m: 0.7937 - val_loss: 0.4142 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4046 - f1_m: 0.7937 - val_loss: 0.3949 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3846 - f1_m: 0.7937 - val_loss: 0.3691 - val_f1_m: 0.7857\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3514 - f1_m: 0.7937 - val_loss: 0.3319 - val_f1_m: 0.7857\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 578us/sample - loss: 0.6736 - f1_m: 0.7900 - val_loss: 0.6482 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6276 - f1_m: 0.7900 - val_loss: 0.5955 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5776 - f1_m: 0.7900 - val_loss: 0.5416 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5364 - f1_m: 0.7900 - val_loss: 0.5113 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5198 - f1_m: 0.7900 - val_loss: 0.4993 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5137 - f1_m: 0.7900 - val_loss: 0.4914 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.5057 - f1_m: 0.7900 - val_loss: 0.4842 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4969 - f1_m: 0.7900 - val_loss: 0.4738 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4869 - f1_m: 0.7900 - val_loss: 0.4624 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4759 - f1_m: 0.7900 - val_loss: 0.4508 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4638 - f1_m: 0.7900 - val_loss: 0.4368 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4486 - f1_m: 0.7900 - val_loss: 0.4192 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.4299 - f1_m: 0.7900 - val_loss: 0.3979 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4076 - f1_m: 0.7900 - val_loss: 0.3731 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3801 - f1_m: 0.7900 - val_loss: 0.3437 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3452 - f1_m: 0.7900 - val_loss: 0.3014 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3046 - f1_m: 0.7900 - val_loss: 0.2635 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2729 - f1_m: 0.7900 - val_loss: 0.2356 - val_f1_m: 0.8125\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2504 - f1_m: 0.7900 - val_loss: 0.2163 - val_f1_m: 0.7857\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2365 - f1_m: 0.7900 - val_loss: 0.2032 - val_f1_m: 0.8125\n",
      "0.7899999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 583us/sample - loss: 0.6721 - f1_m: 0.7880 - val_loss: 0.6457 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6254 - f1_m: 0.7887 - val_loss: 0.5910 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5736 - f1_m: 0.7887 - val_loss: 0.5373 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5361 - f1_m: 0.7887 - val_loss: 0.5065 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5213 - f1_m: 0.7887 - val_loss: 0.4953 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5141 - f1_m: 0.7887 - val_loss: 0.4888 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5076 - f1_m: 0.7887 - val_loss: 0.4816 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4997 - f1_m: 0.7887 - val_loss: 0.4745 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4896 - f1_m: 0.7887 - val_loss: 0.4659 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4783 - f1_m: 0.7887 - val_loss: 0.4534 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4640 - f1_m: 0.7887 - val_loss: 0.4386 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4448 - f1_m: 0.7887 - val_loss: 0.4199 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4204 - f1_m: 0.7887 - val_loss: 0.3946 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3913 - f1_m: 0.7887 - val_loss: 0.3665 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3624 - f1_m: 0.7887 - val_loss: 0.3403 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3338 - f1_m: 0.7887 - val_loss: 0.3167 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3077 - f1_m: 0.7887 - val_loss: 0.2950 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2846 - f1_m: 0.7887 - val_loss: 0.2766 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2628 - f1_m: 0.7887 - val_loss: 0.2609 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2401 - f1_m: 0.8162 - val_loss: 0.2417 - val_f1_m: 0.8616\n",
      "0.8162499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 579us/sample - loss: 0.6741 - f1_m: 0.7825 - val_loss: 0.6445 - val_f1_m: 0.8393\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.6302 - f1_m: 0.7825 - val_loss: 0.5847 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5819 - f1_m: 0.7825 - val_loss: 0.5217 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5448 - f1_m: 0.7825 - val_loss: 0.4815 - val_f1_m: 0.8393\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5297 - f1_m: 0.7825 - val_loss: 0.4655 - val_f1_m: 0.8393\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5221 - f1_m: 0.7825 - val_loss: 0.4566 - val_f1_m: 0.8527\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5149 - f1_m: 0.7825 - val_loss: 0.4487 - val_f1_m: 0.8259\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5058 - f1_m: 0.7825 - val_loss: 0.4399 - val_f1_m: 0.8393\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4945 - f1_m: 0.7825 - val_loss: 0.4287 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4826 - f1_m: 0.7825 - val_loss: 0.4142 - val_f1_m: 0.8393\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4671 - f1_m: 0.7825 - val_loss: 0.3979 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4445 - f1_m: 0.7825 - val_loss: 0.3752 - val_f1_m: 0.8259\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4179 - f1_m: 0.7825 - val_loss: 0.3469 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3894 - f1_m: 0.7825 - val_loss: 0.3184 - val_f1_m: 0.8527\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3595 - f1_m: 0.7825 - val_loss: 0.2881 - val_f1_m: 0.8393\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3318 - f1_m: 0.7825 - val_loss: 0.2650 - val_f1_m: 0.8393\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3075 - f1_m: 0.7825 - val_loss: 0.2401 - val_f1_m: 0.8125\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.2846 - f1_m: 0.7825 - val_loss: 0.2204 - val_f1_m: 0.8393\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2638 - f1_m: 0.7825 - val_loss: 0.2036 - val_f1_m: 0.8259\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2459 - f1_m: 0.7825 - val_loss: 0.1915 - val_f1_m: 0.8125\n",
      "0.7824999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 577us/sample - loss: 0.6743 - f1_m: 0.7812 - val_loss: 0.6418 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6281 - f1_m: 0.7812 - val_loss: 0.5808 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5825 - f1_m: 0.7812 - val_loss: 0.5153 - val_f1_m: 0.8437\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5487 - f1_m: 0.7812 - val_loss: 0.4750 - val_f1_m: 0.8437\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5339 - f1_m: 0.7812 - val_loss: 0.4602 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5270 - f1_m: 0.7812 - val_loss: 0.4501 - val_f1_m: 0.8437\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5207 - f1_m: 0.7812 - val_loss: 0.4414 - val_f1_m: 0.8571\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.5135 - f1_m: 0.7812 - val_loss: 0.4355 - val_f1_m: 0.8571\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5032 - f1_m: 0.7812 - val_loss: 0.4228 - val_f1_m: 0.8571\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4897 - f1_m: 0.7812 - val_loss: 0.4074 - val_f1_m: 0.8437\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4753 - f1_m: 0.7812 - val_loss: 0.3934 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4577 - f1_m: 0.7812 - val_loss: 0.3730 - val_f1_m: 0.8437\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4355 - f1_m: 0.7812 - val_loss: 0.3493 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4098 - f1_m: 0.7812 - val_loss: 0.3220 - val_f1_m: 0.8571\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3794 - f1_m: 0.7812 - val_loss: 0.2949 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3451 - f1_m: 0.7812 - val_loss: 0.2607 - val_f1_m: 0.8304\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3113 - f1_m: 0.7812 - val_loss: 0.2355 - val_f1_m: 0.8437\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2864 - f1_m: 0.7812 - val_loss: 0.2123 - val_f1_m: 0.8437\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2666 - f1_m: 0.7812 - val_loss: 0.1975 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2526 - f1_m: 0.7812 - val_loss: 0.1864 - val_f1_m: 0.8304\n",
      "0.78124994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 576us/sample - loss: 0.6792 - f1_m: 0.8012 - val_loss: 0.6677 - val_f1_m: 0.7723\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6471 - f1_m: 0.8012 - val_loss: 0.6383 - val_f1_m: 0.7589\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6072 - f1_m: 0.8012 - val_loss: 0.6033 - val_f1_m: 0.7455\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5616 - f1_m: 0.8012 - val_loss: 0.5755 - val_f1_m: 0.7455\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5286 - f1_m: 0.8012 - val_loss: 0.5640 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5136 - f1_m: 0.8012 - val_loss: 0.5608 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5058 - f1_m: 0.8012 - val_loss: 0.5560 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4997 - f1_m: 0.8012 - val_loss: 0.5502 - val_f1_m: 0.7589\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4937 - f1_m: 0.8012 - val_loss: 0.5446 - val_f1_m: 0.7321\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4879 - f1_m: 0.8012 - val_loss: 0.5382 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4814 - f1_m: 0.8012 - val_loss: 0.5301 - val_f1_m: 0.7321\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4739 - f1_m: 0.8012 - val_loss: 0.5214 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4639 - f1_m: 0.8012 - val_loss: 0.5086 - val_f1_m: 0.7723\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4520 - f1_m: 0.8012 - val_loss: 0.4939 - val_f1_m: 0.7589\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4375 - f1_m: 0.8012 - val_loss: 0.4777 - val_f1_m: 0.7321\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4207 - f1_m: 0.8012 - val_loss: 0.4573 - val_f1_m: 0.7187\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3994 - f1_m: 0.8012 - val_loss: 0.4347 - val_f1_m: 0.7455\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3804 - f1_m: 0.8012 - val_loss: 0.4115 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3490 - f1_m: 0.8012 - val_loss: 0.3709 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3118 - f1_m: 0.8012 - val_loss: 0.3299 - val_f1_m: 0.7455\n",
      "0.8012499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 577us/sample - loss: 0.6731 - f1_m: 0.7880 - val_loss: 0.6468 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6273 - f1_m: 0.7887 - val_loss: 0.5911 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5774 - f1_m: 0.7887 - val_loss: 0.5371 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5423 - f1_m: 0.7887 - val_loss: 0.5021 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5241 - f1_m: 0.7887 - val_loss: 0.4915 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5167 - f1_m: 0.7887 - val_loss: 0.4818 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5091 - f1_m: 0.7887 - val_loss: 0.4763 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5018 - f1_m: 0.7887 - val_loss: 0.4681 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4911 - f1_m: 0.7887 - val_loss: 0.4563 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4780 - f1_m: 0.7887 - val_loss: 0.4446 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4626 - f1_m: 0.7887 - val_loss: 0.4282 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4443 - f1_m: 0.7887 - val_loss: 0.4087 - val_f1_m: 0.8304\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4216 - f1_m: 0.7887 - val_loss: 0.3850 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3937 - f1_m: 0.7887 - val_loss: 0.3561 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3597 - f1_m: 0.7887 - val_loss: 0.3217 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3195 - f1_m: 0.7887 - val_loss: 0.2816 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2764 - f1_m: 0.7887 - val_loss: 0.2409 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2441 - f1_m: 0.7887 - val_loss: 0.2188 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2264 - f1_m: 0.7887 - val_loss: 0.2029 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2146 - f1_m: 0.7887 - val_loss: 0.1923 - val_f1_m: 0.8036\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 577us/sample - loss: 0.6783 - f1_m: 0.7962 - val_loss: 0.6654 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6476 - f1_m: 0.7962 - val_loss: 0.6328 - val_f1_m: 0.7634\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6094 - f1_m: 0.7962 - val_loss: 0.5952 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5698 - f1_m: 0.7962 - val_loss: 0.5588 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5378 - f1_m: 0.7962 - val_loss: 0.5396 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5206 - f1_m: 0.7962 - val_loss: 0.5319 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5123 - f1_m: 0.7962 - val_loss: 0.5267 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5065 - f1_m: 0.7962 - val_loss: 0.5218 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5007 - f1_m: 0.7962 - val_loss: 0.5167 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4951 - f1_m: 0.7962 - val_loss: 0.5113 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4890 - f1_m: 0.7962 - val_loss: 0.5053 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4828 - f1_m: 0.7962 - val_loss: 0.4975 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4728 - f1_m: 0.7962 - val_loss: 0.4878 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4619 - f1_m: 0.7962 - val_loss: 0.4760 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4485 - f1_m: 0.7962 - val_loss: 0.4606 - val_f1_m: 0.7366\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4329 - f1_m: 0.7962 - val_loss: 0.4437 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4127 - f1_m: 0.7962 - val_loss: 0.4214 - val_f1_m: 0.7634\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3865 - f1_m: 0.7962 - val_loss: 0.3884 - val_f1_m: 0.7768\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3499 - f1_m: 0.7962 - val_loss: 0.3521 - val_f1_m: 0.7634\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3131 - f1_m: 0.7962 - val_loss: 0.3139 - val_f1_m: 0.7768\n",
      "0.7962499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 579us/sample - loss: 0.6740 - f1_m: 0.7862 - val_loss: 0.6455 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6288 - f1_m: 0.7862 - val_loss: 0.5885 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5793 - f1_m: 0.7862 - val_loss: 0.5313 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5415 - f1_m: 0.7862 - val_loss: 0.4949 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5256 - f1_m: 0.7862 - val_loss: 0.4802 - val_f1_m: 0.8259\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5183 - f1_m: 0.7862 - val_loss: 0.4702 - val_f1_m: 0.8393\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5104 - f1_m: 0.7862 - val_loss: 0.4615 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5001 - f1_m: 0.7862 - val_loss: 0.4536 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4896 - f1_m: 0.7862 - val_loss: 0.4408 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4762 - f1_m: 0.7862 - val_loss: 0.4240 - val_f1_m: 0.8393\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4590 - f1_m: 0.7862 - val_loss: 0.4056 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4367 - f1_m: 0.7862 - val_loss: 0.3802 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4106 - f1_m: 0.7862 - val_loss: 0.3552 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3826 - f1_m: 0.7862 - val_loss: 0.3241 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3549 - f1_m: 0.7862 - val_loss: 0.2980 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3285 - f1_m: 0.7862 - val_loss: 0.2744 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3048 - f1_m: 0.7862 - val_loss: 0.2481 - val_f1_m: 0.8259\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2826 - f1_m: 0.7862 - val_loss: 0.2280 - val_f1_m: 0.8259\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2628 - f1_m: 0.7862 - val_loss: 0.2109 - val_f1_m: 0.8259\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2454 - f1_m: 0.7862 - val_loss: 0.1967 - val_f1_m: 0.8259\n",
      "0.78624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 577us/sample - loss: 0.6784 - f1_m: 0.7892 - val_loss: 0.6586 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6335 - f1_m: 0.7900 - val_loss: 0.5992 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5820 - f1_m: 0.7900 - val_loss: 0.5444 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5424 - f1_m: 0.7900 - val_loss: 0.5110 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5242 - f1_m: 0.7900 - val_loss: 0.4955 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5146 - f1_m: 0.7900 - val_loss: 0.4864 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5051 - f1_m: 0.7900 - val_loss: 0.4755 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4909 - f1_m: 0.7900 - val_loss: 0.4601 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4740 - f1_m: 0.7900 - val_loss: 0.4452 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4557 - f1_m: 0.7900 - val_loss: 0.4240 - val_f1_m: 0.8259\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4312 - f1_m: 0.7900 - val_loss: 0.4005 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4038 - f1_m: 0.7900 - val_loss: 0.3714 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3724 - f1_m: 0.7900 - val_loss: 0.3413 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3410 - f1_m: 0.7900 - val_loss: 0.3113 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3148 - f1_m: 0.7900 - val_loss: 0.2872 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2925 - f1_m: 0.7900 - val_loss: 0.2668 - val_f1_m: 0.8125\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2727 - f1_m: 0.7900 - val_loss: 0.2474 - val_f1_m: 0.8125\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2541 - f1_m: 0.7900 - val_loss: 0.2325 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2395 - f1_m: 0.7900 - val_loss: 0.2178 - val_f1_m: 0.8259\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.2270 - f1_m: 0.7900 - val_loss: 0.2096 - val_f1_m: 0.7857\n",
      "0.7899999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 579us/sample - loss: 0.6780 - f1_m: 0.7962 - val_loss: 0.6619 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6320 - f1_m: 0.7962 - val_loss: 0.6080 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5766 - f1_m: 0.7962 - val_loss: 0.5636 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5352 - f1_m: 0.7962 - val_loss: 0.5387 - val_f1_m: 0.7232\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5150 - f1_m: 0.7962 - val_loss: 0.5292 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5046 - f1_m: 0.7962 - val_loss: 0.5202 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4935 - f1_m: 0.7962 - val_loss: 0.5054 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4776 - f1_m: 0.7962 - val_loss: 0.4899 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4616 - f1_m: 0.7962 - val_loss: 0.4722 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4411 - f1_m: 0.7962 - val_loss: 0.4498 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4164 - f1_m: 0.7962 - val_loss: 0.4204 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3872 - f1_m: 0.7962 - val_loss: 0.3894 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3541 - f1_m: 0.7962 - val_loss: 0.3537 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3220 - f1_m: 0.7962 - val_loss: 0.3260 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2964 - f1_m: 0.7962 - val_loss: 0.3023 - val_f1_m: 0.7500\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2733 - f1_m: 0.7962 - val_loss: 0.2815 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2525 - f1_m: 0.7962 - val_loss: 0.2632 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2346 - f1_m: 0.7962 - val_loss: 0.2461 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2195 - f1_m: 0.7962 - val_loss: 0.2328 - val_f1_m: 0.7768\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2087 - f1_m: 0.7962 - val_loss: 0.2245 - val_f1_m: 0.7902\n",
      "0.7962499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 579us/sample - loss: 0.6779 - f1_m: 0.7862 - val_loss: 0.6505 - val_f1_m: 0.8393\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6319 - f1_m: 0.7862 - val_loss: 0.5918 - val_f1_m: 0.8393\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5817 - f1_m: 0.7862 - val_loss: 0.5334 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5449 - f1_m: 0.7862 - val_loss: 0.4962 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5270 - f1_m: 0.7862 - val_loss: 0.4793 - val_f1_m: 0.8259\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5178 - f1_m: 0.7862 - val_loss: 0.4694 - val_f1_m: 0.8259\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5087 - f1_m: 0.7862 - val_loss: 0.4576 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4938 - f1_m: 0.7862 - val_loss: 0.4462 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4796 - f1_m: 0.7862 - val_loss: 0.4320 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4596 - f1_m: 0.7862 - val_loss: 0.4099 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4351 - f1_m: 0.7862 - val_loss: 0.3885 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4049 - f1_m: 0.7862 - val_loss: 0.3567 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3700 - f1_m: 0.7862 - val_loss: 0.3243 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3350 - f1_m: 0.7862 - val_loss: 0.2939 - val_f1_m: 0.8393\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3060 - f1_m: 0.7862 - val_loss: 0.2693 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2815 - f1_m: 0.7862 - val_loss: 0.2489 - val_f1_m: 0.8393\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2597 - f1_m: 0.7862 - val_loss: 0.2310 - val_f1_m: 0.8393\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2394 - f1_m: 0.7862 - val_loss: 0.2141 - val_f1_m: 0.8125\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2261 - f1_m: 0.7862 - val_loss: 0.2098 - val_f1_m: 0.8393\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2150 - f1_m: 0.8675 - val_loss: 0.1959 - val_f1_m: 0.9643\n",
      "0.86749995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 2ms/sample - loss: 0.6716 - f1_m: 0.8000 - val_loss: 0.6533 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6235 - f1_m: 0.8000 - val_loss: 0.6094 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5690 - f1_m: 0.8000 - val_loss: 0.5732 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5284 - f1_m: 0.8000 - val_loss: 0.5596 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5110 - f1_m: 0.8000 - val_loss: 0.5570 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5039 - f1_m: 0.8000 - val_loss: 0.5530 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4980 - f1_m: 0.8000 - val_loss: 0.5458 - val_f1_m: 0.7500\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4921 - f1_m: 0.8000 - val_loss: 0.5402 - val_f1_m: 0.7500\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4844 - f1_m: 0.8000 - val_loss: 0.5295 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4760 - f1_m: 0.8000 - val_loss: 0.5193 - val_f1_m: 0.7500\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4658 - f1_m: 0.8000 - val_loss: 0.5091 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4553 - f1_m: 0.8000 - val_loss: 0.4989 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4429 - f1_m: 0.8000 - val_loss: 0.4828 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4267 - f1_m: 0.8000 - val_loss: 0.4582 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4034 - f1_m: 0.8000 - val_loss: 0.4320 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3791 - f1_m: 0.8000 - val_loss: 0.4069 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3540 - f1_m: 0.8000 - val_loss: 0.3795 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3299 - f1_m: 0.8000 - val_loss: 0.3552 - val_f1_m: 0.7634\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3067 - f1_m: 0.8000 - val_loss: 0.3315 - val_f1_m: 0.7634\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2840 - f1_m: 0.8000 - val_loss: 0.3129 - val_f1_m: 0.7500\n",
      "0.79999995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 616us/sample - loss: 0.6728 - f1_m: 0.7962 - val_loss: 0.6515 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6231 - f1_m: 0.7962 - val_loss: 0.6035 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5730 - f1_m: 0.7962 - val_loss: 0.5585 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5320 - f1_m: 0.7962 - val_loss: 0.5383 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5147 - f1_m: 0.7962 - val_loss: 0.5311 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5082 - f1_m: 0.7962 - val_loss: 0.5257 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5009 - f1_m: 0.7962 - val_loss: 0.5198 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4940 - f1_m: 0.7962 - val_loss: 0.5122 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4852 - f1_m: 0.7962 - val_loss: 0.5016 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4746 - f1_m: 0.7962 - val_loss: 0.4907 - val_f1_m: 0.7634\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4626 - f1_m: 0.7962 - val_loss: 0.4780 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4485 - f1_m: 0.7962 - val_loss: 0.4622 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4311 - f1_m: 0.7962 - val_loss: 0.4425 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4090 - f1_m: 0.7962 - val_loss: 0.4187 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3844 - f1_m: 0.7962 - val_loss: 0.3904 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3546 - f1_m: 0.7962 - val_loss: 0.3583 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3180 - f1_m: 0.7962 - val_loss: 0.3162 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2808 - f1_m: 0.7962 - val_loss: 0.2876 - val_f1_m: 0.7634\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2541 - f1_m: 0.7962 - val_loss: 0.2654 - val_f1_m: 0.7902\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2364 - f1_m: 0.7962 - val_loss: 0.2541 - val_f1_m: 0.7902\n",
      "0.7962499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 589us/sample - loss: 0.6748 - f1_m: 0.7887 - val_loss: 0.6487 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6279 - f1_m: 0.7887 - val_loss: 0.5944 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5776 - f1_m: 0.7887 - val_loss: 0.5383 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5405 - f1_m: 0.7887 - val_loss: 0.5062 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5236 - f1_m: 0.7887 - val_loss: 0.4933 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5156 - f1_m: 0.7887 - val_loss: 0.4855 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5081 - f1_m: 0.7887 - val_loss: 0.4783 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4988 - f1_m: 0.7887 - val_loss: 0.4694 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4876 - f1_m: 0.7887 - val_loss: 0.4588 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4754 - f1_m: 0.7887 - val_loss: 0.4464 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4612 - f1_m: 0.7887 - val_loss: 0.4312 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4410 - f1_m: 0.7887 - val_loss: 0.4112 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4167 - f1_m: 0.7887 - val_loss: 0.3861 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3905 - f1_m: 0.7887 - val_loss: 0.3605 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3625 - f1_m: 0.7887 - val_loss: 0.3331 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3307 - f1_m: 0.7887 - val_loss: 0.3069 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3027 - f1_m: 0.7887 - val_loss: 0.2827 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2774 - f1_m: 0.7887 - val_loss: 0.2613 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2541 - f1_m: 0.7887 - val_loss: 0.2420 - val_f1_m: 0.7902\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2356 - f1_m: 0.7887 - val_loss: 0.2312 - val_f1_m: 0.8170\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 587us/sample - loss: 0.6790 - f1_m: 0.7837 - val_loss: 0.6592 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6481 - f1_m: 0.7837 - val_loss: 0.6192 - val_f1_m: 0.8348\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6115 - f1_m: 0.7837 - val_loss: 0.5695 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5737 - f1_m: 0.7837 - val_loss: 0.5221 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5455 - f1_m: 0.7837 - val_loss: 0.4929 - val_f1_m: 0.8482\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5325 - f1_m: 0.7837 - val_loss: 0.4773 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5255 - f1_m: 0.7837 - val_loss: 0.4701 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5199 - f1_m: 0.7837 - val_loss: 0.4633 - val_f1_m: 0.8348\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5139 - f1_m: 0.7837 - val_loss: 0.4576 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5079 - f1_m: 0.7837 - val_loss: 0.4489 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5007 - f1_m: 0.7837 - val_loss: 0.4426 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4930 - f1_m: 0.7837 - val_loss: 0.4362 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4826 - f1_m: 0.7837 - val_loss: 0.4230 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4687 - f1_m: 0.7837 - val_loss: 0.4083 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4511 - f1_m: 0.7837 - val_loss: 0.3929 - val_f1_m: 0.8482\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4296 - f1_m: 0.7837 - val_loss: 0.3706 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4062 - f1_m: 0.7837 - val_loss: 0.3419 - val_f1_m: 0.8482\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3709 - f1_m: 0.7837 - val_loss: 0.3086 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3334 - f1_m: 0.7837 - val_loss: 0.2733 - val_f1_m: 0.8348\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2982 - f1_m: 0.7837 - val_loss: 0.2443 - val_f1_m: 0.8214\n",
      "0.78374994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 579us/sample - loss: 0.6777 - f1_m: 0.8030 - val_loss: 0.6681 - val_f1_m: 0.7634\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6450 - f1_m: 0.8037 - val_loss: 0.6394 - val_f1_m: 0.7232\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6039 - f1_m: 0.8037 - val_loss: 0.6064 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5579 - f1_m: 0.8037 - val_loss: 0.5808 - val_f1_m: 0.7500\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5250 - f1_m: 0.8037 - val_loss: 0.5727 - val_f1_m: 0.7232\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5072 - f1_m: 0.8037 - val_loss: 0.5706 - val_f1_m: 0.7366\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5010 - f1_m: 0.8037 - val_loss: 0.5704 - val_f1_m: 0.7366\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4951 - f1_m: 0.8037 - val_loss: 0.5628 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4900 - f1_m: 0.8037 - val_loss: 0.5592 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4853 - f1_m: 0.8037 - val_loss: 0.5529 - val_f1_m: 0.7366\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4795 - f1_m: 0.8037 - val_loss: 0.5489 - val_f1_m: 0.7500\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4736 - f1_m: 0.8037 - val_loss: 0.5412 - val_f1_m: 0.7366\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4666 - f1_m: 0.8037 - val_loss: 0.5331 - val_f1_m: 0.7366\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4581 - f1_m: 0.8037 - val_loss: 0.5178 - val_f1_m: 0.7232\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4471 - f1_m: 0.8037 - val_loss: 0.5077 - val_f1_m: 0.7366\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4338 - f1_m: 0.8037 - val_loss: 0.4879 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4179 - f1_m: 0.8037 - val_loss: 0.4692 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3984 - f1_m: 0.8037 - val_loss: 0.4433 - val_f1_m: 0.7366\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3745 - f1_m: 0.8037 - val_loss: 0.4125 - val_f1_m: 0.7500\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3421 - f1_m: 0.8037 - val_loss: 0.3700 - val_f1_m: 0.7634\n",
      "0.8037499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 581us/sample - loss: 0.6727 - f1_m: 0.7912 - val_loss: 0.6485 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6264 - f1_m: 0.7912 - val_loss: 0.5959 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5763 - f1_m: 0.7912 - val_loss: 0.5440 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5390 - f1_m: 0.7912 - val_loss: 0.5174 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5231 - f1_m: 0.7912 - val_loss: 0.5072 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5159 - f1_m: 0.7912 - val_loss: 0.5009 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5098 - f1_m: 0.7912 - val_loss: 0.4946 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5029 - f1_m: 0.7912 - val_loss: 0.4879 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4943 - f1_m: 0.7912 - val_loss: 0.4782 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4829 - f1_m: 0.7912 - val_loss: 0.4648 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4680 - f1_m: 0.7912 - val_loss: 0.4505 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4529 - f1_m: 0.7912 - val_loss: 0.4331 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4324 - f1_m: 0.7912 - val_loss: 0.4119 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4081 - f1_m: 0.7912 - val_loss: 0.3859 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3810 - f1_m: 0.7912 - val_loss: 0.3571 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3489 - f1_m: 0.7912 - val_loss: 0.3249 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3126 - f1_m: 0.7912 - val_loss: 0.2921 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2829 - f1_m: 0.7912 - val_loss: 0.2674 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2597 - f1_m: 0.7912 - val_loss: 0.2466 - val_f1_m: 0.7812\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2413 - f1_m: 0.7912 - val_loss: 0.2335 - val_f1_m: 0.7946\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 584us/sample - loss: 0.6748 - f1_m: 0.7925 - val_loss: 0.6510 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6276 - f1_m: 0.7925 - val_loss: 0.6010 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5764 - f1_m: 0.7925 - val_loss: 0.5493 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5362 - f1_m: 0.7925 - val_loss: 0.5208 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5179 - f1_m: 0.7925 - val_loss: 0.5098 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5092 - f1_m: 0.7925 - val_loss: 0.5019 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5007 - f1_m: 0.7925 - val_loss: 0.4938 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4909 - f1_m: 0.7925 - val_loss: 0.4830 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4789 - f1_m: 0.7925 - val_loss: 0.4705 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4649 - f1_m: 0.7925 - val_loss: 0.4570 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4485 - f1_m: 0.7925 - val_loss: 0.4389 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4285 - f1_m: 0.7925 - val_loss: 0.4168 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4028 - f1_m: 0.7925 - val_loss: 0.3898 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3714 - f1_m: 0.7925 - val_loss: 0.3574 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3318 - f1_m: 0.7925 - val_loss: 0.3128 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2876 - f1_m: 0.7925 - val_loss: 0.2764 - val_f1_m: 0.7500\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2546 - f1_m: 0.7925 - val_loss: 0.2506 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2348 - f1_m: 0.7925 - val_loss: 0.2359 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2222 - f1_m: 0.7925 - val_loss: 0.2250 - val_f1_m: 0.7634\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2122 - f1_m: 0.7925 - val_loss: 0.2162 - val_f1_m: 0.8036\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 582us/sample - loss: 0.6735 - f1_m: 0.7937 - val_loss: 0.6510 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6256 - f1_m: 0.7937 - val_loss: 0.5999 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5713 - f1_m: 0.7937 - val_loss: 0.5536 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5329 - f1_m: 0.7937 - val_loss: 0.5317 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5166 - f1_m: 0.7937 - val_loss: 0.5238 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5097 - f1_m: 0.7937 - val_loss: 0.5169 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5049 - f1_m: 0.7937 - val_loss: 0.5100 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4971 - f1_m: 0.7937 - val_loss: 0.5012 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4888 - f1_m: 0.7937 - val_loss: 0.4907 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4775 - f1_m: 0.7937 - val_loss: 0.4762 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4648 - f1_m: 0.7937 - val_loss: 0.4622 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4504 - f1_m: 0.7937 - val_loss: 0.4442 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4320 - f1_m: 0.7937 - val_loss: 0.4211 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4092 - f1_m: 0.7937 - val_loss: 0.3933 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3820 - f1_m: 0.7937 - val_loss: 0.3594 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3494 - f1_m: 0.7937 - val_loss: 0.3217 - val_f1_m: 0.7455\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3127 - f1_m: 0.7937 - val_loss: 0.2809 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2757 - f1_m: 0.7937 - val_loss: 0.2430 - val_f1_m: 0.7991\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2477 - f1_m: 0.7937 - val_loss: 0.2201 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2318 - f1_m: 0.7937 - val_loss: 0.2065 - val_f1_m: 0.7991\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 582us/sample - loss: 0.6741 - f1_m: 0.7875 - val_loss: 0.6461 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6275 - f1_m: 0.7875 - val_loss: 0.5900 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5771 - f1_m: 0.7875 - val_loss: 0.5332 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5410 - f1_m: 0.7875 - val_loss: 0.4991 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5248 - f1_m: 0.7875 - val_loss: 0.4872 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5170 - f1_m: 0.7875 - val_loss: 0.4781 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5090 - f1_m: 0.7875 - val_loss: 0.4720 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4987 - f1_m: 0.7875 - val_loss: 0.4613 - val_f1_m: 0.8348\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4866 - f1_m: 0.7875 - val_loss: 0.4505 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4731 - f1_m: 0.7875 - val_loss: 0.4352 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4569 - f1_m: 0.7875 - val_loss: 0.4207 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4359 - f1_m: 0.7875 - val_loss: 0.4000 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4106 - f1_m: 0.7875 - val_loss: 0.3761 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3798 - f1_m: 0.7875 - val_loss: 0.3469 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3376 - f1_m: 0.7875 - val_loss: 0.3074 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2893 - f1_m: 0.7875 - val_loss: 0.2706 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2521 - f1_m: 0.7875 - val_loss: 0.2473 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2325 - f1_m: 0.7875 - val_loss: 0.2325 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2189 - f1_m: 0.7875 - val_loss: 0.2219 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2098 - f1_m: 0.7875 - val_loss: 0.2146 - val_f1_m: 0.7812\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 582us/sample - loss: 0.6794 - f1_m: 0.7862 - val_loss: 0.6613 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6504 - f1_m: 0.7862 - val_loss: 0.6239 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6142 - f1_m: 0.7862 - val_loss: 0.5781 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5772 - f1_m: 0.7862 - val_loss: 0.5300 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5448 - f1_m: 0.7862 - val_loss: 0.4996 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5297 - f1_m: 0.7862 - val_loss: 0.4814 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5215 - f1_m: 0.7862 - val_loss: 0.4748 - val_f1_m: 0.8259\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5156 - f1_m: 0.7862 - val_loss: 0.4682 - val_f1_m: 0.8393\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5100 - f1_m: 0.7862 - val_loss: 0.4629 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5038 - f1_m: 0.7862 - val_loss: 0.4557 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4967 - f1_m: 0.7862 - val_loss: 0.4497 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4882 - f1_m: 0.7862 - val_loss: 0.4423 - val_f1_m: 0.8259\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4768 - f1_m: 0.7862 - val_loss: 0.4294 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4638 - f1_m: 0.7862 - val_loss: 0.4183 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4472 - f1_m: 0.7862 - val_loss: 0.4016 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4267 - f1_m: 0.7862 - val_loss: 0.3809 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3977 - f1_m: 0.7862 - val_loss: 0.3510 - val_f1_m: 0.8393\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3627 - f1_m: 0.7862 - val_loss: 0.3143 - val_f1_m: 0.8393\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3227 - f1_m: 0.7862 - val_loss: 0.2783 - val_f1_m: 0.8393\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2867 - f1_m: 0.7862 - val_loss: 0.2507 - val_f1_m: 0.8125\n",
      "0.78624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 581us/sample - loss: 0.6794 - f1_m: 0.7950 - val_loss: 0.6648 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6478 - f1_m: 0.7950 - val_loss: 0.6310 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6085 - f1_m: 0.7950 - val_loss: 0.5913 - val_f1_m: 0.7545\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5676 - f1_m: 0.7950 - val_loss: 0.5553 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5379 - f1_m: 0.7950 - val_loss: 0.5361 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5233 - f1_m: 0.7950 - val_loss: 0.5277 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5162 - f1_m: 0.7950 - val_loss: 0.5215 - val_f1_m: 0.7545\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5102 - f1_m: 0.7950 - val_loss: 0.5160 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5049 - f1_m: 0.7950 - val_loss: 0.5100 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4989 - f1_m: 0.7950 - val_loss: 0.5039 - val_f1_m: 0.7545\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4932 - f1_m: 0.7950 - val_loss: 0.4971 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4862 - f1_m: 0.7950 - val_loss: 0.4887 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4782 - f1_m: 0.7950 - val_loss: 0.4776 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4668 - f1_m: 0.7950 - val_loss: 0.4647 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4541 - f1_m: 0.7950 - val_loss: 0.4491 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4394 - f1_m: 0.7950 - val_loss: 0.4313 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4210 - f1_m: 0.7950 - val_loss: 0.4101 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4018 - f1_m: 0.7950 - val_loss: 0.3879 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3784 - f1_m: 0.7950 - val_loss: 0.3583 - val_f1_m: 0.7679\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3484 - f1_m: 0.7950 - val_loss: 0.3203 - val_f1_m: 0.7946\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 582us/sample - loss: 0.6752 - f1_m: 0.7955 - val_loss: 0.6532 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6245 - f1_m: 0.7962 - val_loss: 0.6048 - val_f1_m: 0.7634\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5724 - f1_m: 0.7962 - val_loss: 0.5628 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5367 - f1_m: 0.7962 - val_loss: 0.5405 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5184 - f1_m: 0.7962 - val_loss: 0.5313 - val_f1_m: 0.7500\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5086 - f1_m: 0.7962 - val_loss: 0.5220 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4973 - f1_m: 0.7962 - val_loss: 0.5098 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4853 - f1_m: 0.7962 - val_loss: 0.4974 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4731 - f1_m: 0.7962 - val_loss: 0.4832 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4568 - f1_m: 0.7962 - val_loss: 0.4656 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4375 - f1_m: 0.7962 - val_loss: 0.4417 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4150 - f1_m: 0.7962 - val_loss: 0.4165 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3895 - f1_m: 0.7962 - val_loss: 0.3881 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3598 - f1_m: 0.7962 - val_loss: 0.3568 - val_f1_m: 0.7500\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3322 - f1_m: 0.7962 - val_loss: 0.3293 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3084 - f1_m: 0.7962 - val_loss: 0.3081 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2888 - f1_m: 0.7962 - val_loss: 0.2881 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2710 - f1_m: 0.7962 - val_loss: 0.2698 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2552 - f1_m: 0.7962 - val_loss: 0.2520 - val_f1_m: 0.7902\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2412 - f1_m: 0.7962 - val_loss: 0.2381 - val_f1_m: 0.7902\n",
      "0.7962499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 582us/sample - loss: 0.6784 - f1_m: 0.7912 - val_loss: 0.6617 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6464 - f1_m: 0.7912 - val_loss: 0.6243 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6075 - f1_m: 0.7912 - val_loss: 0.5793 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5655 - f1_m: 0.7912 - val_loss: 0.5395 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5371 - f1_m: 0.7912 - val_loss: 0.5180 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5231 - f1_m: 0.7912 - val_loss: 0.5090 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5159 - f1_m: 0.7912 - val_loss: 0.5026 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5096 - f1_m: 0.7912 - val_loss: 0.4964 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5037 - f1_m: 0.7912 - val_loss: 0.4901 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4972 - f1_m: 0.7912 - val_loss: 0.4840 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4911 - f1_m: 0.7912 - val_loss: 0.4770 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4830 - f1_m: 0.7912 - val_loss: 0.4694 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4751 - f1_m: 0.7912 - val_loss: 0.4602 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4650 - f1_m: 0.7912 - val_loss: 0.4489 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4511 - f1_m: 0.7912 - val_loss: 0.4336 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4354 - f1_m: 0.7912 - val_loss: 0.4161 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4150 - f1_m: 0.7912 - val_loss: 0.3944 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3930 - f1_m: 0.7912 - val_loss: 0.3706 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3672 - f1_m: 0.7912 - val_loss: 0.3429 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3367 - f1_m: 0.7912 - val_loss: 0.3120 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 583us/sample - loss: 0.6798 - f1_m: 0.7879 - val_loss: 0.6622 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6500 - f1_m: 0.7887 - val_loss: 0.6256 - val_f1_m: 0.7634\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6125 - f1_m: 0.7887 - val_loss: 0.5801 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5734 - f1_m: 0.7887 - val_loss: 0.5338 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5425 - f1_m: 0.7887 - val_loss: 0.5080 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5285 - f1_m: 0.7887 - val_loss: 0.4946 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5220 - f1_m: 0.7887 - val_loss: 0.4874 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5163 - f1_m: 0.7887 - val_loss: 0.4815 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5106 - f1_m: 0.7887 - val_loss: 0.4765 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5049 - f1_m: 0.7887 - val_loss: 0.4705 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4989 - f1_m: 0.7887 - val_loss: 0.4653 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4923 - f1_m: 0.7887 - val_loss: 0.4569 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4829 - f1_m: 0.7887 - val_loss: 0.4476 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4732 - f1_m: 0.7887 - val_loss: 0.4381 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4591 - f1_m: 0.7887 - val_loss: 0.4229 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4434 - f1_m: 0.7887 - val_loss: 0.4067 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4235 - f1_m: 0.7887 - val_loss: 0.3868 - val_f1_m: 0.8304\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4033 - f1_m: 0.7887 - val_loss: 0.3665 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3833 - f1_m: 0.7887 - val_loss: 0.3461 - val_f1_m: 0.8304\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3625 - f1_m: 0.7887 - val_loss: 0.3258 - val_f1_m: 0.7902\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 582us/sample - loss: 0.6798 - f1_m: 0.7950 - val_loss: 0.6648 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6484 - f1_m: 0.7950 - val_loss: 0.6302 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6084 - f1_m: 0.7950 - val_loss: 0.5887 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5665 - f1_m: 0.7950 - val_loss: 0.5484 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5323 - f1_m: 0.7950 - val_loss: 0.5280 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5173 - f1_m: 0.7950 - val_loss: 0.5191 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5102 - f1_m: 0.7950 - val_loss: 0.5142 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5051 - f1_m: 0.7950 - val_loss: 0.5097 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4999 - f1_m: 0.7950 - val_loss: 0.5053 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4948 - f1_m: 0.7950 - val_loss: 0.5004 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4888 - f1_m: 0.7950 - val_loss: 0.4951 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4824 - f1_m: 0.7950 - val_loss: 0.4889 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4742 - f1_m: 0.7950 - val_loss: 0.4799 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4638 - f1_m: 0.7950 - val_loss: 0.4700 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4515 - f1_m: 0.7950 - val_loss: 0.4577 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4365 - f1_m: 0.7950 - val_loss: 0.4426 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4185 - f1_m: 0.7950 - val_loss: 0.4236 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3954 - f1_m: 0.7950 - val_loss: 0.3989 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3625 - f1_m: 0.7950 - val_loss: 0.3613 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3228 - f1_m: 0.7950 - val_loss: 0.3259 - val_f1_m: 0.7812\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 614us/sample - loss: 0.6788 - f1_m: 0.8025 - val_loss: 0.6676 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6473 - f1_m: 0.8025 - val_loss: 0.6381 - val_f1_m: 0.7545\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6077 - f1_m: 0.8025 - val_loss: 0.6038 - val_f1_m: 0.7545\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5647 - f1_m: 0.8025 - val_loss: 0.5753 - val_f1_m: 0.7277\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5296 - f1_m: 0.8025 - val_loss: 0.5634 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5118 - f1_m: 0.8025 - val_loss: 0.5613 - val_f1_m: 0.7545\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5038 - f1_m: 0.8025 - val_loss: 0.5578 - val_f1_m: 0.7411\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4987 - f1_m: 0.8025 - val_loss: 0.5548 - val_f1_m: 0.7411\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4931 - f1_m: 0.8025 - val_loss: 0.5493 - val_f1_m: 0.7545\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4880 - f1_m: 0.8025 - val_loss: 0.5458 - val_f1_m: 0.7411\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4828 - f1_m: 0.8025 - val_loss: 0.5365 - val_f1_m: 0.7277\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4764 - f1_m: 0.8025 - val_loss: 0.5327 - val_f1_m: 0.7545\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4682 - f1_m: 0.8025 - val_loss: 0.5208 - val_f1_m: 0.7545\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4592 - f1_m: 0.8025 - val_loss: 0.5107 - val_f1_m: 0.7411\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4480 - f1_m: 0.8025 - val_loss: 0.4965 - val_f1_m: 0.7411\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4351 - f1_m: 0.8025 - val_loss: 0.4821 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4190 - f1_m: 0.8025 - val_loss: 0.4627 - val_f1_m: 0.7277\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3991 - f1_m: 0.8025 - val_loss: 0.4396 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3768 - f1_m: 0.8025 - val_loss: 0.4134 - val_f1_m: 0.7679\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3472 - f1_m: 0.8025 - val_loss: 0.3753 - val_f1_m: 0.7545\n",
      "0.80249995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 618us/sample - loss: 0.6793 - f1_m: 0.7875 - val_loss: 0.6614 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6492 - f1_m: 0.7875 - val_loss: 0.6240 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6121 - f1_m: 0.7875 - val_loss: 0.5786 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5724 - f1_m: 0.7875 - val_loss: 0.5328 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5424 - f1_m: 0.7875 - val_loss: 0.5053 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5280 - f1_m: 0.7875 - val_loss: 0.4936 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5213 - f1_m: 0.7875 - val_loss: 0.4846 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5158 - f1_m: 0.7875 - val_loss: 0.4798 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5103 - f1_m: 0.7875 - val_loss: 0.4750 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5042 - f1_m: 0.7875 - val_loss: 0.4684 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4980 - f1_m: 0.7875 - val_loss: 0.4628 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4905 - f1_m: 0.7875 - val_loss: 0.4545 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4811 - f1_m: 0.7875 - val_loss: 0.4440 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4683 - f1_m: 0.7875 - val_loss: 0.4317 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4535 - f1_m: 0.7875 - val_loss: 0.4168 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4351 - f1_m: 0.7875 - val_loss: 0.3968 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4126 - f1_m: 0.7875 - val_loss: 0.3747 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3862 - f1_m: 0.7875 - val_loss: 0.3447 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3527 - f1_m: 0.7875 - val_loss: 0.3127 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3173 - f1_m: 0.7875 - val_loss: 0.2819 - val_f1_m: 0.7946\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 606us/sample - loss: 0.6764 - f1_m: 0.7993 - val_loss: 0.6564 - val_f1_m: 0.7634\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6273 - f1_m: 0.8000 - val_loss: 0.6125 - val_f1_m: 0.7634\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5764 - f1_m: 0.8000 - val_loss: 0.5716 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5351 - f1_m: 0.8000 - val_loss: 0.5518 - val_f1_m: 0.7500\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5141 - f1_m: 0.8000 - val_loss: 0.5444 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5043 - f1_m: 0.8000 - val_loss: 0.5375 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4940 - f1_m: 0.8000 - val_loss: 0.5247 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4806 - f1_m: 0.8000 - val_loss: 0.5109 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4668 - f1_m: 0.8000 - val_loss: 0.4959 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4500 - f1_m: 0.8000 - val_loss: 0.4757 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4298 - f1_m: 0.8000 - val_loss: 0.4521 - val_f1_m: 0.7500\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4049 - f1_m: 0.8000 - val_loss: 0.4246 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3783 - f1_m: 0.8000 - val_loss: 0.3928 - val_f1_m: 0.7500\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3495 - f1_m: 0.8000 - val_loss: 0.3628 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3236 - f1_m: 0.8000 - val_loss: 0.3346 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3033 - f1_m: 0.8000 - val_loss: 0.3124 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2846 - f1_m: 0.8000 - val_loss: 0.2922 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2689 - f1_m: 0.8000 - val_loss: 0.2736 - val_f1_m: 0.7366\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2546 - f1_m: 0.8000 - val_loss: 0.2555 - val_f1_m: 0.7500\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2417 - f1_m: 0.8000 - val_loss: 0.2423 - val_f1_m: 0.7768\n",
      "0.79999995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.6768 - f1_m: 0.7862 - val_loss: 0.6504 - val_f1_m: 0.8393\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6312 - f1_m: 0.7862 - val_loss: 0.5916 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5846 - f1_m: 0.7862 - val_loss: 0.5340 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5477 - f1_m: 0.7862 - val_loss: 0.4973 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5302 - f1_m: 0.7862 - val_loss: 0.4800 - val_f1_m: 0.8393\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5194 - f1_m: 0.7862 - val_loss: 0.4729 - val_f1_m: 0.8259\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5077 - f1_m: 0.7862 - val_loss: 0.4618 - val_f1_m: 0.8393\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4943 - f1_m: 0.7862 - val_loss: 0.4482 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4784 - f1_m: 0.7862 - val_loss: 0.4356 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4599 - f1_m: 0.7862 - val_loss: 0.4189 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4352 - f1_m: 0.7862 - val_loss: 0.3953 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4083 - f1_m: 0.7862 - val_loss: 0.3716 - val_f1_m: 0.8259\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3752 - f1_m: 0.7862 - val_loss: 0.3425 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3413 - f1_m: 0.7862 - val_loss: 0.3148 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3164 - f1_m: 0.7862 - val_loss: 0.2962 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2918 - f1_m: 0.7862 - val_loss: 0.2735 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2711 - f1_m: 0.7862 - val_loss: 0.2575 - val_f1_m: 0.8259\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2524 - f1_m: 0.7862 - val_loss: 0.2437 - val_f1_m: 0.8125\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2378 - f1_m: 0.7862 - val_loss: 0.2327 - val_f1_m: 0.7991\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2276 - f1_m: 0.7862 - val_loss: 0.2252 - val_f1_m: 0.8125\n",
      "0.78624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 619us/sample - loss: 0.6736 - f1_m: 0.7918 - val_loss: 0.6495 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6260 - f1_m: 0.7925 - val_loss: 0.5956 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5729 - f1_m: 0.7925 - val_loss: 0.5448 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5347 - f1_m: 0.7925 - val_loss: 0.5176 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5190 - f1_m: 0.7925 - val_loss: 0.5071 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5100 - f1_m: 0.7925 - val_loss: 0.5002 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5023 - f1_m: 0.7925 - val_loss: 0.4933 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4938 - f1_m: 0.7925 - val_loss: 0.4841 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4821 - f1_m: 0.7925 - val_loss: 0.4712 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4669 - f1_m: 0.7925 - val_loss: 0.4563 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4506 - f1_m: 0.7925 - val_loss: 0.4393 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4300 - f1_m: 0.7925 - val_loss: 0.4180 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4059 - f1_m: 0.7925 - val_loss: 0.3916 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3754 - f1_m: 0.7925 - val_loss: 0.3596 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3408 - f1_m: 0.7925 - val_loss: 0.3230 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3000 - f1_m: 0.7925 - val_loss: 0.2806 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2652 - f1_m: 0.7925 - val_loss: 0.2492 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2407 - f1_m: 0.7925 - val_loss: 0.2280 - val_f1_m: 0.7768\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2264 - f1_m: 0.7925 - val_loss: 0.2151 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2166 - f1_m: 0.7925 - val_loss: 0.2060 - val_f1_m: 0.7768\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 599us/sample - loss: 0.6783 - f1_m: 0.7912 - val_loss: 0.6630 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6471 - f1_m: 0.7912 - val_loss: 0.6267 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6073 - f1_m: 0.7912 - val_loss: 0.5831 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5661 - f1_m: 0.7912 - val_loss: 0.5423 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5366 - f1_m: 0.7912 - val_loss: 0.5213 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5232 - f1_m: 0.7912 - val_loss: 0.5121 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5164 - f1_m: 0.7912 - val_loss: 0.5060 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5114 - f1_m: 0.7912 - val_loss: 0.5004 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5062 - f1_m: 0.7912 - val_loss: 0.4949 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5011 - f1_m: 0.7912 - val_loss: 0.4892 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4954 - f1_m: 0.7912 - val_loss: 0.4827 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4889 - f1_m: 0.7912 - val_loss: 0.4754 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4812 - f1_m: 0.7912 - val_loss: 0.4666 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4715 - f1_m: 0.7912 - val_loss: 0.4544 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4592 - f1_m: 0.7912 - val_loss: 0.4401 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4439 - f1_m: 0.7912 - val_loss: 0.4229 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4258 - f1_m: 0.7912 - val_loss: 0.4024 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4047 - f1_m: 0.7912 - val_loss: 0.3795 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3798 - f1_m: 0.7912 - val_loss: 0.3490 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3467 - f1_m: 0.7912 - val_loss: 0.3140 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 619us/sample - loss: 0.6724 - f1_m: 0.7906 - val_loss: 0.6481 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6249 - f1_m: 0.7912 - val_loss: 0.5953 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5743 - f1_m: 0.7912 - val_loss: 0.5430 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5368 - f1_m: 0.7912 - val_loss: 0.5139 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5215 - f1_m: 0.7912 - val_loss: 0.5038 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5147 - f1_m: 0.7912 - val_loss: 0.4972 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5079 - f1_m: 0.7912 - val_loss: 0.4912 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5010 - f1_m: 0.7912 - val_loss: 0.4826 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4908 - f1_m: 0.7912 - val_loss: 0.4729 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4807 - f1_m: 0.7912 - val_loss: 0.4626 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4689 - f1_m: 0.7912 - val_loss: 0.4508 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4555 - f1_m: 0.7912 - val_loss: 0.4366 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4379 - f1_m: 0.7912 - val_loss: 0.4182 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4177 - f1_m: 0.7912 - val_loss: 0.3957 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3905 - f1_m: 0.7912 - val_loss: 0.3649 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3524 - f1_m: 0.7912 - val_loss: 0.3262 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3145 - f1_m: 0.7912 - val_loss: 0.2929 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2844 - f1_m: 0.7912 - val_loss: 0.2670 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2619 - f1_m: 0.7912 - val_loss: 0.2499 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2482 - f1_m: 0.7912 - val_loss: 0.2383 - val_f1_m: 0.7946\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 605us/sample - loss: 0.6727 - f1_m: 0.7825 - val_loss: 0.6410 - val_f1_m: 0.8393\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6273 - f1_m: 0.7825 - val_loss: 0.5796 - val_f1_m: 0.8393\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5793 - f1_m: 0.7825 - val_loss: 0.5177 - val_f1_m: 0.8527\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5448 - f1_m: 0.7825 - val_loss: 0.4762 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5321 - f1_m: 0.7825 - val_loss: 0.4601 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5243 - f1_m: 0.7825 - val_loss: 0.4538 - val_f1_m: 0.8527\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5176 - f1_m: 0.7825 - val_loss: 0.4457 - val_f1_m: 0.8393\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5103 - f1_m: 0.7825 - val_loss: 0.4387 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5010 - f1_m: 0.7825 - val_loss: 0.4289 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4878 - f1_m: 0.7825 - val_loss: 0.4173 - val_f1_m: 0.8393\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4732 - f1_m: 0.7825 - val_loss: 0.4010 - val_f1_m: 0.8393\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4559 - f1_m: 0.7825 - val_loss: 0.3824 - val_f1_m: 0.8393\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4345 - f1_m: 0.7825 - val_loss: 0.3624 - val_f1_m: 0.8527\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4078 - f1_m: 0.7825 - val_loss: 0.3347 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3770 - f1_m: 0.7825 - val_loss: 0.3064 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3396 - f1_m: 0.7825 - val_loss: 0.2747 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3039 - f1_m: 0.7825 - val_loss: 0.2397 - val_f1_m: 0.8393\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2734 - f1_m: 0.7825 - val_loss: 0.2122 - val_f1_m: 0.8259\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2486 - f1_m: 0.7825 - val_loss: 0.1937 - val_f1_m: 0.8259\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2342 - f1_m: 0.7825 - val_loss: 0.1848 - val_f1_m: 0.7991\n",
      "0.7824999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 618us/sample - loss: 0.6753 - f1_m: 0.7934 - val_loss: 0.6535 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6266 - f1_m: 0.7950 - val_loss: 0.6067 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5773 - f1_m: 0.7950 - val_loss: 0.5652 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5385 - f1_m: 0.7950 - val_loss: 0.5434 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5195 - f1_m: 0.7950 - val_loss: 0.5339 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5099 - f1_m: 0.7950 - val_loss: 0.5254 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4994 - f1_m: 0.7950 - val_loss: 0.5116 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4867 - f1_m: 0.7950 - val_loss: 0.4974 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4721 - f1_m: 0.7950 - val_loss: 0.4809 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4552 - f1_m: 0.7950 - val_loss: 0.4598 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4344 - f1_m: 0.7950 - val_loss: 0.4333 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4089 - f1_m: 0.7950 - val_loss: 0.4042 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3799 - f1_m: 0.7950 - val_loss: 0.3695 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3475 - f1_m: 0.7950 - val_loss: 0.3370 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3182 - f1_m: 0.7950 - val_loss: 0.3121 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2950 - f1_m: 0.7950 - val_loss: 0.2924 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2748 - f1_m: 0.7950 - val_loss: 0.2713 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2564 - f1_m: 0.7950 - val_loss: 0.2538 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2405 - f1_m: 0.7950 - val_loss: 0.2374 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2261 - f1_m: 0.7950 - val_loss: 0.2263 - val_f1_m: 0.7812\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 633us/sample - loss: 0.6791 - f1_m: 0.7905 - val_loss: 0.6626 - val_f1_m: 0.7545\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6481 - f1_m: 0.7912 - val_loss: 0.6269 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6099 - f1_m: 0.7912 - val_loss: 0.5838 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5695 - f1_m: 0.7912 - val_loss: 0.5425 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5400 - f1_m: 0.7912 - val_loss: 0.5172 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5257 - f1_m: 0.7912 - val_loss: 0.5063 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5179 - f1_m: 0.7912 - val_loss: 0.5010 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5132 - f1_m: 0.7912 - val_loss: 0.4951 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5072 - f1_m: 0.7912 - val_loss: 0.4902 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5019 - f1_m: 0.7912 - val_loss: 0.4850 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4968 - f1_m: 0.7912 - val_loss: 0.4796 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4901 - f1_m: 0.7912 - val_loss: 0.4727 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4836 - f1_m: 0.7912 - val_loss: 0.4644 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4725 - f1_m: 0.7912 - val_loss: 0.4541 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4611 - f1_m: 0.7912 - val_loss: 0.4417 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4455 - f1_m: 0.7912 - val_loss: 0.4267 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4285 - f1_m: 0.7912 - val_loss: 0.4079 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4068 - f1_m: 0.7912 - val_loss: 0.3824 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3721 - f1_m: 0.7912 - val_loss: 0.3424 - val_f1_m: 0.7679\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3302 - f1_m: 0.7912 - val_loss: 0.3036 - val_f1_m: 0.7946\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 617us/sample - loss: 0.6735 - f1_m: 0.7873 - val_loss: 0.6472 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6266 - f1_m: 0.7887 - val_loss: 0.5904 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5748 - f1_m: 0.7887 - val_loss: 0.5346 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5376 - f1_m: 0.7887 - val_loss: 0.5024 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5216 - f1_m: 0.7887 - val_loss: 0.4905 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5144 - f1_m: 0.7887 - val_loss: 0.4836 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5072 - f1_m: 0.7887 - val_loss: 0.4768 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4992 - f1_m: 0.7887 - val_loss: 0.4682 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4881 - f1_m: 0.7887 - val_loss: 0.4573 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4753 - f1_m: 0.7887 - val_loss: 0.4443 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4603 - f1_m: 0.7887 - val_loss: 0.4278 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4413 - f1_m: 0.7887 - val_loss: 0.4074 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4166 - f1_m: 0.7887 - val_loss: 0.3819 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3872 - f1_m: 0.7887 - val_loss: 0.3520 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3484 - f1_m: 0.7887 - val_loss: 0.3103 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2995 - f1_m: 0.7887 - val_loss: 0.2691 - val_f1_m: 0.8304\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2647 - f1_m: 0.7887 - val_loss: 0.2449 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2425 - f1_m: 0.7887 - val_loss: 0.2313 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2294 - f1_m: 0.7887 - val_loss: 0.2202 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2195 - f1_m: 0.7887 - val_loss: 0.2110 - val_f1_m: 0.8036\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 622us/sample - loss: 0.6731 - f1_m: 0.7937 - val_loss: 0.6503 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6249 - f1_m: 0.7937 - val_loss: 0.5994 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5724 - f1_m: 0.7937 - val_loss: 0.5530 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5383 - f1_m: 0.7937 - val_loss: 0.5281 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5207 - f1_m: 0.7937 - val_loss: 0.5200 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5137 - f1_m: 0.7937 - val_loss: 0.5136 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5073 - f1_m: 0.7937 - val_loss: 0.5074 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5007 - f1_m: 0.7937 - val_loss: 0.5005 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4924 - f1_m: 0.7937 - val_loss: 0.4906 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4821 - f1_m: 0.7937 - val_loss: 0.4787 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4700 - f1_m: 0.7937 - val_loss: 0.4665 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4559 - f1_m: 0.7937 - val_loss: 0.4519 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4398 - f1_m: 0.7937 - val_loss: 0.4338 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4196 - f1_m: 0.7937 - val_loss: 0.4116 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3954 - f1_m: 0.7937 - val_loss: 0.3850 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3670 - f1_m: 0.7937 - val_loss: 0.3537 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3344 - f1_m: 0.7937 - val_loss: 0.3184 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2985 - f1_m: 0.7937 - val_loss: 0.2828 - val_f1_m: 0.7991\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2661 - f1_m: 0.7937 - val_loss: 0.2553 - val_f1_m: 0.7991\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2448 - f1_m: 0.7937 - val_loss: 0.2392 - val_f1_m: 0.7857\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 586us/sample - loss: 0.6728 - f1_m: 0.7912 - val_loss: 0.6479 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6251 - f1_m: 0.7912 - val_loss: 0.5924 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5732 - f1_m: 0.7912 - val_loss: 0.5412 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5359 - f1_m: 0.7912 - val_loss: 0.5136 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5196 - f1_m: 0.7912 - val_loss: 0.5025 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5102 - f1_m: 0.7912 - val_loss: 0.4959 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5027 - f1_m: 0.7912 - val_loss: 0.4882 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4933 - f1_m: 0.7912 - val_loss: 0.4785 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4818 - f1_m: 0.7912 - val_loss: 0.4667 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4683 - f1_m: 0.7912 - val_loss: 0.4533 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4526 - f1_m: 0.7912 - val_loss: 0.4357 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4314 - f1_m: 0.7912 - val_loss: 0.4133 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4059 - f1_m: 0.7912 - val_loss: 0.3858 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3746 - f1_m: 0.7912 - val_loss: 0.3531 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3383 - f1_m: 0.7912 - val_loss: 0.3113 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2950 - f1_m: 0.7912 - val_loss: 0.2720 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2609 - f1_m: 0.7912 - val_loss: 0.2471 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2394 - f1_m: 0.7912 - val_loss: 0.2231 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2255 - f1_m: 0.7912 - val_loss: 0.2132 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2168 - f1_m: 0.7912 - val_loss: 0.2039 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6747 - f1_m: 0.7900 - val_loss: 0.6487 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6268 - f1_m: 0.7900 - val_loss: 0.5948 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5757 - f1_m: 0.7900 - val_loss: 0.5417 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5380 - f1_m: 0.7900 - val_loss: 0.5130 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5235 - f1_m: 0.7900 - val_loss: 0.5031 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5163 - f1_m: 0.7900 - val_loss: 0.4961 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5105 - f1_m: 0.7900 - val_loss: 0.4896 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5041 - f1_m: 0.7900 - val_loss: 0.4829 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4964 - f1_m: 0.7900 - val_loss: 0.4749 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4856 - f1_m: 0.7900 - val_loss: 0.4618 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4715 - f1_m: 0.7900 - val_loss: 0.4478 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4566 - f1_m: 0.7900 - val_loss: 0.4314 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4377 - f1_m: 0.7900 - val_loss: 0.4114 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.4145 - f1_m: 0.7900 - val_loss: 0.3872 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3876 - f1_m: 0.7900 - val_loss: 0.3586 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3572 - f1_m: 0.7900 - val_loss: 0.3273 - val_f1_m: 0.8125\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3214 - f1_m: 0.7900 - val_loss: 0.2942 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.2906 - f1_m: 0.7900 - val_loss: 0.2679 - val_f1_m: 0.8259\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2657 - f1_m: 0.7900 - val_loss: 0.2446 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2447 - f1_m: 0.7900 - val_loss: 0.2262 - val_f1_m: 0.8125\n",
      "0.7899999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 603us/sample - loss: 0.6777 - f1_m: 0.7967 - val_loss: 0.6657 - val_f1_m: 0.7455\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.6467 - f1_m: 0.7975 - val_loss: 0.6344 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.6084 - f1_m: 0.7975 - val_loss: 0.5978 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.5660 - f1_m: 0.7975 - val_loss: 0.5662 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5337 - f1_m: 0.7975 - val_loss: 0.5506 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5190 - f1_m: 0.7975 - val_loss: 0.5457 - val_f1_m: 0.7589\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5102 - f1_m: 0.7975 - val_loss: 0.5400 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5046 - f1_m: 0.7975 - val_loss: 0.5343 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4988 - f1_m: 0.7975 - val_loss: 0.5301 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.4935 - f1_m: 0.7975 - val_loss: 0.5248 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.4875 - f1_m: 0.7975 - val_loss: 0.5186 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4801 - f1_m: 0.7975 - val_loss: 0.5090 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4709 - f1_m: 0.7975 - val_loss: 0.5005 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4612 - f1_m: 0.7975 - val_loss: 0.4884 - val_f1_m: 0.7455\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4484 - f1_m: 0.7975 - val_loss: 0.4735 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.4337 - f1_m: 0.7975 - val_loss: 0.4570 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4153 - f1_m: 0.7975 - val_loss: 0.4353 - val_f1_m: 0.7589\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3955 - f1_m: 0.7975 - val_loss: 0.4168 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3776 - f1_m: 0.7975 - val_loss: 0.3998 - val_f1_m: 0.7857\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.3584 - f1_m: 0.7975 - val_loss: 0.3814 - val_f1_m: 0.7723\n",
      "0.7974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 603us/sample - loss: 0.6732 - f1_m: 0.7937 - val_loss: 0.6505 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.6250 - f1_m: 0.7937 - val_loss: 0.6002 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5733 - f1_m: 0.7937 - val_loss: 0.5526 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5356 - f1_m: 0.7937 - val_loss: 0.5279 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5186 - f1_m: 0.7937 - val_loss: 0.5182 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5099 - f1_m: 0.7937 - val_loss: 0.5103 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.5020 - f1_m: 0.7937 - val_loss: 0.5016 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.4923 - f1_m: 0.7937 - val_loss: 0.4898 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4792 - f1_m: 0.7937 - val_loss: 0.4759 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.4654 - f1_m: 0.7937 - val_loss: 0.4613 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4492 - f1_m: 0.7937 - val_loss: 0.4427 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4286 - f1_m: 0.7937 - val_loss: 0.4185 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.4033 - f1_m: 0.7937 - val_loss: 0.3909 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.3741 - f1_m: 0.7937 - val_loss: 0.3591 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.3398 - f1_m: 0.7937 - val_loss: 0.3209 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.3013 - f1_m: 0.7937 - val_loss: 0.2821 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.2667 - f1_m: 0.7937 - val_loss: 0.2520 - val_f1_m: 0.8125\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.2433 - f1_m: 0.7937 - val_loss: 0.2360 - val_f1_m: 0.8125\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 0.2302 - f1_m: 0.7937 - val_loss: 0.2248 - val_f1_m: 0.7857\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.2213 - f1_m: 0.7937 - val_loss: 0.2191 - val_f1_m: 0.7991\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 581us/sample - loss: 0.6735 - f1_m: 0.7837 - val_loss: 0.6430 - val_f1_m: 0.8348\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6268 - f1_m: 0.7837 - val_loss: 0.5821 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5790 - f1_m: 0.7837 - val_loss: 0.5199 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5444 - f1_m: 0.7837 - val_loss: 0.4846 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5296 - f1_m: 0.7837 - val_loss: 0.4746 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5216 - f1_m: 0.7837 - val_loss: 0.4623 - val_f1_m: 0.8482\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5151 - f1_m: 0.7837 - val_loss: 0.4560 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5080 - f1_m: 0.7837 - val_loss: 0.4513 - val_f1_m: 0.8348\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4974 - f1_m: 0.7837 - val_loss: 0.4410 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4848 - f1_m: 0.7837 - val_loss: 0.4280 - val_f1_m: 0.8482\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4704 - f1_m: 0.7837 - val_loss: 0.4139 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4525 - f1_m: 0.7837 - val_loss: 0.3961 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4298 - f1_m: 0.7837 - val_loss: 0.3749 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4006 - f1_m: 0.7837 - val_loss: 0.3475 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3659 - f1_m: 0.7837 - val_loss: 0.3191 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3253 - f1_m: 0.7837 - val_loss: 0.2887 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2834 - f1_m: 0.7837 - val_loss: 0.2564 - val_f1_m: 0.8348\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2496 - f1_m: 0.7837 - val_loss: 0.2344 - val_f1_m: 0.8348\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2299 - f1_m: 0.7837 - val_loss: 0.2220 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2182 - f1_m: 0.7837 - val_loss: 0.2146 - val_f1_m: 0.8482\n",
      "0.78374994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 587us/sample - loss: 0.6743 - f1_m: 0.7875 - val_loss: 0.6475 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6297 - f1_m: 0.7875 - val_loss: 0.5920 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5789 - f1_m: 0.7875 - val_loss: 0.5363 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5416 - f1_m: 0.7875 - val_loss: 0.5022 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5261 - f1_m: 0.7875 - val_loss: 0.4891 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5186 - f1_m: 0.7875 - val_loss: 0.4820 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5122 - f1_m: 0.7875 - val_loss: 0.4756 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5044 - f1_m: 0.7875 - val_loss: 0.4667 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4948 - f1_m: 0.7875 - val_loss: 0.4561 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4811 - f1_m: 0.7875 - val_loss: 0.4423 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4674 - f1_m: 0.7875 - val_loss: 0.4278 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4502 - f1_m: 0.7875 - val_loss: 0.4088 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4290 - f1_m: 0.7875 - val_loss: 0.3873 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4036 - f1_m: 0.7875 - val_loss: 0.3619 - val_f1_m: 0.8348\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3743 - f1_m: 0.7875 - val_loss: 0.3314 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3389 - f1_m: 0.7875 - val_loss: 0.3014 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3053 - f1_m: 0.7875 - val_loss: 0.2686 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2727 - f1_m: 0.7875 - val_loss: 0.2417 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2502 - f1_m: 0.7875 - val_loss: 0.2247 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2377 - f1_m: 0.7875 - val_loss: 0.2142 - val_f1_m: 0.8080\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 609us/sample - loss: 0.6707 - f1_m: 0.8075 - val_loss: 0.6572 - val_f1_m: 0.7366\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6195 - f1_m: 0.8075 - val_loss: 0.6185 - val_f1_m: 0.7366\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5652 - f1_m: 0.8075 - val_loss: 0.5878 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5205 - f1_m: 0.8075 - val_loss: 0.5806 - val_f1_m: 0.7098\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5026 - f1_m: 0.8075 - val_loss: 0.5836 - val_f1_m: 0.7634\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4946 - f1_m: 0.8075 - val_loss: 0.5785 - val_f1_m: 0.7500\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4880 - f1_m: 0.8075 - val_loss: 0.5696 - val_f1_m: 0.7366\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4811 - f1_m: 0.8075 - val_loss: 0.5667 - val_f1_m: 0.7366\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4731 - f1_m: 0.8075 - val_loss: 0.5541 - val_f1_m: 0.7366\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4628 - f1_m: 0.8075 - val_loss: 0.5451 - val_f1_m: 0.7500\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4506 - f1_m: 0.8075 - val_loss: 0.5312 - val_f1_m: 0.7098\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4371 - f1_m: 0.8075 - val_loss: 0.5178 - val_f1_m: 0.7366\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4207 - f1_m: 0.8075 - val_loss: 0.4994 - val_f1_m: 0.7366\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4007 - f1_m: 0.8075 - val_loss: 0.4739 - val_f1_m: 0.7098\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3761 - f1_m: 0.8075 - val_loss: 0.4437 - val_f1_m: 0.7098\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3480 - f1_m: 0.8075 - val_loss: 0.4056 - val_f1_m: 0.7232\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3145 - f1_m: 0.8075 - val_loss: 0.3690 - val_f1_m: 0.7634\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2821 - f1_m: 0.8075 - val_loss: 0.3322 - val_f1_m: 0.7500\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2562 - f1_m: 0.8075 - val_loss: 0.3055 - val_f1_m: 0.7366\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2342 - f1_m: 0.8075 - val_loss: 0.2849 - val_f1_m: 0.7366\n",
      "0.80749995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 605us/sample - loss: 0.6735 - f1_m: 0.7975 - val_loss: 0.6537 - val_f1_m: 0.7589\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6261 - f1_m: 0.7975 - val_loss: 0.6084 - val_f1_m: 0.7589\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5719 - f1_m: 0.7975 - val_loss: 0.5647 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5296 - f1_m: 0.7975 - val_loss: 0.5447 - val_f1_m: 0.7589\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5116 - f1_m: 0.7975 - val_loss: 0.5387 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5033 - f1_m: 0.7975 - val_loss: 0.5324 - val_f1_m: 0.7589\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4972 - f1_m: 0.7975 - val_loss: 0.5249 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4893 - f1_m: 0.7975 - val_loss: 0.5181 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4793 - f1_m: 0.7975 - val_loss: 0.5046 - val_f1_m: 0.7589\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4669 - f1_m: 0.7975 - val_loss: 0.4910 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4526 - f1_m: 0.7975 - val_loss: 0.4763 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4353 - f1_m: 0.7975 - val_loss: 0.4563 - val_f1_m: 0.7589\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4123 - f1_m: 0.7975 - val_loss: 0.4311 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3858 - f1_m: 0.7975 - val_loss: 0.4027 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3549 - f1_m: 0.7975 - val_loss: 0.3671 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3142 - f1_m: 0.7975 - val_loss: 0.3167 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2692 - f1_m: 0.7975 - val_loss: 0.2763 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2390 - f1_m: 0.7975 - val_loss: 0.2529 - val_f1_m: 0.7589\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2219 - f1_m: 0.7975 - val_loss: 0.2398 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2097 - f1_m: 0.7975 - val_loss: 0.2262 - val_f1_m: 0.7723\n",
      "0.7974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 611us/sample - loss: 0.6721 - f1_m: 0.7937 - val_loss: 0.6509 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6278 - f1_m: 0.7937 - val_loss: 0.6044 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5778 - f1_m: 0.7937 - val_loss: 0.5579 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5351 - f1_m: 0.7937 - val_loss: 0.5264 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5121 - f1_m: 0.7937 - val_loss: 0.5136 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5007 - f1_m: 0.7937 - val_loss: 0.5043 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4896 - f1_m: 0.7937 - val_loss: 0.4922 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4763 - f1_m: 0.7937 - val_loss: 0.4770 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4606 - f1_m: 0.7937 - val_loss: 0.4588 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4400 - f1_m: 0.7937 - val_loss: 0.4396 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4174 - f1_m: 0.7937 - val_loss: 0.4158 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3912 - f1_m: 0.7937 - val_loss: 0.3880 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3619 - f1_m: 0.7937 - val_loss: 0.3603 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3338 - f1_m: 0.7937 - val_loss: 0.3334 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3094 - f1_m: 0.7937 - val_loss: 0.3120 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2877 - f1_m: 0.7937 - val_loss: 0.2922 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2676 - f1_m: 0.7937 - val_loss: 0.2726 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2501 - f1_m: 0.7937 - val_loss: 0.2572 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2351 - f1_m: 0.7937 - val_loss: 0.2410 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2231 - f1_m: 0.7937 - val_loss: 0.2320 - val_f1_m: 0.7991\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.6742 - f1_m: 0.7987 - val_loss: 0.6551 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6248 - f1_m: 0.7987 - val_loss: 0.6104 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5722 - f1_m: 0.7987 - val_loss: 0.5707 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5311 - f1_m: 0.7987 - val_loss: 0.5519 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5147 - f1_m: 0.7987 - val_loss: 0.5462 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5050 - f1_m: 0.7987 - val_loss: 0.5374 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4968 - f1_m: 0.7987 - val_loss: 0.5270 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4835 - f1_m: 0.7987 - val_loss: 0.5120 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4700 - f1_m: 0.7987 - val_loss: 0.4966 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4541 - f1_m: 0.7987 - val_loss: 0.4785 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4352 - f1_m: 0.7987 - val_loss: 0.4552 - val_f1_m: 0.7545\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4115 - f1_m: 0.7987 - val_loss: 0.4263 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3841 - f1_m: 0.7987 - val_loss: 0.3966 - val_f1_m: 0.7679\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3520 - f1_m: 0.7987 - val_loss: 0.3593 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3217 - f1_m: 0.7987 - val_loss: 0.3318 - val_f1_m: 0.7545\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2964 - f1_m: 0.7987 - val_loss: 0.3084 - val_f1_m: 0.7679\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2750 - f1_m: 0.7987 - val_loss: 0.2877 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2564 - f1_m: 0.7987 - val_loss: 0.2693 - val_f1_m: 0.7545\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2399 - f1_m: 0.7987 - val_loss: 0.2551 - val_f1_m: 0.7679\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2252 - f1_m: 0.7987 - val_loss: 0.2393 - val_f1_m: 0.7679\n",
      "0.7987499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6723 - f1_m: 0.7862 - val_loss: 0.6449 - val_f1_m: 0.8393\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6258 - f1_m: 0.7862 - val_loss: 0.5879 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5764 - f1_m: 0.7862 - val_loss: 0.5304 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5392 - f1_m: 0.7862 - val_loss: 0.4972 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5237 - f1_m: 0.7862 - val_loss: 0.4827 - val_f1_m: 0.8259\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5165 - f1_m: 0.7862 - val_loss: 0.4737 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5093 - f1_m: 0.7862 - val_loss: 0.4658 - val_f1_m: 0.8393\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5004 - f1_m: 0.7862 - val_loss: 0.4552 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4899 - f1_m: 0.7862 - val_loss: 0.4450 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4784 - f1_m: 0.7862 - val_loss: 0.4304 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4650 - f1_m: 0.7862 - val_loss: 0.4153 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4490 - f1_m: 0.7862 - val_loss: 0.3959 - val_f1_m: 0.8393\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4275 - f1_m: 0.7862 - val_loss: 0.3722 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3995 - f1_m: 0.7862 - val_loss: 0.3426 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3707 - f1_m: 0.7862 - val_loss: 0.3124 - val_f1_m: 0.8393\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3433 - f1_m: 0.7862 - val_loss: 0.2836 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3158 - f1_m: 0.7862 - val_loss: 0.2606 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2910 - f1_m: 0.7862 - val_loss: 0.2393 - val_f1_m: 0.8393\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2689 - f1_m: 0.7862 - val_loss: 0.2247 - val_f1_m: 0.7991\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2495 - f1_m: 0.7862 - val_loss: 0.2038 - val_f1_m: 0.8259\n",
      "0.78624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 626us/sample - loss: 0.6708 - f1_m: 0.8087 - val_loss: 0.6596 - val_f1_m: 0.7187\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6183 - f1_m: 0.8087 - val_loss: 0.6233 - val_f1_m: 0.7321\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5627 - f1_m: 0.8087 - val_loss: 0.5984 - val_f1_m: 0.6920\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5177 - f1_m: 0.8087 - val_loss: 0.5972 - val_f1_m: 0.7187\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4999 - f1_m: 0.8087 - val_loss: 0.6034 - val_f1_m: 0.7455\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4920 - f1_m: 0.8087 - val_loss: 0.5983 - val_f1_m: 0.7187\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4861 - f1_m: 0.8087 - val_loss: 0.5911 - val_f1_m: 0.7455\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4804 - f1_m: 0.8087 - val_loss: 0.5826 - val_f1_m: 0.7187\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4725 - f1_m: 0.8087 - val_loss: 0.5739 - val_f1_m: 0.7455\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4632 - f1_m: 0.8087 - val_loss: 0.5620 - val_f1_m: 0.7187\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4525 - f1_m: 0.8087 - val_loss: 0.5493 - val_f1_m: 0.7054\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4413 - f1_m: 0.8087 - val_loss: 0.5360 - val_f1_m: 0.7589\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4279 - f1_m: 0.8087 - val_loss: 0.5167 - val_f1_m: 0.7321\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4108 - f1_m: 0.8087 - val_loss: 0.4940 - val_f1_m: 0.7589\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3912 - f1_m: 0.8087 - val_loss: 0.4719 - val_f1_m: 0.7187\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3679 - f1_m: 0.8087 - val_loss: 0.4392 - val_f1_m: 0.7321\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3403 - f1_m: 0.8087 - val_loss: 0.3978 - val_f1_m: 0.7054\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3016 - f1_m: 0.8087 - val_loss: 0.3507 - val_f1_m: 0.7187\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2692 - f1_m: 0.8087 - val_loss: 0.3176 - val_f1_m: 0.7589\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2451 - f1_m: 0.8087 - val_loss: 0.2983 - val_f1_m: 0.7321\n",
      "0.8087499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 583us/sample - loss: 0.6719 - f1_m: 0.8025 - val_loss: 0.6557 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6222 - f1_m: 0.8025 - val_loss: 0.6126 - val_f1_m: 0.7143\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5672 - f1_m: 0.8025 - val_loss: 0.5773 - val_f1_m: 0.7545\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5269 - f1_m: 0.8025 - val_loss: 0.5657 - val_f1_m: 0.7277\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5090 - f1_m: 0.8025 - val_loss: 0.5622 - val_f1_m: 0.7545\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5010 - f1_m: 0.8025 - val_loss: 0.5569 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4944 - f1_m: 0.8025 - val_loss: 0.5512 - val_f1_m: 0.7277\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4872 - f1_m: 0.8025 - val_loss: 0.5420 - val_f1_m: 0.7545\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4781 - f1_m: 0.8025 - val_loss: 0.5286 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4660 - f1_m: 0.8025 - val_loss: 0.5134 - val_f1_m: 0.7411\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4515 - f1_m: 0.8025 - val_loss: 0.5002 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4372 - f1_m: 0.8025 - val_loss: 0.4837 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4175 - f1_m: 0.8025 - val_loss: 0.4570 - val_f1_m: 0.7545\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3940 - f1_m: 0.8025 - val_loss: 0.4292 - val_f1_m: 0.7411\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3675 - f1_m: 0.8025 - val_loss: 0.3978 - val_f1_m: 0.7545\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3369 - f1_m: 0.8025 - val_loss: 0.3569 - val_f1_m: 0.7679\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3027 - f1_m: 0.8025 - val_loss: 0.3153 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2690 - f1_m: 0.8025 - val_loss: 0.2795 - val_f1_m: 0.7411\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2400 - f1_m: 0.8025 - val_loss: 0.2539 - val_f1_m: 0.7545\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2228 - f1_m: 0.8025 - val_loss: 0.2403 - val_f1_m: 0.7812\n",
      "0.80249995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 586us/sample - loss: 0.6738 - f1_m: 0.7875 - val_loss: 0.6468 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6285 - f1_m: 0.7875 - val_loss: 0.5905 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5787 - f1_m: 0.7875 - val_loss: 0.5346 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5410 - f1_m: 0.7875 - val_loss: 0.5009 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5267 - f1_m: 0.7875 - val_loss: 0.4860 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5195 - f1_m: 0.7875 - val_loss: 0.4804 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5126 - f1_m: 0.7875 - val_loss: 0.4723 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5056 - f1_m: 0.7875 - val_loss: 0.4648 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4941 - f1_m: 0.7875 - val_loss: 0.4557 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4819 - f1_m: 0.7875 - val_loss: 0.4434 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4678 - f1_m: 0.7875 - val_loss: 0.4298 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4506 - f1_m: 0.7875 - val_loss: 0.4116 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4290 - f1_m: 0.7875 - val_loss: 0.3902 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4035 - f1_m: 0.7875 - val_loss: 0.3654 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3728 - f1_m: 0.7875 - val_loss: 0.3368 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3374 - f1_m: 0.7875 - val_loss: 0.3011 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2986 - f1_m: 0.7875 - val_loss: 0.2711 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2707 - f1_m: 0.7875 - val_loss: 0.2488 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2524 - f1_m: 0.7875 - val_loss: 0.2344 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2400 - f1_m: 0.7875 - val_loss: 0.2234 - val_f1_m: 0.8348\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 616us/sample - loss: 0.6799 - f1_m: 0.7862 - val_loss: 0.6609 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6456 - f1_m: 0.7862 - val_loss: 0.6044 - val_f1_m: 0.8393\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5871 - f1_m: 0.7862 - val_loss: 0.5361 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5438 - f1_m: 0.7862 - val_loss: 0.4986 - val_f1_m: 0.8259\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5265 - f1_m: 0.7862 - val_loss: 0.4859 - val_f1_m: 0.8393\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5200 - f1_m: 0.7862 - val_loss: 0.4777 - val_f1_m: 0.8259\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5133 - f1_m: 0.7862 - val_loss: 0.4727 - val_f1_m: 0.8393\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5073 - f1_m: 0.7862 - val_loss: 0.4665 - val_f1_m: 0.8393\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4999 - f1_m: 0.7862 - val_loss: 0.4593 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4911 - f1_m: 0.7862 - val_loss: 0.4509 - val_f1_m: 0.8259\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4797 - f1_m: 0.7862 - val_loss: 0.4391 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4639 - f1_m: 0.7862 - val_loss: 0.4233 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4458 - f1_m: 0.7862 - val_loss: 0.4041 - val_f1_m: 0.8393\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4236 - f1_m: 0.7862 - val_loss: 0.3824 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3971 - f1_m: 0.7862 - val_loss: 0.3554 - val_f1_m: 0.8393\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3639 - f1_m: 0.7862 - val_loss: 0.3238 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3217 - f1_m: 0.7862 - val_loss: 0.2910 - val_f1_m: 0.8393\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2826 - f1_m: 0.7862 - val_loss: 0.2668 - val_f1_m: 0.8393\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2547 - f1_m: 0.7862 - val_loss: 0.2410 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2352 - f1_m: 0.7862 - val_loss: 0.2265 - val_f1_m: 0.8259\n",
      "0.78624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 601us/sample - loss: 0.6733 - f1_m: 0.8018 - val_loss: 0.6565 - val_f1_m: 0.7277\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6229 - f1_m: 0.8025 - val_loss: 0.6140 - val_f1_m: 0.7545\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5664 - f1_m: 0.8025 - val_loss: 0.5782 - val_f1_m: 0.7545\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5239 - f1_m: 0.8025 - val_loss: 0.5678 - val_f1_m: 0.7545\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5070 - f1_m: 0.8025 - val_loss: 0.5664 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4986 - f1_m: 0.8025 - val_loss: 0.5590 - val_f1_m: 0.7545\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4924 - f1_m: 0.8025 - val_loss: 0.5531 - val_f1_m: 0.7411\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4854 - f1_m: 0.8025 - val_loss: 0.5480 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4783 - f1_m: 0.8025 - val_loss: 0.5364 - val_f1_m: 0.7545\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4671 - f1_m: 0.8025 - val_loss: 0.5258 - val_f1_m: 0.7411\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4561 - f1_m: 0.8025 - val_loss: 0.5148 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4431 - f1_m: 0.8025 - val_loss: 0.4983 - val_f1_m: 0.7545\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4275 - f1_m: 0.8025 - val_loss: 0.4778 - val_f1_m: 0.7679\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4069 - f1_m: 0.8025 - val_loss: 0.4558 - val_f1_m: 0.7411\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3834 - f1_m: 0.8025 - val_loss: 0.4280 - val_f1_m: 0.7411\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3545 - f1_m: 0.8025 - val_loss: 0.3937 - val_f1_m: 0.7277\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3158 - f1_m: 0.8025 - val_loss: 0.3401 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2721 - f1_m: 0.8025 - val_loss: 0.2995 - val_f1_m: 0.7411\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2427 - f1_m: 0.8025 - val_loss: 0.2750 - val_f1_m: 0.7545\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2246 - f1_m: 0.8025 - val_loss: 0.2609 - val_f1_m: 0.7545\n",
      "0.80249995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 607us/sample - loss: 0.6727 - f1_m: 0.7980 - val_loss: 0.6524 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6228 - f1_m: 0.7987 - val_loss: 0.6060 - val_f1_m: 0.7411\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5697 - f1_m: 0.7987 - val_loss: 0.5658 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5302 - f1_m: 0.7987 - val_loss: 0.5489 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5138 - f1_m: 0.7987 - val_loss: 0.5430 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5050 - f1_m: 0.7987 - val_loss: 0.5372 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4984 - f1_m: 0.7987 - val_loss: 0.5309 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4913 - f1_m: 0.7987 - val_loss: 0.5215 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4817 - f1_m: 0.7987 - val_loss: 0.5121 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4720 - f1_m: 0.7987 - val_loss: 0.5010 - val_f1_m: 0.7277\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4605 - f1_m: 0.7987 - val_loss: 0.4896 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4479 - f1_m: 0.7987 - val_loss: 0.4751 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4321 - f1_m: 0.7987 - val_loss: 0.4571 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4133 - f1_m: 0.7987 - val_loss: 0.4360 - val_f1_m: 0.7411\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3913 - f1_m: 0.7987 - val_loss: 0.4098 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3640 - f1_m: 0.7987 - val_loss: 0.3761 - val_f1_m: 0.7679\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3252 - f1_m: 0.7987 - val_loss: 0.3333 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2841 - f1_m: 0.7987 - val_loss: 0.2971 - val_f1_m: 0.7679\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2537 - f1_m: 0.7987 - val_loss: 0.2751 - val_f1_m: 0.7679\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2344 - f1_m: 0.7987 - val_loss: 0.2631 - val_f1_m: 0.7679\n",
      "0.7987499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 629us/sample - loss: 0.6708 - f1_m: 0.8050 - val_loss: 0.6564 - val_f1_m: 0.7589\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6202 - f1_m: 0.8050 - val_loss: 0.6159 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5642 - f1_m: 0.8050 - val_loss: 0.5837 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5238 - f1_m: 0.8050 - val_loss: 0.5775 - val_f1_m: 0.7455\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5044 - f1_m: 0.8050 - val_loss: 0.5743 - val_f1_m: 0.7321\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4974 - f1_m: 0.8050 - val_loss: 0.5730 - val_f1_m: 0.7589\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4926 - f1_m: 0.8050 - val_loss: 0.5697 - val_f1_m: 0.7589\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4869 - f1_m: 0.8050 - val_loss: 0.5592 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4807 - f1_m: 0.8050 - val_loss: 0.5537 - val_f1_m: 0.7321\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4726 - f1_m: 0.8050 - val_loss: 0.5420 - val_f1_m: 0.7455\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4624 - f1_m: 0.8050 - val_loss: 0.5256 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4498 - f1_m: 0.8050 - val_loss: 0.5162 - val_f1_m: 0.7455\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4370 - f1_m: 0.8050 - val_loss: 0.5002 - val_f1_m: 0.7455\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4210 - f1_m: 0.8050 - val_loss: 0.4771 - val_f1_m: 0.7589\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4004 - f1_m: 0.8050 - val_loss: 0.4502 - val_f1_m: 0.7455\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3763 - f1_m: 0.8050 - val_loss: 0.4206 - val_f1_m: 0.7455\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3501 - f1_m: 0.8050 - val_loss: 0.3829 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3190 - f1_m: 0.8050 - val_loss: 0.3431 - val_f1_m: 0.7589\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2914 - f1_m: 0.8050 - val_loss: 0.3171 - val_f1_m: 0.7455\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2675 - f1_m: 0.8050 - val_loss: 0.2907 - val_f1_m: 0.7455\n",
      "0.80499995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.6720 - f1_m: 0.7950 - val_loss: 0.6508 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6246 - f1_m: 0.7950 - val_loss: 0.6016 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5724 - f1_m: 0.7950 - val_loss: 0.5587 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5339 - f1_m: 0.7950 - val_loss: 0.5359 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5165 - f1_m: 0.7950 - val_loss: 0.5281 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5102 - f1_m: 0.7950 - val_loss: 0.5215 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5043 - f1_m: 0.7950 - val_loss: 0.5155 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4976 - f1_m: 0.7950 - val_loss: 0.5075 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4899 - f1_m: 0.7950 - val_loss: 0.4968 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4794 - f1_m: 0.7950 - val_loss: 0.4844 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4673 - f1_m: 0.7950 - val_loss: 0.4713 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4540 - f1_m: 0.7950 - val_loss: 0.4554 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4370 - f1_m: 0.7950 - val_loss: 0.4358 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4158 - f1_m: 0.7950 - val_loss: 0.4110 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3911 - f1_m: 0.7950 - val_loss: 0.3818 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3633 - f1_m: 0.7950 - val_loss: 0.3473 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3280 - f1_m: 0.7950 - val_loss: 0.3045 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2910 - f1_m: 0.7950 - val_loss: 0.2699 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2613 - f1_m: 0.7950 - val_loss: 0.2423 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2407 - f1_m: 0.7950 - val_loss: 0.2256 - val_f1_m: 0.7545\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6798 - f1_m: 0.7942 - val_loss: 0.6650 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6420 - f1_m: 0.7950 - val_loss: 0.6145 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5842 - f1_m: 0.7950 - val_loss: 0.5660 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5404 - f1_m: 0.7950 - val_loss: 0.5384 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5203 - f1_m: 0.7950 - val_loss: 0.5296 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5121 - f1_m: 0.7950 - val_loss: 0.5237 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5062 - f1_m: 0.7950 - val_loss: 0.5174 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5003 - f1_m: 0.7950 - val_loss: 0.5109 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4939 - f1_m: 0.7950 - val_loss: 0.5033 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4863 - f1_m: 0.7950 - val_loss: 0.4935 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4760 - f1_m: 0.7950 - val_loss: 0.4813 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4627 - f1_m: 0.7950 - val_loss: 0.4646 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4466 - f1_m: 0.7950 - val_loss: 0.4473 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4295 - f1_m: 0.7950 - val_loss: 0.4260 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4082 - f1_m: 0.7950 - val_loss: 0.4028 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3817 - f1_m: 0.7950 - val_loss: 0.3699 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3484 - f1_m: 0.7950 - val_loss: 0.3322 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3136 - f1_m: 0.7950 - val_loss: 0.2987 - val_f1_m: 0.7946\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2823 - f1_m: 0.7950 - val_loss: 0.2645 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2572 - f1_m: 0.7950 - val_loss: 0.2441 - val_f1_m: 0.7946\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 587us/sample - loss: 0.6789 - f1_m: 0.7962 - val_loss: 0.6657 - val_f1_m: 0.7500\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6484 - f1_m: 0.7962 - val_loss: 0.6339 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6093 - f1_m: 0.7962 - val_loss: 0.5966 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5682 - f1_m: 0.7962 - val_loss: 0.5615 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5360 - f1_m: 0.7962 - val_loss: 0.5440 - val_f1_m: 0.7634\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5193 - f1_m: 0.7962 - val_loss: 0.5367 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5116 - f1_m: 0.7962 - val_loss: 0.5313 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5057 - f1_m: 0.7962 - val_loss: 0.5257 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5005 - f1_m: 0.7962 - val_loss: 0.5194 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4956 - f1_m: 0.7962 - val_loss: 0.5138 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4894 - f1_m: 0.7962 - val_loss: 0.5068 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4833 - f1_m: 0.7962 - val_loss: 0.4999 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4763 - f1_m: 0.7962 - val_loss: 0.4888 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4651 - f1_m: 0.7962 - val_loss: 0.4774 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4537 - f1_m: 0.7962 - val_loss: 0.4617 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4392 - f1_m: 0.7962 - val_loss: 0.4457 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4223 - f1_m: 0.7962 - val_loss: 0.4227 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3969 - f1_m: 0.7962 - val_loss: 0.3910 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3658 - f1_m: 0.7962 - val_loss: 0.3545 - val_f1_m: 0.7902\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3320 - f1_m: 0.7962 - val_loss: 0.3176 - val_f1_m: 0.7500\n",
      "0.7962499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.6794 - f1_m: 0.7912 - val_loss: 0.6641 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6491 - f1_m: 0.7912 - val_loss: 0.6278 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6102 - f1_m: 0.7912 - val_loss: 0.5843 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5684 - f1_m: 0.7912 - val_loss: 0.5447 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5375 - f1_m: 0.7912 - val_loss: 0.5233 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5228 - f1_m: 0.7912 - val_loss: 0.5148 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5159 - f1_m: 0.7912 - val_loss: 0.5084 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5111 - f1_m: 0.7912 - val_loss: 0.5032 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5060 - f1_m: 0.7912 - val_loss: 0.4981 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5008 - f1_m: 0.7912 - val_loss: 0.4924 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4952 - f1_m: 0.7912 - val_loss: 0.4865 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4893 - f1_m: 0.7912 - val_loss: 0.4797 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4811 - f1_m: 0.7912 - val_loss: 0.4719 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4719 - f1_m: 0.7912 - val_loss: 0.4609 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4594 - f1_m: 0.7912 - val_loss: 0.4474 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4441 - f1_m: 0.7912 - val_loss: 0.4305 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4265 - f1_m: 0.7912 - val_loss: 0.4102 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4047 - f1_m: 0.7912 - val_loss: 0.3886 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3806 - f1_m: 0.7912 - val_loss: 0.3597 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3454 - f1_m: 0.7912 - val_loss: 0.3274 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 627us/sample - loss: 0.6780 - f1_m: 0.8000 - val_loss: 0.6667 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6466 - f1_m: 0.8000 - val_loss: 0.6352 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6064 - f1_m: 0.8000 - val_loss: 0.5997 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5624 - f1_m: 0.8000 - val_loss: 0.5695 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5300 - f1_m: 0.8000 - val_loss: 0.5565 - val_f1_m: 0.7500\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5138 - f1_m: 0.8000 - val_loss: 0.5517 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5067 - f1_m: 0.8000 - val_loss: 0.5478 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5010 - f1_m: 0.8000 - val_loss: 0.5413 - val_f1_m: 0.7366\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4953 - f1_m: 0.8000 - val_loss: 0.5373 - val_f1_m: 0.7500\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4895 - f1_m: 0.8000 - val_loss: 0.5311 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4834 - f1_m: 0.8000 - val_loss: 0.5241 - val_f1_m: 0.7500\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4764 - f1_m: 0.8000 - val_loss: 0.5164 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4678 - f1_m: 0.8000 - val_loss: 0.5059 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4574 - f1_m: 0.8000 - val_loss: 0.4925 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4418 - f1_m: 0.8000 - val_loss: 0.4746 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4247 - f1_m: 0.8000 - val_loss: 0.4551 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4038 - f1_m: 0.8000 - val_loss: 0.4321 - val_f1_m: 0.7634\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3804 - f1_m: 0.8000 - val_loss: 0.4046 - val_f1_m: 0.7768\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3457 - f1_m: 0.8000 - val_loss: 0.3652 - val_f1_m: 0.7634\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3078 - f1_m: 0.8000 - val_loss: 0.3284 - val_f1_m: 0.7366\n",
      "0.79999995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 643us/sample - loss: 0.6741 - f1_m: 0.7828 - val_loss: 0.6441 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.6270 - f1_m: 0.7850 - val_loss: 0.5848 - val_f1_m: 0.8437\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5820 - f1_m: 0.7850 - val_loss: 0.5243 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5464 - f1_m: 0.7850 - val_loss: 0.4903 - val_f1_m: 0.8437\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5300 - f1_m: 0.7850 - val_loss: 0.4766 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5225 - f1_m: 0.7850 - val_loss: 0.4665 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5156 - f1_m: 0.7850 - val_loss: 0.4600 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5075 - f1_m: 0.7850 - val_loss: 0.4534 - val_f1_m: 0.8304\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4970 - f1_m: 0.7850 - val_loss: 0.4405 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4830 - f1_m: 0.7850 - val_loss: 0.4287 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4680 - f1_m: 0.7850 - val_loss: 0.4114 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4501 - f1_m: 0.7850 - val_loss: 0.3926 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4252 - f1_m: 0.7850 - val_loss: 0.3677 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3966 - f1_m: 0.7850 - val_loss: 0.3405 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3613 - f1_m: 0.7850 - val_loss: 0.3124 - val_f1_m: 0.8437\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3229 - f1_m: 0.7850 - val_loss: 0.2793 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2838 - f1_m: 0.7850 - val_loss: 0.2448 - val_f1_m: 0.8437\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2520 - f1_m: 0.7850 - val_loss: 0.2268 - val_f1_m: 0.8304\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2334 - f1_m: 0.7850 - val_loss: 0.2117 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2213 - f1_m: 0.7850 - val_loss: 0.2027 - val_f1_m: 0.8170\n",
      "0.7849999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 620us/sample - loss: 0.6728 - f1_m: 0.7837 - val_loss: 0.6424 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6267 - f1_m: 0.7837 - val_loss: 0.5811 - val_f1_m: 0.8482\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5807 - f1_m: 0.7837 - val_loss: 0.5200 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5472 - f1_m: 0.7837 - val_loss: 0.4838 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5320 - f1_m: 0.7837 - val_loss: 0.4702 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5238 - f1_m: 0.7837 - val_loss: 0.4594 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5169 - f1_m: 0.7837 - val_loss: 0.4523 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5088 - f1_m: 0.7837 - val_loss: 0.4463 - val_f1_m: 0.8348\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4983 - f1_m: 0.7837 - val_loss: 0.4346 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4846 - f1_m: 0.7837 - val_loss: 0.4205 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4700 - f1_m: 0.7837 - val_loss: 0.4067 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4520 - f1_m: 0.7837 - val_loss: 0.3875 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4285 - f1_m: 0.7837 - val_loss: 0.3647 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4012 - f1_m: 0.7837 - val_loss: 0.3365 - val_f1_m: 0.8482\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3678 - f1_m: 0.7837 - val_loss: 0.3065 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3304 - f1_m: 0.7837 - val_loss: 0.2747 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2912 - f1_m: 0.7837 - val_loss: 0.2418 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2593 - f1_m: 0.7837 - val_loss: 0.2177 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2403 - f1_m: 0.7837 - val_loss: 0.2013 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2285 - f1_m: 0.7837 - val_loss: 0.1976 - val_f1_m: 0.8482\n",
      "0.78374994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 615us/sample - loss: 0.6734 - f1_m: 0.7950 - val_loss: 0.6506 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6253 - f1_m: 0.7950 - val_loss: 0.6024 - val_f1_m: 0.7545\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5722 - f1_m: 0.7950 - val_loss: 0.5561 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5335 - f1_m: 0.7950 - val_loss: 0.5326 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5179 - f1_m: 0.7950 - val_loss: 0.5240 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5089 - f1_m: 0.7950 - val_loss: 0.5165 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5006 - f1_m: 0.7950 - val_loss: 0.5090 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4929 - f1_m: 0.7950 - val_loss: 0.4991 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4814 - f1_m: 0.7950 - val_loss: 0.4860 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4687 - f1_m: 0.7950 - val_loss: 0.4734 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4543 - f1_m: 0.7950 - val_loss: 0.4569 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4368 - f1_m: 0.7950 - val_loss: 0.4372 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4142 - f1_m: 0.7950 - val_loss: 0.4120 - val_f1_m: 0.7545\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3873 - f1_m: 0.7950 - val_loss: 0.3811 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3551 - f1_m: 0.7950 - val_loss: 0.3444 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3138 - f1_m: 0.7950 - val_loss: 0.3003 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2724 - f1_m: 0.7950 - val_loss: 0.2619 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2440 - f1_m: 0.7950 - val_loss: 0.2410 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2283 - f1_m: 0.7950 - val_loss: 0.2286 - val_f1_m: 0.7812\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2170 - f1_m: 0.7950 - val_loss: 0.2197 - val_f1_m: 0.7545\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 620us/sample - loss: 0.6789 - f1_m: 0.7837 - val_loss: 0.6594 - val_f1_m: 0.8348\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6487 - f1_m: 0.7837 - val_loss: 0.6182 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6110 - f1_m: 0.7837 - val_loss: 0.5667 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5715 - f1_m: 0.7837 - val_loss: 0.5171 - val_f1_m: 0.8482\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5454 - f1_m: 0.7837 - val_loss: 0.4859 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5314 - f1_m: 0.7837 - val_loss: 0.4717 - val_f1_m: 0.8482\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5226 - f1_m: 0.7837 - val_loss: 0.4613 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5138 - f1_m: 0.7837 - val_loss: 0.4520 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5040 - f1_m: 0.7837 - val_loss: 0.4408 - val_f1_m: 0.8482\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4900 - f1_m: 0.7837 - val_loss: 0.4286 - val_f1_m: 0.8482\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4748 - f1_m: 0.7837 - val_loss: 0.4141 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4565 - f1_m: 0.7837 - val_loss: 0.3961 - val_f1_m: 0.8482\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4334 - f1_m: 0.7837 - val_loss: 0.3727 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4027 - f1_m: 0.7837 - val_loss: 0.3429 - val_f1_m: 0.8348\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3691 - f1_m: 0.7837 - val_loss: 0.3107 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3371 - f1_m: 0.7837 - val_loss: 0.2842 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3118 - f1_m: 0.7837 - val_loss: 0.2599 - val_f1_m: 0.8482\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2925 - f1_m: 0.7837 - val_loss: 0.2428 - val_f1_m: 0.8348\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2744 - f1_m: 0.7837 - val_loss: 0.2284 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2586 - f1_m: 0.7837 - val_loss: 0.2162 - val_f1_m: 0.8214\n",
      "0.78374994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6796 - f1_m: 0.7850 - val_loss: 0.6606 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6499 - f1_m: 0.7850 - val_loss: 0.6209 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6126 - f1_m: 0.7850 - val_loss: 0.5712 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5730 - f1_m: 0.7850 - val_loss: 0.5222 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5460 - f1_m: 0.7850 - val_loss: 0.4920 - val_f1_m: 0.8437\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5315 - f1_m: 0.7850 - val_loss: 0.4798 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5251 - f1_m: 0.7850 - val_loss: 0.4733 - val_f1_m: 0.8437\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5197 - f1_m: 0.7850 - val_loss: 0.4671 - val_f1_m: 0.8304\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5148 - f1_m: 0.7850 - val_loss: 0.4627 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5097 - f1_m: 0.7850 - val_loss: 0.4576 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5037 - f1_m: 0.7850 - val_loss: 0.4518 - val_f1_m: 0.8437\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4972 - f1_m: 0.7850 - val_loss: 0.4447 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4888 - f1_m: 0.7850 - val_loss: 0.4361 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4798 - f1_m: 0.7850 - val_loss: 0.4288 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4654 - f1_m: 0.7850 - val_loss: 0.4130 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4500 - f1_m: 0.7850 - val_loss: 0.3988 - val_f1_m: 0.8304\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4313 - f1_m: 0.7850 - val_loss: 0.3806 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4099 - f1_m: 0.7850 - val_loss: 0.3571 - val_f1_m: 0.8437\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3835 - f1_m: 0.7850 - val_loss: 0.3301 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3550 - f1_m: 0.7850 - val_loss: 0.3044 - val_f1_m: 0.8437\n",
      "0.7849999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 596us/sample - loss: 0.6770 - f1_m: 0.7905 - val_loss: 0.6523 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6291 - f1_m: 0.7912 - val_loss: 0.5984 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5784 - f1_m: 0.7912 - val_loss: 0.5470 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5411 - f1_m: 0.7912 - val_loss: 0.5159 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5216 - f1_m: 0.7912 - val_loss: 0.5033 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5119 - f1_m: 0.7912 - val_loss: 0.4935 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4994 - f1_m: 0.7912 - val_loss: 0.4811 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4850 - f1_m: 0.7912 - val_loss: 0.4679 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4699 - f1_m: 0.7912 - val_loss: 0.4526 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4489 - f1_m: 0.7912 - val_loss: 0.4320 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4234 - f1_m: 0.7912 - val_loss: 0.4073 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3938 - f1_m: 0.7912 - val_loss: 0.3783 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3601 - f1_m: 0.7912 - val_loss: 0.3461 - val_f1_m: 0.7679\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3270 - f1_m: 0.7912 - val_loss: 0.3176 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2995 - f1_m: 0.7912 - val_loss: 0.2947 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2767 - f1_m: 0.7912 - val_loss: 0.2745 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2561 - f1_m: 0.7912 - val_loss: 0.2563 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2380 - f1_m: 0.7912 - val_loss: 0.2387 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2235 - f1_m: 0.7912 - val_loss: 0.2266 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2125 - f1_m: 0.8150 - val_loss: 0.2183 - val_f1_m: 0.9018\n",
      "0.81499994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.6735 - f1_m: 0.7937 - val_loss: 0.6507 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6270 - f1_m: 0.7937 - val_loss: 0.6001 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5733 - f1_m: 0.7937 - val_loss: 0.5527 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5345 - f1_m: 0.7937 - val_loss: 0.5271 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5189 - f1_m: 0.7937 - val_loss: 0.5180 - val_f1_m: 0.7589\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5111 - f1_m: 0.7937 - val_loss: 0.5113 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5044 - f1_m: 0.7937 - val_loss: 0.5044 - val_f1_m: 0.7589\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4974 - f1_m: 0.7937 - val_loss: 0.4961 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4872 - f1_m: 0.7937 - val_loss: 0.4843 - val_f1_m: 0.7589\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4747 - f1_m: 0.7937 - val_loss: 0.4716 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4610 - f1_m: 0.7937 - val_loss: 0.4565 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4443 - f1_m: 0.7937 - val_loss: 0.4372 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4234 - f1_m: 0.7937 - val_loss: 0.4130 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3964 - f1_m: 0.7937 - val_loss: 0.3849 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3650 - f1_m: 0.7937 - val_loss: 0.3504 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3289 - f1_m: 0.7937 - val_loss: 0.3102 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2855 - f1_m: 0.7937 - val_loss: 0.2754 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2536 - f1_m: 0.7937 - val_loss: 0.2469 - val_f1_m: 0.7589\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2320 - f1_m: 0.7937 - val_loss: 0.2329 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2184 - f1_m: 0.7937 - val_loss: 0.2221 - val_f1_m: 0.8125\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 597us/sample - loss: 0.6799 - f1_m: 0.7868 - val_loss: 0.6613 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6493 - f1_m: 0.7875 - val_loss: 0.6232 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6121 - f1_m: 0.7875 - val_loss: 0.5759 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5720 - f1_m: 0.7875 - val_loss: 0.5286 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5426 - f1_m: 0.7875 - val_loss: 0.4997 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5272 - f1_m: 0.7875 - val_loss: 0.4878 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5213 - f1_m: 0.7875 - val_loss: 0.4806 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5152 - f1_m: 0.7875 - val_loss: 0.4759 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5095 - f1_m: 0.7875 - val_loss: 0.4695 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5033 - f1_m: 0.7875 - val_loss: 0.4652 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4967 - f1_m: 0.7875 - val_loss: 0.4590 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4897 - f1_m: 0.7875 - val_loss: 0.4509 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4813 - f1_m: 0.7875 - val_loss: 0.4434 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4705 - f1_m: 0.7875 - val_loss: 0.4354 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4574 - f1_m: 0.7875 - val_loss: 0.4216 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4419 - f1_m: 0.7875 - val_loss: 0.4062 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4217 - f1_m: 0.7875 - val_loss: 0.3884 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3980 - f1_m: 0.7875 - val_loss: 0.3658 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3713 - f1_m: 0.7875 - val_loss: 0.3388 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3359 - f1_m: 0.7875 - val_loss: 0.3064 - val_f1_m: 0.8348\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.6785 - f1_m: 0.7896 - val_loss: 0.6625 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6482 - f1_m: 0.7912 - val_loss: 0.6265 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6095 - f1_m: 0.7912 - val_loss: 0.5827 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5679 - f1_m: 0.7912 - val_loss: 0.5417 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5378 - f1_m: 0.7912 - val_loss: 0.5180 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5234 - f1_m: 0.7912 - val_loss: 0.5081 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5164 - f1_m: 0.7912 - val_loss: 0.5017 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5110 - f1_m: 0.7912 - val_loss: 0.4957 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5050 - f1_m: 0.7912 - val_loss: 0.4896 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4991 - f1_m: 0.7912 - val_loss: 0.4834 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4933 - f1_m: 0.7912 - val_loss: 0.4762 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4851 - f1_m: 0.7912 - val_loss: 0.4681 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4757 - f1_m: 0.7912 - val_loss: 0.4565 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4625 - f1_m: 0.7912 - val_loss: 0.4425 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4468 - f1_m: 0.7912 - val_loss: 0.4250 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4280 - f1_m: 0.7912 - val_loss: 0.4038 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4063 - f1_m: 0.7912 - val_loss: 0.3820 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3833 - f1_m: 0.7912 - val_loss: 0.3503 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3469 - f1_m: 0.7912 - val_loss: 0.3117 - val_f1_m: 0.7812\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3096 - f1_m: 0.7912 - val_loss: 0.2735 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 585us/sample - loss: 0.6793 - f1_m: 0.7904 - val_loss: 0.6631 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6487 - f1_m: 0.7912 - val_loss: 0.6268 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6086 - f1_m: 0.7912 - val_loss: 0.5852 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5693 - f1_m: 0.7912 - val_loss: 0.5446 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5378 - f1_m: 0.7912 - val_loss: 0.5228 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5239 - f1_m: 0.7912 - val_loss: 0.5123 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5161 - f1_m: 0.7912 - val_loss: 0.5056 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5104 - f1_m: 0.7912 - val_loss: 0.4997 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5048 - f1_m: 0.7912 - val_loss: 0.4938 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4990 - f1_m: 0.7912 - val_loss: 0.4877 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4927 - f1_m: 0.7912 - val_loss: 0.4807 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4855 - f1_m: 0.7912 - val_loss: 0.4724 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4768 - f1_m: 0.7912 - val_loss: 0.4616 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4649 - f1_m: 0.7912 - val_loss: 0.4484 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4502 - f1_m: 0.7912 - val_loss: 0.4317 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4331 - f1_m: 0.7912 - val_loss: 0.4120 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4124 - f1_m: 0.7912 - val_loss: 0.3894 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3897 - f1_m: 0.7912 - val_loss: 0.3637 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3618 - f1_m: 0.7912 - val_loss: 0.3351 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3322 - f1_m: 0.7912 - val_loss: 0.3050 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 589us/sample - loss: 0.6773 - f1_m: 0.7912 - val_loss: 0.6525 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6299 - f1_m: 0.7912 - val_loss: 0.6004 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5802 - f1_m: 0.7912 - val_loss: 0.5512 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5421 - f1_m: 0.7912 - val_loss: 0.5204 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5234 - f1_m: 0.7912 - val_loss: 0.5079 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5144 - f1_m: 0.7912 - val_loss: 0.4982 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5041 - f1_m: 0.7912 - val_loss: 0.4856 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4907 - f1_m: 0.7912 - val_loss: 0.4722 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4762 - f1_m: 0.7912 - val_loss: 0.4566 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4592 - f1_m: 0.7912 - val_loss: 0.4369 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4376 - f1_m: 0.7912 - val_loss: 0.4122 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4109 - f1_m: 0.7912 - val_loss: 0.3831 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3812 - f1_m: 0.7912 - val_loss: 0.3507 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3493 - f1_m: 0.7912 - val_loss: 0.3175 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3209 - f1_m: 0.7912 - val_loss: 0.2910 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2978 - f1_m: 0.7912 - val_loss: 0.2667 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2765 - f1_m: 0.7912 - val_loss: 0.2461 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2580 - f1_m: 0.7912 - val_loss: 0.2261 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2404 - f1_m: 0.7912 - val_loss: 0.2115 - val_f1_m: 0.7812\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2284 - f1_m: 0.7912 - val_loss: 0.1982 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 606us/sample - loss: 0.6806 - f1_m: 0.7875 - val_loss: 0.6629 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6499 - f1_m: 0.7875 - val_loss: 0.6262 - val_f1_m: 0.8348\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6131 - f1_m: 0.7875 - val_loss: 0.5791 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5714 - f1_m: 0.7875 - val_loss: 0.5360 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5406 - f1_m: 0.7875 - val_loss: 0.5079 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5292 - f1_m: 0.7875 - val_loss: 0.4927 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5205 - f1_m: 0.7875 - val_loss: 0.4869 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5144 - f1_m: 0.7875 - val_loss: 0.4795 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5089 - f1_m: 0.7875 - val_loss: 0.4738 - val_f1_m: 0.8214\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5027 - f1_m: 0.7875 - val_loss: 0.4657 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4957 - f1_m: 0.7875 - val_loss: 0.4576 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4876 - f1_m: 0.7875 - val_loss: 0.4492 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4766 - f1_m: 0.7875 - val_loss: 0.4353 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4627 - f1_m: 0.7875 - val_loss: 0.4210 - val_f1_m: 0.8348\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4456 - f1_m: 0.7875 - val_loss: 0.4014 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4245 - f1_m: 0.7875 - val_loss: 0.3781 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4011 - f1_m: 0.7875 - val_loss: 0.3529 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3734 - f1_m: 0.7875 - val_loss: 0.3226 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3433 - f1_m: 0.7875 - val_loss: 0.2911 - val_f1_m: 0.7679\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3124 - f1_m: 0.7875 - val_loss: 0.2600 - val_f1_m: 0.7946\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 587us/sample - loss: 0.6800 - f1_m: 0.7887 - val_loss: 0.6623 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6501 - f1_m: 0.7887 - val_loss: 0.6253 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6126 - f1_m: 0.7887 - val_loss: 0.5785 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5729 - f1_m: 0.7887 - val_loss: 0.5332 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5442 - f1_m: 0.7887 - val_loss: 0.5044 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5282 - f1_m: 0.7887 - val_loss: 0.4935 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5206 - f1_m: 0.7887 - val_loss: 0.4862 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5143 - f1_m: 0.7887 - val_loss: 0.4805 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5084 - f1_m: 0.7887 - val_loss: 0.4750 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5023 - f1_m: 0.7887 - val_loss: 0.4686 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4950 - f1_m: 0.7887 - val_loss: 0.4623 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4867 - f1_m: 0.7887 - val_loss: 0.4533 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4749 - f1_m: 0.7887 - val_loss: 0.4423 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4612 - f1_m: 0.7887 - val_loss: 0.4281 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4443 - f1_m: 0.7887 - val_loss: 0.4119 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4234 - f1_m: 0.7887 - val_loss: 0.3930 - val_f1_m: 0.8304\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4019 - f1_m: 0.7887 - val_loss: 0.3674 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3738 - f1_m: 0.7887 - val_loss: 0.3407 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3410 - f1_m: 0.7887 - val_loss: 0.3039 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3042 - f1_m: 0.7887 - val_loss: 0.2714 - val_f1_m: 0.7902\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 586us/sample - loss: 0.6790 - f1_m: 0.7925 - val_loss: 0.6628 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6475 - f1_m: 0.7925 - val_loss: 0.6262 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6087 - f1_m: 0.7925 - val_loss: 0.5818 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5677 - f1_m: 0.7925 - val_loss: 0.5418 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5389 - f1_m: 0.7925 - val_loss: 0.5185 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5251 - f1_m: 0.7925 - val_loss: 0.5099 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5187 - f1_m: 0.7925 - val_loss: 0.5038 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5134 - f1_m: 0.7925 - val_loss: 0.4993 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5079 - f1_m: 0.7925 - val_loss: 0.4945 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5025 - f1_m: 0.7925 - val_loss: 0.4901 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4969 - f1_m: 0.7925 - val_loss: 0.4843 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4901 - f1_m: 0.7925 - val_loss: 0.4786 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4818 - f1_m: 0.7925 - val_loss: 0.4705 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4712 - f1_m: 0.7925 - val_loss: 0.4594 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4579 - f1_m: 0.7925 - val_loss: 0.4463 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4418 - f1_m: 0.7925 - val_loss: 0.4307 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4236 - f1_m: 0.7925 - val_loss: 0.4130 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4031 - f1_m: 0.7925 - val_loss: 0.3884 - val_f1_m: 0.7768\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3711 - f1_m: 0.7925 - val_loss: 0.3579 - val_f1_m: 0.7768\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3379 - f1_m: 0.7925 - val_loss: 0.3232 - val_f1_m: 0.8170\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6761 - f1_m: 0.7962 - val_loss: 0.6544 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6290 - f1_m: 0.7962 - val_loss: 0.6074 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5772 - f1_m: 0.7962 - val_loss: 0.5647 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5384 - f1_m: 0.7962 - val_loss: 0.5411 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5185 - f1_m: 0.7962 - val_loss: 0.5316 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5089 - f1_m: 0.7962 - val_loss: 0.5234 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4978 - f1_m: 0.7962 - val_loss: 0.5099 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4845 - f1_m: 0.7962 - val_loss: 0.4966 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4699 - f1_m: 0.7962 - val_loss: 0.4807 - val_f1_m: 0.7634\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4521 - f1_m: 0.7962 - val_loss: 0.4622 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4302 - f1_m: 0.7962 - val_loss: 0.4359 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4035 - f1_m: 0.7962 - val_loss: 0.4088 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3735 - f1_m: 0.7962 - val_loss: 0.3760 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3417 - f1_m: 0.7962 - val_loss: 0.3449 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3134 - f1_m: 0.7962 - val_loss: 0.3186 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2899 - f1_m: 0.7962 - val_loss: 0.2961 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2692 - f1_m: 0.7962 - val_loss: 0.2763 - val_f1_m: 0.7634\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2503 - f1_m: 0.7962 - val_loss: 0.2586 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2328 - f1_m: 0.7962 - val_loss: 0.2414 - val_f1_m: 0.7768\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2197 - f1_m: 0.7962 - val_loss: 0.2301 - val_f1_m: 0.8036\n",
      "0.7962499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 609us/sample - loss: 0.6783 - f1_m: 0.7934 - val_loss: 0.6644 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6458 - f1_m: 0.7950 - val_loss: 0.6305 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6064 - f1_m: 0.7950 - val_loss: 0.5899 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5636 - f1_m: 0.7950 - val_loss: 0.5567 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5343 - f1_m: 0.7950 - val_loss: 0.5397 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5210 - f1_m: 0.7950 - val_loss: 0.5325 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5134 - f1_m: 0.7950 - val_loss: 0.5269 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5079 - f1_m: 0.7950 - val_loss: 0.5214 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5021 - f1_m: 0.7950 - val_loss: 0.5161 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4963 - f1_m: 0.7950 - val_loss: 0.5104 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4902 - f1_m: 0.7950 - val_loss: 0.5039 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4830 - f1_m: 0.7950 - val_loss: 0.4968 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4729 - f1_m: 0.7950 - val_loss: 0.4854 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4612 - f1_m: 0.7950 - val_loss: 0.4729 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4465 - f1_m: 0.7950 - val_loss: 0.4560 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4302 - f1_m: 0.7950 - val_loss: 0.4376 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4087 - f1_m: 0.7950 - val_loss: 0.4145 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3841 - f1_m: 0.7950 - val_loss: 0.3881 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3522 - f1_m: 0.7950 - val_loss: 0.3547 - val_f1_m: 0.7812\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3189 - f1_m: 0.7950 - val_loss: 0.3234 - val_f1_m: 0.7679\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 619us/sample - loss: 0.6789 - f1_m: 0.7875 - val_loss: 0.6608 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6483 - f1_m: 0.7875 - val_loss: 0.6227 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6104 - f1_m: 0.7875 - val_loss: 0.5754 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5709 - f1_m: 0.7875 - val_loss: 0.5301 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5401 - f1_m: 0.7875 - val_loss: 0.5046 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5270 - f1_m: 0.7875 - val_loss: 0.4917 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5209 - f1_m: 0.7875 - val_loss: 0.4843 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5160 - f1_m: 0.7875 - val_loss: 0.4787 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5109 - f1_m: 0.7875 - val_loss: 0.4736 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5061 - f1_m: 0.7875 - val_loss: 0.4678 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5011 - f1_m: 0.7875 - val_loss: 0.4624 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4945 - f1_m: 0.7875 - val_loss: 0.4548 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4866 - f1_m: 0.7875 - val_loss: 0.4463 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4775 - f1_m: 0.7875 - val_loss: 0.4362 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4658 - f1_m: 0.7875 - val_loss: 0.4222 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4526 - f1_m: 0.7875 - val_loss: 0.4071 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4355 - f1_m: 0.7875 - val_loss: 0.3878 - val_f1_m: 0.8348\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4145 - f1_m: 0.7875 - val_loss: 0.3655 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3900 - f1_m: 0.7875 - val_loss: 0.3354 - val_f1_m: 0.8348\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3580 - f1_m: 0.7875 - val_loss: 0.3083 - val_f1_m: 0.8214\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 620us/sample - loss: 0.6794 - f1_m: 0.7937 - val_loss: 0.6640 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6480 - f1_m: 0.7937 - val_loss: 0.6287 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6082 - f1_m: 0.7937 - val_loss: 0.5853 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5659 - f1_m: 0.7937 - val_loss: 0.5465 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5343 - f1_m: 0.7937 - val_loss: 0.5279 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5204 - f1_m: 0.7937 - val_loss: 0.5199 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5137 - f1_m: 0.7937 - val_loss: 0.5146 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5083 - f1_m: 0.7937 - val_loss: 0.5098 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5031 - f1_m: 0.7937 - val_loss: 0.5051 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4977 - f1_m: 0.7937 - val_loss: 0.5000 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4919 - f1_m: 0.7937 - val_loss: 0.4942 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4857 - f1_m: 0.7937 - val_loss: 0.4875 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4783 - f1_m: 0.7937 - val_loss: 0.4792 - val_f1_m: 0.7723\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4676 - f1_m: 0.7937 - val_loss: 0.4683 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4552 - f1_m: 0.7937 - val_loss: 0.4553 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4400 - f1_m: 0.7937 - val_loss: 0.4398 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4218 - f1_m: 0.7937 - val_loss: 0.4206 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4000 - f1_m: 0.7937 - val_loss: 0.3975 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3705 - f1_m: 0.7937 - val_loss: 0.3630 - val_f1_m: 0.7991\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3338 - f1_m: 0.7937 - val_loss: 0.3274 - val_f1_m: 0.7723\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 626us/sample - loss: 0.6727 - f1_m: 0.7962 - val_loss: 0.6509 - val_f1_m: 0.7500\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.6225 - f1_m: 0.7962 - val_loss: 0.6017 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5709 - f1_m: 0.7962 - val_loss: 0.5567 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5329 - f1_m: 0.7962 - val_loss: 0.5361 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5151 - f1_m: 0.7962 - val_loss: 0.5286 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5074 - f1_m: 0.7962 - val_loss: 0.5229 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5010 - f1_m: 0.7962 - val_loss: 0.5161 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4942 - f1_m: 0.7962 - val_loss: 0.5089 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4856 - f1_m: 0.7962 - val_loss: 0.4980 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4725 - f1_m: 0.7962 - val_loss: 0.4834 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4580 - f1_m: 0.7962 - val_loss: 0.4682 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4423 - f1_m: 0.7962 - val_loss: 0.4491 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4207 - f1_m: 0.7962 - val_loss: 0.4247 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3953 - f1_m: 0.7962 - val_loss: 0.3955 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3655 - f1_m: 0.7962 - val_loss: 0.3621 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3328 - f1_m: 0.7962 - val_loss: 0.3252 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2986 - f1_m: 0.7962 - val_loss: 0.2903 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2703 - f1_m: 0.7962 - val_loss: 0.2638 - val_f1_m: 0.7500\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2471 - f1_m: 0.7962 - val_loss: 0.2420 - val_f1_m: 0.7634\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2303 - f1_m: 0.7962 - val_loss: 0.2285 - val_f1_m: 0.7902\n",
      "0.7962499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 589us/sample - loss: 0.6745 - f1_m: 0.7900 - val_loss: 0.6483 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6269 - f1_m: 0.7900 - val_loss: 0.5943 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5765 - f1_m: 0.7900 - val_loss: 0.5397 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5374 - f1_m: 0.7900 - val_loss: 0.5086 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5214 - f1_m: 0.7900 - val_loss: 0.4968 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5138 - f1_m: 0.7900 - val_loss: 0.4897 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5069 - f1_m: 0.7900 - val_loss: 0.4823 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4999 - f1_m: 0.7900 - val_loss: 0.4733 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4892 - f1_m: 0.7900 - val_loss: 0.4627 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4778 - f1_m: 0.7900 - val_loss: 0.4501 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4654 - f1_m: 0.7900 - val_loss: 0.4355 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4487 - f1_m: 0.7900 - val_loss: 0.4162 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4276 - f1_m: 0.7900 - val_loss: 0.3920 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4016 - f1_m: 0.7900 - val_loss: 0.3627 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3661 - f1_m: 0.7900 - val_loss: 0.3188 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3175 - f1_m: 0.7900 - val_loss: 0.2703 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2768 - f1_m: 0.7900 - val_loss: 0.2334 - val_f1_m: 0.8259\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2481 - f1_m: 0.7900 - val_loss: 0.2133 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2310 - f1_m: 0.7900 - val_loss: 0.2021 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2199 - f1_m: 0.7900 - val_loss: 0.1905 - val_f1_m: 0.8125\n",
      "0.7899999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 586us/sample - loss: 0.6791 - f1_m: 0.8012 - val_loss: 0.6682 - val_f1_m: 0.7723\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6460 - f1_m: 0.8012 - val_loss: 0.6388 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6063 - f1_m: 0.8012 - val_loss: 0.6049 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5613 - f1_m: 0.8012 - val_loss: 0.5766 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5274 - f1_m: 0.8012 - val_loss: 0.5648 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5121 - f1_m: 0.8012 - val_loss: 0.5618 - val_f1_m: 0.7589\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5032 - f1_m: 0.8012 - val_loss: 0.5562 - val_f1_m: 0.7455\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4972 - f1_m: 0.8012 - val_loss: 0.5512 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4918 - f1_m: 0.8012 - val_loss: 0.5466 - val_f1_m: 0.7589\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4860 - f1_m: 0.8012 - val_loss: 0.5405 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4801 - f1_m: 0.8012 - val_loss: 0.5337 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4728 - f1_m: 0.8012 - val_loss: 0.5253 - val_f1_m: 0.7455\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4644 - f1_m: 0.8012 - val_loss: 0.5145 - val_f1_m: 0.7455\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4525 - f1_m: 0.8012 - val_loss: 0.5011 - val_f1_m: 0.7455\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4388 - f1_m: 0.8012 - val_loss: 0.4827 - val_f1_m: 0.7321\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4221 - f1_m: 0.8012 - val_loss: 0.4668 - val_f1_m: 0.7455\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4013 - f1_m: 0.8012 - val_loss: 0.4401 - val_f1_m: 0.7589\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3767 - f1_m: 0.8012 - val_loss: 0.4080 - val_f1_m: 0.7455\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3427 - f1_m: 0.8012 - val_loss: 0.3671 - val_f1_m: 0.7455\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3058 - f1_m: 0.8012 - val_loss: 0.3342 - val_f1_m: 0.7857\n",
      "0.8012499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 586us/sample - loss: 0.6720 - f1_m: 0.8012 - val_loss: 0.6552 - val_f1_m: 0.7321\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6232 - f1_m: 0.8012 - val_loss: 0.6127 - val_f1_m: 0.7455\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5693 - f1_m: 0.8012 - val_loss: 0.5775 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5269 - f1_m: 0.8012 - val_loss: 0.5661 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5087 - f1_m: 0.8012 - val_loss: 0.5641 - val_f1_m: 0.7589\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5014 - f1_m: 0.8012 - val_loss: 0.5596 - val_f1_m: 0.7187\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4959 - f1_m: 0.8012 - val_loss: 0.5529 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4903 - f1_m: 0.8012 - val_loss: 0.5495 - val_f1_m: 0.7321\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4842 - f1_m: 0.8012 - val_loss: 0.5355 - val_f1_m: 0.7455\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4740 - f1_m: 0.8012 - val_loss: 0.5264 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4634 - f1_m: 0.8012 - val_loss: 0.5118 - val_f1_m: 0.7455\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4523 - f1_m: 0.8012 - val_loss: 0.5013 - val_f1_m: 0.7589\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4387 - f1_m: 0.8012 - val_loss: 0.4820 - val_f1_m: 0.7455\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4214 - f1_m: 0.8012 - val_loss: 0.4598 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4010 - f1_m: 0.8012 - val_loss: 0.4357 - val_f1_m: 0.7455\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3761 - f1_m: 0.8012 - val_loss: 0.4043 - val_f1_m: 0.7455\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3467 - f1_m: 0.8012 - val_loss: 0.3674 - val_f1_m: 0.7455\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3115 - f1_m: 0.8012 - val_loss: 0.3227 - val_f1_m: 0.7589\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2736 - f1_m: 0.8012 - val_loss: 0.2840 - val_f1_m: 0.7857\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2473 - f1_m: 0.8012 - val_loss: 0.2688 - val_f1_m: 0.7723\n",
      "0.8012499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 586us/sample - loss: 0.6730 - f1_m: 0.7937 - val_loss: 0.6506 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6246 - f1_m: 0.7937 - val_loss: 0.6009 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5735 - f1_m: 0.7937 - val_loss: 0.5525 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5349 - f1_m: 0.7937 - val_loss: 0.5276 - val_f1_m: 0.7589\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5198 - f1_m: 0.7937 - val_loss: 0.5173 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5111 - f1_m: 0.7937 - val_loss: 0.5100 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5037 - f1_m: 0.7937 - val_loss: 0.5025 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4957 - f1_m: 0.7937 - val_loss: 0.4933 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4847 - f1_m: 0.7937 - val_loss: 0.4806 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4717 - f1_m: 0.7937 - val_loss: 0.4672 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4575 - f1_m: 0.7937 - val_loss: 0.4515 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4396 - f1_m: 0.7937 - val_loss: 0.4318 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4166 - f1_m: 0.7937 - val_loss: 0.4064 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3898 - f1_m: 0.7937 - val_loss: 0.3761 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3567 - f1_m: 0.7937 - val_loss: 0.3396 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3206 - f1_m: 0.7937 - val_loss: 0.3035 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2861 - f1_m: 0.7937 - val_loss: 0.2698 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2587 - f1_m: 0.7937 - val_loss: 0.2443 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2373 - f1_m: 0.7937 - val_loss: 0.2290 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2236 - f1_m: 0.7937 - val_loss: 0.2164 - val_f1_m: 0.7991\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 586us/sample - loss: 0.6791 - f1_m: 0.7879 - val_loss: 0.6631 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6497 - f1_m: 0.7887 - val_loss: 0.6274 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6130 - f1_m: 0.7887 - val_loss: 0.5834 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5707 - f1_m: 0.7887 - val_loss: 0.5402 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5390 - f1_m: 0.7887 - val_loss: 0.5136 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5245 - f1_m: 0.7887 - val_loss: 0.5013 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5165 - f1_m: 0.7887 - val_loss: 0.4952 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5101 - f1_m: 0.7887 - val_loss: 0.4884 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5043 - f1_m: 0.7887 - val_loss: 0.4824 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4981 - f1_m: 0.7887 - val_loss: 0.4762 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4913 - f1_m: 0.7887 - val_loss: 0.4686 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4834 - f1_m: 0.7887 - val_loss: 0.4614 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4742 - f1_m: 0.7887 - val_loss: 0.4509 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4629 - f1_m: 0.7887 - val_loss: 0.4388 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4488 - f1_m: 0.7887 - val_loss: 0.4230 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4315 - f1_m: 0.7887 - val_loss: 0.4050 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4103 - f1_m: 0.7887 - val_loss: 0.3826 - val_f1_m: 0.8304\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3848 - f1_m: 0.7887 - val_loss: 0.3548 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3551 - f1_m: 0.7887 - val_loss: 0.3272 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3244 - f1_m: 0.7887 - val_loss: 0.3020 - val_f1_m: 0.8170\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 586us/sample - loss: 0.6802 - f1_m: 0.7887 - val_loss: 0.6633 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6501 - f1_m: 0.7887 - val_loss: 0.6274 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6134 - f1_m: 0.7887 - val_loss: 0.5810 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5727 - f1_m: 0.7887 - val_loss: 0.5360 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5421 - f1_m: 0.7887 - val_loss: 0.5093 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5276 - f1_m: 0.7887 - val_loss: 0.4980 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5203 - f1_m: 0.7887 - val_loss: 0.4913 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5157 - f1_m: 0.7887 - val_loss: 0.4851 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5090 - f1_m: 0.7887 - val_loss: 0.4808 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5034 - f1_m: 0.7887 - val_loss: 0.4751 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4972 - f1_m: 0.7887 - val_loss: 0.4690 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4903 - f1_m: 0.7887 - val_loss: 0.4623 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4813 - f1_m: 0.7887 - val_loss: 0.4524 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4698 - f1_m: 0.7887 - val_loss: 0.4417 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4544 - f1_m: 0.7887 - val_loss: 0.4264 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4356 - f1_m: 0.7887 - val_loss: 0.4082 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4138 - f1_m: 0.7887 - val_loss: 0.3877 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3885 - f1_m: 0.7887 - val_loss: 0.3577 - val_f1_m: 0.8304\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3519 - f1_m: 0.7887 - val_loss: 0.3246 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3148 - f1_m: 0.7887 - val_loss: 0.2900 - val_f1_m: 0.8170\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 592us/sample - loss: 0.6794 - f1_m: 0.7975 - val_loss: 0.6658 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6439 - f1_m: 0.7975 - val_loss: 0.6193 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5820 - f1_m: 0.7975 - val_loss: 0.5674 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5364 - f1_m: 0.7975 - val_loss: 0.5433 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5187 - f1_m: 0.7975 - val_loss: 0.5368 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5101 - f1_m: 0.7975 - val_loss: 0.5319 - val_f1_m: 0.7589\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5049 - f1_m: 0.7975 - val_loss: 0.5270 - val_f1_m: 0.7589\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4993 - f1_m: 0.7975 - val_loss: 0.5221 - val_f1_m: 0.7455\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4936 - f1_m: 0.7975 - val_loss: 0.5156 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4869 - f1_m: 0.7975 - val_loss: 0.5086 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4789 - f1_m: 0.7975 - val_loss: 0.4981 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4679 - f1_m: 0.7975 - val_loss: 0.4861 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4537 - f1_m: 0.7975 - val_loss: 0.4702 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4385 - f1_m: 0.7975 - val_loss: 0.4543 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4205 - f1_m: 0.7975 - val_loss: 0.4328 - val_f1_m: 0.7455\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3977 - f1_m: 0.7975 - val_loss: 0.4001 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3589 - f1_m: 0.7975 - val_loss: 0.3544 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3189 - f1_m: 0.7975 - val_loss: 0.3114 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2820 - f1_m: 0.7975 - val_loss: 0.2821 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2581 - f1_m: 0.7975 - val_loss: 0.2574 - val_f1_m: 0.7991\n",
      "0.7974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 586us/sample - loss: 0.6792 - f1_m: 0.7925 - val_loss: 0.6634 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6417 - f1_m: 0.7925 - val_loss: 0.6104 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5850 - f1_m: 0.7925 - val_loss: 0.5571 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5430 - f1_m: 0.7925 - val_loss: 0.5265 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5223 - f1_m: 0.7925 - val_loss: 0.5134 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5120 - f1_m: 0.7925 - val_loss: 0.5053 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5022 - f1_m: 0.7925 - val_loss: 0.4961 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4915 - f1_m: 0.7925 - val_loss: 0.4844 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4771 - f1_m: 0.7925 - val_loss: 0.4681 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4574 - f1_m: 0.7925 - val_loss: 0.4480 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4345 - f1_m: 0.7925 - val_loss: 0.4251 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4092 - f1_m: 0.7925 - val_loss: 0.4009 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3796 - f1_m: 0.7925 - val_loss: 0.3717 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3490 - f1_m: 0.7925 - val_loss: 0.3469 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3230 - f1_m: 0.7925 - val_loss: 0.3243 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3007 - f1_m: 0.7925 - val_loss: 0.3075 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2804 - f1_m: 0.7925 - val_loss: 0.2930 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2622 - f1_m: 0.7925 - val_loss: 0.2785 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2463 - f1_m: 0.7925 - val_loss: 0.2677 - val_f1_m: 0.7902\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2327 - f1_m: 0.7925 - val_loss: 0.2576 - val_f1_m: 0.7768\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 589us/sample - loss: 0.6789 - f1_m: 0.7900 - val_loss: 0.6627 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6466 - f1_m: 0.7900 - val_loss: 0.6257 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6071 - f1_m: 0.7900 - val_loss: 0.5808 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5673 - f1_m: 0.7900 - val_loss: 0.5412 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5382 - f1_m: 0.7900 - val_loss: 0.5176 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5242 - f1_m: 0.7900 - val_loss: 0.5066 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5174 - f1_m: 0.7900 - val_loss: 0.5000 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5116 - f1_m: 0.7900 - val_loss: 0.4945 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5061 - f1_m: 0.7900 - val_loss: 0.4885 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5002 - f1_m: 0.7900 - val_loss: 0.4828 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4937 - f1_m: 0.7900 - val_loss: 0.4758 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4870 - f1_m: 0.7900 - val_loss: 0.4684 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4764 - f1_m: 0.7900 - val_loss: 0.4571 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4645 - f1_m: 0.7900 - val_loss: 0.4449 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4499 - f1_m: 0.7900 - val_loss: 0.4285 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4328 - f1_m: 0.7900 - val_loss: 0.4089 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4107 - f1_m: 0.7900 - val_loss: 0.3860 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3886 - f1_m: 0.7900 - val_loss: 0.3632 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3609 - f1_m: 0.7900 - val_loss: 0.3345 - val_f1_m: 0.8259\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3308 - f1_m: 0.7900 - val_loss: 0.3064 - val_f1_m: 0.8125\n",
      "0.7899999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 588us/sample - loss: 0.6723 - f1_m: 0.7943 - val_loss: 0.6510 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6242 - f1_m: 0.7950 - val_loss: 0.6014 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5711 - f1_m: 0.7950 - val_loss: 0.5563 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5318 - f1_m: 0.7950 - val_loss: 0.5359 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5152 - f1_m: 0.7950 - val_loss: 0.5284 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5082 - f1_m: 0.7950 - val_loss: 0.5219 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5035 - f1_m: 0.7950 - val_loss: 0.5150 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4959 - f1_m: 0.7950 - val_loss: 0.5079 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4884 - f1_m: 0.7950 - val_loss: 0.4986 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4789 - f1_m: 0.7950 - val_loss: 0.4858 - val_f1_m: 0.7679\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4655 - f1_m: 0.7950 - val_loss: 0.4703 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4513 - f1_m: 0.7950 - val_loss: 0.4536 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4346 - f1_m: 0.7950 - val_loss: 0.4328 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4126 - f1_m: 0.7950 - val_loss: 0.4064 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3859 - f1_m: 0.7950 - val_loss: 0.3755 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3552 - f1_m: 0.7950 - val_loss: 0.3398 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3207 - f1_m: 0.7950 - val_loss: 0.3013 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2889 - f1_m: 0.7950 - val_loss: 0.2719 - val_f1_m: 0.7946\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2641 - f1_m: 0.7950 - val_loss: 0.2474 - val_f1_m: 0.7545\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2441 - f1_m: 0.7950 - val_loss: 0.2304 - val_f1_m: 0.7946\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 585us/sample - loss: 0.6737 - f1_m: 0.7962 - val_loss: 0.6524 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6243 - f1_m: 0.7962 - val_loss: 0.6045 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5732 - f1_m: 0.7962 - val_loss: 0.5574 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5334 - f1_m: 0.7962 - val_loss: 0.5351 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5177 - f1_m: 0.7962 - val_loss: 0.5268 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5093 - f1_m: 0.7962 - val_loss: 0.5207 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5025 - f1_m: 0.7962 - val_loss: 0.5141 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4955 - f1_m: 0.7962 - val_loss: 0.5069 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4866 - f1_m: 0.7962 - val_loss: 0.4965 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4746 - f1_m: 0.7962 - val_loss: 0.4844 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4613 - f1_m: 0.7962 - val_loss: 0.4710 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4458 - f1_m: 0.7962 - val_loss: 0.4540 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4262 - f1_m: 0.7962 - val_loss: 0.4318 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4026 - f1_m: 0.7962 - val_loss: 0.4047 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3741 - f1_m: 0.7962 - val_loss: 0.3721 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3401 - f1_m: 0.7962 - val_loss: 0.3364 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3032 - f1_m: 0.7962 - val_loss: 0.2991 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2710 - f1_m: 0.7962 - val_loss: 0.2716 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2459 - f1_m: 0.7962 - val_loss: 0.2514 - val_f1_m: 0.7902\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2287 - f1_m: 0.7962 - val_loss: 0.2371 - val_f1_m: 0.7500\n",
      "0.7962499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 588us/sample - loss: 0.6751 - f1_m: 0.7867 - val_loss: 0.6481 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6302 - f1_m: 0.7875 - val_loss: 0.5929 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5842 - f1_m: 0.7875 - val_loss: 0.5408 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5489 - f1_m: 0.7875 - val_loss: 0.5060 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5288 - f1_m: 0.7875 - val_loss: 0.4907 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5187 - f1_m: 0.7875 - val_loss: 0.4768 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5066 - f1_m: 0.7875 - val_loss: 0.4668 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4946 - f1_m: 0.7875 - val_loss: 0.4532 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4794 - f1_m: 0.7875 - val_loss: 0.4384 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4616 - f1_m: 0.7875 - val_loss: 0.4194 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4390 - f1_m: 0.7875 - val_loss: 0.3977 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4132 - f1_m: 0.7875 - val_loss: 0.3705 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3836 - f1_m: 0.7875 - val_loss: 0.3398 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3530 - f1_m: 0.7875 - val_loss: 0.3109 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3263 - f1_m: 0.7875 - val_loss: 0.2936 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3030 - f1_m: 0.7875 - val_loss: 0.2653 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2827 - f1_m: 0.7875 - val_loss: 0.2480 - val_f1_m: 0.8348\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2632 - f1_m: 0.7875 - val_loss: 0.2333 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2455 - f1_m: 0.7875 - val_loss: 0.2187 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2326 - f1_m: 0.7875 - val_loss: 0.2054 - val_f1_m: 0.8080\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 587us/sample - loss: 0.6777 - f1_m: 0.7987 - val_loss: 0.6601 - val_f1_m: 0.7545\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6293 - f1_m: 0.7987 - val_loss: 0.6118 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5742 - f1_m: 0.7987 - val_loss: 0.5720 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5325 - f1_m: 0.7987 - val_loss: 0.5530 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5150 - f1_m: 0.7987 - val_loss: 0.5480 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5053 - f1_m: 0.7987 - val_loss: 0.5406 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4990 - f1_m: 0.7987 - val_loss: 0.5340 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4901 - f1_m: 0.7987 - val_loss: 0.5183 - val_f1_m: 0.7679\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4775 - f1_m: 0.7987 - val_loss: 0.5060 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4641 - f1_m: 0.7987 - val_loss: 0.4909 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4483 - f1_m: 0.7987 - val_loss: 0.4703 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4289 - f1_m: 0.7987 - val_loss: 0.4458 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4045 - f1_m: 0.7987 - val_loss: 0.4180 - val_f1_m: 0.7545\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3776 - f1_m: 0.7987 - val_loss: 0.3864 - val_f1_m: 0.7411\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3469 - f1_m: 0.7987 - val_loss: 0.3523 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3190 - f1_m: 0.7987 - val_loss: 0.3304 - val_f1_m: 0.7545\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2956 - f1_m: 0.7987 - val_loss: 0.3074 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2754 - f1_m: 0.7987 - val_loss: 0.2883 - val_f1_m: 0.7679\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2587 - f1_m: 0.7987 - val_loss: 0.2702 - val_f1_m: 0.7545\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2413 - f1_m: 0.7987 - val_loss: 0.2544 - val_f1_m: 0.7411\n",
      "0.7987499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6710 - f1_m: 0.8012 - val_loss: 0.6551 - val_f1_m: 0.7455\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6229 - f1_m: 0.8012 - val_loss: 0.6123 - val_f1_m: 0.7589\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5697 - f1_m: 0.8012 - val_loss: 0.5773 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5287 - f1_m: 0.8012 - val_loss: 0.5642 - val_f1_m: 0.7455\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5098 - f1_m: 0.8012 - val_loss: 0.5615 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5022 - f1_m: 0.8012 - val_loss: 0.5564 - val_f1_m: 0.7187\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4956 - f1_m: 0.8012 - val_loss: 0.5490 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4882 - f1_m: 0.8012 - val_loss: 0.5422 - val_f1_m: 0.7455\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4796 - f1_m: 0.8012 - val_loss: 0.5293 - val_f1_m: 0.7589\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4677 - f1_m: 0.8012 - val_loss: 0.5155 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4563 - f1_m: 0.8012 - val_loss: 0.5053 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4416 - f1_m: 0.8012 - val_loss: 0.4854 - val_f1_m: 0.7321\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4238 - f1_m: 0.8012 - val_loss: 0.4636 - val_f1_m: 0.7455\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4010 - f1_m: 0.8012 - val_loss: 0.4381 - val_f1_m: 0.7589\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3752 - f1_m: 0.8012 - val_loss: 0.4058 - val_f1_m: 0.7455\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3435 - f1_m: 0.8012 - val_loss: 0.3674 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3079 - f1_m: 0.8012 - val_loss: 0.3212 - val_f1_m: 0.7455\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2696 - f1_m: 0.8012 - val_loss: 0.2874 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2408 - f1_m: 0.8012 - val_loss: 0.2615 - val_f1_m: 0.7455\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2236 - f1_m: 0.8012 - val_loss: 0.2480 - val_f1_m: 0.7589\n",
      "0.8012499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.6786 - f1_m: 0.7950 - val_loss: 0.6636 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6474 - f1_m: 0.7950 - val_loss: 0.6304 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6089 - f1_m: 0.7950 - val_loss: 0.5911 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5674 - f1_m: 0.7950 - val_loss: 0.5540 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5352 - f1_m: 0.7950 - val_loss: 0.5334 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5195 - f1_m: 0.7950 - val_loss: 0.5224 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5093 - f1_m: 0.7950 - val_loss: 0.5138 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4992 - f1_m: 0.7950 - val_loss: 0.5027 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4883 - f1_m: 0.7950 - val_loss: 0.4915 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4765 - f1_m: 0.7950 - val_loss: 0.4789 - val_f1_m: 0.7411\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4626 - f1_m: 0.7950 - val_loss: 0.4632 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4459 - f1_m: 0.7950 - val_loss: 0.4435 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4240 - f1_m: 0.7950 - val_loss: 0.4191 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3982 - f1_m: 0.7950 - val_loss: 0.3901 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3687 - f1_m: 0.7950 - val_loss: 0.3619 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3396 - f1_m: 0.7950 - val_loss: 0.3306 - val_f1_m: 0.7679\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3130 - f1_m: 0.7950 - val_loss: 0.3095 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2916 - f1_m: 0.7950 - val_loss: 0.2889 - val_f1_m: 0.7679\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2739 - f1_m: 0.7950 - val_loss: 0.2721 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2580 - f1_m: 0.7950 - val_loss: 0.2663 - val_f1_m: 0.8080\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 592us/sample - loss: 0.6787 - f1_m: 0.7937 - val_loss: 0.6637 - val_f1_m: 0.7723\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6467 - f1_m: 0.7937 - val_loss: 0.6290 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6073 - f1_m: 0.7937 - val_loss: 0.5865 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5664 - f1_m: 0.7937 - val_loss: 0.5485 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5364 - f1_m: 0.7937 - val_loss: 0.5290 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5232 - f1_m: 0.7937 - val_loss: 0.5209 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5157 - f1_m: 0.7937 - val_loss: 0.5152 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5102 - f1_m: 0.7937 - val_loss: 0.5101 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5054 - f1_m: 0.7937 - val_loss: 0.5050 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4998 - f1_m: 0.7937 - val_loss: 0.4996 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4942 - f1_m: 0.7937 - val_loss: 0.4934 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4877 - f1_m: 0.7937 - val_loss: 0.4863 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4798 - f1_m: 0.7937 - val_loss: 0.4764 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4695 - f1_m: 0.7937 - val_loss: 0.4652 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4569 - f1_m: 0.7937 - val_loss: 0.4512 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4418 - f1_m: 0.7937 - val_loss: 0.4350 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4240 - f1_m: 0.7937 - val_loss: 0.4148 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4029 - f1_m: 0.7937 - val_loss: 0.3918 - val_f1_m: 0.7991\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3781 - f1_m: 0.7937 - val_loss: 0.3651 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3524 - f1_m: 0.7937 - val_loss: 0.3374 - val_f1_m: 0.7991\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.6719 - f1_m: 0.8075 - val_loss: 0.6589 - val_f1_m: 0.7500\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6211 - f1_m: 0.8075 - val_loss: 0.6212 - val_f1_m: 0.7232\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5633 - f1_m: 0.8075 - val_loss: 0.5922 - val_f1_m: 0.7232\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5174 - f1_m: 0.8075 - val_loss: 0.5890 - val_f1_m: 0.7366\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5003 - f1_m: 0.8075 - val_loss: 0.5946 - val_f1_m: 0.7500\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4930 - f1_m: 0.8075 - val_loss: 0.5851 - val_f1_m: 0.7098\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4854 - f1_m: 0.8075 - val_loss: 0.5841 - val_f1_m: 0.7232\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4795 - f1_m: 0.8075 - val_loss: 0.5787 - val_f1_m: 0.7500\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4721 - f1_m: 0.8075 - val_loss: 0.5658 - val_f1_m: 0.7098\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4621 - f1_m: 0.8075 - val_loss: 0.5538 - val_f1_m: 0.7232\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4497 - f1_m: 0.8075 - val_loss: 0.5365 - val_f1_m: 0.7500\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4351 - f1_m: 0.8075 - val_loss: 0.5233 - val_f1_m: 0.7098\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4180 - f1_m: 0.8075 - val_loss: 0.5024 - val_f1_m: 0.7098\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3954 - f1_m: 0.8075 - val_loss: 0.4726 - val_f1_m: 0.7634\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3684 - f1_m: 0.8075 - val_loss: 0.4410 - val_f1_m: 0.7500\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3372 - f1_m: 0.8075 - val_loss: 0.4029 - val_f1_m: 0.7232\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3030 - f1_m: 0.8075 - val_loss: 0.3582 - val_f1_m: 0.7500\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2663 - f1_m: 0.8075 - val_loss: 0.3126 - val_f1_m: 0.7366\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2337 - f1_m: 0.8075 - val_loss: 0.2912 - val_f1_m: 0.7634\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2158 - f1_m: 0.8075 - val_loss: 0.2724 - val_f1_m: 0.7232\n",
      "0.80749995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 600us/sample - loss: 0.6781 - f1_m: 0.7867 - val_loss: 0.6543 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6319 - f1_m: 0.7875 - val_loss: 0.5938 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5808 - f1_m: 0.7875 - val_loss: 0.5374 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5442 - f1_m: 0.7875 - val_loss: 0.5006 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5262 - f1_m: 0.7875 - val_loss: 0.4845 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5165 - f1_m: 0.7875 - val_loss: 0.4760 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5059 - f1_m: 0.7875 - val_loss: 0.4635 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4905 - f1_m: 0.7875 - val_loss: 0.4528 - val_f1_m: 0.8348\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4756 - f1_m: 0.7875 - val_loss: 0.4370 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4559 - f1_m: 0.7875 - val_loss: 0.4209 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4311 - f1_m: 0.7875 - val_loss: 0.3949 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4016 - f1_m: 0.7875 - val_loss: 0.3678 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3687 - f1_m: 0.7875 - val_loss: 0.3368 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3356 - f1_m: 0.7875 - val_loss: 0.3083 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3066 - f1_m: 0.7875 - val_loss: 0.2858 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2834 - f1_m: 0.7875 - val_loss: 0.2660 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2626 - f1_m: 0.7875 - val_loss: 0.2518 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2443 - f1_m: 0.7875 - val_loss: 0.2366 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2272 - f1_m: 0.7875 - val_loss: 0.2261 - val_f1_m: 0.8348\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2175 - f1_m: 0.8125 - val_loss: 0.2174 - val_f1_m: 0.9196\n",
      "0.81249994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 594us/sample - loss: 0.6746 - f1_m: 0.7943 - val_loss: 0.6522 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.6263 - f1_m: 0.7950 - val_loss: 0.6038 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5702 - f1_m: 0.7950 - val_loss: 0.5589 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5297 - f1_m: 0.7950 - val_loss: 0.5373 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5137 - f1_m: 0.7950 - val_loss: 0.5311 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5074 - f1_m: 0.7950 - val_loss: 0.5254 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5027 - f1_m: 0.7950 - val_loss: 0.5190 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4968 - f1_m: 0.7950 - val_loss: 0.5116 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4895 - f1_m: 0.7950 - val_loss: 0.5021 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4805 - f1_m: 0.7950 - val_loss: 0.4915 - val_f1_m: 0.7545\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4700 - f1_m: 0.7950 - val_loss: 0.4785 - val_f1_m: 0.7545\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4592 - f1_m: 0.7950 - val_loss: 0.4646 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4453 - f1_m: 0.7950 - val_loss: 0.4462 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4270 - f1_m: 0.7950 - val_loss: 0.4223 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4040 - f1_m: 0.7950 - val_loss: 0.3954 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3767 - f1_m: 0.7950 - val_loss: 0.3598 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3411 - f1_m: 0.7950 - val_loss: 0.3131 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2997 - f1_m: 0.7950 - val_loss: 0.2694 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2687 - f1_m: 0.7950 - val_loss: 0.2373 - val_f1_m: 0.7545\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2452 - f1_m: 0.7950 - val_loss: 0.2177 - val_f1_m: 0.7946\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.6797 - f1_m: 0.7825 - val_loss: 0.6604 - val_f1_m: 0.8393\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6507 - f1_m: 0.7825 - val_loss: 0.6209 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6151 - f1_m: 0.7825 - val_loss: 0.5713 - val_f1_m: 0.8527\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5758 - f1_m: 0.7825 - val_loss: 0.5224 - val_f1_m: 0.8393\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5488 - f1_m: 0.7825 - val_loss: 0.4874 - val_f1_m: 0.8527\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5343 - f1_m: 0.7825 - val_loss: 0.4717 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5270 - f1_m: 0.7825 - val_loss: 0.4616 - val_f1_m: 0.8259\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5211 - f1_m: 0.7825 - val_loss: 0.4561 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5148 - f1_m: 0.7825 - val_loss: 0.4499 - val_f1_m: 0.8393\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5087 - f1_m: 0.7825 - val_loss: 0.4439 - val_f1_m: 0.8393\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5012 - f1_m: 0.7825 - val_loss: 0.4346 - val_f1_m: 0.8527\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4920 - f1_m: 0.7825 - val_loss: 0.4249 - val_f1_m: 0.8393\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4799 - f1_m: 0.7825 - val_loss: 0.4156 - val_f1_m: 0.8527\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4663 - f1_m: 0.7825 - val_loss: 0.3997 - val_f1_m: 0.8393\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4484 - f1_m: 0.7825 - val_loss: 0.3818 - val_f1_m: 0.8393\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4280 - f1_m: 0.7825 - val_loss: 0.3611 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4010 - f1_m: 0.7825 - val_loss: 0.3324 - val_f1_m: 0.8259\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3641 - f1_m: 0.7825 - val_loss: 0.2970 - val_f1_m: 0.8393\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3258 - f1_m: 0.7825 - val_loss: 0.2637 - val_f1_m: 0.7991\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2918 - f1_m: 0.7825 - val_loss: 0.2415 - val_f1_m: 0.8393\n",
      "0.7824999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 587us/sample - loss: 0.6740 - f1_m: 0.7887 - val_loss: 0.6474 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6284 - f1_m: 0.7887 - val_loss: 0.5926 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5773 - f1_m: 0.7887 - val_loss: 0.5384 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5408 - f1_m: 0.7887 - val_loss: 0.5069 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5259 - f1_m: 0.7887 - val_loss: 0.4964 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5182 - f1_m: 0.7887 - val_loss: 0.4893 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5119 - f1_m: 0.7887 - val_loss: 0.4825 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5047 - f1_m: 0.7887 - val_loss: 0.4759 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4956 - f1_m: 0.7887 - val_loss: 0.4646 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4825 - f1_m: 0.7887 - val_loss: 0.4509 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4691 - f1_m: 0.7887 - val_loss: 0.4366 - val_f1_m: 0.8304\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4529 - f1_m: 0.7887 - val_loss: 0.4193 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4331 - f1_m: 0.7887 - val_loss: 0.3977 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4082 - f1_m: 0.7887 - val_loss: 0.3713 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3797 - f1_m: 0.7887 - val_loss: 0.3411 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3461 - f1_m: 0.7887 - val_loss: 0.3082 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3123 - f1_m: 0.7887 - val_loss: 0.2770 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2844 - f1_m: 0.7887 - val_loss: 0.2531 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2629 - f1_m: 0.7887 - val_loss: 0.2343 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2481 - f1_m: 0.7887 - val_loss: 0.2222 - val_f1_m: 0.8036\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.6736 - f1_m: 0.7925 - val_loss: 0.6496 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6274 - f1_m: 0.7925 - val_loss: 0.5983 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5751 - f1_m: 0.7925 - val_loss: 0.5494 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5356 - f1_m: 0.7925 - val_loss: 0.5199 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5184 - f1_m: 0.7925 - val_loss: 0.5081 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5093 - f1_m: 0.7925 - val_loss: 0.5009 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5016 - f1_m: 0.7925 - val_loss: 0.4928 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4916 - f1_m: 0.7925 - val_loss: 0.4830 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4804 - f1_m: 0.7925 - val_loss: 0.4712 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4682 - f1_m: 0.7925 - val_loss: 0.4590 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4538 - f1_m: 0.7925 - val_loss: 0.4435 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4349 - f1_m: 0.7925 - val_loss: 0.4231 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4117 - f1_m: 0.7925 - val_loss: 0.4000 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3832 - f1_m: 0.7925 - val_loss: 0.3701 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3432 - f1_m: 0.7925 - val_loss: 0.3210 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2906 - f1_m: 0.7925 - val_loss: 0.2788 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2529 - f1_m: 0.7925 - val_loss: 0.2501 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2275 - f1_m: 0.7925 - val_loss: 0.2337 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2125 - f1_m: 0.7925 - val_loss: 0.2228 - val_f1_m: 0.7634\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2016 - f1_m: 0.7925 - val_loss: 0.2142 - val_f1_m: 0.8036\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.6796 - f1_m: 0.7887 - val_loss: 0.6610 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6431 - f1_m: 0.7887 - val_loss: 0.6057 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5874 - f1_m: 0.7887 - val_loss: 0.5401 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5448 - f1_m: 0.7887 - val_loss: 0.5041 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5259 - f1_m: 0.7887 - val_loss: 0.4892 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5179 - f1_m: 0.7887 - val_loss: 0.4821 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5116 - f1_m: 0.7887 - val_loss: 0.4740 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5050 - f1_m: 0.7887 - val_loss: 0.4680 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4975 - f1_m: 0.7887 - val_loss: 0.4594 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4878 - f1_m: 0.7887 - val_loss: 0.4491 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4758 - f1_m: 0.7887 - val_loss: 0.4351 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4595 - f1_m: 0.7887 - val_loss: 0.4194 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4419 - f1_m: 0.7887 - val_loss: 0.3997 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4201 - f1_m: 0.7887 - val_loss: 0.3799 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3944 - f1_m: 0.7887 - val_loss: 0.3465 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3597 - f1_m: 0.7887 - val_loss: 0.3153 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3207 - f1_m: 0.7887 - val_loss: 0.2651 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2777 - f1_m: 0.7887 - val_loss: 0.2347 - val_f1_m: 0.8304\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2516 - f1_m: 0.7887 - val_loss: 0.2135 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2327 - f1_m: 0.7887 - val_loss: 0.2003 - val_f1_m: 0.8036\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.6798 - f1_m: 0.7925 - val_loss: 0.6642 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6492 - f1_m: 0.7925 - val_loss: 0.6290 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6108 - f1_m: 0.7925 - val_loss: 0.5864 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5692 - f1_m: 0.7925 - val_loss: 0.5461 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5375 - f1_m: 0.7925 - val_loss: 0.5239 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5225 - f1_m: 0.7925 - val_loss: 0.5143 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5156 - f1_m: 0.7925 - val_loss: 0.5085 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5099 - f1_m: 0.7925 - val_loss: 0.5032 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5046 - f1_m: 0.7925 - val_loss: 0.4980 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4984 - f1_m: 0.7925 - val_loss: 0.4924 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4924 - f1_m: 0.7925 - val_loss: 0.4861 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4853 - f1_m: 0.7925 - val_loss: 0.4788 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4764 - f1_m: 0.7925 - val_loss: 0.4679 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4646 - f1_m: 0.7925 - val_loss: 0.4556 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4510 - f1_m: 0.7925 - val_loss: 0.4394 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4343 - f1_m: 0.7925 - val_loss: 0.4209 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4144 - f1_m: 0.7925 - val_loss: 0.3987 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3926 - f1_m: 0.7925 - val_loss: 0.3741 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3654 - f1_m: 0.7925 - val_loss: 0.3459 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3367 - f1_m: 0.7925 - val_loss: 0.3169 - val_f1_m: 0.7902\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 592us/sample - loss: 0.6729 - f1_m: 0.7887 - val_loss: 0.6468 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6273 - f1_m: 0.7887 - val_loss: 0.5924 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5758 - f1_m: 0.7887 - val_loss: 0.5397 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5378 - f1_m: 0.7887 - val_loss: 0.5061 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5231 - f1_m: 0.7887 - val_loss: 0.4931 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5137 - f1_m: 0.7887 - val_loss: 0.4856 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5051 - f1_m: 0.7887 - val_loss: 0.4764 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4947 - f1_m: 0.7887 - val_loss: 0.4667 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4831 - f1_m: 0.7887 - val_loss: 0.4556 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4688 - f1_m: 0.7887 - val_loss: 0.4402 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4492 - f1_m: 0.7887 - val_loss: 0.4201 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4247 - f1_m: 0.7887 - val_loss: 0.3951 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3972 - f1_m: 0.7887 - val_loss: 0.3686 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3699 - f1_m: 0.7887 - val_loss: 0.3462 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3418 - f1_m: 0.7887 - val_loss: 0.3198 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3160 - f1_m: 0.7887 - val_loss: 0.2987 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2919 - f1_m: 0.7887 - val_loss: 0.2793 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2696 - f1_m: 0.7887 - val_loss: 0.2634 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2498 - f1_m: 0.7887 - val_loss: 0.2476 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2339 - f1_m: 0.7887 - val_loss: 0.2374 - val_f1_m: 0.8170\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6721 - f1_m: 0.8005 - val_loss: 0.6540 - val_f1_m: 0.7321\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6215 - f1_m: 0.8012 - val_loss: 0.6111 - val_f1_m: 0.7187\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5690 - f1_m: 0.8012 - val_loss: 0.5744 - val_f1_m: 0.7455\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5265 - f1_m: 0.8012 - val_loss: 0.5614 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5086 - f1_m: 0.8012 - val_loss: 0.5577 - val_f1_m: 0.7589\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5013 - f1_m: 0.8012 - val_loss: 0.5547 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4956 - f1_m: 0.8012 - val_loss: 0.5493 - val_f1_m: 0.7589\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4900 - f1_m: 0.8012 - val_loss: 0.5384 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4803 - f1_m: 0.8012 - val_loss: 0.5295 - val_f1_m: 0.7321\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4705 - f1_m: 0.8012 - val_loss: 0.5164 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4596 - f1_m: 0.8012 - val_loss: 0.5055 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4473 - f1_m: 0.8012 - val_loss: 0.4912 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4319 - f1_m: 0.8012 - val_loss: 0.4704 - val_f1_m: 0.7589\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4110 - f1_m: 0.8012 - val_loss: 0.4399 - val_f1_m: 0.7589\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3856 - f1_m: 0.8012 - val_loss: 0.4129 - val_f1_m: 0.7455\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3595 - f1_m: 0.8012 - val_loss: 0.3881 - val_f1_m: 0.7321\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3339 - f1_m: 0.8012 - val_loss: 0.3580 - val_f1_m: 0.7589\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3100 - f1_m: 0.8012 - val_loss: 0.3331 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2878 - f1_m: 0.8012 - val_loss: 0.3078 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2685 - f1_m: 0.8012 - val_loss: 0.2847 - val_f1_m: 0.7723\n",
      "0.8012499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 592us/sample - loss: 0.6735 - f1_m: 0.7867 - val_loss: 0.6469 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6283 - f1_m: 0.7887 - val_loss: 0.5915 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5778 - f1_m: 0.7887 - val_loss: 0.5376 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5394 - f1_m: 0.7887 - val_loss: 0.5038 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5234 - f1_m: 0.7887 - val_loss: 0.4896 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5161 - f1_m: 0.7887 - val_loss: 0.4826 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5095 - f1_m: 0.7887 - val_loss: 0.4768 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5010 - f1_m: 0.7887 - val_loss: 0.4679 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4911 - f1_m: 0.7887 - val_loss: 0.4592 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4802 - f1_m: 0.7887 - val_loss: 0.4476 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4669 - f1_m: 0.7887 - val_loss: 0.4343 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4489 - f1_m: 0.7887 - val_loss: 0.4157 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4257 - f1_m: 0.7887 - val_loss: 0.3931 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3999 - f1_m: 0.7887 - val_loss: 0.3672 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3721 - f1_m: 0.7887 - val_loss: 0.3421 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3454 - f1_m: 0.7887 - val_loss: 0.3167 - val_f1_m: 0.8304\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3200 - f1_m: 0.7887 - val_loss: 0.2944 - val_f1_m: 0.8304\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2970 - f1_m: 0.7887 - val_loss: 0.2734 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2763 - f1_m: 0.7887 - val_loss: 0.2545 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2564 - f1_m: 0.7887 - val_loss: 0.2389 - val_f1_m: 0.8036\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6727 - f1_m: 0.7900 - val_loss: 0.6482 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6288 - f1_m: 0.7900 - val_loss: 0.5978 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5803 - f1_m: 0.7900 - val_loss: 0.5465 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5409 - f1_m: 0.7900 - val_loss: 0.5096 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5179 - f1_m: 0.7900 - val_loss: 0.4936 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5069 - f1_m: 0.7900 - val_loss: 0.4822 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4952 - f1_m: 0.7900 - val_loss: 0.4709 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4803 - f1_m: 0.7900 - val_loss: 0.4550 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4621 - f1_m: 0.7900 - val_loss: 0.4360 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4402 - f1_m: 0.7900 - val_loss: 0.4133 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4148 - f1_m: 0.7900 - val_loss: 0.3867 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3864 - f1_m: 0.7900 - val_loss: 0.3577 - val_f1_m: 0.7589\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3561 - f1_m: 0.7900 - val_loss: 0.3293 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3284 - f1_m: 0.7900 - val_loss: 0.3057 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3051 - f1_m: 0.7900 - val_loss: 0.2857 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2834 - f1_m: 0.7900 - val_loss: 0.2659 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2646 - f1_m: 0.7900 - val_loss: 0.2494 - val_f1_m: 0.8125\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2475 - f1_m: 0.7900 - val_loss: 0.2344 - val_f1_m: 0.8259\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2330 - f1_m: 0.7900 - val_loss: 0.2231 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2246 - f1_m: 0.8325 - val_loss: 0.2154 - val_f1_m: 0.9107\n",
      "0.8325\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 588us/sample - loss: 0.6721 - f1_m: 0.7925 - val_loss: 0.6485 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6240 - f1_m: 0.7925 - val_loss: 0.5959 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5737 - f1_m: 0.7925 - val_loss: 0.5459 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5368 - f1_m: 0.7925 - val_loss: 0.5196 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5192 - f1_m: 0.7925 - val_loss: 0.5102 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5121 - f1_m: 0.7925 - val_loss: 0.5038 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5050 - f1_m: 0.7925 - val_loss: 0.4981 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4982 - f1_m: 0.7925 - val_loss: 0.4901 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4889 - f1_m: 0.7925 - val_loss: 0.4814 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4784 - f1_m: 0.7925 - val_loss: 0.4707 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4669 - f1_m: 0.7925 - val_loss: 0.4596 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4541 - f1_m: 0.7925 - val_loss: 0.4460 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4374 - f1_m: 0.7925 - val_loss: 0.4285 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4168 - f1_m: 0.7925 - val_loss: 0.4062 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3912 - f1_m: 0.7925 - val_loss: 0.3796 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3620 - f1_m: 0.7925 - val_loss: 0.3509 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3333 - f1_m: 0.7925 - val_loss: 0.3206 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3002 - f1_m: 0.7925 - val_loss: 0.2872 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2655 - f1_m: 0.8087 - val_loss: 0.2525 - val_f1_m: 0.8750\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2356 - f1_m: 0.8925 - val_loss: 0.2250 - val_f1_m: 0.9062\n",
      "0.8924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 594us/sample - loss: 0.6727 - f1_m: 0.7898 - val_loss: 0.6471 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6241 - f1_m: 0.7912 - val_loss: 0.5934 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5726 - f1_m: 0.7912 - val_loss: 0.5411 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5386 - f1_m: 0.7912 - val_loss: 0.5125 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5233 - f1_m: 0.7912 - val_loss: 0.5034 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5170 - f1_m: 0.7912 - val_loss: 0.4965 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5100 - f1_m: 0.7912 - val_loss: 0.4920 - val_f1_m: 0.7545\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5022 - f1_m: 0.7912 - val_loss: 0.4856 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4931 - f1_m: 0.7912 - val_loss: 0.4767 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4799 - f1_m: 0.7912 - val_loss: 0.4652 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4657 - f1_m: 0.7912 - val_loss: 0.4524 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4497 - f1_m: 0.7912 - val_loss: 0.4365 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4300 - f1_m: 0.7912 - val_loss: 0.4177 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4037 - f1_m: 0.7912 - val_loss: 0.3936 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3736 - f1_m: 0.7912 - val_loss: 0.3656 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3397 - f1_m: 0.7912 - val_loss: 0.3336 - val_f1_m: 0.7545\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3000 - f1_m: 0.7912 - val_loss: 0.3008 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2686 - f1_m: 0.7912 - val_loss: 0.2782 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2456 - f1_m: 0.7912 - val_loss: 0.2614 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2329 - f1_m: 0.7912 - val_loss: 0.2556 - val_f1_m: 0.7946\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6795 - f1_m: 0.7875 - val_loss: 0.6614 - val_f1_m: 0.8348\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6497 - f1_m: 0.7875 - val_loss: 0.6226 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6127 - f1_m: 0.7875 - val_loss: 0.5761 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5723 - f1_m: 0.7875 - val_loss: 0.5319 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5440 - f1_m: 0.7875 - val_loss: 0.5037 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5303 - f1_m: 0.7875 - val_loss: 0.4920 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5227 - f1_m: 0.7875 - val_loss: 0.4843 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5166 - f1_m: 0.7875 - val_loss: 0.4775 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5104 - f1_m: 0.7875 - val_loss: 0.4712 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5039 - f1_m: 0.7875 - val_loss: 0.4646 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4967 - f1_m: 0.7875 - val_loss: 0.4566 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4882 - f1_m: 0.7875 - val_loss: 0.4467 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4757 - f1_m: 0.7875 - val_loss: 0.4350 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4614 - f1_m: 0.7875 - val_loss: 0.4193 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4432 - f1_m: 0.7875 - val_loss: 0.3993 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4214 - f1_m: 0.7875 - val_loss: 0.3764 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3944 - f1_m: 0.7875 - val_loss: 0.3452 - val_f1_m: 0.8348\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3625 - f1_m: 0.7875 - val_loss: 0.3094 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3223 - f1_m: 0.7875 - val_loss: 0.2735 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2901 - f1_m: 0.7875 - val_loss: 0.2454 - val_f1_m: 0.8214\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.6731 - f1_m: 0.7975 - val_loss: 0.6537 - val_f1_m: 0.7589\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6251 - f1_m: 0.7975 - val_loss: 0.6067 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5712 - f1_m: 0.7975 - val_loss: 0.5643 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5304 - f1_m: 0.7975 - val_loss: 0.5464 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5133 - f1_m: 0.7975 - val_loss: 0.5404 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5064 - f1_m: 0.7975 - val_loss: 0.5337 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5002 - f1_m: 0.7975 - val_loss: 0.5270 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4945 - f1_m: 0.7975 - val_loss: 0.5183 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4866 - f1_m: 0.7975 - val_loss: 0.5087 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4758 - f1_m: 0.7975 - val_loss: 0.4931 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4619 - f1_m: 0.7975 - val_loss: 0.4786 - val_f1_m: 0.7455\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4471 - f1_m: 0.7975 - val_loss: 0.4618 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4292 - f1_m: 0.7975 - val_loss: 0.4390 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4072 - f1_m: 0.7975 - val_loss: 0.4098 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3806 - f1_m: 0.7975 - val_loss: 0.3771 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3505 - f1_m: 0.7975 - val_loss: 0.3408 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3163 - f1_m: 0.7975 - val_loss: 0.2982 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2856 - f1_m: 0.7975 - val_loss: 0.2685 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2614 - f1_m: 0.7975 - val_loss: 0.2429 - val_f1_m: 0.7857\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2427 - f1_m: 0.7975 - val_loss: 0.2248 - val_f1_m: 0.7857\n",
      "0.7974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 592us/sample - loss: 0.6791 - f1_m: 0.7875 - val_loss: 0.6618 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6493 - f1_m: 0.7875 - val_loss: 0.6230 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6120 - f1_m: 0.7875 - val_loss: 0.5762 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5727 - f1_m: 0.7875 - val_loss: 0.5307 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5422 - f1_m: 0.7875 - val_loss: 0.5051 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5290 - f1_m: 0.7875 - val_loss: 0.4909 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5206 - f1_m: 0.7875 - val_loss: 0.4837 - val_f1_m: 0.8348\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5142 - f1_m: 0.7875 - val_loss: 0.4775 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5086 - f1_m: 0.7875 - val_loss: 0.4714 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5018 - f1_m: 0.7875 - val_loss: 0.4639 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4948 - f1_m: 0.7875 - val_loss: 0.4569 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4861 - f1_m: 0.7875 - val_loss: 0.4479 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4757 - f1_m: 0.7875 - val_loss: 0.4364 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4599 - f1_m: 0.7875 - val_loss: 0.4207 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4420 - f1_m: 0.7875 - val_loss: 0.4025 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4217 - f1_m: 0.7875 - val_loss: 0.3821 - val_f1_m: 0.8348\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4002 - f1_m: 0.7875 - val_loss: 0.3594 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3735 - f1_m: 0.7875 - val_loss: 0.3322 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3442 - f1_m: 0.7875 - val_loss: 0.3037 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3141 - f1_m: 0.7875 - val_loss: 0.2766 - val_f1_m: 0.8348\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 603us/sample - loss: 0.6712 - f1_m: 0.7975 - val_loss: 0.6516 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6211 - f1_m: 0.7975 - val_loss: 0.6049 - val_f1_m: 0.7455\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5681 - f1_m: 0.7975 - val_loss: 0.5640 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5287 - f1_m: 0.7975 - val_loss: 0.5466 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5147 - f1_m: 0.7975 - val_loss: 0.5407 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5063 - f1_m: 0.7975 - val_loss: 0.5335 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4995 - f1_m: 0.7975 - val_loss: 0.5266 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4928 - f1_m: 0.7975 - val_loss: 0.5193 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4841 - f1_m: 0.7975 - val_loss: 0.5075 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4723 - f1_m: 0.7975 - val_loss: 0.4924 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4583 - f1_m: 0.7975 - val_loss: 0.4790 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4426 - f1_m: 0.7975 - val_loss: 0.4608 - val_f1_m: 0.7321\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4235 - f1_m: 0.7975 - val_loss: 0.4364 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3996 - f1_m: 0.7975 - val_loss: 0.4091 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3711 - f1_m: 0.7975 - val_loss: 0.3753 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3378 - f1_m: 0.7975 - val_loss: 0.3373 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3010 - f1_m: 0.7975 - val_loss: 0.2949 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2651 - f1_m: 0.7975 - val_loss: 0.2588 - val_f1_m: 0.7991\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2394 - f1_m: 0.7975 - val_loss: 0.2380 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2245 - f1_m: 0.7975 - val_loss: 0.2283 - val_f1_m: 0.7857\n",
      "0.7974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 587us/sample - loss: 0.6775 - f1_m: 0.7950 - val_loss: 0.6538 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6287 - f1_m: 0.7950 - val_loss: 0.6058 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5756 - f1_m: 0.7950 - val_loss: 0.5604 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5347 - f1_m: 0.7950 - val_loss: 0.5352 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5156 - f1_m: 0.7950 - val_loss: 0.5253 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5061 - f1_m: 0.7950 - val_loss: 0.5164 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4946 - f1_m: 0.7950 - val_loss: 0.5019 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4811 - f1_m: 0.7950 - val_loss: 0.4881 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4668 - f1_m: 0.7950 - val_loss: 0.4718 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4488 - f1_m: 0.7950 - val_loss: 0.4522 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4269 - f1_m: 0.7950 - val_loss: 0.4276 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3997 - f1_m: 0.7950 - val_loss: 0.3987 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3688 - f1_m: 0.7950 - val_loss: 0.3663 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3351 - f1_m: 0.7950 - val_loss: 0.3348 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3044 - f1_m: 0.7950 - val_loss: 0.3079 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2795 - f1_m: 0.7950 - val_loss: 0.2867 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2580 - f1_m: 0.7950 - val_loss: 0.2665 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2372 - f1_m: 0.7950 - val_loss: 0.2492 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2216 - f1_m: 0.7950 - val_loss: 0.2364 - val_f1_m: 0.7812\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2082 - f1_m: 0.7950 - val_loss: 0.2271 - val_f1_m: 0.9018\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 589us/sample - loss: 0.6796 - f1_m: 0.7912 - val_loss: 0.6632 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6484 - f1_m: 0.7912 - val_loss: 0.6294 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6127 - f1_m: 0.7912 - val_loss: 0.5874 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5712 - f1_m: 0.7912 - val_loss: 0.5483 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5399 - f1_m: 0.7912 - val_loss: 0.5216 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5248 - f1_m: 0.7912 - val_loss: 0.5099 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5170 - f1_m: 0.7912 - val_loss: 0.5039 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5112 - f1_m: 0.7912 - val_loss: 0.4985 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5069 - f1_m: 0.7912 - val_loss: 0.4926 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4996 - f1_m: 0.7912 - val_loss: 0.4875 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4939 - f1_m: 0.7912 - val_loss: 0.4808 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4862 - f1_m: 0.7912 - val_loss: 0.4730 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4761 - f1_m: 0.7912 - val_loss: 0.4625 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4637 - f1_m: 0.7912 - val_loss: 0.4500 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4496 - f1_m: 0.7912 - val_loss: 0.4345 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4309 - f1_m: 0.7912 - val_loss: 0.4154 - val_f1_m: 0.7679\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4083 - f1_m: 0.7912 - val_loss: 0.3948 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3839 - f1_m: 0.7912 - val_loss: 0.3681 - val_f1_m: 0.7946\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3546 - f1_m: 0.7912 - val_loss: 0.3414 - val_f1_m: 0.7812\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3248 - f1_m: 0.7912 - val_loss: 0.3133 - val_f1_m: 0.7946\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 589us/sample - loss: 0.6763 - f1_m: 0.7912 - val_loss: 0.6527 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6296 - f1_m: 0.7912 - val_loss: 0.6003 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5814 - f1_m: 0.7912 - val_loss: 0.5500 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5423 - f1_m: 0.7912 - val_loss: 0.5205 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5234 - f1_m: 0.7912 - val_loss: 0.5062 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5142 - f1_m: 0.7912 - val_loss: 0.4967 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5028 - f1_m: 0.7912 - val_loss: 0.4840 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4892 - f1_m: 0.7912 - val_loss: 0.4716 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4734 - f1_m: 0.7912 - val_loss: 0.4565 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4548 - f1_m: 0.7912 - val_loss: 0.4372 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4312 - f1_m: 0.7912 - val_loss: 0.4143 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4041 - f1_m: 0.7912 - val_loss: 0.3864 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3721 - f1_m: 0.7912 - val_loss: 0.3542 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3382 - f1_m: 0.7912 - val_loss: 0.3233 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3088 - f1_m: 0.7912 - val_loss: 0.2967 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2814 - f1_m: 0.7912 - val_loss: 0.2684 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2516 - f1_m: 0.7912 - val_loss: 0.2436 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2253 - f1_m: 0.8800 - val_loss: 0.2221 - val_f1_m: 0.9107\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2050 - f1_m: 0.9150 - val_loss: 0.2068 - val_f1_m: 0.9107\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.1891 - f1_m: 0.9312 - val_loss: 0.1939 - val_f1_m: 0.9241\n",
      "0.93125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 589us/sample - loss: 0.6764 - f1_m: 0.7962 - val_loss: 0.6565 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6267 - f1_m: 0.7962 - val_loss: 0.6054 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5745 - f1_m: 0.7962 - val_loss: 0.5624 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5374 - f1_m: 0.7962 - val_loss: 0.5409 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5159 - f1_m: 0.7962 - val_loss: 0.5334 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5075 - f1_m: 0.7962 - val_loss: 0.5274 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4998 - f1_m: 0.7962 - val_loss: 0.5175 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4882 - f1_m: 0.7962 - val_loss: 0.5035 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4753 - f1_m: 0.7962 - val_loss: 0.4889 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4614 - f1_m: 0.7962 - val_loss: 0.4714 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4433 - f1_m: 0.7962 - val_loss: 0.4501 - val_f1_m: 0.7634\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4213 - f1_m: 0.7962 - val_loss: 0.4238 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3956 - f1_m: 0.7962 - val_loss: 0.3936 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3642 - f1_m: 0.7962 - val_loss: 0.3572 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3309 - f1_m: 0.7962 - val_loss: 0.3261 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3049 - f1_m: 0.7962 - val_loss: 0.3028 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2826 - f1_m: 0.7962 - val_loss: 0.2814 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2629 - f1_m: 0.7962 - val_loss: 0.2618 - val_f1_m: 0.7768\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2451 - f1_m: 0.7962 - val_loss: 0.2431 - val_f1_m: 0.7634\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2309 - f1_m: 0.7962 - val_loss: 0.2303 - val_f1_m: 0.7902\n",
      "0.7962499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6752 - f1_m: 0.7917 - val_loss: 0.6515 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6284 - f1_m: 0.7925 - val_loss: 0.5995 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5773 - f1_m: 0.7925 - val_loss: 0.5484 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5374 - f1_m: 0.7925 - val_loss: 0.5177 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5193 - f1_m: 0.7925 - val_loss: 0.5074 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5129 - f1_m: 0.7925 - val_loss: 0.5003 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5061 - f1_m: 0.7925 - val_loss: 0.4939 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4994 - f1_m: 0.7925 - val_loss: 0.4851 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4897 - f1_m: 0.7925 - val_loss: 0.4747 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4799 - f1_m: 0.7925 - val_loss: 0.4635 - val_f1_m: 0.7634\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4682 - f1_m: 0.7925 - val_loss: 0.4510 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4556 - f1_m: 0.7925 - val_loss: 0.4353 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4387 - f1_m: 0.7925 - val_loss: 0.4160 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4188 - f1_m: 0.7925 - val_loss: 0.3921 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3943 - f1_m: 0.7925 - val_loss: 0.3565 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3550 - f1_m: 0.7925 - val_loss: 0.3098 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3115 - f1_m: 0.7925 - val_loss: 0.2664 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2760 - f1_m: 0.7925 - val_loss: 0.2341 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2518 - f1_m: 0.7925 - val_loss: 0.2177 - val_f1_m: 0.7902\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2370 - f1_m: 0.7925 - val_loss: 0.2049 - val_f1_m: 0.8036\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 594us/sample - loss: 0.6735 - f1_m: 0.7830 - val_loss: 0.6427 - val_f1_m: 0.8482\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6270 - f1_m: 0.7837 - val_loss: 0.5825 - val_f1_m: 0.8482\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5806 - f1_m: 0.7837 - val_loss: 0.5207 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5450 - f1_m: 0.7837 - val_loss: 0.4818 - val_f1_m: 0.8482\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5286 - f1_m: 0.7837 - val_loss: 0.4669 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5208 - f1_m: 0.7837 - val_loss: 0.4564 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5131 - f1_m: 0.7837 - val_loss: 0.4505 - val_f1_m: 0.8348\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5044 - f1_m: 0.7837 - val_loss: 0.4417 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4914 - f1_m: 0.7837 - val_loss: 0.4335 - val_f1_m: 0.8482\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4771 - f1_m: 0.7837 - val_loss: 0.4171 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4601 - f1_m: 0.7837 - val_loss: 0.4009 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4392 - f1_m: 0.7837 - val_loss: 0.3809 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4133 - f1_m: 0.7837 - val_loss: 0.3571 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3827 - f1_m: 0.7837 - val_loss: 0.3308 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3433 - f1_m: 0.7837 - val_loss: 0.2938 - val_f1_m: 0.8482\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2983 - f1_m: 0.7837 - val_loss: 0.2575 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2585 - f1_m: 0.7837 - val_loss: 0.2324 - val_f1_m: 0.8348\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2364 - f1_m: 0.7837 - val_loss: 0.2157 - val_f1_m: 0.8482\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2223 - f1_m: 0.7837 - val_loss: 0.2048 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2120 - f1_m: 0.7912 - val_loss: 0.1969 - val_f1_m: 0.8973\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.6752 - f1_m: 0.7967 - val_loss: 0.6548 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6265 - f1_m: 0.7975 - val_loss: 0.6099 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5756 - f1_m: 0.7975 - val_loss: 0.5714 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5353 - f1_m: 0.7975 - val_loss: 0.5551 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5156 - f1_m: 0.7975 - val_loss: 0.5490 - val_f1_m: 0.7455\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5070 - f1_m: 0.7975 - val_loss: 0.5433 - val_f1_m: 0.7589\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4970 - f1_m: 0.7975 - val_loss: 0.5287 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4847 - f1_m: 0.7975 - val_loss: 0.5146 - val_f1_m: 0.7589\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4720 - f1_m: 0.7975 - val_loss: 0.4983 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4558 - f1_m: 0.7975 - val_loss: 0.4787 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4359 - f1_m: 0.7975 - val_loss: 0.4534 - val_f1_m: 0.7321\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4118 - f1_m: 0.7975 - val_loss: 0.4256 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3843 - f1_m: 0.7975 - val_loss: 0.3928 - val_f1_m: 0.7723\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3519 - f1_m: 0.7975 - val_loss: 0.3570 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3203 - f1_m: 0.7975 - val_loss: 0.3293 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2940 - f1_m: 0.7975 - val_loss: 0.3070 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2725 - f1_m: 0.7975 - val_loss: 0.2897 - val_f1_m: 0.7455\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2534 - f1_m: 0.7975 - val_loss: 0.2685 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2353 - f1_m: 0.7975 - val_loss: 0.2483 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2213 - f1_m: 0.7975 - val_loss: 0.2362 - val_f1_m: 0.7857\n",
      "0.7974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.6727 - f1_m: 0.7887 - val_loss: 0.6450 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6256 - f1_m: 0.7887 - val_loss: 0.5877 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5758 - f1_m: 0.7887 - val_loss: 0.5324 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5414 - f1_m: 0.7887 - val_loss: 0.5053 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5273 - f1_m: 0.7887 - val_loss: 0.4936 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5197 - f1_m: 0.7887 - val_loss: 0.4887 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5133 - f1_m: 0.7887 - val_loss: 0.4816 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5067 - f1_m: 0.7887 - val_loss: 0.4755 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4990 - f1_m: 0.7887 - val_loss: 0.4674 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4877 - f1_m: 0.7887 - val_loss: 0.4556 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4747 - f1_m: 0.7887 - val_loss: 0.4437 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4602 - f1_m: 0.7887 - val_loss: 0.4292 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4419 - f1_m: 0.7887 - val_loss: 0.4111 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4195 - f1_m: 0.7887 - val_loss: 0.3898 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3929 - f1_m: 0.7887 - val_loss: 0.3646 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3624 - f1_m: 0.7887 - val_loss: 0.3354 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3279 - f1_m: 0.7887 - val_loss: 0.3066 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2953 - f1_m: 0.7887 - val_loss: 0.2822 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2700 - f1_m: 0.7887 - val_loss: 0.2622 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2493 - f1_m: 0.7887 - val_loss: 0.2469 - val_f1_m: 0.7768\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 594us/sample - loss: 0.6760 - f1_m: 0.7900 - val_loss: 0.6510 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6301 - f1_m: 0.7900 - val_loss: 0.5961 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5788 - f1_m: 0.7900 - val_loss: 0.5473 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5426 - f1_m: 0.7900 - val_loss: 0.5159 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5251 - f1_m: 0.7900 - val_loss: 0.5024 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5158 - f1_m: 0.7900 - val_loss: 0.4913 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5039 - f1_m: 0.7900 - val_loss: 0.4776 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4906 - f1_m: 0.7900 - val_loss: 0.4629 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4755 - f1_m: 0.7900 - val_loss: 0.4459 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4570 - f1_m: 0.7900 - val_loss: 0.4236 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4334 - f1_m: 0.7900 - val_loss: 0.3969 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4060 - f1_m: 0.7900 - val_loss: 0.3672 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3759 - f1_m: 0.7900 - val_loss: 0.3331 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3442 - f1_m: 0.7900 - val_loss: 0.3051 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3175 - f1_m: 0.7900 - val_loss: 0.2785 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2945 - f1_m: 0.7900 - val_loss: 0.2553 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2743 - f1_m: 0.7900 - val_loss: 0.2357 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2551 - f1_m: 0.7900 - val_loss: 0.2170 - val_f1_m: 0.8125\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2380 - f1_m: 0.7900 - val_loss: 0.2052 - val_f1_m: 0.7991\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2252 - f1_m: 0.7900 - val_loss: 0.1947 - val_f1_m: 0.8125\n",
      "0.7899999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6782 - f1_m: 0.7992 - val_loss: 0.6666 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6470 - f1_m: 0.8000 - val_loss: 0.6369 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.6092 - f1_m: 0.8000 - val_loss: 0.6013 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5659 - f1_m: 0.8000 - val_loss: 0.5696 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5315 - f1_m: 0.8000 - val_loss: 0.5530 - val_f1_m: 0.7500\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5138 - f1_m: 0.8000 - val_loss: 0.5477 - val_f1_m: 0.7902\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5076 - f1_m: 0.8000 - val_loss: 0.5445 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5014 - f1_m: 0.8000 - val_loss: 0.5380 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4966 - f1_m: 0.8000 - val_loss: 0.5347 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4920 - f1_m: 0.8000 - val_loss: 0.5286 - val_f1_m: 0.7500\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4859 - f1_m: 0.8000 - val_loss: 0.5228 - val_f1_m: 0.7366\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4801 - f1_m: 0.8000 - val_loss: 0.5152 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4724 - f1_m: 0.8000 - val_loss: 0.5056 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4632 - f1_m: 0.8000 - val_loss: 0.4960 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4524 - f1_m: 0.8000 - val_loss: 0.4817 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4398 - f1_m: 0.8000 - val_loss: 0.4650 - val_f1_m: 0.7232\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4244 - f1_m: 0.8000 - val_loss: 0.4462 - val_f1_m: 0.7500\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4048 - f1_m: 0.8000 - val_loss: 0.4188 - val_f1_m: 0.7634\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3744 - f1_m: 0.8000 - val_loss: 0.3782 - val_f1_m: 0.7768\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3393 - f1_m: 0.8000 - val_loss: 0.3377 - val_f1_m: 0.7500\n",
      "0.79999995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6795 - f1_m: 0.7943 - val_loss: 0.6654 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6478 - f1_m: 0.7950 - val_loss: 0.6317 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6077 - f1_m: 0.7950 - val_loss: 0.5900 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5650 - f1_m: 0.7950 - val_loss: 0.5534 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5341 - f1_m: 0.7950 - val_loss: 0.5353 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5190 - f1_m: 0.7950 - val_loss: 0.5283 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5123 - f1_m: 0.7950 - val_loss: 0.5233 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5067 - f1_m: 0.7950 - val_loss: 0.5185 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5009 - f1_m: 0.7950 - val_loss: 0.5136 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4954 - f1_m: 0.7950 - val_loss: 0.5087 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4896 - f1_m: 0.7950 - val_loss: 0.5026 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4825 - f1_m: 0.7950 - val_loss: 0.4963 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4739 - f1_m: 0.7950 - val_loss: 0.4866 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4632 - f1_m: 0.7950 - val_loss: 0.4754 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4503 - f1_m: 0.7950 - val_loss: 0.4607 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4340 - f1_m: 0.7950 - val_loss: 0.4438 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4151 - f1_m: 0.7950 - val_loss: 0.4227 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3911 - f1_m: 0.7950 - val_loss: 0.3953 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3584 - f1_m: 0.7950 - val_loss: 0.3604 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3220 - f1_m: 0.7950 - val_loss: 0.3256 - val_f1_m: 0.7946\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 598us/sample - loss: 0.6802 - f1_m: 0.7837 - val_loss: 0.6602 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6503 - f1_m: 0.7837 - val_loss: 0.6199 - val_f1_m: 0.8348\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6136 - f1_m: 0.7837 - val_loss: 0.5683 - val_f1_m: 0.8482\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5748 - f1_m: 0.7837 - val_loss: 0.5182 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5461 - f1_m: 0.7837 - val_loss: 0.4867 - val_f1_m: 0.8482\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5308 - f1_m: 0.7837 - val_loss: 0.4721 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5213 - f1_m: 0.7837 - val_loss: 0.4611 - val_f1_m: 0.8348\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5118 - f1_m: 0.7837 - val_loss: 0.4514 - val_f1_m: 0.8348\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5002 - f1_m: 0.7837 - val_loss: 0.4414 - val_f1_m: 0.8348\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4868 - f1_m: 0.7837 - val_loss: 0.4275 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4717 - f1_m: 0.7837 - val_loss: 0.4129 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4530 - f1_m: 0.7837 - val_loss: 0.3958 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4289 - f1_m: 0.7837 - val_loss: 0.3716 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3989 - f1_m: 0.7837 - val_loss: 0.3436 - val_f1_m: 0.8348\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3661 - f1_m: 0.7837 - val_loss: 0.3104 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3347 - f1_m: 0.7837 - val_loss: 0.2811 - val_f1_m: 0.8482\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3088 - f1_m: 0.7837 - val_loss: 0.2598 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2882 - f1_m: 0.7837 - val_loss: 0.2402 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2709 - f1_m: 0.7837 - val_loss: 0.2259 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2560 - f1_m: 0.7837 - val_loss: 0.2128 - val_f1_m: 0.8482\n",
      "0.78374994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 592us/sample - loss: 0.6762 - f1_m: 0.7925 - val_loss: 0.6527 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6277 - f1_m: 0.7925 - val_loss: 0.5988 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5782 - f1_m: 0.7925 - val_loss: 0.5503 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5388 - f1_m: 0.7925 - val_loss: 0.5246 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5230 - f1_m: 0.7925 - val_loss: 0.5122 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5143 - f1_m: 0.7925 - val_loss: 0.5049 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5059 - f1_m: 0.7925 - val_loss: 0.4941 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4943 - f1_m: 0.7925 - val_loss: 0.4829 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4825 - f1_m: 0.7925 - val_loss: 0.4701 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4692 - f1_m: 0.7925 - val_loss: 0.4545 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4515 - f1_m: 0.7925 - val_loss: 0.4356 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4320 - f1_m: 0.7925 - val_loss: 0.4125 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4068 - f1_m: 0.7925 - val_loss: 0.3862 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3789 - f1_m: 0.7925 - val_loss: 0.3561 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3481 - f1_m: 0.7925 - val_loss: 0.3270 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3222 - f1_m: 0.7925 - val_loss: 0.3024 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3001 - f1_m: 0.7925 - val_loss: 0.2809 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2805 - f1_m: 0.7925 - val_loss: 0.2606 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2614 - f1_m: 0.7925 - val_loss: 0.2426 - val_f1_m: 0.7902\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2452 - f1_m: 0.7925 - val_loss: 0.2283 - val_f1_m: 0.8036\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.6749 - f1_m: 0.7937 - val_loss: 0.6519 - val_f1_m: 0.7723\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6278 - f1_m: 0.7937 - val_loss: 0.6024 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5743 - f1_m: 0.7937 - val_loss: 0.5555 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5339 - f1_m: 0.7937 - val_loss: 0.5298 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5174 - f1_m: 0.7937 - val_loss: 0.5209 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5083 - f1_m: 0.7937 - val_loss: 0.5133 - val_f1_m: 0.7589\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5007 - f1_m: 0.7937 - val_loss: 0.5060 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4920 - f1_m: 0.7937 - val_loss: 0.4960 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4807 - f1_m: 0.7937 - val_loss: 0.4842 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4683 - f1_m: 0.7937 - val_loss: 0.4709 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4540 - f1_m: 0.7937 - val_loss: 0.4545 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4350 - f1_m: 0.7937 - val_loss: 0.4344 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4118 - f1_m: 0.7937 - val_loss: 0.4096 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3840 - f1_m: 0.7937 - val_loss: 0.3800 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3497 - f1_m: 0.7937 - val_loss: 0.3416 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2992 - f1_m: 0.7937 - val_loss: 0.2953 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2556 - f1_m: 0.7937 - val_loss: 0.2638 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2286 - f1_m: 0.7937 - val_loss: 0.2451 - val_f1_m: 0.8125\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2120 - f1_m: 0.7937 - val_loss: 0.2326 - val_f1_m: 0.7991\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2004 - f1_m: 0.7937 - val_loss: 0.2242 - val_f1_m: 0.7857\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6783 - f1_m: 0.7983 - val_loss: 0.6670 - val_f1_m: 0.7634\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6474 - f1_m: 0.8000 - val_loss: 0.6371 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6084 - f1_m: 0.8000 - val_loss: 0.6023 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5652 - f1_m: 0.8000 - val_loss: 0.5712 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5324 - f1_m: 0.8000 - val_loss: 0.5572 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5155 - f1_m: 0.8000 - val_loss: 0.5529 - val_f1_m: 0.7366\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5073 - f1_m: 0.8000 - val_loss: 0.5480 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5009 - f1_m: 0.8000 - val_loss: 0.5425 - val_f1_m: 0.7500\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4954 - f1_m: 0.8000 - val_loss: 0.5385 - val_f1_m: 0.7500\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4896 - f1_m: 0.8000 - val_loss: 0.5313 - val_f1_m: 0.7634\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4822 - f1_m: 0.8000 - val_loss: 0.5244 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4746 - f1_m: 0.8000 - val_loss: 0.5154 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4641 - f1_m: 0.8000 - val_loss: 0.5015 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4521 - f1_m: 0.8000 - val_loss: 0.4875 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4366 - f1_m: 0.8000 - val_loss: 0.4708 - val_f1_m: 0.7500\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4194 - f1_m: 0.8000 - val_loss: 0.4502 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3964 - f1_m: 0.8000 - val_loss: 0.4199 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3638 - f1_m: 0.8000 - val_loss: 0.3831 - val_f1_m: 0.7634\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3282 - f1_m: 0.8000 - val_loss: 0.3414 - val_f1_m: 0.7768\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2930 - f1_m: 0.8000 - val_loss: 0.3076 - val_f1_m: 0.7902\n",
      "0.79999995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.6793 - f1_m: 0.7887 - val_loss: 0.6621 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6491 - f1_m: 0.7887 - val_loss: 0.6248 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6108 - f1_m: 0.7887 - val_loss: 0.5777 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5696 - f1_m: 0.7887 - val_loss: 0.5344 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5405 - f1_m: 0.7887 - val_loss: 0.5074 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5259 - f1_m: 0.7887 - val_loss: 0.4970 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5199 - f1_m: 0.7887 - val_loss: 0.4898 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5143 - f1_m: 0.7887 - val_loss: 0.4842 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5090 - f1_m: 0.7887 - val_loss: 0.4789 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5035 - f1_m: 0.7887 - val_loss: 0.4750 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4975 - f1_m: 0.7887 - val_loss: 0.4679 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4908 - f1_m: 0.7887 - val_loss: 0.4600 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4817 - f1_m: 0.7887 - val_loss: 0.4508 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4714 - f1_m: 0.7887 - val_loss: 0.4397 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4584 - f1_m: 0.7887 - val_loss: 0.4256 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4427 - f1_m: 0.7887 - val_loss: 0.4089 - val_f1_m: 0.8304\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4228 - f1_m: 0.7887 - val_loss: 0.3866 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3978 - f1_m: 0.7887 - val_loss: 0.3578 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3641 - f1_m: 0.7887 - val_loss: 0.3224 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3272 - f1_m: 0.7887 - val_loss: 0.2880 - val_f1_m: 0.8170\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.6794 - f1_m: 0.7880 - val_loss: 0.6613 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6402 - f1_m: 0.7887 - val_loss: 0.6018 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5849 - f1_m: 0.7887 - val_loss: 0.5444 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5432 - f1_m: 0.7887 - val_loss: 0.5086 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5247 - f1_m: 0.7887 - val_loss: 0.4943 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5187 - f1_m: 0.7887 - val_loss: 0.4857 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5121 - f1_m: 0.7887 - val_loss: 0.4814 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5068 - f1_m: 0.7887 - val_loss: 0.4730 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4986 - f1_m: 0.7887 - val_loss: 0.4657 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4890 - f1_m: 0.7887 - val_loss: 0.4534 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4769 - f1_m: 0.7887 - val_loss: 0.4399 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4627 - f1_m: 0.7887 - val_loss: 0.4236 - val_f1_m: 0.8304\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4459 - f1_m: 0.7887 - val_loss: 0.4045 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4272 - f1_m: 0.7887 - val_loss: 0.3830 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4042 - f1_m: 0.7887 - val_loss: 0.3588 - val_f1_m: 0.7902\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3745 - f1_m: 0.7887 - val_loss: 0.3200 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3385 - f1_m: 0.7887 - val_loss: 0.2812 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3022 - f1_m: 0.7887 - val_loss: 0.2456 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2718 - f1_m: 0.7887 - val_loss: 0.2162 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2506 - f1_m: 0.7887 - val_loss: 0.2008 - val_f1_m: 0.8036\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.6797 - f1_m: 0.7912 - val_loss: 0.6635 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6483 - f1_m: 0.7912 - val_loss: 0.6272 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6108 - f1_m: 0.7912 - val_loss: 0.5832 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5695 - f1_m: 0.7912 - val_loss: 0.5454 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5395 - f1_m: 0.7912 - val_loss: 0.5223 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5231 - f1_m: 0.7912 - val_loss: 0.5100 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5131 - f1_m: 0.7912 - val_loss: 0.4998 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5030 - f1_m: 0.7912 - val_loss: 0.4877 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4905 - f1_m: 0.7912 - val_loss: 0.4753 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4772 - f1_m: 0.7912 - val_loss: 0.4611 - val_f1_m: 0.7679\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4620 - f1_m: 0.7912 - val_loss: 0.4431 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4427 - f1_m: 0.7912 - val_loss: 0.4211 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4176 - f1_m: 0.7912 - val_loss: 0.3932 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3878 - f1_m: 0.7912 - val_loss: 0.3608 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3565 - f1_m: 0.7912 - val_loss: 0.3298 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3265 - f1_m: 0.7912 - val_loss: 0.3065 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3045 - f1_m: 0.7912 - val_loss: 0.2853 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2832 - f1_m: 0.7912 - val_loss: 0.2663 - val_f1_m: 0.7946\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2663 - f1_m: 0.7912 - val_loss: 0.2533 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2520 - f1_m: 0.7912 - val_loss: 0.2385 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6719 - f1_m: 0.7925 - val_loss: 0.6478 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6253 - f1_m: 0.7925 - val_loss: 0.5958 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5741 - f1_m: 0.7925 - val_loss: 0.5479 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5360 - f1_m: 0.7925 - val_loss: 0.5209 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5191 - f1_m: 0.7925 - val_loss: 0.5110 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5120 - f1_m: 0.7925 - val_loss: 0.5041 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5051 - f1_m: 0.7925 - val_loss: 0.4970 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4983 - f1_m: 0.7925 - val_loss: 0.4877 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4880 - f1_m: 0.7925 - val_loss: 0.4771 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4771 - f1_m: 0.7925 - val_loss: 0.4655 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4654 - f1_m: 0.7925 - val_loss: 0.4531 - val_f1_m: 0.7902\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4522 - f1_m: 0.7925 - val_loss: 0.4378 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4346 - f1_m: 0.7925 - val_loss: 0.4168 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4127 - f1_m: 0.7925 - val_loss: 0.3933 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3887 - f1_m: 0.7925 - val_loss: 0.3643 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3514 - f1_m: 0.7925 - val_loss: 0.3224 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3120 - f1_m: 0.7925 - val_loss: 0.2815 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2784 - f1_m: 0.7925 - val_loss: 0.2516 - val_f1_m: 0.8036\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2543 - f1_m: 0.7925 - val_loss: 0.2318 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2394 - f1_m: 0.7925 - val_loss: 0.2189 - val_f1_m: 0.7902\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6711 - f1_m: 0.7867 - val_loss: 0.6448 - val_f1_m: 0.8348\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6248 - f1_m: 0.7875 - val_loss: 0.5898 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5753 - f1_m: 0.7875 - val_loss: 0.5341 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5388 - f1_m: 0.7875 - val_loss: 0.5016 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5232 - f1_m: 0.7875 - val_loss: 0.4903 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5161 - f1_m: 0.7875 - val_loss: 0.4807 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5083 - f1_m: 0.7875 - val_loss: 0.4729 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4993 - f1_m: 0.7875 - val_loss: 0.4639 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4897 - f1_m: 0.7875 - val_loss: 0.4528 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4795 - f1_m: 0.7875 - val_loss: 0.4414 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4655 - f1_m: 0.7875 - val_loss: 0.4271 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4475 - f1_m: 0.7875 - val_loss: 0.4073 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4234 - f1_m: 0.7875 - val_loss: 0.3820 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3966 - f1_m: 0.7875 - val_loss: 0.3540 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3699 - f1_m: 0.7875 - val_loss: 0.3325 - val_f1_m: 0.8348\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3413 - f1_m: 0.7875 - val_loss: 0.3018 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3157 - f1_m: 0.7875 - val_loss: 0.2805 - val_f1_m: 0.8348\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2904 - f1_m: 0.7875 - val_loss: 0.2587 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2678 - f1_m: 0.7875 - val_loss: 0.2409 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2466 - f1_m: 0.7875 - val_loss: 0.2283 - val_f1_m: 0.8214\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.6778 - f1_m: 0.8012 - val_loss: 0.6669 - val_f1_m: 0.7723\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6462 - f1_m: 0.8012 - val_loss: 0.6362 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6047 - f1_m: 0.8012 - val_loss: 0.6023 - val_f1_m: 0.7723\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5624 - f1_m: 0.8012 - val_loss: 0.5728 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5299 - f1_m: 0.8012 - val_loss: 0.5607 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5149 - f1_m: 0.8012 - val_loss: 0.5562 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5066 - f1_m: 0.8012 - val_loss: 0.5513 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5003 - f1_m: 0.8012 - val_loss: 0.5468 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4937 - f1_m: 0.8012 - val_loss: 0.5392 - val_f1_m: 0.7589\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4873 - f1_m: 0.8012 - val_loss: 0.5340 - val_f1_m: 0.7455\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4800 - f1_m: 0.8012 - val_loss: 0.5248 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4714 - f1_m: 0.8012 - val_loss: 0.5160 - val_f1_m: 0.7455\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4603 - f1_m: 0.8012 - val_loss: 0.5007 - val_f1_m: 0.7589\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4451 - f1_m: 0.8012 - val_loss: 0.4868 - val_f1_m: 0.7321\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4287 - f1_m: 0.8012 - val_loss: 0.4679 - val_f1_m: 0.7589\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4078 - f1_m: 0.8012 - val_loss: 0.4451 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3854 - f1_m: 0.8012 - val_loss: 0.4190 - val_f1_m: 0.7589\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3509 - f1_m: 0.8012 - val_loss: 0.3759 - val_f1_m: 0.7589\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3116 - f1_m: 0.8012 - val_loss: 0.3371 - val_f1_m: 0.7455\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2796 - f1_m: 0.8012 - val_loss: 0.3089 - val_f1_m: 0.7589\n",
      "0.80125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.6752 - f1_m: 0.7930 - val_loss: 0.6515 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6260 - f1_m: 0.7937 - val_loss: 0.6002 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5760 - f1_m: 0.7937 - val_loss: 0.5539 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5369 - f1_m: 0.7937 - val_loss: 0.5281 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5193 - f1_m: 0.7937 - val_loss: 0.5167 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5104 - f1_m: 0.7937 - val_loss: 0.5082 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4997 - f1_m: 0.7937 - val_loss: 0.4969 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4883 - f1_m: 0.7937 - val_loss: 0.4859 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4757 - f1_m: 0.7937 - val_loss: 0.4723 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4589 - f1_m: 0.7937 - val_loss: 0.4554 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4394 - f1_m: 0.7937 - val_loss: 0.4342 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4136 - f1_m: 0.7937 - val_loss: 0.4091 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3848 - f1_m: 0.7937 - val_loss: 0.3798 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3516 - f1_m: 0.7937 - val_loss: 0.3493 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3205 - f1_m: 0.7937 - val_loss: 0.3255 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2961 - f1_m: 0.7937 - val_loss: 0.3044 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2749 - f1_m: 0.7937 - val_loss: 0.2872 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2571 - f1_m: 0.7937 - val_loss: 0.2708 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2394 - f1_m: 0.7937 - val_loss: 0.2577 - val_f1_m: 0.7857\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2261 - f1_m: 0.7937 - val_loss: 0.2472 - val_f1_m: 0.7857\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 593us/sample - loss: 0.6793 - f1_m: 0.7842 - val_loss: 0.6616 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6517 - f1_m: 0.7850 - val_loss: 0.6247 - val_f1_m: 0.8437\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6169 - f1_m: 0.7850 - val_loss: 0.5800 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5783 - f1_m: 0.7850 - val_loss: 0.5351 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5485 - f1_m: 0.7850 - val_loss: 0.5006 - val_f1_m: 0.8170\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5316 - f1_m: 0.7850 - val_loss: 0.4851 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5241 - f1_m: 0.7850 - val_loss: 0.4758 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5172 - f1_m: 0.7850 - val_loss: 0.4687 - val_f1_m: 0.8437\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5108 - f1_m: 0.7850 - val_loss: 0.4625 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5037 - f1_m: 0.7850 - val_loss: 0.4548 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4953 - f1_m: 0.7850 - val_loss: 0.4458 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4844 - f1_m: 0.7850 - val_loss: 0.4352 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4710 - f1_m: 0.7850 - val_loss: 0.4209 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4552 - f1_m: 0.7850 - val_loss: 0.4043 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4359 - f1_m: 0.7850 - val_loss: 0.3824 - val_f1_m: 0.8304\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4132 - f1_m: 0.7850 - val_loss: 0.3613 - val_f1_m: 0.8304\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3878 - f1_m: 0.7850 - val_loss: 0.3335 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3579 - f1_m: 0.7850 - val_loss: 0.3035 - val_f1_m: 0.8437\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3193 - f1_m: 0.7850 - val_loss: 0.2701 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2847 - f1_m: 0.7850 - val_loss: 0.2493 - val_f1_m: 0.8036\n",
      "0.7849999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 592us/sample - loss: 0.6726 - f1_m: 0.7900 - val_loss: 0.6463 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6256 - f1_m: 0.7900 - val_loss: 0.5919 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5749 - f1_m: 0.7900 - val_loss: 0.5376 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5375 - f1_m: 0.7900 - val_loss: 0.5064 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5210 - f1_m: 0.7900 - val_loss: 0.4955 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5151 - f1_m: 0.7900 - val_loss: 0.4871 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5075 - f1_m: 0.7900 - val_loss: 0.4819 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4997 - f1_m: 0.7900 - val_loss: 0.4736 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4894 - f1_m: 0.7900 - val_loss: 0.4633 - val_f1_m: 0.8259\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4773 - f1_m: 0.7900 - val_loss: 0.4517 - val_f1_m: 0.8125\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4639 - f1_m: 0.7900 - val_loss: 0.4371 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4475 - f1_m: 0.7900 - val_loss: 0.4199 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4269 - f1_m: 0.7900 - val_loss: 0.3980 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4021 - f1_m: 0.7900 - val_loss: 0.3717 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3718 - f1_m: 0.7900 - val_loss: 0.3408 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3363 - f1_m: 0.7900 - val_loss: 0.3006 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2921 - f1_m: 0.7900 - val_loss: 0.2607 - val_f1_m: 0.8259\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2582 - f1_m: 0.7900 - val_loss: 0.2340 - val_f1_m: 0.7991\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2372 - f1_m: 0.7900 - val_loss: 0.2183 - val_f1_m: 0.7991\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2237 - f1_m: 0.7900 - val_loss: 0.2082 - val_f1_m: 0.8125\n",
      "0.7899999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6722 - f1_m: 0.7887 - val_loss: 0.6454 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6258 - f1_m: 0.7887 - val_loss: 0.5901 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5749 - f1_m: 0.7887 - val_loss: 0.5348 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5352 - f1_m: 0.7887 - val_loss: 0.5018 - val_f1_m: 0.8170\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5160 - f1_m: 0.7887 - val_loss: 0.4861 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5074 - f1_m: 0.7887 - val_loss: 0.4756 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4983 - f1_m: 0.7887 - val_loss: 0.4666 - val_f1_m: 0.8170\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4862 - f1_m: 0.7887 - val_loss: 0.4529 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4724 - f1_m: 0.7887 - val_loss: 0.4376 - val_f1_m: 0.8170\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4553 - f1_m: 0.7887 - val_loss: 0.4186 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4341 - f1_m: 0.7887 - val_loss: 0.3963 - val_f1_m: 0.8304\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4111 - f1_m: 0.7887 - val_loss: 0.3719 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3830 - f1_m: 0.7887 - val_loss: 0.3431 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3560 - f1_m: 0.7887 - val_loss: 0.3168 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3305 - f1_m: 0.7887 - val_loss: 0.2921 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3086 - f1_m: 0.7887 - val_loss: 0.2692 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2868 - f1_m: 0.7887 - val_loss: 0.2505 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.2678 - f1_m: 0.7887 - val_loss: 0.2329 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2481 - f1_m: 0.8087 - val_loss: 0.2124 - val_f1_m: 0.9018\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2255 - f1_m: 0.9050 - val_loss: 0.1909 - val_f1_m: 0.8973\n",
      "0.9049999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 590us/sample - loss: 0.6743 - f1_m: 0.7950 - val_loss: 0.6525 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6267 - f1_m: 0.7950 - val_loss: 0.6047 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5748 - f1_m: 0.7950 - val_loss: 0.5633 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5374 - f1_m: 0.7950 - val_loss: 0.5394 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5172 - f1_m: 0.7950 - val_loss: 0.5313 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5092 - f1_m: 0.7950 - val_loss: 0.5242 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5007 - f1_m: 0.7950 - val_loss: 0.5130 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4897 - f1_m: 0.7950 - val_loss: 0.5019 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4775 - f1_m: 0.7950 - val_loss: 0.4883 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4636 - f1_m: 0.7950 - val_loss: 0.4718 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4462 - f1_m: 0.7950 - val_loss: 0.4516 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4256 - f1_m: 0.7950 - val_loss: 0.4260 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3995 - f1_m: 0.7950 - val_loss: 0.3986 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3700 - f1_m: 0.7950 - val_loss: 0.3664 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3388 - f1_m: 0.7950 - val_loss: 0.3361 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3111 - f1_m: 0.7950 - val_loss: 0.3122 - val_f1_m: 0.7679\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2872 - f1_m: 0.7950 - val_loss: 0.2943 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2669 - f1_m: 0.7950 - val_loss: 0.2723 - val_f1_m: 0.7946\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2507 - f1_m: 0.7950 - val_loss: 0.2602 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2345 - f1_m: 0.7950 - val_loss: 0.2452 - val_f1_m: 0.7946\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 592us/sample - loss: 0.6789 - f1_m: 0.7850 - val_loss: 0.6601 - val_f1_m: 0.8304\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6480 - f1_m: 0.7850 - val_loss: 0.6201 - val_f1_m: 0.8437\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6100 - f1_m: 0.7850 - val_loss: 0.5710 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5709 - f1_m: 0.7850 - val_loss: 0.5250 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5439 - f1_m: 0.7850 - val_loss: 0.4970 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5323 - f1_m: 0.7850 - val_loss: 0.4839 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5241 - f1_m: 0.7850 - val_loss: 0.4774 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5185 - f1_m: 0.7850 - val_loss: 0.4698 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5127 - f1_m: 0.7850 - val_loss: 0.4647 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5068 - f1_m: 0.7850 - val_loss: 0.4577 - val_f1_m: 0.8304\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5002 - f1_m: 0.7850 - val_loss: 0.4508 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4927 - f1_m: 0.7850 - val_loss: 0.4432 - val_f1_m: 0.8437\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4833 - f1_m: 0.7850 - val_loss: 0.4332 - val_f1_m: 0.8170\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4700 - f1_m: 0.7850 - val_loss: 0.4193 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4544 - f1_m: 0.7850 - val_loss: 0.4040 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4340 - f1_m: 0.7850 - val_loss: 0.3819 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4111 - f1_m: 0.7850 - val_loss: 0.3600 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3854 - f1_m: 0.7850 - val_loss: 0.3314 - val_f1_m: 0.8437\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3487 - f1_m: 0.7850 - val_loss: 0.2964 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.3090 - f1_m: 0.7850 - val_loss: 0.2630 - val_f1_m: 0.8304\n",
      "0.7849999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 594us/sample - loss: 0.6710 - f1_m: 0.7912 - val_loss: 0.6459 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6228 - f1_m: 0.7912 - val_loss: 0.5922 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5717 - f1_m: 0.7912 - val_loss: 0.5410 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5346 - f1_m: 0.7912 - val_loss: 0.5148 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5208 - f1_m: 0.7912 - val_loss: 0.5046 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5133 - f1_m: 0.7912 - val_loss: 0.4979 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5070 - f1_m: 0.7912 - val_loss: 0.4912 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4997 - f1_m: 0.7912 - val_loss: 0.4829 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4901 - f1_m: 0.7912 - val_loss: 0.4720 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4793 - f1_m: 0.7912 - val_loss: 0.4605 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4670 - f1_m: 0.7912 - val_loss: 0.4471 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4533 - f1_m: 0.7912 - val_loss: 0.4304 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4347 - f1_m: 0.7912 - val_loss: 0.4101 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4133 - f1_m: 0.7912 - val_loss: 0.3852 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3875 - f1_m: 0.7912 - val_loss: 0.3564 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3583 - f1_m: 0.7912 - val_loss: 0.3253 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3252 - f1_m: 0.7912 - val_loss: 0.2895 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2940 - f1_m: 0.7912 - val_loss: 0.2615 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2704 - f1_m: 0.7912 - val_loss: 0.2395 - val_f1_m: 0.7812\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2492 - f1_m: 0.7950 - val_loss: 0.2215 - val_f1_m: 0.8884\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 596us/sample - loss: 0.6746 - f1_m: 0.7918 - val_loss: 0.6503 - val_f1_m: 0.8170\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6267 - f1_m: 0.7925 - val_loss: 0.5982 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5753 - f1_m: 0.7925 - val_loss: 0.5463 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5350 - f1_m: 0.7925 - val_loss: 0.5197 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5184 - f1_m: 0.7925 - val_loss: 0.5094 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5106 - f1_m: 0.7925 - val_loss: 0.5026 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5036 - f1_m: 0.7925 - val_loss: 0.4957 - val_f1_m: 0.7902\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4948 - f1_m: 0.7925 - val_loss: 0.4873 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4838 - f1_m: 0.7925 - val_loss: 0.4754 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4707 - f1_m: 0.7925 - val_loss: 0.4627 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4554 - f1_m: 0.7925 - val_loss: 0.4475 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4373 - f1_m: 0.7925 - val_loss: 0.4285 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4138 - f1_m: 0.7925 - val_loss: 0.4058 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3870 - f1_m: 0.7925 - val_loss: 0.3776 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3547 - f1_m: 0.7925 - val_loss: 0.3457 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3173 - f1_m: 0.7925 - val_loss: 0.3093 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2714 - f1_m: 0.7925 - val_loss: 0.2703 - val_f1_m: 0.7902\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2395 - f1_m: 0.7925 - val_loss: 0.2504 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2217 - f1_m: 0.7925 - val_loss: 0.2381 - val_f1_m: 0.7902\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2110 - f1_m: 0.7925 - val_loss: 0.2297 - val_f1_m: 0.8036\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 594us/sample - loss: 0.6800 - f1_m: 0.7837 - val_loss: 0.6610 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6502 - f1_m: 0.7837 - val_loss: 0.6208 - val_f1_m: 0.8348\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6130 - f1_m: 0.7837 - val_loss: 0.5681 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5724 - f1_m: 0.7837 - val_loss: 0.5163 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5437 - f1_m: 0.7837 - val_loss: 0.4844 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5313 - f1_m: 0.7837 - val_loss: 0.4686 - val_f1_m: 0.8348\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5246 - f1_m: 0.7837 - val_loss: 0.4623 - val_f1_m: 0.8348\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5193 - f1_m: 0.7837 - val_loss: 0.4578 - val_f1_m: 0.8348\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5141 - f1_m: 0.7837 - val_loss: 0.4513 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5086 - f1_m: 0.7837 - val_loss: 0.4453 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5027 - f1_m: 0.7837 - val_loss: 0.4391 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4959 - f1_m: 0.7837 - val_loss: 0.4329 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4880 - f1_m: 0.7837 - val_loss: 0.4249 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4778 - f1_m: 0.7837 - val_loss: 0.4145 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4647 - f1_m: 0.7837 - val_loss: 0.3997 - val_f1_m: 0.8348\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4469 - f1_m: 0.7837 - val_loss: 0.3854 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4277 - f1_m: 0.7837 - val_loss: 0.3639 - val_f1_m: 0.8482\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4049 - f1_m: 0.7837 - val_loss: 0.3405 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3720 - f1_m: 0.7837 - val_loss: 0.3035 - val_f1_m: 0.8348\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3276 - f1_m: 0.7837 - val_loss: 0.2605 - val_f1_m: 0.8348\n",
      "0.78374994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 592us/sample - loss: 0.6736 - f1_m: 0.7980 - val_loss: 0.6535 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6237 - f1_m: 0.7987 - val_loss: 0.6078 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5720 - f1_m: 0.7987 - val_loss: 0.5681 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5329 - f1_m: 0.7987 - val_loss: 0.5494 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5140 - f1_m: 0.7987 - val_loss: 0.5420 - val_f1_m: 0.7411\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5042 - f1_m: 0.7987 - val_loss: 0.5330 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4936 - f1_m: 0.7987 - val_loss: 0.5205 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4804 - f1_m: 0.7987 - val_loss: 0.5088 - val_f1_m: 0.7545\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4653 - f1_m: 0.7987 - val_loss: 0.4907 - val_f1_m: 0.7679\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4477 - f1_m: 0.7987 - val_loss: 0.4711 - val_f1_m: 0.7545\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4249 - f1_m: 0.7987 - val_loss: 0.4454 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3995 - f1_m: 0.7987 - val_loss: 0.4186 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3699 - f1_m: 0.7987 - val_loss: 0.3841 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3379 - f1_m: 0.7987 - val_loss: 0.3517 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3087 - f1_m: 0.7987 - val_loss: 0.3255 - val_f1_m: 0.7812\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2856 - f1_m: 0.7987 - val_loss: 0.3038 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.2652 - f1_m: 0.7987 - val_loss: 0.2843 - val_f1_m: 0.7545\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2466 - f1_m: 0.7987 - val_loss: 0.2657 - val_f1_m: 0.7812\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2311 - f1_m: 0.7987 - val_loss: 0.2499 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2185 - f1_m: 0.7987 - val_loss: 0.2390 - val_f1_m: 0.7679\n",
      "0.7987499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.6732 - f1_m: 0.7787 - val_loss: 0.6393 - val_f1_m: 0.8393\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6296 - f1_m: 0.7787 - val_loss: 0.5764 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5833 - f1_m: 0.7787 - val_loss: 0.5086 - val_f1_m: 0.8393\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5485 - f1_m: 0.7787 - val_loss: 0.4616 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5336 - f1_m: 0.7787 - val_loss: 0.4452 - val_f1_m: 0.8527\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5267 - f1_m: 0.7787 - val_loss: 0.4348 - val_f1_m: 0.8527\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5182 - f1_m: 0.7787 - val_loss: 0.4294 - val_f1_m: 0.8661\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5084 - f1_m: 0.7787 - val_loss: 0.4224 - val_f1_m: 0.8661\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4972 - f1_m: 0.7787 - val_loss: 0.4094 - val_f1_m: 0.8661\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4838 - f1_m: 0.7787 - val_loss: 0.3953 - val_f1_m: 0.8393\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4661 - f1_m: 0.7787 - val_loss: 0.3804 - val_f1_m: 0.8661\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4422 - f1_m: 0.7787 - val_loss: 0.3577 - val_f1_m: 0.8527\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4154 - f1_m: 0.7787 - val_loss: 0.3340 - val_f1_m: 0.8393\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3871 - f1_m: 0.7787 - val_loss: 0.3072 - val_f1_m: 0.8527\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3597 - f1_m: 0.7787 - val_loss: 0.2791 - val_f1_m: 0.8393\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3342 - f1_m: 0.7787 - val_loss: 0.2594 - val_f1_m: 0.8527\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3104 - f1_m: 0.7787 - val_loss: 0.2389 - val_f1_m: 0.8527\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2896 - f1_m: 0.7787 - val_loss: 0.2239 - val_f1_m: 0.8661\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2692 - f1_m: 0.7787 - val_loss: 0.2138 - val_f1_m: 0.8393\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2537 - f1_m: 0.7787 - val_loss: 0.1980 - val_f1_m: 0.8393\n",
      "0.77874994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.6744 - f1_m: 0.7762 - val_loss: 0.6390 - val_f1_m: 0.8750\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6300 - f1_m: 0.7762 - val_loss: 0.5717 - val_f1_m: 0.8750\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5832 - f1_m: 0.7762 - val_loss: 0.4993 - val_f1_m: 0.8616\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5507 - f1_m: 0.7762 - val_loss: 0.4587 - val_f1_m: 0.8482\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5381 - f1_m: 0.7762 - val_loss: 0.4367 - val_f1_m: 0.8616\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5306 - f1_m: 0.7762 - val_loss: 0.4278 - val_f1_m: 0.8482\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5237 - f1_m: 0.7762 - val_loss: 0.4237 - val_f1_m: 0.8750\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5160 - f1_m: 0.7762 - val_loss: 0.4137 - val_f1_m: 0.8616\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5057 - f1_m: 0.7762 - val_loss: 0.4000 - val_f1_m: 0.8482\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4918 - f1_m: 0.7762 - val_loss: 0.3864 - val_f1_m: 0.8616\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4754 - f1_m: 0.7762 - val_loss: 0.3703 - val_f1_m: 0.8616\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4553 - f1_m: 0.7762 - val_loss: 0.3480 - val_f1_m: 0.8616\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4310 - f1_m: 0.7762 - val_loss: 0.3254 - val_f1_m: 0.8616\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4027 - f1_m: 0.7762 - val_loss: 0.2982 - val_f1_m: 0.8482\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3689 - f1_m: 0.7762 - val_loss: 0.2670 - val_f1_m: 0.8616\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3324 - f1_m: 0.7762 - val_loss: 0.2389 - val_f1_m: 0.8616\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3012 - f1_m: 0.7762 - val_loss: 0.2109 - val_f1_m: 0.8482\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2762 - f1_m: 0.7762 - val_loss: 0.1933 - val_f1_m: 0.8348\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2587 - f1_m: 0.7762 - val_loss: 0.1770 - val_f1_m: 0.8750\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.2466 - f1_m: 0.7762 - val_loss: 0.1686 - val_f1_m: 0.8348\n",
      "0.77624995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 591us/sample - loss: 0.6722 - f1_m: 0.7950 - val_loss: 0.6508 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6250 - f1_m: 0.7950 - val_loss: 0.6015 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5723 - f1_m: 0.7950 - val_loss: 0.5561 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5353 - f1_m: 0.7950 - val_loss: 0.5326 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5180 - f1_m: 0.7950 - val_loss: 0.5254 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5104 - f1_m: 0.7950 - val_loss: 0.5194 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5030 - f1_m: 0.7950 - val_loss: 0.5130 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4965 - f1_m: 0.7950 - val_loss: 0.5061 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4866 - f1_m: 0.7950 - val_loss: 0.4952 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4764 - f1_m: 0.7950 - val_loss: 0.4840 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4643 - f1_m: 0.7950 - val_loss: 0.4715 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4497 - f1_m: 0.7950 - val_loss: 0.4560 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4320 - f1_m: 0.7950 - val_loss: 0.4358 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4100 - f1_m: 0.7950 - val_loss: 0.4118 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3838 - f1_m: 0.7950 - val_loss: 0.3825 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3528 - f1_m: 0.7950 - val_loss: 0.3505 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3150 - f1_m: 0.7950 - val_loss: 0.3091 - val_f1_m: 0.7679\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2771 - f1_m: 0.7950 - val_loss: 0.2774 - val_f1_m: 0.7679\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2487 - f1_m: 0.7950 - val_loss: 0.2568 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.2324 - f1_m: 0.7950 - val_loss: 0.2441 - val_f1_m: 0.8080\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 597us/sample - loss: 0.6781 - f1_m: 0.7983 - val_loss: 0.6669 - val_f1_m: 0.7634\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6460 - f1_m: 0.8000 - val_loss: 0.6369 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6050 - f1_m: 0.8000 - val_loss: 0.6017 - val_f1_m: 0.7366\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5608 - f1_m: 0.8000 - val_loss: 0.5722 - val_f1_m: 0.7768\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5295 - f1_m: 0.8000 - val_loss: 0.5596 - val_f1_m: 0.7500\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5148 - f1_m: 0.8000 - val_loss: 0.5555 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5069 - f1_m: 0.8000 - val_loss: 0.5505 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5009 - f1_m: 0.8000 - val_loss: 0.5451 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4951 - f1_m: 0.8000 - val_loss: 0.5400 - val_f1_m: 0.7500\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4891 - f1_m: 0.8000 - val_loss: 0.5338 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4833 - f1_m: 0.8000 - val_loss: 0.5287 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4763 - f1_m: 0.8000 - val_loss: 0.5175 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4670 - f1_m: 0.8000 - val_loss: 0.5092 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4546 - f1_m: 0.8000 - val_loss: 0.4951 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4407 - f1_m: 0.8000 - val_loss: 0.4766 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4232 - f1_m: 0.8000 - val_loss: 0.4573 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4024 - f1_m: 0.8000 - val_loss: 0.4320 - val_f1_m: 0.7500\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3794 - f1_m: 0.8000 - val_loss: 0.4041 - val_f1_m: 0.7500\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3439 - f1_m: 0.8000 - val_loss: 0.3636 - val_f1_m: 0.7634\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3053 - f1_m: 0.8000 - val_loss: 0.3196 - val_f1_m: 0.7232\n",
      "0.79999995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 599us/sample - loss: 0.6729 - f1_m: 0.7912 - val_loss: 0.6490 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.6271 - f1_m: 0.7912 - val_loss: 0.5976 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5735 - f1_m: 0.7912 - val_loss: 0.5484 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5361 - f1_m: 0.7912 - val_loss: 0.5213 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5193 - f1_m: 0.7912 - val_loss: 0.5126 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5127 - f1_m: 0.7912 - val_loss: 0.5064 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5062 - f1_m: 0.7912 - val_loss: 0.5000 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5006 - f1_m: 0.7912 - val_loss: 0.4930 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4907 - f1_m: 0.7912 - val_loss: 0.4823 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4792 - f1_m: 0.7912 - val_loss: 0.4701 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4668 - f1_m: 0.7912 - val_loss: 0.4571 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4510 - f1_m: 0.7912 - val_loss: 0.4408 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4317 - f1_m: 0.7912 - val_loss: 0.4201 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4072 - f1_m: 0.7912 - val_loss: 0.3959 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3788 - f1_m: 0.7912 - val_loss: 0.3670 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3451 - f1_m: 0.7912 - val_loss: 0.3329 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3020 - f1_m: 0.7912 - val_loss: 0.2926 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2664 - f1_m: 0.7912 - val_loss: 0.2665 - val_f1_m: 0.7679\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2461 - f1_m: 0.7912 - val_loss: 0.2481 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2330 - f1_m: 0.7912 - val_loss: 0.2362 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 607us/sample - loss: 0.6779 - f1_m: 0.7867 - val_loss: 0.6596 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6462 - f1_m: 0.7875 - val_loss: 0.6192 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6067 - f1_m: 0.7875 - val_loss: 0.5713 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5655 - f1_m: 0.7875 - val_loss: 0.5268 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5399 - f1_m: 0.7875 - val_loss: 0.4997 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5277 - f1_m: 0.7875 - val_loss: 0.4889 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5210 - f1_m: 0.7875 - val_loss: 0.4825 - val_f1_m: 0.8348\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5164 - f1_m: 0.7875 - val_loss: 0.4782 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5112 - f1_m: 0.7875 - val_loss: 0.4710 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5064 - f1_m: 0.7875 - val_loss: 0.4678 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4999 - f1_m: 0.7875 - val_loss: 0.4601 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4934 - f1_m: 0.7875 - val_loss: 0.4532 - val_f1_m: 0.8348\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.4843 - f1_m: 0.7875 - val_loss: 0.4435 - val_f1_m: 0.8214\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4744 - f1_m: 0.7875 - val_loss: 0.4344 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.4616 - f1_m: 0.7875 - val_loss: 0.4204 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4452 - f1_m: 0.7875 - val_loss: 0.4030 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.4250 - f1_m: 0.7875 - val_loss: 0.3826 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.4027 - f1_m: 0.7875 - val_loss: 0.3627 - val_f1_m: 0.7946\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3777 - f1_m: 0.7875 - val_loss: 0.3357 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.3478 - f1_m: 0.7875 - val_loss: 0.3085 - val_f1_m: 0.8348\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 609us/sample - loss: 0.6747 - f1_m: 0.7900 - val_loss: 0.6490 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.6278 - f1_m: 0.7900 - val_loss: 0.5945 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.5783 - f1_m: 0.7900 - val_loss: 0.5417 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.5408 - f1_m: 0.7900 - val_loss: 0.5086 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5234 - f1_m: 0.7900 - val_loss: 0.4932 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5133 - f1_m: 0.7900 - val_loss: 0.4847 - val_f1_m: 0.8259\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 72us/sample - loss: 0.5007 - f1_m: 0.7900 - val_loss: 0.4731 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.4871 - f1_m: 0.7900 - val_loss: 0.4597 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.4711 - f1_m: 0.7900 - val_loss: 0.4434 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4503 - f1_m: 0.7900 - val_loss: 0.4245 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.4260 - f1_m: 0.7900 - val_loss: 0.4006 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.3975 - f1_m: 0.7900 - val_loss: 0.3731 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.3658 - f1_m: 0.7900 - val_loss: 0.3437 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.3342 - f1_m: 0.7900 - val_loss: 0.3148 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.3080 - f1_m: 0.7900 - val_loss: 0.2902 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.2851 - f1_m: 0.7900 - val_loss: 0.2691 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.2651 - f1_m: 0.7900 - val_loss: 0.2503 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.2469 - f1_m: 0.7900 - val_loss: 0.2338 - val_f1_m: 0.8259\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 0.2322 - f1_m: 0.7900 - val_loss: 0.2204 - val_f1_m: 0.7991\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.2220 - f1_m: 0.7900 - val_loss: 0.2116 - val_f1_m: 0.7723\n",
      "0.7899999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 619us/sample - loss: 0.6747 - f1_m: 0.8030 - val_loss: 0.6580 - val_f1_m: 0.7634\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.6240 - f1_m: 0.8037 - val_loss: 0.6195 - val_f1_m: 0.7366\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.5699 - f1_m: 0.8037 - val_loss: 0.5880 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.5292 - f1_m: 0.8037 - val_loss: 0.5781 - val_f1_m: 0.7634\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.5084 - f1_m: 0.8037 - val_loss: 0.5778 - val_f1_m: 0.7634\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.4996 - f1_m: 0.8037 - val_loss: 0.5717 - val_f1_m: 0.7500\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.4912 - f1_m: 0.8037 - val_loss: 0.5611 - val_f1_m: 0.7500\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.4812 - f1_m: 0.8037 - val_loss: 0.5494 - val_f1_m: 0.7366\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.4696 - f1_m: 0.8037 - val_loss: 0.5305 - val_f1_m: 0.7232\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.4551 - f1_m: 0.8037 - val_loss: 0.5121 - val_f1_m: 0.7634\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.4379 - f1_m: 0.8037 - val_loss: 0.4903 - val_f1_m: 0.7366\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.4161 - f1_m: 0.8037 - val_loss: 0.4591 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.3897 - f1_m: 0.8037 - val_loss: 0.4293 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.3596 - f1_m: 0.8037 - val_loss: 0.3913 - val_f1_m: 0.7366\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.3274 - f1_m: 0.8037 - val_loss: 0.3586 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.2993 - f1_m: 0.8037 - val_loss: 0.3351 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.2764 - f1_m: 0.8037 - val_loss: 0.3159 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.2575 - f1_m: 0.8037 - val_loss: 0.2953 - val_f1_m: 0.7500\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.2409 - f1_m: 0.8037 - val_loss: 0.2777 - val_f1_m: 0.7500\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.2257 - f1_m: 0.8037 - val_loss: 0.2612 - val_f1_m: 0.7366\n",
      "0.8037499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 675us/sample - loss: 0.6789 - f1_m: 0.7937 - val_loss: 0.6644 - val_f1_m: 0.7723\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.6496 - f1_m: 0.7937 - val_loss: 0.6306 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 0.6115 - f1_m: 0.7937 - val_loss: 0.5904 - val_f1_m: 0.7455\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.5707 - f1_m: 0.7937 - val_loss: 0.5516 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.5382 - f1_m: 0.7937 - val_loss: 0.5279 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.5220 - f1_m: 0.7937 - val_loss: 0.5189 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.5152 - f1_m: 0.7937 - val_loss: 0.5130 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.5105 - f1_m: 0.7937 - val_loss: 0.5080 - val_f1_m: 0.7991\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.5049 - f1_m: 0.7937 - val_loss: 0.5031 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.4991 - f1_m: 0.7937 - val_loss: 0.4977 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 0.4934 - f1_m: 0.7937 - val_loss: 0.4919 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 0.4869 - f1_m: 0.7937 - val_loss: 0.4851 - val_f1_m: 0.7857\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 0.4801 - f1_m: 0.7937 - val_loss: 0.4758 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 0.4691 - f1_m: 0.7937 - val_loss: 0.4654 - val_f1_m: 0.7455\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.4571 - f1_m: 0.7937 - val_loss: 0.4523 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.4419 - f1_m: 0.7937 - val_loss: 0.4366 - val_f1_m: 0.7723\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 0.4233 - f1_m: 0.7937 - val_loss: 0.4168 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 0.4021 - f1_m: 0.7937 - val_loss: 0.3946 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 0.3755 - f1_m: 0.7937 - val_loss: 0.3628 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 0.3440 - f1_m: 0.7937 - val_loss: 0.3287 - val_f1_m: 0.8125\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 684us/sample - loss: 0.6786 - f1_m: 0.7905 - val_loss: 0.6628 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 0.6476 - f1_m: 0.7912 - val_loss: 0.6260 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.6096 - f1_m: 0.7912 - val_loss: 0.5824 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 0.5688 - f1_m: 0.7912 - val_loss: 0.5429 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.5389 - f1_m: 0.7912 - val_loss: 0.5208 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 0.5248 - f1_m: 0.7912 - val_loss: 0.5108 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 0.5174 - f1_m: 0.7912 - val_loss: 0.5046 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 0.5114 - f1_m: 0.7912 - val_loss: 0.4992 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 0.5062 - f1_m: 0.7912 - val_loss: 0.4938 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 0.5003 - f1_m: 0.7912 - val_loss: 0.4878 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 171us/sample - loss: 0.4951 - f1_m: 0.7912 - val_loss: 0.4812 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 185us/sample - loss: 0.4871 - f1_m: 0.7912 - val_loss: 0.4741 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 180us/sample - loss: 0.4793 - f1_m: 0.7912 - val_loss: 0.4645 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 220us/sample - loss: 0.4669 - f1_m: 0.7912 - val_loss: 0.4511 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 0.4527 - f1_m: 0.7912 - val_loss: 0.4355 - val_f1_m: 0.7679\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 205us/sample - loss: 0.4357 - f1_m: 0.7912 - val_loss: 0.4173 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 199us/sample - loss: 0.4145 - f1_m: 0.7912 - val_loss: 0.3950 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 221us/sample - loss: 0.3920 - f1_m: 0.7912 - val_loss: 0.3695 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 221us/sample - loss: 0.3650 - f1_m: 0.7912 - val_loss: 0.3399 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 207us/sample - loss: 0.3289 - f1_m: 0.7912 - val_loss: 0.3014 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 721us/sample - loss: 0.6792 - f1_m: 0.7925 - val_loss: 0.6644 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 0.6480 - f1_m: 0.7925 - val_loss: 0.6301 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 0.6084 - f1_m: 0.7925 - val_loss: 0.5886 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 195us/sample - loss: 0.5695 - f1_m: 0.7925 - val_loss: 0.5483 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 208us/sample - loss: 0.5367 - f1_m: 0.7925 - val_loss: 0.5266 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 212us/sample - loss: 0.5200 - f1_m: 0.7925 - val_loss: 0.5137 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 173us/sample - loss: 0.5089 - f1_m: 0.7925 - val_loss: 0.5038 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 191us/sample - loss: 0.4995 - f1_m: 0.7925 - val_loss: 0.4931 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 200us/sample - loss: 0.4896 - f1_m: 0.7925 - val_loss: 0.4812 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 177us/sample - loss: 0.4779 - f1_m: 0.7925 - val_loss: 0.4672 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 195us/sample - loss: 0.4643 - f1_m: 0.7925 - val_loss: 0.4510 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 0.4468 - f1_m: 0.7925 - val_loss: 0.4300 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 0.4252 - f1_m: 0.7925 - val_loss: 0.4037 - val_f1_m: 0.7768\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 196us/sample - loss: 0.3990 - f1_m: 0.7925 - val_loss: 0.3726 - val_f1_m: 0.7902\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 181us/sample - loss: 0.3674 - f1_m: 0.7925 - val_loss: 0.3378 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 199us/sample - loss: 0.3350 - f1_m: 0.7925 - val_loss: 0.3062 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 202us/sample - loss: 0.3063 - f1_m: 0.7925 - val_loss: 0.2813 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 207us/sample - loss: 0.2843 - f1_m: 0.7925 - val_loss: 0.2613 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 204us/sample - loss: 0.2667 - f1_m: 0.7925 - val_loss: 0.2456 - val_f1_m: 0.8036\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 187us/sample - loss: 0.2523 - f1_m: 0.7925 - val_loss: 0.2305 - val_f1_m: 0.8036\n",
      "0.7925\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 734us/sample - loss: 0.6735 - f1_m: 0.7968 - val_loss: 0.6520 - val_f1_m: 0.7455\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 218us/sample - loss: 0.6249 - f1_m: 0.7975 - val_loss: 0.6044 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 250us/sample - loss: 0.5722 - f1_m: 0.7975 - val_loss: 0.5618 - val_f1_m: 0.7589\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.5327 - f1_m: 0.7975 - val_loss: 0.5428 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 199us/sample - loss: 0.5156 - f1_m: 0.7975 - val_loss: 0.5353 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 182us/sample - loss: 0.5080 - f1_m: 0.7975 - val_loss: 0.5300 - val_f1_m: 0.7723\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 200us/sample - loss: 0.5007 - f1_m: 0.7975 - val_loss: 0.5228 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.4933 - f1_m: 0.7975 - val_loss: 0.5148 - val_f1_m: 0.7589\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 205us/sample - loss: 0.4855 - f1_m: 0.7975 - val_loss: 0.5032 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 258us/sample - loss: 0.4721 - f1_m: 0.7975 - val_loss: 0.4908 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 246us/sample - loss: 0.4582 - f1_m: 0.7975 - val_loss: 0.4781 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.4434 - f1_m: 0.7975 - val_loss: 0.4615 - val_f1_m: 0.7589\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 239us/sample - loss: 0.4248 - f1_m: 0.7975 - val_loss: 0.4408 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 257us/sample - loss: 0.4017 - f1_m: 0.7975 - val_loss: 0.4151 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 0.3751 - f1_m: 0.7975 - val_loss: 0.3853 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.3437 - f1_m: 0.7975 - val_loss: 0.3520 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 274us/sample - loss: 0.3084 - f1_m: 0.7975 - val_loss: 0.3138 - val_f1_m: 0.7723\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 300us/sample - loss: 0.2732 - f1_m: 0.7975 - val_loss: 0.2823 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 223us/sample - loss: 0.2466 - f1_m: 0.7975 - val_loss: 0.2616 - val_f1_m: 0.7857\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 0.2305 - f1_m: 0.7975 - val_loss: 0.2504 - val_f1_m: 0.7589\n",
      "0.7974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 768us/sample - loss: 0.6793 - f1_m: 0.7937 - val_loss: 0.6649 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.6493 - f1_m: 0.7937 - val_loss: 0.6327 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 198us/sample - loss: 0.6137 - f1_m: 0.7937 - val_loss: 0.5939 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 229us/sample - loss: 0.5743 - f1_m: 0.7937 - val_loss: 0.5578 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 223us/sample - loss: 0.5414 - f1_m: 0.7937 - val_loss: 0.5351 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 198us/sample - loss: 0.5242 - f1_m: 0.7937 - val_loss: 0.5236 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 0.5136 - f1_m: 0.7937 - val_loss: 0.5150 - val_f1_m: 0.7857\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 216us/sample - loss: 0.5056 - f1_m: 0.7937 - val_loss: 0.5060 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.4951 - f1_m: 0.7937 - val_loss: 0.4941 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 221us/sample - loss: 0.4823 - f1_m: 0.7937 - val_loss: 0.4817 - val_f1_m: 0.7857\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 220us/sample - loss: 0.4689 - f1_m: 0.7937 - val_loss: 0.4673 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 203us/sample - loss: 0.4524 - f1_m: 0.7937 - val_loss: 0.4489 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 0.4316 - f1_m: 0.7937 - val_loss: 0.4253 - val_f1_m: 0.7991\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.4062 - f1_m: 0.7937 - val_loss: 0.3983 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 274us/sample - loss: 0.3764 - f1_m: 0.7937 - val_loss: 0.3684 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 224us/sample - loss: 0.3484 - f1_m: 0.7937 - val_loss: 0.3406 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 0.3206 - f1_m: 0.7937 - val_loss: 0.3176 - val_f1_m: 0.8125\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 240us/sample - loss: 0.2992 - f1_m: 0.7937 - val_loss: 0.2975 - val_f1_m: 0.8125\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 0.2824 - f1_m: 0.7937 - val_loss: 0.2811 - val_f1_m: 0.7857\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 247us/sample - loss: 0.2678 - f1_m: 0.7937 - val_loss: 0.2676 - val_f1_m: 0.7723\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 772us/sample - loss: 0.6796 - f1_m: 0.7912 - val_loss: 0.6633 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 224us/sample - loss: 0.6481 - f1_m: 0.7912 - val_loss: 0.6264 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 260us/sample - loss: 0.6084 - f1_m: 0.7912 - val_loss: 0.5817 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.5654 - f1_m: 0.7912 - val_loss: 0.5414 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.5352 - f1_m: 0.7912 - val_loss: 0.5190 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.5212 - f1_m: 0.7912 - val_loss: 0.5093 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.5145 - f1_m: 0.7912 - val_loss: 0.5034 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 243us/sample - loss: 0.5085 - f1_m: 0.7912 - val_loss: 0.4981 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 0.5027 - f1_m: 0.7912 - val_loss: 0.4930 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 190us/sample - loss: 0.4972 - f1_m: 0.7912 - val_loss: 0.4870 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 0.4910 - f1_m: 0.7912 - val_loss: 0.4813 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.4827 - f1_m: 0.7912 - val_loss: 0.4738 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 0.4735 - f1_m: 0.7912 - val_loss: 0.4639 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 319us/sample - loss: 0.4603 - f1_m: 0.7912 - val_loss: 0.4520 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.4447 - f1_m: 0.7912 - val_loss: 0.4355 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 256us/sample - loss: 0.4259 - f1_m: 0.7912 - val_loss: 0.4159 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 280us/sample - loss: 0.4032 - f1_m: 0.7912 - val_loss: 0.3934 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 236us/sample - loss: 0.3750 - f1_m: 0.7912 - val_loss: 0.3596 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 238us/sample - loss: 0.3317 - f1_m: 0.7912 - val_loss: 0.3245 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 265us/sample - loss: 0.2962 - f1_m: 0.7912 - val_loss: 0.2978 - val_f1_m: 0.7946\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 757us/sample - loss: 0.6789 - f1_m: 0.7875 - val_loss: 0.6578 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.6353 - f1_m: 0.7875 - val_loss: 0.5960 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 263us/sample - loss: 0.5808 - f1_m: 0.7875 - val_loss: 0.5395 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 302us/sample - loss: 0.5446 - f1_m: 0.7875 - val_loss: 0.5055 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 213us/sample - loss: 0.5278 - f1_m: 0.7875 - val_loss: 0.4894 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 0.5186 - f1_m: 0.7875 - val_loss: 0.4803 - val_f1_m: 0.8348\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 281us/sample - loss: 0.5095 - f1_m: 0.7875 - val_loss: 0.4701 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.4963 - f1_m: 0.7875 - val_loss: 0.4554 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 0.4814 - f1_m: 0.7875 - val_loss: 0.4401 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.4640 - f1_m: 0.7875 - val_loss: 0.4197 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 208us/sample - loss: 0.4433 - f1_m: 0.7875 - val_loss: 0.3975 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 194us/sample - loss: 0.4177 - f1_m: 0.7875 - val_loss: 0.3709 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 213us/sample - loss: 0.3893 - f1_m: 0.7875 - val_loss: 0.3419 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 199us/sample - loss: 0.3575 - f1_m: 0.7875 - val_loss: 0.3096 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 189us/sample - loss: 0.3320 - f1_m: 0.7875 - val_loss: 0.2853 - val_f1_m: 0.7679\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.3084 - f1_m: 0.7875 - val_loss: 0.2645 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 264us/sample - loss: 0.2889 - f1_m: 0.7875 - val_loss: 0.2458 - val_f1_m: 0.8348\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 253us/sample - loss: 0.2709 - f1_m: 0.7875 - val_loss: 0.2287 - val_f1_m: 0.8214\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 203us/sample - loss: 0.2544 - f1_m: 0.7875 - val_loss: 0.2142 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 216us/sample - loss: 0.2413 - f1_m: 0.7875 - val_loss: 0.2035 - val_f1_m: 0.8080\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 592us/sample - loss: 0.6779 - f1_m: 0.7879 - val_loss: 0.6555 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6331 - f1_m: 0.7887 - val_loss: 0.5995 - val_f1_m: 0.8036\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5837 - f1_m: 0.7887 - val_loss: 0.5462 - val_f1_m: 0.8036\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5445 - f1_m: 0.7887 - val_loss: 0.5124 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5263 - f1_m: 0.7887 - val_loss: 0.4963 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5174 - f1_m: 0.7887 - val_loss: 0.4875 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5089 - f1_m: 0.7887 - val_loss: 0.4761 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4977 - f1_m: 0.7887 - val_loss: 0.4652 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4838 - f1_m: 0.7887 - val_loss: 0.4496 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4687 - f1_m: 0.7887 - val_loss: 0.4341 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4484 - f1_m: 0.7887 - val_loss: 0.4123 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4254 - f1_m: 0.7887 - val_loss: 0.3870 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3976 - f1_m: 0.7887 - val_loss: 0.3594 - val_f1_m: 0.8304\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3659 - f1_m: 0.7887 - val_loss: 0.3282 - val_f1_m: 0.8170\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3357 - f1_m: 0.7887 - val_loss: 0.3027 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3099 - f1_m: 0.7887 - val_loss: 0.2795 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2875 - f1_m: 0.7887 - val_loss: 0.2601 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2682 - f1_m: 0.7887 - val_loss: 0.2441 - val_f1_m: 0.8304\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2496 - f1_m: 0.7887 - val_loss: 0.2300 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2355 - f1_m: 0.7887 - val_loss: 0.2205 - val_f1_m: 0.7902\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.6739 - f1_m: 0.7931 - val_loss: 0.6514 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6265 - f1_m: 0.7937 - val_loss: 0.6018 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5746 - f1_m: 0.7937 - val_loss: 0.5545 - val_f1_m: 0.7857\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5341 - f1_m: 0.7937 - val_loss: 0.5310 - val_f1_m: 0.7723\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5166 - f1_m: 0.7937 - val_loss: 0.5225 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5097 - f1_m: 0.7937 - val_loss: 0.5165 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5034 - f1_m: 0.7937 - val_loss: 0.5095 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4971 - f1_m: 0.7937 - val_loss: 0.5023 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4889 - f1_m: 0.7937 - val_loss: 0.4913 - val_f1_m: 0.7857\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4779 - f1_m: 0.7937 - val_loss: 0.4784 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4651 - f1_m: 0.7937 - val_loss: 0.4644 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4500 - f1_m: 0.7937 - val_loss: 0.4471 - val_f1_m: 0.7589\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4320 - f1_m: 0.7937 - val_loss: 0.4247 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4091 - f1_m: 0.7937 - val_loss: 0.3979 - val_f1_m: 0.7991\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3821 - f1_m: 0.7937 - val_loss: 0.3676 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3500 - f1_m: 0.7937 - val_loss: 0.3320 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3132 - f1_m: 0.7937 - val_loss: 0.2877 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2740 - f1_m: 0.7937 - val_loss: 0.2504 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2466 - f1_m: 0.7937 - val_loss: 0.2306 - val_f1_m: 0.7857\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2294 - f1_m: 0.7937 - val_loss: 0.2166 - val_f1_m: 0.7857\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 594us/sample - loss: 0.6780 - f1_m: 0.7860 - val_loss: 0.6547 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6313 - f1_m: 0.7875 - val_loss: 0.5933 - val_f1_m: 0.8348\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5806 - f1_m: 0.7875 - val_loss: 0.5385 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5446 - f1_m: 0.7875 - val_loss: 0.5029 - val_f1_m: 0.8348\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5277 - f1_m: 0.7875 - val_loss: 0.4875 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5178 - f1_m: 0.7875 - val_loss: 0.4791 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5082 - f1_m: 0.7875 - val_loss: 0.4689 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4943 - f1_m: 0.7875 - val_loss: 0.4556 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4783 - f1_m: 0.7875 - val_loss: 0.4400 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4589 - f1_m: 0.7875 - val_loss: 0.4222 - val_f1_m: 0.8080\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4351 - f1_m: 0.7875 - val_loss: 0.3997 - val_f1_m: 0.8080\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4074 - f1_m: 0.7875 - val_loss: 0.3716 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3750 - f1_m: 0.7875 - val_loss: 0.3426 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3426 - f1_m: 0.7875 - val_loss: 0.3120 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3154 - f1_m: 0.7875 - val_loss: 0.2879 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2910 - f1_m: 0.7875 - val_loss: 0.2673 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2695 - f1_m: 0.7875 - val_loss: 0.2499 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2496 - f1_m: 0.7875 - val_loss: 0.2342 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.2328 - f1_m: 0.7875 - val_loss: 0.2224 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.2206 - f1_m: 0.7875 - val_loss: 0.2132 - val_f1_m: 0.8348\n",
      "0.7874999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.6740 - f1_m: 0.7812 - val_loss: 0.6437 - val_f1_m: 0.8437\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6342 - f1_m: 0.7812 - val_loss: 0.5889 - val_f1_m: 0.8170\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5927 - f1_m: 0.7812 - val_loss: 0.5311 - val_f1_m: 0.8437\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5561 - f1_m: 0.7812 - val_loss: 0.4855 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5340 - f1_m: 0.7812 - val_loss: 0.4565 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5224 - f1_m: 0.7812 - val_loss: 0.4433 - val_f1_m: 0.8304\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5132 - f1_m: 0.7812 - val_loss: 0.4356 - val_f1_m: 0.8304\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5032 - f1_m: 0.7812 - val_loss: 0.4241 - val_f1_m: 0.8304\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4909 - f1_m: 0.7812 - val_loss: 0.4130 - val_f1_m: 0.8437\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4770 - f1_m: 0.7812 - val_loss: 0.3989 - val_f1_m: 0.8571\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4590 - f1_m: 0.7812 - val_loss: 0.3840 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4354 - f1_m: 0.7812 - val_loss: 0.3601 - val_f1_m: 0.8304\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4078 - f1_m: 0.7812 - val_loss: 0.3367 - val_f1_m: 0.8437\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3806 - f1_m: 0.7812 - val_loss: 0.3091 - val_f1_m: 0.8437\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3538 - f1_m: 0.7812 - val_loss: 0.2859 - val_f1_m: 0.8437\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3273 - f1_m: 0.7812 - val_loss: 0.2641 - val_f1_m: 0.8437\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2990 - f1_m: 0.7812 - val_loss: 0.2371 - val_f1_m: 0.8437\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2701 - f1_m: 0.7812 - val_loss: 0.2164 - val_f1_m: 0.8437\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2478 - f1_m: 0.7812 - val_loss: 0.1994 - val_f1_m: 0.8304\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2297 - f1_m: 0.7812 - val_loss: 0.1889 - val_f1_m: 0.8571\n",
      "0.78124994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 597us/sample - loss: 0.6718 - f1_m: 0.8037 - val_loss: 0.6563 - val_f1_m: 0.7098\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.6211 - f1_m: 0.8037 - val_loss: 0.6147 - val_f1_m: 0.7366\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5631 - f1_m: 0.8037 - val_loss: 0.5816 - val_f1_m: 0.7500\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5230 - f1_m: 0.8037 - val_loss: 0.5743 - val_f1_m: 0.7366\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5056 - f1_m: 0.8037 - val_loss: 0.5734 - val_f1_m: 0.7634\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4979 - f1_m: 0.8037 - val_loss: 0.5658 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4917 - f1_m: 0.8037 - val_loss: 0.5617 - val_f1_m: 0.7366\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4855 - f1_m: 0.8037 - val_loss: 0.5552 - val_f1_m: 0.7634\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4777 - f1_m: 0.8037 - val_loss: 0.5440 - val_f1_m: 0.7366\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4686 - f1_m: 0.8037 - val_loss: 0.5307 - val_f1_m: 0.7634\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4552 - f1_m: 0.8037 - val_loss: 0.5146 - val_f1_m: 0.7366\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4413 - f1_m: 0.8037 - val_loss: 0.5003 - val_f1_m: 0.7232\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4245 - f1_m: 0.8037 - val_loss: 0.4795 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4040 - f1_m: 0.8037 - val_loss: 0.4520 - val_f1_m: 0.7500\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3798 - f1_m: 0.8037 - val_loss: 0.4211 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3502 - f1_m: 0.8037 - val_loss: 0.3836 - val_f1_m: 0.7634\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3171 - f1_m: 0.8037 - val_loss: 0.3437 - val_f1_m: 0.7366\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2850 - f1_m: 0.8037 - val_loss: 0.3126 - val_f1_m: 0.7634\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.2565 - f1_m: 0.8037 - val_loss: 0.2779 - val_f1_m: 0.7768\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2332 - f1_m: 0.8037 - val_loss: 0.2627 - val_f1_m: 0.7366\n",
      "0.8037499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 608us/sample - loss: 0.6741 - f1_m: 0.7912 - val_loss: 0.6506 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6259 - f1_m: 0.7912 - val_loss: 0.5985 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5756 - f1_m: 0.7912 - val_loss: 0.5474 - val_f1_m: 0.8080\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5353 - f1_m: 0.7912 - val_loss: 0.5192 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5195 - f1_m: 0.7912 - val_loss: 0.5084 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5135 - f1_m: 0.7912 - val_loss: 0.5014 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5062 - f1_m: 0.7912 - val_loss: 0.4955 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4988 - f1_m: 0.7912 - val_loss: 0.4876 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4897 - f1_m: 0.7912 - val_loss: 0.4768 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4788 - f1_m: 0.7912 - val_loss: 0.4648 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4652 - f1_m: 0.7912 - val_loss: 0.4518 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4497 - f1_m: 0.7912 - val_loss: 0.4350 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4295 - f1_m: 0.7912 - val_loss: 0.4137 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4058 - f1_m: 0.7912 - val_loss: 0.3896 - val_f1_m: 0.7679\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3765 - f1_m: 0.7912 - val_loss: 0.3598 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3419 - f1_m: 0.7912 - val_loss: 0.3252 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2975 - f1_m: 0.7912 - val_loss: 0.2861 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2587 - f1_m: 0.7912 - val_loss: 0.2616 - val_f1_m: 0.7946\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2356 - f1_m: 0.7912 - val_loss: 0.2445 - val_f1_m: 0.7679\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.2201 - f1_m: 0.7912 - val_loss: 0.2338 - val_f1_m: 0.7946\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 603us/sample - loss: 0.6756 - f1_m: 0.7880 - val_loss: 0.6495 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.6290 - f1_m: 0.7887 - val_loss: 0.5950 - val_f1_m: 0.8304\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5785 - f1_m: 0.7887 - val_loss: 0.5436 - val_f1_m: 0.8304\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5411 - f1_m: 0.7887 - val_loss: 0.5131 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5245 - f1_m: 0.7887 - val_loss: 0.4995 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5164 - f1_m: 0.7887 - val_loss: 0.4919 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5080 - f1_m: 0.7887 - val_loss: 0.4810 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.4968 - f1_m: 0.7887 - val_loss: 0.4694 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.4849 - f1_m: 0.7887 - val_loss: 0.4560 - val_f1_m: 0.8304\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.4703 - f1_m: 0.7887 - val_loss: 0.4402 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4519 - f1_m: 0.7887 - val_loss: 0.4194 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.4289 - f1_m: 0.7887 - val_loss: 0.3942 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.4015 - f1_m: 0.7887 - val_loss: 0.3657 - val_f1_m: 0.7902\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3714 - f1_m: 0.7887 - val_loss: 0.3343 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.3398 - f1_m: 0.7887 - val_loss: 0.3060 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.3118 - f1_m: 0.7887 - val_loss: 0.2855 - val_f1_m: 0.8170\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 70us/sample - loss: 0.2909 - f1_m: 0.7887 - val_loss: 0.2617 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2717 - f1_m: 0.7887 - val_loss: 0.2450 - val_f1_m: 0.8170\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2540 - f1_m: 0.7887 - val_loss: 0.2290 - val_f1_m: 0.7768\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2395 - f1_m: 0.7887 - val_loss: 0.2188 - val_f1_m: 0.8036\n",
      "0.78874993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 609us/sample - loss: 0.6796 - f1_m: 0.7830 - val_loss: 0.6589 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.6490 - f1_m: 0.7837 - val_loss: 0.6179 - val_f1_m: 0.8482\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6115 - f1_m: 0.7837 - val_loss: 0.5676 - val_f1_m: 0.8348\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5713 - f1_m: 0.7837 - val_loss: 0.5197 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5448 - f1_m: 0.7837 - val_loss: 0.4870 - val_f1_m: 0.8348\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5290 - f1_m: 0.7837 - val_loss: 0.4701 - val_f1_m: 0.8348\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5181 - f1_m: 0.7837 - val_loss: 0.4577 - val_f1_m: 0.8482\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5077 - f1_m: 0.7837 - val_loss: 0.4472 - val_f1_m: 0.8482\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4962 - f1_m: 0.7837 - val_loss: 0.4366 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4835 - f1_m: 0.7837 - val_loss: 0.4236 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.4684 - f1_m: 0.7837 - val_loss: 0.4063 - val_f1_m: 0.8348\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4490 - f1_m: 0.7837 - val_loss: 0.3883 - val_f1_m: 0.8214\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4221 - f1_m: 0.7837 - val_loss: 0.3605 - val_f1_m: 0.8348\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3887 - f1_m: 0.7837 - val_loss: 0.3261 - val_f1_m: 0.8348\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.3534 - f1_m: 0.7837 - val_loss: 0.2921 - val_f1_m: 0.8214\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.3210 - f1_m: 0.7837 - val_loss: 0.2661 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.2963 - f1_m: 0.7837 - val_loss: 0.2480 - val_f1_m: 0.8482\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2742 - f1_m: 0.7837 - val_loss: 0.2277 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2569 - f1_m: 0.7837 - val_loss: 0.2142 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 0.2431 - f1_m: 0.7837 - val_loss: 0.2041 - val_f1_m: 0.8348\n",
      "0.78374994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 620us/sample - loss: 0.6732 - f1_m: 0.7918 - val_loss: 0.6500 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.6273 - f1_m: 0.7925 - val_loss: 0.5980 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.5733 - f1_m: 0.7925 - val_loss: 0.5493 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.5341 - f1_m: 0.7925 - val_loss: 0.5218 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.5181 - f1_m: 0.7925 - val_loss: 0.5121 - val_f1_m: 0.7902\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.5109 - f1_m: 0.7925 - val_loss: 0.5053 - val_f1_m: 0.8036\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.5040 - f1_m: 0.7925 - val_loss: 0.4987 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.4977 - f1_m: 0.7925 - val_loss: 0.4907 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.4892 - f1_m: 0.7925 - val_loss: 0.4801 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.4778 - f1_m: 0.7925 - val_loss: 0.4675 - val_f1_m: 0.8170\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.4647 - f1_m: 0.7925 - val_loss: 0.4531 - val_f1_m: 0.8170\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.4489 - f1_m: 0.7925 - val_loss: 0.4345 - val_f1_m: 0.8170\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.4287 - f1_m: 0.7925 - val_loss: 0.4110 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.4027 - f1_m: 0.7925 - val_loss: 0.3819 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.3714 - f1_m: 0.7925 - val_loss: 0.3464 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.3330 - f1_m: 0.7925 - val_loss: 0.2998 - val_f1_m: 0.8036\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.2838 - f1_m: 0.7925 - val_loss: 0.2568 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 0.2507 - f1_m: 0.7925 - val_loss: 0.2310 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.2316 - f1_m: 0.7925 - val_loss: 0.2154 - val_f1_m: 0.7902\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2194 - f1_m: 0.7925 - val_loss: 0.2045 - val_f1_m: 0.7902\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 633us/sample - loss: 0.6793 - f1_m: 0.7862 - val_loss: 0.6603 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.6497 - f1_m: 0.7862 - val_loss: 0.6208 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.6135 - f1_m: 0.7862 - val_loss: 0.5726 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.5737 - f1_m: 0.7862 - val_loss: 0.5254 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.5439 - f1_m: 0.7862 - val_loss: 0.4936 - val_f1_m: 0.8259\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.5324 - f1_m: 0.7862 - val_loss: 0.4782 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.5228 - f1_m: 0.7862 - val_loss: 0.4746 - val_f1_m: 0.8259\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5174 - f1_m: 0.7862 - val_loss: 0.4680 - val_f1_m: 0.8393\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.5126 - f1_m: 0.7862 - val_loss: 0.4618 - val_f1_m: 0.8393\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5063 - f1_m: 0.7862 - val_loss: 0.4572 - val_f1_m: 0.8259\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.5006 - f1_m: 0.7862 - val_loss: 0.4498 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.4934 - f1_m: 0.7862 - val_loss: 0.4434 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.4851 - f1_m: 0.7862 - val_loss: 0.4349 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.4743 - f1_m: 0.7862 - val_loss: 0.4238 - val_f1_m: 0.8393\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.4595 - f1_m: 0.7862 - val_loss: 0.4098 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.4415 - f1_m: 0.7862 - val_loss: 0.3900 - val_f1_m: 0.8259\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.4205 - f1_m: 0.7862 - val_loss: 0.3693 - val_f1_m: 0.8125\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.3982 - f1_m: 0.7862 - val_loss: 0.3419 - val_f1_m: 0.8259\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.3643 - f1_m: 0.7862 - val_loss: 0.3042 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.3265 - f1_m: 0.7862 - val_loss: 0.2681 - val_f1_m: 0.7991\n",
      "0.78624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 638us/sample - loss: 0.6758 - f1_m: 0.8037 - val_loss: 0.6600 - val_f1_m: 0.7366\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.6252 - f1_m: 0.8037 - val_loss: 0.6184 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 0.5704 - f1_m: 0.8037 - val_loss: 0.5848 - val_f1_m: 0.7366\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.5282 - f1_m: 0.8037 - val_loss: 0.5727 - val_f1_m: 0.7366\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.5075 - f1_m: 0.8037 - val_loss: 0.5710 - val_f1_m: 0.7634\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.4976 - f1_m: 0.8037 - val_loss: 0.5648 - val_f1_m: 0.7500\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.4865 - f1_m: 0.8037 - val_loss: 0.5499 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.4733 - f1_m: 0.8037 - val_loss: 0.5331 - val_f1_m: 0.7500\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.4590 - f1_m: 0.8037 - val_loss: 0.5158 - val_f1_m: 0.7500\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.4421 - f1_m: 0.8037 - val_loss: 0.4920 - val_f1_m: 0.7366\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.4200 - f1_m: 0.8037 - val_loss: 0.4674 - val_f1_m: 0.7500\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.3940 - f1_m: 0.8037 - val_loss: 0.4345 - val_f1_m: 0.7634\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.3646 - f1_m: 0.8037 - val_loss: 0.3974 - val_f1_m: 0.6830\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 0.3320 - f1_m: 0.8037 - val_loss: 0.3638 - val_f1_m: 0.7366\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.3031 - f1_m: 0.8037 - val_loss: 0.3376 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.2798 - f1_m: 0.8037 - val_loss: 0.3134 - val_f1_m: 0.7366\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 0.2598 - f1_m: 0.8037 - val_loss: 0.2922 - val_f1_m: 0.7500\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.2419 - f1_m: 0.8037 - val_loss: 0.2707 - val_f1_m: 0.7500\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.2254 - f1_m: 0.8037 - val_loss: 0.2573 - val_f1_m: 0.7500\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.2132 - f1_m: 0.8037 - val_loss: 0.2415 - val_f1_m: 0.7500\n",
      "0.8037499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 658us/sample - loss: 0.6740 - f1_m: 0.7950 - val_loss: 0.6518 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.6271 - f1_m: 0.7950 - val_loss: 0.6029 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 0.5764 - f1_m: 0.7950 - val_loss: 0.5554 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.5351 - f1_m: 0.7950 - val_loss: 0.5291 - val_f1_m: 0.7679\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.5160 - f1_m: 0.7950 - val_loss: 0.5188 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.5072 - f1_m: 0.7950 - val_loss: 0.5113 - val_f1_m: 0.7812\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 0.4992 - f1_m: 0.7950 - val_loss: 0.5032 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 0.4889 - f1_m: 0.7950 - val_loss: 0.4918 - val_f1_m: 0.7812\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 0.4758 - f1_m: 0.7950 - val_loss: 0.4784 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 0.4609 - f1_m: 0.7950 - val_loss: 0.4634 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.4433 - f1_m: 0.7950 - val_loss: 0.4449 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.4224 - f1_m: 0.7950 - val_loss: 0.4227 - val_f1_m: 0.7679\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.3977 - f1_m: 0.7950 - val_loss: 0.3966 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.3666 - f1_m: 0.7950 - val_loss: 0.3630 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 0.3309 - f1_m: 0.7950 - val_loss: 0.3232 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 0.2883 - f1_m: 0.7950 - val_loss: 0.2825 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 0.2530 - f1_m: 0.7950 - val_loss: 0.2560 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 0.2325 - f1_m: 0.7950 - val_loss: 0.2371 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.2164 - f1_m: 0.7950 - val_loss: 0.2248 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 108us/sample - loss: 0.2052 - f1_m: 0.7950 - val_loss: 0.2145 - val_f1_m: 0.7946\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 697us/sample - loss: 0.6801 - f1_m: 0.7800 - val_loss: 0.6576 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 0.6506 - f1_m: 0.7800 - val_loss: 0.6132 - val_f1_m: 0.8482\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.6154 - f1_m: 0.7800 - val_loss: 0.5587 - val_f1_m: 0.8482\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 0.5782 - f1_m: 0.7800 - val_loss: 0.5051 - val_f1_m: 0.8482\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 199us/sample - loss: 0.5507 - f1_m: 0.7800 - val_loss: 0.4714 - val_f1_m: 0.8616\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 189us/sample - loss: 0.5380 - f1_m: 0.7800 - val_loss: 0.4513 - val_f1_m: 0.8482\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 0.5300 - f1_m: 0.7800 - val_loss: 0.4443 - val_f1_m: 0.8482\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 0.5240 - f1_m: 0.7800 - val_loss: 0.4354 - val_f1_m: 0.8348\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 0.5173 - f1_m: 0.7800 - val_loss: 0.4335 - val_f1_m: 0.8482\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 0.5107 - f1_m: 0.7800 - val_loss: 0.4233 - val_f1_m: 0.8348\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 176us/sample - loss: 0.5018 - f1_m: 0.7800 - val_loss: 0.4162 - val_f1_m: 0.8482\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 174us/sample - loss: 0.4909 - f1_m: 0.7800 - val_loss: 0.4049 - val_f1_m: 0.8482\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 183us/sample - loss: 0.4768 - f1_m: 0.7800 - val_loss: 0.3949 - val_f1_m: 0.8616\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 191us/sample - loss: 0.4602 - f1_m: 0.7800 - val_loss: 0.3788 - val_f1_m: 0.8616\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 0.4383 - f1_m: 0.7800 - val_loss: 0.3586 - val_f1_m: 0.8482\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 202us/sample - loss: 0.4131 - f1_m: 0.7800 - val_loss: 0.3312 - val_f1_m: 0.8616\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 205us/sample - loss: 0.3800 - f1_m: 0.7800 - val_loss: 0.2991 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 190us/sample - loss: 0.3405 - f1_m: 0.7800 - val_loss: 0.2622 - val_f1_m: 0.8348\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 182us/sample - loss: 0.3027 - f1_m: 0.7800 - val_loss: 0.2327 - val_f1_m: 0.8616\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 215us/sample - loss: 0.2726 - f1_m: 0.7800 - val_loss: 0.2098 - val_f1_m: 0.8482\n",
      "0.7799999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 743us/sample - loss: 0.6725 - f1_m: 0.7925 - val_loss: 0.6490 - val_f1_m: 0.8036\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 200us/sample - loss: 0.6245 - f1_m: 0.7925 - val_loss: 0.5974 - val_f1_m: 0.7902\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 209us/sample - loss: 0.5728 - f1_m: 0.7925 - val_loss: 0.5488 - val_f1_m: 0.8170\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 0.5354 - f1_m: 0.7925 - val_loss: 0.5240 - val_f1_m: 0.8036\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 181us/sample - loss: 0.5210 - f1_m: 0.7925 - val_loss: 0.5147 - val_f1_m: 0.8036\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 192us/sample - loss: 0.5130 - f1_m: 0.7925 - val_loss: 0.5081 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 0.5068 - f1_m: 0.7925 - val_loss: 0.5013 - val_f1_m: 0.7634\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 175us/sample - loss: 0.5004 - f1_m: 0.7925 - val_loss: 0.4938 - val_f1_m: 0.8036\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 0.4927 - f1_m: 0.7925 - val_loss: 0.4840 - val_f1_m: 0.8036\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 176us/sample - loss: 0.4826 - f1_m: 0.7925 - val_loss: 0.4706 - val_f1_m: 0.7902\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 184us/sample - loss: 0.4688 - f1_m: 0.7925 - val_loss: 0.4565 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 213us/sample - loss: 0.4541 - f1_m: 0.7925 - val_loss: 0.4395 - val_f1_m: 0.8036\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 190us/sample - loss: 0.4361 - f1_m: 0.7925 - val_loss: 0.4187 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 0.4138 - f1_m: 0.7925 - val_loss: 0.3928 - val_f1_m: 0.7768\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 0.3866 - f1_m: 0.7925 - val_loss: 0.3625 - val_f1_m: 0.8036\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 214us/sample - loss: 0.3553 - f1_m: 0.7925 - val_loss: 0.3285 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 0.3204 - f1_m: 0.7925 - val_loss: 0.2907 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 181us/sample - loss: 0.2869 - f1_m: 0.7925 - val_loss: 0.2617 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 213us/sample - loss: 0.2563 - f1_m: 0.7925 - val_loss: 0.2319 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 0.2361 - f1_m: 0.7925 - val_loss: 0.2202 - val_f1_m: 0.7902\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 737us/sample - loss: 0.6752 - f1_m: 0.7950 - val_loss: 0.6511 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 0.6270 - f1_m: 0.7950 - val_loss: 0.6005 - val_f1_m: 0.7679\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 216us/sample - loss: 0.5729 - f1_m: 0.7950 - val_loss: 0.5506 - val_f1_m: 0.7679\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 200us/sample - loss: 0.5326 - f1_m: 0.7950 - val_loss: 0.5253 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 195us/sample - loss: 0.5180 - f1_m: 0.7950 - val_loss: 0.5165 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 177us/sample - loss: 0.5091 - f1_m: 0.7950 - val_loss: 0.5106 - val_f1_m: 0.7679\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 224us/sample - loss: 0.5023 - f1_m: 0.7950 - val_loss: 0.5047 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 201us/sample - loss: 0.4949 - f1_m: 0.7950 - val_loss: 0.4969 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 0.4852 - f1_m: 0.7950 - val_loss: 0.4866 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 196us/sample - loss: 0.4738 - f1_m: 0.7950 - val_loss: 0.4757 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 0.4614 - f1_m: 0.7950 - val_loss: 0.4627 - val_f1_m: 0.7946\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 183us/sample - loss: 0.4457 - f1_m: 0.7950 - val_loss: 0.4457 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 189us/sample - loss: 0.4274 - f1_m: 0.7950 - val_loss: 0.4249 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 0.4048 - f1_m: 0.7950 - val_loss: 0.3998 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 0.3777 - f1_m: 0.7950 - val_loss: 0.3702 - val_f1_m: 0.7679\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 201us/sample - loss: 0.3464 - f1_m: 0.7950 - val_loss: 0.3320 - val_f1_m: 0.7679\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 173us/sample - loss: 0.3055 - f1_m: 0.7950 - val_loss: 0.2909 - val_f1_m: 0.7946\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 162us/sample - loss: 0.2698 - f1_m: 0.7950 - val_loss: 0.2572 - val_f1_m: 0.7679\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 0.2444 - f1_m: 0.7950 - val_loss: 0.2390 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 181us/sample - loss: 0.2292 - f1_m: 0.7950 - val_loss: 0.2261 - val_f1_m: 0.7812\n",
      "0.7949999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 736us/sample - loss: 0.6771 - f1_m: 0.7825 - val_loss: 0.6465 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 206us/sample - loss: 0.6320 - f1_m: 0.7825 - val_loss: 0.5864 - val_f1_m: 0.8259\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 220us/sample - loss: 0.5844 - f1_m: 0.7825 - val_loss: 0.5255 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 208us/sample - loss: 0.5477 - f1_m: 0.7825 - val_loss: 0.4874 - val_f1_m: 0.8527\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 274us/sample - loss: 0.5316 - f1_m: 0.7825 - val_loss: 0.4690 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 278us/sample - loss: 0.5233 - f1_m: 0.7825 - val_loss: 0.4575 - val_f1_m: 0.8393\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 258us/sample - loss: 0.5129 - f1_m: 0.7825 - val_loss: 0.4481 - val_f1_m: 0.8393\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 289us/sample - loss: 0.5005 - f1_m: 0.7825 - val_loss: 0.4353 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 252us/sample - loss: 0.4873 - f1_m: 0.7825 - val_loss: 0.4205 - val_f1_m: 0.8259\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 305us/sample - loss: 0.4692 - f1_m: 0.7825 - val_loss: 0.4034 - val_f1_m: 0.8393\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 299us/sample - loss: 0.4470 - f1_m: 0.7825 - val_loss: 0.3817 - val_f1_m: 0.8393\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 328us/sample - loss: 0.4195 - f1_m: 0.7825 - val_loss: 0.3540 - val_f1_m: 0.8259\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 299us/sample - loss: 0.3876 - f1_m: 0.7825 - val_loss: 0.3260 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 276us/sample - loss: 0.3547 - f1_m: 0.7825 - val_loss: 0.2932 - val_f1_m: 0.8259\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 288us/sample - loss: 0.3229 - f1_m: 0.7825 - val_loss: 0.2668 - val_f1_m: 0.8527\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 315us/sample - loss: 0.2945 - f1_m: 0.7825 - val_loss: 0.2388 - val_f1_m: 0.8393\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 328us/sample - loss: 0.2604 - f1_m: 0.7850 - val_loss: 0.2131 - val_f1_m: 0.9062\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 319us/sample - loss: 0.2328 - f1_m: 0.9037 - val_loss: 0.1931 - val_f1_m: 0.8973\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 324us/sample - loss: 0.2106 - f1_m: 0.9200 - val_loss: 0.1783 - val_f1_m: 0.9062\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 277us/sample - loss: 0.1949 - f1_m: 0.9250 - val_loss: 0.1675 - val_f1_m: 0.9420\n",
      "0.92499995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 596us/sample - loss: 0.6734 - f1_m: 0.7912 - val_loss: 0.6474 - val_f1_m: 0.8080\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6264 - f1_m: 0.7912 - val_loss: 0.5922 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5739 - f1_m: 0.7912 - val_loss: 0.5410 - val_f1_m: 0.8214\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5362 - f1_m: 0.7912 - val_loss: 0.5108 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5232 - f1_m: 0.7912 - val_loss: 0.4997 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5155 - f1_m: 0.7912 - val_loss: 0.4935 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5080 - f1_m: 0.7912 - val_loss: 0.4875 - val_f1_m: 0.7946\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5005 - f1_m: 0.7912 - val_loss: 0.4786 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4900 - f1_m: 0.7912 - val_loss: 0.4686 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4783 - f1_m: 0.7912 - val_loss: 0.4573 - val_f1_m: 0.8214\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4653 - f1_m: 0.7912 - val_loss: 0.4425 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4492 - f1_m: 0.7912 - val_loss: 0.4241 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4279 - f1_m: 0.7912 - val_loss: 0.4011 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4027 - f1_m: 0.7912 - val_loss: 0.3731 - val_f1_m: 0.7812\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3716 - f1_m: 0.7912 - val_loss: 0.3392 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3324 - f1_m: 0.7912 - val_loss: 0.2884 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2864 - f1_m: 0.7912 - val_loss: 0.2485 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2549 - f1_m: 0.7912 - val_loss: 0.2222 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2355 - f1_m: 0.7912 - val_loss: 0.2075 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2228 - f1_m: 0.7912 - val_loss: 0.1971 - val_f1_m: 0.7812\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 597us/sample - loss: 0.6744 - f1_m: 0.7975 - val_loss: 0.6536 - val_f1_m: 0.7857\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6257 - f1_m: 0.7975 - val_loss: 0.6051 - val_f1_m: 0.7723\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5714 - f1_m: 0.7975 - val_loss: 0.5612 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5309 - f1_m: 0.7975 - val_loss: 0.5407 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5141 - f1_m: 0.7975 - val_loss: 0.5345 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5060 - f1_m: 0.7975 - val_loss: 0.5280 - val_f1_m: 0.7455\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4996 - f1_m: 0.7975 - val_loss: 0.5221 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4931 - f1_m: 0.7975 - val_loss: 0.5153 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4846 - f1_m: 0.7975 - val_loss: 0.5030 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4746 - f1_m: 0.7975 - val_loss: 0.4923 - val_f1_m: 0.7589\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4637 - f1_m: 0.7975 - val_loss: 0.4809 - val_f1_m: 0.7589\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4511 - f1_m: 0.7975 - val_loss: 0.4660 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4355 - f1_m: 0.7975 - val_loss: 0.4463 - val_f1_m: 0.7723\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4160 - f1_m: 0.7975 - val_loss: 0.4232 - val_f1_m: 0.7589\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3933 - f1_m: 0.7975 - val_loss: 0.3948 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3653 - f1_m: 0.7975 - val_loss: 0.3635 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3345 - f1_m: 0.7975 - val_loss: 0.3271 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3028 - f1_m: 0.7975 - val_loss: 0.2937 - val_f1_m: 0.7589\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2760 - f1_m: 0.7975 - val_loss: 0.2698 - val_f1_m: 0.7321\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.2546 - f1_m: 0.7975 - val_loss: 0.2496 - val_f1_m: 0.7589\n",
      "0.7974999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 602us/sample - loss: 0.6738 - f1_m: 0.7812 - val_loss: 0.6420 - val_f1_m: 0.8437\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6281 - f1_m: 0.7812 - val_loss: 0.5792 - val_f1_m: 0.8571\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5784 - f1_m: 0.7812 - val_loss: 0.5151 - val_f1_m: 0.8571\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5424 - f1_m: 0.7812 - val_loss: 0.4715 - val_f1_m: 0.8304\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5289 - f1_m: 0.7812 - val_loss: 0.4542 - val_f1_m: 0.8304\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5202 - f1_m: 0.7812 - val_loss: 0.4460 - val_f1_m: 0.8437\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5101 - f1_m: 0.7812 - val_loss: 0.4328 - val_f1_m: 0.8571\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4986 - f1_m: 0.7812 - val_loss: 0.4246 - val_f1_m: 0.8170\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4849 - f1_m: 0.7812 - val_loss: 0.4080 - val_f1_m: 0.8437\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.4702 - f1_m: 0.7812 - val_loss: 0.3928 - val_f1_m: 0.8437\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4497 - f1_m: 0.7812 - val_loss: 0.3726 - val_f1_m: 0.8437\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4221 - f1_m: 0.7812 - val_loss: 0.3447 - val_f1_m: 0.8437\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3901 - f1_m: 0.7812 - val_loss: 0.3145 - val_f1_m: 0.8437\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3578 - f1_m: 0.7812 - val_loss: 0.2857 - val_f1_m: 0.8304\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3255 - f1_m: 0.7812 - val_loss: 0.2561 - val_f1_m: 0.8170\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2963 - f1_m: 0.7812 - val_loss: 0.2311 - val_f1_m: 0.8571\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2695 - f1_m: 0.7812 - val_loss: 0.2100 - val_f1_m: 0.8170\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.2464 - f1_m: 0.7812 - val_loss: 0.1919 - val_f1_m: 0.8304\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2297 - f1_m: 0.7812 - val_loss: 0.1805 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.2186 - f1_m: 0.9100 - val_loss: 0.1736 - val_f1_m: 0.9062\n",
      "0.91\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 594us/sample - loss: 0.6792 - f1_m: 0.7900 - val_loss: 0.6629 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.6496 - f1_m: 0.7900 - val_loss: 0.6286 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6148 - f1_m: 0.7900 - val_loss: 0.5870 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5768 - f1_m: 0.7900 - val_loss: 0.5438 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5441 - f1_m: 0.7900 - val_loss: 0.5154 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5279 - f1_m: 0.7900 - val_loss: 0.5015 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5194 - f1_m: 0.7900 - val_loss: 0.4943 - val_f1_m: 0.8259\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5132 - f1_m: 0.7900 - val_loss: 0.4887 - val_f1_m: 0.8259\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5070 - f1_m: 0.7900 - val_loss: 0.4823 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5009 - f1_m: 0.7900 - val_loss: 0.4756 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4929 - f1_m: 0.7900 - val_loss: 0.4693 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4839 - f1_m: 0.7900 - val_loss: 0.4597 - val_f1_m: 0.7589\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4721 - f1_m: 0.7900 - val_loss: 0.4480 - val_f1_m: 0.8259\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4579 - f1_m: 0.7900 - val_loss: 0.4333 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4418 - f1_m: 0.7900 - val_loss: 0.4164 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4208 - f1_m: 0.7900 - val_loss: 0.3972 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3983 - f1_m: 0.7900 - val_loss: 0.3753 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3726 - f1_m: 0.7900 - val_loss: 0.3445 - val_f1_m: 0.8259\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3366 - f1_m: 0.7900 - val_loss: 0.3109 - val_f1_m: 0.8259\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2983 - f1_m: 0.7900 - val_loss: 0.2721 - val_f1_m: 0.7991\n",
      "0.7899999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 596us/sample - loss: 0.6788 - f1_m: 0.7925 - val_loss: 0.6648 - val_f1_m: 0.7902\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6503 - f1_m: 0.7925 - val_loss: 0.6328 - val_f1_m: 0.7768\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6154 - f1_m: 0.7925 - val_loss: 0.5934 - val_f1_m: 0.7902\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5741 - f1_m: 0.7925 - val_loss: 0.5557 - val_f1_m: 0.7902\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5420 - f1_m: 0.7925 - val_loss: 0.5290 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5246 - f1_m: 0.7925 - val_loss: 0.5178 - val_f1_m: 0.8170\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5166 - f1_m: 0.7925 - val_loss: 0.5113 - val_f1_m: 0.8036\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5113 - f1_m: 0.7925 - val_loss: 0.5058 - val_f1_m: 0.7902\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5058 - f1_m: 0.7925 - val_loss: 0.5001 - val_f1_m: 0.7902\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5001 - f1_m: 0.7925 - val_loss: 0.4943 - val_f1_m: 0.8036\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4939 - f1_m: 0.7925 - val_loss: 0.4876 - val_f1_m: 0.8036\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4872 - f1_m: 0.7925 - val_loss: 0.4796 - val_f1_m: 0.7902\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4772 - f1_m: 0.7925 - val_loss: 0.4687 - val_f1_m: 0.8036\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4661 - f1_m: 0.7925 - val_loss: 0.4559 - val_f1_m: 0.8036\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4512 - f1_m: 0.7925 - val_loss: 0.4401 - val_f1_m: 0.7768\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4336 - f1_m: 0.7925 - val_loss: 0.4197 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4115 - f1_m: 0.7925 - val_loss: 0.3981 - val_f1_m: 0.8036\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3866 - f1_m: 0.7925 - val_loss: 0.3708 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3589 - f1_m: 0.7925 - val_loss: 0.3429 - val_f1_m: 0.8170\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3260 - f1_m: 0.7925 - val_loss: 0.3065 - val_f1_m: 0.8036\n",
      "0.7924999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.6787 - f1_m: 0.7912 - val_loss: 0.6637 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6477 - f1_m: 0.7912 - val_loss: 0.6280 - val_f1_m: 0.8080\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.6102 - f1_m: 0.7912 - val_loss: 0.5856 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5696 - f1_m: 0.7912 - val_loss: 0.5458 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5422 - f1_m: 0.7912 - val_loss: 0.5211 - val_f1_m: 0.8080\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5258 - f1_m: 0.7912 - val_loss: 0.5117 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5188 - f1_m: 0.7912 - val_loss: 0.5048 - val_f1_m: 0.8214\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5133 - f1_m: 0.7912 - val_loss: 0.4990 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5079 - f1_m: 0.7912 - val_loss: 0.4934 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5028 - f1_m: 0.7912 - val_loss: 0.4878 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4969 - f1_m: 0.7912 - val_loss: 0.4810 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4897 - f1_m: 0.7912 - val_loss: 0.4737 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4809 - f1_m: 0.7912 - val_loss: 0.4633 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4705 - f1_m: 0.7912 - val_loss: 0.4515 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4563 - f1_m: 0.7912 - val_loss: 0.4359 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4403 - f1_m: 0.7912 - val_loss: 0.4182 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4201 - f1_m: 0.7912 - val_loss: 0.3954 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.3948 - f1_m: 0.7912 - val_loss: 0.3651 - val_f1_m: 0.7946\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3638 - f1_m: 0.7912 - val_loss: 0.3326 - val_f1_m: 0.8080\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3271 - f1_m: 0.7912 - val_loss: 0.2952 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.6726 - f1_m: 0.7900 - val_loss: 0.6461 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6244 - f1_m: 0.7900 - val_loss: 0.5894 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5722 - f1_m: 0.7900 - val_loss: 0.5330 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5350 - f1_m: 0.7900 - val_loss: 0.5056 - val_f1_m: 0.7589\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5231 - f1_m: 0.7900 - val_loss: 0.4934 - val_f1_m: 0.7723\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5148 - f1_m: 0.7900 - val_loss: 0.4881 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5082 - f1_m: 0.7900 - val_loss: 0.4829 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5009 - f1_m: 0.7900 - val_loss: 0.4746 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4913 - f1_m: 0.7900 - val_loss: 0.4654 - val_f1_m: 0.7723\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4777 - f1_m: 0.7900 - val_loss: 0.4525 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4632 - f1_m: 0.7900 - val_loss: 0.4379 - val_f1_m: 0.8259\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4458 - f1_m: 0.7900 - val_loss: 0.4201 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4230 - f1_m: 0.7900 - val_loss: 0.3968 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3960 - f1_m: 0.7900 - val_loss: 0.3693 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3637 - f1_m: 0.7900 - val_loss: 0.3371 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3262 - f1_m: 0.7900 - val_loss: 0.3016 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.2876 - f1_m: 0.7900 - val_loss: 0.2670 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2556 - f1_m: 0.7900 - val_loss: 0.2416 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2352 - f1_m: 0.7900 - val_loss: 0.2272 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2218 - f1_m: 0.7900 - val_loss: 0.2166 - val_f1_m: 0.7857\n",
      "0.7899999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 596us/sample - loss: 0.6800 - f1_m: 0.7818 - val_loss: 0.6603 - val_f1_m: 0.8527\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.6508 - f1_m: 0.7825 - val_loss: 0.6203 - val_f1_m: 0.8393\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6170 - f1_m: 0.7825 - val_loss: 0.5730 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5805 - f1_m: 0.7825 - val_loss: 0.5244 - val_f1_m: 0.8527\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5512 - f1_m: 0.7825 - val_loss: 0.4883 - val_f1_m: 0.8393\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5352 - f1_m: 0.7825 - val_loss: 0.4708 - val_f1_m: 0.8259\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5270 - f1_m: 0.7825 - val_loss: 0.4601 - val_f1_m: 0.8527\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5202 - f1_m: 0.7825 - val_loss: 0.4534 - val_f1_m: 0.8393\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5135 - f1_m: 0.7825 - val_loss: 0.4464 - val_f1_m: 0.8393\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5069 - f1_m: 0.7825 - val_loss: 0.4390 - val_f1_m: 0.8393\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4987 - f1_m: 0.7825 - val_loss: 0.4305 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4876 - f1_m: 0.7825 - val_loss: 0.4178 - val_f1_m: 0.8125\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4735 - f1_m: 0.7825 - val_loss: 0.4049 - val_f1_m: 0.8393\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4560 - f1_m: 0.7825 - val_loss: 0.3870 - val_f1_m: 0.8393\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4340 - f1_m: 0.7825 - val_loss: 0.3648 - val_f1_m: 0.8259\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4045 - f1_m: 0.7825 - val_loss: 0.3280 - val_f1_m: 0.8527\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3619 - f1_m: 0.7825 - val_loss: 0.2898 - val_f1_m: 0.8527\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3174 - f1_m: 0.7825 - val_loss: 0.2588 - val_f1_m: 0.8393\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2841 - f1_m: 0.7825 - val_loss: 0.2267 - val_f1_m: 0.8125\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2586 - f1_m: 0.7825 - val_loss: 0.2093 - val_f1_m: 0.8259\n",
      "0.7824999\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 595us/sample - loss: 0.6719 - f1_m: 0.7912 - val_loss: 0.6459 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.6245 - f1_m: 0.7912 - val_loss: 0.5916 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5732 - f1_m: 0.7912 - val_loss: 0.5411 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5378 - f1_m: 0.7912 - val_loss: 0.5124 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5210 - f1_m: 0.7912 - val_loss: 0.5027 - val_f1_m: 0.8214\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5141 - f1_m: 0.7912 - val_loss: 0.4958 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5076 - f1_m: 0.7912 - val_loss: 0.4894 - val_f1_m: 0.7812\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5009 - f1_m: 0.7912 - val_loss: 0.4821 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4920 - f1_m: 0.7912 - val_loss: 0.4728 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4831 - f1_m: 0.7912 - val_loss: 0.4628 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4709 - f1_m: 0.7912 - val_loss: 0.4498 - val_f1_m: 0.7679\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4584 - f1_m: 0.7912 - val_loss: 0.4353 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4426 - f1_m: 0.7912 - val_loss: 0.4171 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4224 - f1_m: 0.7912 - val_loss: 0.3949 - val_f1_m: 0.7946\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3998 - f1_m: 0.7912 - val_loss: 0.3711 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3699 - f1_m: 0.7912 - val_loss: 0.3358 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3282 - f1_m: 0.7912 - val_loss: 0.2900 - val_f1_m: 0.7812\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.2874 - f1_m: 0.7912 - val_loss: 0.2571 - val_f1_m: 0.7946\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2585 - f1_m: 0.7912 - val_loss: 0.2336 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.2408 - f1_m: 0.7912 - val_loss: 0.2199 - val_f1_m: 0.7946\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 601us/sample - loss: 0.6708 - f1_m: 0.8054 - val_loss: 0.6571 - val_f1_m: 0.7679\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.6199 - f1_m: 0.8062 - val_loss: 0.6180 - val_f1_m: 0.7545\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5631 - f1_m: 0.8062 - val_loss: 0.5866 - val_f1_m: 0.7277\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5196 - f1_m: 0.8062 - val_loss: 0.5809 - val_f1_m: 0.7277\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5020 - f1_m: 0.8062 - val_loss: 0.5835 - val_f1_m: 0.7411\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4925 - f1_m: 0.8062 - val_loss: 0.5753 - val_f1_m: 0.7545\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4857 - f1_m: 0.8062 - val_loss: 0.5694 - val_f1_m: 0.7545\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4785 - f1_m: 0.8062 - val_loss: 0.5586 - val_f1_m: 0.7545\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4683 - f1_m: 0.8062 - val_loss: 0.5479 - val_f1_m: 0.7545\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4564 - f1_m: 0.8062 - val_loss: 0.5308 - val_f1_m: 0.7277\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4427 - f1_m: 0.8062 - val_loss: 0.5179 - val_f1_m: 0.7411\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4271 - f1_m: 0.8062 - val_loss: 0.4980 - val_f1_m: 0.7277\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4073 - f1_m: 0.8062 - val_loss: 0.4698 - val_f1_m: 0.7411\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3823 - f1_m: 0.8062 - val_loss: 0.4377 - val_f1_m: 0.7679\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3541 - f1_m: 0.8062 - val_loss: 0.4003 - val_f1_m: 0.7277\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3211 - f1_m: 0.8062 - val_loss: 0.3532 - val_f1_m: 0.7143\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2792 - f1_m: 0.8062 - val_loss: 0.3006 - val_f1_m: 0.7277\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.2429 - f1_m: 0.8062 - val_loss: 0.2714 - val_f1_m: 0.7411\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.2227 - f1_m: 0.8062 - val_loss: 0.2543 - val_f1_m: 0.7411\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.2093 - f1_m: 0.8062 - val_loss: 0.2415 - val_f1_m: 0.7411\n",
      "0.8062499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 611us/sample - loss: 0.6740 - f1_m: 0.7912 - val_loss: 0.6482 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.6263 - f1_m: 0.7912 - val_loss: 0.5942 - val_f1_m: 0.7946\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.5722 - f1_m: 0.7912 - val_loss: 0.5418 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.5355 - f1_m: 0.7912 - val_loss: 0.5124 - val_f1_m: 0.8214\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5204 - f1_m: 0.7912 - val_loss: 0.5038 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5140 - f1_m: 0.7912 - val_loss: 0.4982 - val_f1_m: 0.8080\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5088 - f1_m: 0.7912 - val_loss: 0.4926 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5022 - f1_m: 0.7912 - val_loss: 0.4868 - val_f1_m: 0.7946\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4943 - f1_m: 0.7912 - val_loss: 0.4781 - val_f1_m: 0.7812\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4841 - f1_m: 0.7912 - val_loss: 0.4679 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4729 - f1_m: 0.7912 - val_loss: 0.4566 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4596 - f1_m: 0.7912 - val_loss: 0.4423 - val_f1_m: 0.7812\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4433 - f1_m: 0.7912 - val_loss: 0.4248 - val_f1_m: 0.8080\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4224 - f1_m: 0.7912 - val_loss: 0.4030 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.3977 - f1_m: 0.7912 - val_loss: 0.3778 - val_f1_m: 0.8080\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3676 - f1_m: 0.7912 - val_loss: 0.3482 - val_f1_m: 0.7812\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.3321 - f1_m: 0.7912 - val_loss: 0.3099 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.2913 - f1_m: 0.7912 - val_loss: 0.2766 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.2596 - f1_m: 0.7912 - val_loss: 0.2528 - val_f1_m: 0.7946\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.2397 - f1_m: 0.7912 - val_loss: 0.2441 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 625us/sample - loss: 0.6788 - f1_m: 0.7912 - val_loss: 0.6628 - val_f1_m: 0.8214\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.6485 - f1_m: 0.7912 - val_loss: 0.6266 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.6097 - f1_m: 0.7912 - val_loss: 0.5835 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.5696 - f1_m: 0.7912 - val_loss: 0.5439 - val_f1_m: 0.7946\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5383 - f1_m: 0.7912 - val_loss: 0.5208 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.5242 - f1_m: 0.7912 - val_loss: 0.5084 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 72us/sample - loss: 0.5127 - f1_m: 0.7912 - val_loss: 0.4998 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.5034 - f1_m: 0.7912 - val_loss: 0.4904 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.4919 - f1_m: 0.7912 - val_loss: 0.4782 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.4781 - f1_m: 0.7912 - val_loss: 0.4652 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.4630 - f1_m: 0.7912 - val_loss: 0.4492 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.4429 - f1_m: 0.7912 - val_loss: 0.4276 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.4169 - f1_m: 0.7912 - val_loss: 0.4010 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.3856 - f1_m: 0.7912 - val_loss: 0.3686 - val_f1_m: 0.8214\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.3512 - f1_m: 0.7912 - val_loss: 0.3367 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.3208 - f1_m: 0.7912 - val_loss: 0.3105 - val_f1_m: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.2955 - f1_m: 0.7912 - val_loss: 0.2908 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.2738 - f1_m: 0.7912 - val_loss: 0.2722 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.2556 - f1_m: 0.7912 - val_loss: 0.2596 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.2415 - f1_m: 0.7912 - val_loss: 0.2475 - val_f1_m: 0.7812\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 622us/sample - loss: 0.6706 - f1_m: 0.8037 - val_loss: 0.6552 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.6214 - f1_m: 0.8037 - val_loss: 0.6135 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 0.5661 - f1_m: 0.8037 - val_loss: 0.5782 - val_f1_m: 0.7634\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.5228 - f1_m: 0.8037 - val_loss: 0.5673 - val_f1_m: 0.7500\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.5068 - f1_m: 0.8037 - val_loss: 0.5672 - val_f1_m: 0.7768\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.4986 - f1_m: 0.8037 - val_loss: 0.5613 - val_f1_m: 0.7634\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.4918 - f1_m: 0.8037 - val_loss: 0.5541 - val_f1_m: 0.7500\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.4835 - f1_m: 0.8037 - val_loss: 0.5470 - val_f1_m: 0.7232\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.4751 - f1_m: 0.8037 - val_loss: 0.5376 - val_f1_m: 0.7500\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.4646 - f1_m: 0.8037 - val_loss: 0.5259 - val_f1_m: 0.7366\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.4524 - f1_m: 0.8037 - val_loss: 0.5108 - val_f1_m: 0.7768\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.4367 - f1_m: 0.8037 - val_loss: 0.4915 - val_f1_m: 0.7232\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 0.4158 - f1_m: 0.8037 - val_loss: 0.4676 - val_f1_m: 0.7366\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.3928 - f1_m: 0.8037 - val_loss: 0.4395 - val_f1_m: 0.7232\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.3679 - f1_m: 0.8037 - val_loss: 0.4152 - val_f1_m: 0.7634\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.3417 - f1_m: 0.8037 - val_loss: 0.3901 - val_f1_m: 0.7768\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.3182 - f1_m: 0.8037 - val_loss: 0.3655 - val_f1_m: 0.7634\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.2962 - f1_m: 0.8037 - val_loss: 0.3430 - val_f1_m: 0.7634\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.2766 - f1_m: 0.8037 - val_loss: 0.3224 - val_f1_m: 0.7768\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.2592 - f1_m: 0.8037 - val_loss: 0.3023 - val_f1_m: 0.7634\n",
      "0.8037499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 651us/sample - loss: 0.6721 - f1_m: 0.7937 - val_loss: 0.6499 - val_f1_m: 0.7991\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.6240 - f1_m: 0.7937 - val_loss: 0.5984 - val_f1_m: 0.7857\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.5724 - f1_m: 0.7937 - val_loss: 0.5503 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.5347 - f1_m: 0.7937 - val_loss: 0.5263 - val_f1_m: 0.7857\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.5184 - f1_m: 0.7937 - val_loss: 0.5166 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.5102 - f1_m: 0.7937 - val_loss: 0.5095 - val_f1_m: 0.8125\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.5030 - f1_m: 0.7937 - val_loss: 0.5019 - val_f1_m: 0.7991\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.4945 - f1_m: 0.7937 - val_loss: 0.4927 - val_f1_m: 0.7589\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.4826 - f1_m: 0.7937 - val_loss: 0.4799 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 0.4696 - f1_m: 0.7937 - val_loss: 0.4666 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.4553 - f1_m: 0.7937 - val_loss: 0.4517 - val_f1_m: 0.7991\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.4384 - f1_m: 0.7937 - val_loss: 0.4326 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.4160 - f1_m: 0.7937 - val_loss: 0.4079 - val_f1_m: 0.7857\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.3898 - f1_m: 0.7937 - val_loss: 0.3812 - val_f1_m: 0.8125\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 0.3596 - f1_m: 0.7937 - val_loss: 0.3467 - val_f1_m: 0.7857\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.3228 - f1_m: 0.7937 - val_loss: 0.3085 - val_f1_m: 0.7991\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.2859 - f1_m: 0.7937 - val_loss: 0.2777 - val_f1_m: 0.7857\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.2579 - f1_m: 0.7937 - val_loss: 0.2534 - val_f1_m: 0.7857\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.2344 - f1_m: 0.7937 - val_loss: 0.2359 - val_f1_m: 0.7857\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.2201 - f1_m: 0.7937 - val_loss: 0.2239 - val_f1_m: 0.8125\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 694us/sample - loss: 0.6788 - f1_m: 0.7905 - val_loss: 0.6636 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.6502 - f1_m: 0.7912 - val_loss: 0.6302 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.6153 - f1_m: 0.7912 - val_loss: 0.5907 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.5767 - f1_m: 0.7912 - val_loss: 0.5503 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 0.5437 - f1_m: 0.7912 - val_loss: 0.5235 - val_f1_m: 0.7679\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 0.5238 - f1_m: 0.7912 - val_loss: 0.5073 - val_f1_m: 0.7946\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 0.5112 - f1_m: 0.7912 - val_loss: 0.4940 - val_f1_m: 0.8080\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 0.4972 - f1_m: 0.7912 - val_loss: 0.4786 - val_f1_m: 0.8214\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 0.4817 - f1_m: 0.7912 - val_loss: 0.4627 - val_f1_m: 0.8080\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 181us/sample - loss: 0.4634 - f1_m: 0.7912 - val_loss: 0.4415 - val_f1_m: 0.7812\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 180us/sample - loss: 0.4392 - f1_m: 0.7912 - val_loss: 0.4146 - val_f1_m: 0.8214\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 0.4097 - f1_m: 0.7912 - val_loss: 0.3822 - val_f1_m: 0.7946\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 179us/sample - loss: 0.3750 - f1_m: 0.7912 - val_loss: 0.3467 - val_f1_m: 0.7812\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 0.3401 - f1_m: 0.7912 - val_loss: 0.3150 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 194us/sample - loss: 0.3124 - f1_m: 0.7912 - val_loss: 0.2890 - val_f1_m: 0.7946\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 173us/sample - loss: 0.2901 - f1_m: 0.7912 - val_loss: 0.2720 - val_f1_m: 0.7946\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 0.2729 - f1_m: 0.7912 - val_loss: 0.2525 - val_f1_m: 0.8080\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 176us/sample - loss: 0.2547 - f1_m: 0.7912 - val_loss: 0.2360 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 176us/sample - loss: 0.2420 - f1_m: 0.7912 - val_loss: 0.2253 - val_f1_m: 0.8214\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 186us/sample - loss: 0.2338 - f1_m: 0.7912 - val_loss: 0.2162 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 693us/sample - loss: 0.6719 - f1_m: 0.8000 - val_loss: 0.6539 - val_f1_m: 0.7768\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 0.6232 - f1_m: 0.8000 - val_loss: 0.6080 - val_f1_m: 0.7500\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 0.5668 - f1_m: 0.8000 - val_loss: 0.5687 - val_f1_m: 0.7768\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 0.5267 - f1_m: 0.8000 - val_loss: 0.5532 - val_f1_m: 0.7500\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 177us/sample - loss: 0.5097 - f1_m: 0.8000 - val_loss: 0.5494 - val_f1_m: 0.7634\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 197us/sample - loss: 0.5018 - f1_m: 0.8000 - val_loss: 0.5439 - val_f1_m: 0.7768\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 211us/sample - loss: 0.4959 - f1_m: 0.8000 - val_loss: 0.5373 - val_f1_m: 0.7768\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 206us/sample - loss: 0.4898 - f1_m: 0.8000 - val_loss: 0.5313 - val_f1_m: 0.7768\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 0.4814 - f1_m: 0.8000 - val_loss: 0.5219 - val_f1_m: 0.7768\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 200us/sample - loss: 0.4716 - f1_m: 0.8000 - val_loss: 0.5091 - val_f1_m: 0.7768\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 212us/sample - loss: 0.4574 - f1_m: 0.8000 - val_loss: 0.4955 - val_f1_m: 0.7500\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 229us/sample - loss: 0.4425 - f1_m: 0.8000 - val_loss: 0.4802 - val_f1_m: 0.7768\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.4244 - f1_m: 0.8000 - val_loss: 0.4595 - val_f1_m: 0.7634\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 199us/sample - loss: 0.4020 - f1_m: 0.8000 - val_loss: 0.4332 - val_f1_m: 0.7366\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 0.3743 - f1_m: 0.8000 - val_loss: 0.4044 - val_f1_m: 0.7500\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 0.3442 - f1_m: 0.8000 - val_loss: 0.3703 - val_f1_m: 0.7902\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.3099 - f1_m: 0.8000 - val_loss: 0.3344 - val_f1_m: 0.7768\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 262us/sample - loss: 0.2797 - f1_m: 0.8000 - val_loss: 0.3069 - val_f1_m: 0.7902\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 181us/sample - loss: 0.2543 - f1_m: 0.8000 - val_loss: 0.2853 - val_f1_m: 0.7902\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 201us/sample - loss: 0.2354 - f1_m: 0.8000 - val_loss: 0.2701 - val_f1_m: 0.7500\n",
      "0.79999995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 705us/sample - loss: 0.6764 - f1_m: 0.8012 - val_loss: 0.6609 - val_f1_m: 0.7589\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 196us/sample - loss: 0.6265 - f1_m: 0.8012 - val_loss: 0.6125 - val_f1_m: 0.7589\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 189us/sample - loss: 0.5719 - f1_m: 0.8012 - val_loss: 0.5752 - val_f1_m: 0.7455\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 0.5308 - f1_m: 0.8012 - val_loss: 0.5591 - val_f1_m: 0.7589\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 239us/sample - loss: 0.5093 - f1_m: 0.8012 - val_loss: 0.5542 - val_f1_m: 0.7857\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 255us/sample - loss: 0.5000 - f1_m: 0.8012 - val_loss: 0.5486 - val_f1_m: 0.7589\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 239us/sample - loss: 0.4921 - f1_m: 0.8012 - val_loss: 0.5408 - val_f1_m: 0.7589\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.4800 - f1_m: 0.8012 - val_loss: 0.5222 - val_f1_m: 0.7723\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 241us/sample - loss: 0.4652 - f1_m: 0.8012 - val_loss: 0.5074 - val_f1_m: 0.7589\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 193us/sample - loss: 0.4488 - f1_m: 0.8012 - val_loss: 0.4873 - val_f1_m: 0.7455\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.4291 - f1_m: 0.8012 - val_loss: 0.4637 - val_f1_m: 0.7723\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 208us/sample - loss: 0.4040 - f1_m: 0.8012 - val_loss: 0.4344 - val_f1_m: 0.7723\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 0.3768 - f1_m: 0.8012 - val_loss: 0.4006 - val_f1_m: 0.7455\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 221us/sample - loss: 0.3452 - f1_m: 0.8012 - val_loss: 0.3659 - val_f1_m: 0.7723\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 299us/sample - loss: 0.3143 - f1_m: 0.8012 - val_loss: 0.3398 - val_f1_m: 0.7723\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 218us/sample - loss: 0.2898 - f1_m: 0.8012 - val_loss: 0.3147 - val_f1_m: 0.7589\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 202us/sample - loss: 0.2703 - f1_m: 0.8012 - val_loss: 0.2936 - val_f1_m: 0.7589\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 265us/sample - loss: 0.2525 - f1_m: 0.8012 - val_loss: 0.2742 - val_f1_m: 0.7723\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 285us/sample - loss: 0.2369 - f1_m: 0.8012 - val_loss: 0.2542 - val_f1_m: 0.7723\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 248us/sample - loss: 0.2241 - f1_m: 0.8012 - val_loss: 0.2402 - val_f1_m: 0.7589\n",
      "0.8012499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 721us/sample - loss: 0.6784 - f1_m: 0.7862 - val_loss: 0.6596 - val_f1_m: 0.8259\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 226us/sample - loss: 0.6478 - f1_m: 0.7862 - val_loss: 0.6189 - val_f1_m: 0.7991\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 195us/sample - loss: 0.6087 - f1_m: 0.7862 - val_loss: 0.5722 - val_f1_m: 0.8259\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 200us/sample - loss: 0.5716 - f1_m: 0.7862 - val_loss: 0.5255 - val_f1_m: 0.7991\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 245us/sample - loss: 0.5424 - f1_m: 0.7862 - val_loss: 0.4970 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 283us/sample - loss: 0.5291 - f1_m: 0.7862 - val_loss: 0.4812 - val_f1_m: 0.7991\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.5213 - f1_m: 0.7862 - val_loss: 0.4746 - val_f1_m: 0.8125\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 270us/sample - loss: 0.5150 - f1_m: 0.7862 - val_loss: 0.4669 - val_f1_m: 0.8125\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 259us/sample - loss: 0.5090 - f1_m: 0.7862 - val_loss: 0.4607 - val_f1_m: 0.8125\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 277us/sample - loss: 0.5016 - f1_m: 0.7862 - val_loss: 0.4547 - val_f1_m: 0.7991\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 260us/sample - loss: 0.4939 - f1_m: 0.7862 - val_loss: 0.4478 - val_f1_m: 0.8125\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 265us/sample - loss: 0.4842 - f1_m: 0.7862 - val_loss: 0.4375 - val_f1_m: 0.8393\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 249us/sample - loss: 0.4714 - f1_m: 0.7862 - val_loss: 0.4247 - val_f1_m: 0.8125\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 310us/sample - loss: 0.4557 - f1_m: 0.7862 - val_loss: 0.4096 - val_f1_m: 0.8393\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.4376 - f1_m: 0.7862 - val_loss: 0.3912 - val_f1_m: 0.8125\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 314us/sample - loss: 0.4156 - f1_m: 0.7862 - val_loss: 0.3678 - val_f1_m: 0.8393\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 289us/sample - loss: 0.3905 - f1_m: 0.7862 - val_loss: 0.3424 - val_f1_m: 0.8259\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 306us/sample - loss: 0.3626 - f1_m: 0.7862 - val_loss: 0.3141 - val_f1_m: 0.8259\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 296us/sample - loss: 0.3252 - f1_m: 0.7862 - val_loss: 0.2824 - val_f1_m: 0.7857\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 293us/sample - loss: 0.2915 - f1_m: 0.7862 - val_loss: 0.2514 - val_f1_m: 0.8259\n",
      "0.78624994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 775us/sample - loss: 0.6737 - f1_m: 0.7904 - val_loss: 0.6499 - val_f1_m: 0.7946\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 266us/sample - loss: 0.6305 - f1_m: 0.7912 - val_loss: 0.6029 - val_f1_m: 0.8214\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 191us/sample - loss: 0.5854 - f1_m: 0.7912 - val_loss: 0.5550 - val_f1_m: 0.7946\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 0.5480 - f1_m: 0.7912 - val_loss: 0.5214 - val_f1_m: 0.8080\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 184us/sample - loss: 0.5240 - f1_m: 0.7912 - val_loss: 0.5038 - val_f1_m: 0.7946\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 230us/sample - loss: 0.5129 - f1_m: 0.7912 - val_loss: 0.4948 - val_f1_m: 0.8214\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 187us/sample - loss: 0.5055 - f1_m: 0.7912 - val_loss: 0.4865 - val_f1_m: 0.7679\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 203us/sample - loss: 0.4975 - f1_m: 0.7912 - val_loss: 0.4788 - val_f1_m: 0.8080\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 186us/sample - loss: 0.4893 - f1_m: 0.7912 - val_loss: 0.4705 - val_f1_m: 0.7946\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 203us/sample - loss: 0.4785 - f1_m: 0.7912 - val_loss: 0.4594 - val_f1_m: 0.7946\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 168us/sample - loss: 0.4673 - f1_m: 0.7912 - val_loss: 0.4473 - val_f1_m: 0.7812\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 216us/sample - loss: 0.4530 - f1_m: 0.7912 - val_loss: 0.4328 - val_f1_m: 0.8080\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 203us/sample - loss: 0.4351 - f1_m: 0.7912 - val_loss: 0.4130 - val_f1_m: 0.7946\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 194us/sample - loss: 0.4124 - f1_m: 0.7912 - val_loss: 0.3898 - val_f1_m: 0.8080\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 203us/sample - loss: 0.3888 - f1_m: 0.7912 - val_loss: 0.3663 - val_f1_m: 0.7679\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 251us/sample - loss: 0.3651 - f1_m: 0.7912 - val_loss: 0.3416 - val_f1_m: 0.8080\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 200us/sample - loss: 0.3400 - f1_m: 0.7912 - val_loss: 0.3149 - val_f1_m: 0.8214\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 269us/sample - loss: 0.3129 - f1_m: 0.7912 - val_loss: 0.2902 - val_f1_m: 0.8080\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 229us/sample - loss: 0.2878 - f1_m: 0.7912 - val_loss: 0.2653 - val_f1_m: 0.7812\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.2638 - f1_m: 0.7912 - val_loss: 0.2420 - val_f1_m: 0.8080\n",
      "0.79124993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 865us/sample - loss: 0.6785 - f1_m: 0.7937 - val_loss: 0.6643 - val_f1_m: 0.7723\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 210us/sample - loss: 0.6454 - f1_m: 0.7937 - val_loss: 0.6302 - val_f1_m: 0.8125\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 213us/sample - loss: 0.6051 - f1_m: 0.7937 - val_loss: 0.5895 - val_f1_m: 0.7991\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 0.5614 - f1_m: 0.7937 - val_loss: 0.5561 - val_f1_m: 0.7589\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 228us/sample - loss: 0.5310 - f1_m: 0.7937 - val_loss: 0.5400 - val_f1_m: 0.7991\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 331us/sample - loss: 0.5169 - f1_m: 0.7937 - val_loss: 0.5327 - val_f1_m: 0.7857\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 254us/sample - loss: 0.5108 - f1_m: 0.7937 - val_loss: 0.5270 - val_f1_m: 0.7723\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 282us/sample - loss: 0.5055 - f1_m: 0.7937 - val_loss: 0.5206 - val_f1_m: 0.7857\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 338us/sample - loss: 0.5005 - f1_m: 0.7937 - val_loss: 0.5143 - val_f1_m: 0.7991\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 240us/sample - loss: 0.4957 - f1_m: 0.7937 - val_loss: 0.5083 - val_f1_m: 0.7723\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 315us/sample - loss: 0.4913 - f1_m: 0.7937 - val_loss: 0.5017 - val_f1_m: 0.7857\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 272us/sample - loss: 0.4848 - f1_m: 0.7937 - val_loss: 0.4931 - val_f1_m: 0.7991\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 317us/sample - loss: 0.4772 - f1_m: 0.7937 - val_loss: 0.4842 - val_f1_m: 0.7589\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 295us/sample - loss: 0.4691 - f1_m: 0.7937 - val_loss: 0.4726 - val_f1_m: 0.7857\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 304us/sample - loss: 0.4581 - f1_m: 0.7937 - val_loss: 0.4575 - val_f1_m: 0.7991\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 233us/sample - loss: 0.4444 - f1_m: 0.7937 - val_loss: 0.4371 - val_f1_m: 0.7857\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 314us/sample - loss: 0.4268 - f1_m: 0.7937 - val_loss: 0.4144 - val_f1_m: 0.7991\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 335us/sample - loss: 0.4056 - f1_m: 0.7937 - val_loss: 0.3884 - val_f1_m: 0.8125\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 285us/sample - loss: 0.3836 - f1_m: 0.7937 - val_loss: 0.3633 - val_f1_m: 0.7857\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 307us/sample - loss: 0.3557 - f1_m: 0.7937 - val_loss: 0.3257 - val_f1_m: 0.8125\n",
      "0.7937499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "207 793\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 730 samples, validate on 183 samples\n",
      "Epoch 1/20\n",
      "730/730 [==============================] - 1s 858us/sample - loss: 0.6768 - f1_m: 0.7658 - val_loss: 0.6523 - val_f1_m: 0.7942\n",
      "Epoch 2/20\n",
      "730/730 [==============================] - 0s 270us/sample - loss: 0.6390 - f1_m: 0.7661 - val_loss: 0.6049 - val_f1_m: 0.7982\n",
      "Epoch 3/20\n",
      "730/730 [==============================] - 0s 190us/sample - loss: 0.5994 - f1_m: 0.7648 - val_loss: 0.5572 - val_f1_m: 0.8023\n",
      "Epoch 4/20\n",
      "730/730 [==============================] - 0s 154us/sample - loss: 0.5659 - f1_m: 0.7661 - val_loss: 0.5249 - val_f1_m: 0.8043\n",
      "Epoch 5/20\n",
      "730/730 [==============================] - 0s 217us/sample - loss: 0.5503 - f1_m: 0.7658 - val_loss: 0.5090 - val_f1_m: 0.8023\n",
      "Epoch 6/20\n",
      "730/730 [==============================] - 0s 168us/sample - loss: 0.5424 - f1_m: 0.7661 - val_loss: 0.5003 - val_f1_m: 0.8043\n",
      "Epoch 7/20\n",
      "730/730 [==============================] - 0s 195us/sample - loss: 0.5361 - f1_m: 0.7655 - val_loss: 0.4935 - val_f1_m: 0.8023\n",
      "Epoch 8/20\n",
      "730/730 [==============================] - 0s 234us/sample - loss: 0.5282 - f1_m: 0.7655 - val_loss: 0.4840 - val_f1_m: 0.8003\n",
      "Epoch 9/20\n",
      "730/730 [==============================] - 0s 137us/sample - loss: 0.5176 - f1_m: 0.7652 - val_loss: 0.4730 - val_f1_m: 0.8003\n",
      "Epoch 10/20\n",
      "730/730 [==============================] - 0s 159us/sample - loss: 0.5062 - f1_m: 0.7670 - val_loss: 0.4592 - val_f1_m: 0.8064\n",
      "Epoch 11/20\n",
      "730/730 [==============================] - 0s 216us/sample - loss: 0.4921 - f1_m: 0.7648 - val_loss: 0.4431 - val_f1_m: 0.8023\n",
      "Epoch 12/20\n",
      "730/730 [==============================] - 0s 193us/sample - loss: 0.4776 - f1_m: 0.7658 - val_loss: 0.4256 - val_f1_m: 0.8064\n",
      "Epoch 13/20\n",
      "730/730 [==============================] - 0s 189us/sample - loss: 0.4546 - f1_m: 0.7655 - val_loss: 0.4022 - val_f1_m: 0.7982\n",
      "Epoch 14/20\n",
      "730/730 [==============================] - 0s 203us/sample - loss: 0.4290 - f1_m: 0.7658 - val_loss: 0.3758 - val_f1_m: 0.8064\n",
      "Epoch 15/20\n",
      "730/730 [==============================] - 0s 196us/sample - loss: 0.3989 - f1_m: 0.7648 - val_loss: 0.3440 - val_f1_m: 0.7962\n",
      "Epoch 16/20\n",
      "730/730 [==============================] - 0s 223us/sample - loss: 0.3627 - f1_m: 0.7664 - val_loss: 0.3062 - val_f1_m: 0.8084\n",
      "Epoch 17/20\n",
      "730/730 [==============================] - 0s 215us/sample - loss: 0.3182 - f1_m: 0.7655 - val_loss: 0.2645 - val_f1_m: 0.8064\n",
      "Epoch 18/20\n",
      "730/730 [==============================] - 0s 211us/sample - loss: 0.2804 - f1_m: 0.7667 - val_loss: 0.2376 - val_f1_m: 0.8003\n",
      "Epoch 19/20\n",
      "730/730 [==============================] - 0s 144us/sample - loss: 0.2584 - f1_m: 0.7652 - val_loss: 0.2207 - val_f1_m: 0.8064\n",
      "Epoch 20/20\n",
      "730/730 [==============================] - 0s 168us/sample - loss: 0.2437 - f1_m: 0.7661 - val_loss: 0.2092 - val_f1_m: 0.8084\n",
      "0.7660952\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "12\n",
      "15\n",
      "17\n",
      "5\n",
      "22\n",
      "28\n",
      "5\n",
      "1\n",
      "11\n",
      "33\n",
      "9\n",
      "18\n",
      "3\n",
      "5\n",
      "8\n",
      "1\n",
      "2\n",
      "4\n",
      "7\n",
      "2\n",
      "6\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "All Done\n"
     ]
    }
   ],
   "source": [
    "#the below code is for binary classification since MNSIT is a multi-class low-resolution image dataset. I am updating the code in the next cell.\n",
    "N=1000\n",
    "#Positive=Pos\n",
    "#Negative=Neg\n",
    "positiveN=int((Positive.shape[0]/dataset.shape[0])*N)\n",
    "negativeN=int(N-positiveN)\n",
    "print(positiveN, negativeN)\n",
    "#target variable\n",
    "#target_variable=\"default.payment.next.month\"\n",
    "df1=Positive.sample(positiveN)\n",
    "Positive.drop(df1.index, inplace=True)\n",
    "df2=Negative.sample(negativeN)\n",
    "Negative.drop(df2.index, inplace=True)\n",
    "test_data=df1.append(df2, ignore_index=True)\n",
    "test_data=test_data.sample(frac = 1) #This is to shuffel the training and testing data\n",
    "test_data=test_data.sample(frac = 1)\n",
    "test_data=test_data.sample(frac = 1)\n",
    "X_test=test_data.drop(columns=[target_variable])\n",
    "y_test=to_categorical(test_data[target_variable])\n",
    "\n",
    "# adding dense layer\n",
    "initial_model= get_initial_model(X_test.shape[1], 2)\n",
    "initial_model.set_weights(update_weights(initial_model.get_weights()))\n",
    "Models=[]\n",
    "val_acc=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "val_loss=[]\n",
    "train_loss=[]\n",
    "add_weights=[]\n",
    "while Positive.empty==False and Negative.empty==False:\n",
    "  print(positiveN, negativeN)\n",
    "  df1=Positive.sample(min(positiveN, len(Positive)))\n",
    "  Positive.drop(df1.index, inplace=True)\n",
    "  df2=Negative.sample(min(negativeN, len(Negative)))\n",
    "  Negative.drop(df2.index, inplace=True)\n",
    "  train_data=df1.append(df2, ignore_index=True)\n",
    "  train_data=train_data.sample(frac = 1) #shuffel train data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel train data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel train data 3 times\n",
    "    \n",
    "  #all models have different initialization\n",
    "  # define the sequential model\n",
    "  \"\"\"initial_model = keras.Sequential()\n",
    "\n",
    "    # adding dense layer\n",
    "  initial_model.add(Dense(5, input_dim=X_test.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "  initial_model.add(Dense(10, activation='relu'))\n",
    "  initial_model.add(Dense(5, activation='relu'))\n",
    "\n",
    "    # adding dense layer with softmax activation/output layer\n",
    "  initial_model.add(Dense(2, activation='softmax'))\n",
    "  #initial_model.summary()\"\"\"\n",
    "  ann_model=get_initial_model(X_test.shape[1], 2) #same intial weights\n",
    "  ann_model.set_weights(initial_model.get_weights())\n",
    "  X_train=train_data.drop(columns=[target_variable])\n",
    "  #train_data[target_variable]=train_data[target_variable]-1 #only for skin_nonskin dataset\n",
    "  y_train=to_categorical(train_data[target_variable])\n",
    "  #print(y_train)\n",
    "  ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m]) # metrics=['accuracy']\n",
    "  history = ann_model.fit(X_train, y_train, epochs=20, validation_split=0.2, verbose=1)\n",
    "  print(history.history['f1_m'][-1])\n",
    "  ann_model.set_weights(update_weights(ann_model.get_weights()))\n",
    "  pred_test=ann_model.predict(X_test)\n",
    "  present=False\n",
    "  for i in range(len(Models)):\n",
    "    if (check_models(Models[i][0], ann_model.get_weights())):\n",
    "      print(\"if any\")\n",
    "      Models[i][1]=Models[i][1]+1\n",
    "      add_weights[i].append(ann_model.get_weights())\n",
    "      val_acc[i].append(history.history['val_f1_m'])\n",
    "      train_acc[i].append(history.history['f1_m'])\n",
    "      test_acc[i].append(f1_m(y_test, pred_test))\n",
    "      val_loss[i].append(history.history['val_loss'])\n",
    "      train_loss[i].append(history.history['loss'])\n",
    "      present=True\n",
    "      break;\n",
    "  if present==False:\n",
    "    add_weights.append([ann_model.get_weights()])\n",
    "    Models.append([ann_model.get_weights(), 1])\n",
    "    val_acc.append([history.history['val_f1_m']])\n",
    "    train_acc.append([history.history['f1_m']])\n",
    "    test_acc.append([f1_m(y_test, pred_test)])\n",
    "    val_loss.append([history.history['val_loss']])\n",
    "    train_loss.append([history.history['loss']])\n",
    "for i in range(len(Models)):\n",
    "  print(Models[i][1])\n",
    "print(\"All Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3653e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "15\n",
      "17\n",
      "5\n",
      "22\n",
      "28\n",
      "5\n",
      "1\n",
      "11\n",
      "33\n",
      "9\n",
      "18\n",
      "3\n",
      "5\n",
      "8\n",
      "1\n",
      "2\n",
      "4\n",
      "7\n",
      "2\n",
      "6\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "All Done\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Models)):\n",
    "  print(Models[i][1])\n",
    "print(\"All Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16bb2d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 15 17 5 22 28 5 1 11 33 9 18 3 5 8 1 2 4 7 2 6 1 1 2 1 2 3 3 1 1 1 1 3\n",
      " 1 1 1 1 1 1 1 1 1 1]\n",
      "[ 9  5  4 11  2]\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#top 5 recurrent models\n",
    "#this works for getting sorted recurrent models by frequency\n",
    "A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "print(np.array(Models).T[1])\n",
    "print(A)\n",
    "temp=list(np.array(Models)[A])\n",
    "print(temp[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68deb1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"\"\"\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#reducing the metrics lists to top 5 models only\n",
    "val_acc=list(np.array(val_acc)[A])\n",
    "test_acc=list(np.array(test_acc)[A])\n",
    "train_acc=list(np.array(train_acc)[A])\n",
    "val_loss=list(np.array(val_loss)[A])\n",
    "train_loss=list(np.array(train_loss)[A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0f62c67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 137231 samples, validate on 34308 samples\n",
      "Epoch 1/20\n",
      "137231/137231 [==============================] - 25s 182us/sample - loss: 0.1391 - f1_m: 0.9453 - val_loss: 0.1249 - val_f1_m: 0.9511\n",
      "Epoch 2/20\n",
      "137231/137231 [==============================] - 27s 196us/sample - loss: 0.1131 - f1_m: 0.9581 - val_loss: 0.1095 - val_f1_m: 0.9592\n",
      "Epoch 3/20\n",
      "137231/137231 [==============================] - 29s 211us/sample - loss: 0.0817 - f1_m: 0.9724 - val_loss: 0.0233 - val_f1_m: 0.9940\n",
      "Epoch 4/20\n",
      "137231/137231 [==============================] - 10s 74us/sample - loss: 0.0138 - f1_m: 0.9972 - val_loss: 0.0101 - val_f1_m: 0.9977\n",
      "Epoch 5/20\n",
      "137231/137231 [==============================] - 6s 46us/sample - loss: 0.0108 - f1_m: 0.9975 - val_loss: 0.0098 - val_f1_m: 0.9978\n",
      "Epoch 6/20\n",
      "137231/137231 [==============================] - 6s 46us/sample - loss: 0.0102 - f1_m: 0.9976 - val_loss: 0.0089 - val_f1_m: 0.9980\n",
      "Epoch 7/20\n",
      "137231/137231 [==============================] - 6s 46us/sample - loss: 0.0098 - f1_m: 0.9976 - val_loss: 0.0087 - val_f1_m: 0.9979\n",
      "Epoch 8/20\n",
      "137231/137231 [==============================] - 6s 46us/sample - loss: 0.0095 - f1_m: 0.9978 - val_loss: 0.0094 - val_f1_m: 0.9978\n",
      "Epoch 9/20\n",
      "137231/137231 [==============================] - 8s 59us/sample - loss: 0.0096 - f1_m: 0.9977 - val_loss: 0.0118 - val_f1_m: 0.9966\n",
      "Epoch 10/20\n",
      "137231/137231 [==============================] - 15s 106us/sample - loss: 0.0090 - f1_m: 0.9979 - val_loss: 0.0129 - val_f1_m: 0.9964\n",
      "Epoch 11/20\n",
      "137231/137231 [==============================] - 9s 63us/sample - loss: 0.0084 - f1_m: 0.9980 - val_loss: 0.0260 - val_f1_m: 0.9895\n",
      "Epoch 12/20\n",
      "137231/137231 [==============================] - 9s 68us/sample - loss: 0.0086 - f1_m: 0.9979 - val_loss: 0.0078 - val_f1_m: 0.9982\n",
      "Epoch 13/20\n",
      "137231/137231 [==============================] - 10s 75us/sample - loss: 0.0087 - f1_m: 0.9979 - val_loss: 0.0067 - val_f1_m: 0.9985\n",
      "Epoch 14/20\n",
      "137231/137231 [==============================] - 14s 104us/sample - loss: 0.0079 - f1_m: 0.9981 - val_loss: 0.0089 - val_f1_m: 0.9977\n",
      "Epoch 15/20\n",
      "137231/137231 [==============================] - 10s 69us/sample - loss: 0.0079 - f1_m: 0.9981 - val_loss: 0.0073 - val_f1_m: 0.9984\n",
      "Epoch 16/20\n",
      "137231/137231 [==============================] - 16s 117us/sample - loss: 0.0081 - f1_m: 0.9980 - val_loss: 0.0077 - val_f1_m: 0.9981\n",
      "Epoch 17/20\n",
      "137231/137231 [==============================] - 17s 125us/sample - loss: 0.0079 - f1_m: 0.9981 - val_loss: 0.0084 - val_f1_m: 0.9979\n",
      "Epoch 18/20\n",
      "137231/137231 [==============================] - 7s 55us/sample - loss: 0.0080 - f1_m: 0.9981 - val_loss: 0.0071 - val_f1_m: 0.9984\n",
      "Epoch 19/20\n",
      "137231/137231 [==============================] - 12s 90us/sample - loss: 0.0079 - f1_m: 0.9981 - val_loss: 0.0087 - val_f1_m: 0.9978\n",
      "Epoch 20/20\n",
      "137231/137231 [==============================] - 19s 138us/sample - loss: 0.0082 - f1_m: 0.9980 - val_loss: 0.0066 - val_f1_m: 0.9983\n"
     ]
    }
   ],
   "source": [
    "#benchmark model\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = to_categorical(dataset[target_variable], num_classes=2)\n",
    "X = dataset.drop(columns=target_variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "benchmark_model=initial_model #same intial weights\n",
    "benchmark_model.set_weights(initial_model.get_weights())\n",
    "history = ann_model.fit(X_train, y_train, epochs=20, validation_split=0.2, verbose=1)\n",
    "benchmark_model.set_weights(update_weights(ann_model.get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cef5f6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 17us/sample - loss: 0.0445 - accuracy: 0.9872\n",
      "[0.04448178674152727, 0.9872276]\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 16us/sample - loss: 0.0445 - accuracy: 0.9872\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "73518/73518 [==============================] - 1s 16us/sample - loss: 0.0445 - accuracy: 0.9872\n"
     ]
    }
   ],
   "source": [
    "print(benchmark_model.evaluate(X_test, y_test))\n",
    "benchmark_loss=history.history['loss']\n",
    "benchmark_val_loss=history.history['val_loss']\n",
    "benchmark_acc=history.history['f1_m']\n",
    "benchmark_val_acc=history.history['val_f1_m']\n",
    "benchmark_test_loss=benchmark_model.evaluate(X_test, y_test)[0]\n",
    "benchmark_test_accuracy=benchmark_model.evaluate(X_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eef35417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting graphs for loss and accuracies:\n",
    "#plotting val_loss and loss for the models generated and the benchmark model.\n",
    "from random import randint\n",
    "import matplotlib.patches as mpatches\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "leg=[]\n",
    "for i in range(len(color)):\n",
    "    leg.append(mpatches.Patch(color=color[i], label=str(len(val_acc[i]))))\n",
    "n = len(val_acc)\n",
    "x_axis=np.arange(1, 21, 1)\n",
    "print(x_axis)\n",
    "for i in range(n):\n",
    "    for j in range(len(val_acc[i])):\n",
    "        plt.plot(x_axis,val_acc[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis, np.mean(val_acc[i], axis=0), color=color[i])\n",
    "#plt.xlim(-0.5,20.5)\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.plot(x_axis, benchmark_val_acc, color='black')\n",
    "plt.savefig(\"fig/SKIN_NONSKIN_F1_Val_20Epochs.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecf66455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7539618, 0.7849999, 0.7849999, 0.7849999, 0.7849999, 0.7849999, 0.7849999, 0.7849999, 0.7849999, 0.7849999, 0.7849999, 0.77374995, 0.8262499, 0.87749994, 0.8999999, 0.91125, 0.91374993, 0.9225, 0.9237499, 0.925]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n",
      "0 10\n",
      "0 11\n",
      "0 12\n",
      "0 13\n",
      "0 14\n",
      "0 15\n",
      "0 16\n",
      "0 17\n",
      "0 18\n",
      "0 19\n",
      "0 20\n",
      "0 21\n",
      "0 22\n",
      "0 23\n",
      "0 24\n",
      "0 25\n",
      "0 26\n",
      "0 27\n",
      "0 28\n",
      "0 29\n",
      "0 30\n",
      "0 31\n",
      "0 32\n",
      "0 33\n",
      "0 34\n",
      "0 35\n",
      "0 36\n",
      "0 37\n",
      "0 38\n",
      "0 39\n",
      "0 40\n",
      "0 41\n",
      "0 42\n",
      "0 43\n",
      "0 44\n",
      "0 45\n",
      "0 46\n",
      "0 47\n",
      "0 48\n",
      "0 49\n",
      "0 50\n",
      "0 51\n",
      "0 52\n",
      "0 53\n",
      "0 54\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "1 10\n",
      "1 11\n",
      "1 12\n",
      "1 13\n",
      "1 14\n",
      "1 15\n",
      "1 16\n",
      "1 17\n",
      "1 18\n",
      "1 19\n",
      "1 20\n",
      "1 21\n",
      "1 22\n",
      "1 23\n",
      "1 24\n",
      "1 25\n",
      "1 26\n",
      "1 27\n",
      "1 28\n",
      "1 29\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "2 8\n",
      "2 9\n",
      "2 10\n",
      "2 11\n",
      "2 12\n",
      "2 13\n",
      "2 14\n",
      "2 15\n",
      "2 16\n",
      "2 17\n",
      "2 18\n",
      "2 19\n",
      "2 20\n",
      "2 21\n",
      "2 22\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "3 8\n",
      "3 9\n",
      "3 10\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "4 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train accuracy \n",
    "from random import randint\n",
    "color = []\n",
    "print(train_acc[4][0])\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "x_axis=np.arange(1, 21, 1)\n",
    "print(x_axis)\n",
    "for i in range(n):\n",
    "    for j in range(len(train_acc[i])):\n",
    "        print(i,j)\n",
    "        plt.plot(x_axis,train_acc[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis,np.mean(train_acc[i], axis=0), color=color[i])\n",
    "plt.plot(x_axis,benchmark_acc, color='black')\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/SKIN_NONSKIN_012_F1_train_20Epochs.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2492b53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training loss\n",
    "from random import randint\n",
    "color = []\n",
    "n = len(train_loss)\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "for i in range(n):\n",
    "    for j in range(len(train_loss[i])):\n",
    "        plt.plot(x_axis,train_loss[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis,np.mean(train_loss[i], axis=0), color=color[i])\n",
    "plt.plot(x_axis,benchmark_loss, color='black')\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/SKIN_NONSKIN_loss_train_20Epochs.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "472ab27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#validation loss loss\n",
    "from random import randint\n",
    "color = []\n",
    "n = len(val_acc)\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "for i in range(n):\n",
    "    for j in range(len(train_loss[i])):\n",
    "        plt.plot(x_axis,val_loss[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis,np.mean(val_loss[i], axis=0), color=color[i])\n",
    "plt.plot(x_axis,benchmark_val_loss, color='black')\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/SKIN_NONSKIN_loss_val_20Epochs.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e193947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of               x1        x2        x3  label\n",
      "0       0.290196  0.333333  0.482353    0.0\n",
      "1       0.286275  0.329412  0.478431    0.0\n",
      "2       0.282353  0.325490  0.474510    0.0\n",
      "3       0.274510  0.317647  0.466667    0.0\n",
      "4       0.274510  0.317647  0.466667    0.0\n",
      "...          ...       ...       ...    ...\n",
      "245052  0.639216  0.635294  0.439216    1.0\n",
      "245053  0.639216  0.635294  0.439216    1.0\n",
      "245054  0.639216  0.635294  0.439216    1.0\n",
      "245055  0.639216  0.635294  0.439216    1.0\n",
      "245056  1.000000  1.000000  1.000000    1.0\n",
      "\n",
      "[245057 rows x 4 columns]>\n",
      "50859\n",
      "194198\n"
     ]
    }
   ],
   "source": [
    "#from here on trying for epsilon-IP, have updated layer comparison\n",
    "#for SKIN_NonSkin dataset\n",
    "dataset = pd.read_csv(\"Skin_NonSkin.csv\",sep=';', names=['x1','x2','x3','label'])\n",
    "#print(dataset['label'])\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "dataset = pd.DataFrame(scaler.fit_transform(dataset), columns=['x1','x2','x3','label'])\n",
    "target_variable=\"label\"\n",
    "print(dataset.head)\n",
    "Positive=dataset[dataset[target_variable]==0]\n",
    "Negative=dataset[dataset[target_variable]==1]\n",
    "print(len(Positive))\n",
    "print(len(Negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40a25645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037 3963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 175us/sample - loss: 0.6057 - f1_m: 0.7920 - val_loss: 0.5294 - val_f1_m: 0.7969\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5080 - f1_m: 0.7920 - val_loss: 0.4781 - val_f1_m: 0.7998\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.4395 - f1_m: 0.7920 - val_loss: 0.3726 - val_f1_m: 0.7939\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.3117 - f1_m: 0.7920 - val_loss: 0.2612 - val_f1_m: 0.7939\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2423 - f1_m: 0.7920 - val_loss: 0.2202 - val_f1_m: 0.7998\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2106 - f1_m: 0.8385 - val_loss: 0.1976 - val_f1_m: 0.9365\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1907 - f1_m: 0.9315 - val_loss: 0.1819 - val_f1_m: 0.9404\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 51us/sample - loss: 0.1762 - f1_m: 0.9375 - val_loss: 0.1702 - val_f1_m: 0.9355\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 60us/sample - loss: 0.1657 - f1_m: 0.9385 - val_loss: 0.1624 - val_f1_m: 0.9434\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 53us/sample - loss: 0.1574 - f1_m: 0.9417 - val_loss: 0.1543 - val_f1_m: 0.9443\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 60us/sample - loss: 0.1515 - f1_m: 0.9445 - val_loss: 0.1484 - val_f1_m: 0.9453\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 59us/sample - loss: 0.1467 - f1_m: 0.9455 - val_loss: 0.1467 - val_f1_m: 0.9473\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 58us/sample - loss: 0.1433 - f1_m: 0.9477 - val_loss: 0.1420 - val_f1_m: 0.9473\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 56us/sample - loss: 0.1406 - f1_m: 0.9473 - val_loss: 0.1394 - val_f1_m: 0.9463\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1386 - f1_m: 0.9485 - val_loss: 0.1377 - val_f1_m: 0.9492\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1369 - f1_m: 0.9485 - val_loss: 0.1386 - val_f1_m: 0.9443\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 55us/sample - loss: 0.1359 - f1_m: 0.9480 - val_loss: 0.1355 - val_f1_m: 0.9443\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 55us/sample - loss: 0.1348 - f1_m: 0.9482 - val_loss: 0.1344 - val_f1_m: 0.9492\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1340 - f1_m: 0.9477 - val_loss: 0.1339 - val_f1_m: 0.9492\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1337 - f1_m: 0.9482 - val_loss: 0.1339 - val_f1_m: 0.9473\n",
      "0.94825\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 183us/sample - loss: 0.6050 - f1_m: 0.7995 - val_loss: 0.5540 - val_f1_m: 0.7676\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 61us/sample - loss: 0.4941 - f1_m: 0.7995 - val_loss: 0.4967 - val_f1_m: 0.7676\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 60us/sample - loss: 0.4120 - f1_m: 0.7995 - val_loss: 0.3761 - val_f1_m: 0.7676\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 54us/sample - loss: 0.2905 - f1_m: 0.7995 - val_loss: 0.2826 - val_f1_m: 0.7676\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 56us/sample - loss: 0.2325 - f1_m: 0.7995 - val_loss: 0.2445 - val_f1_m: 0.7705\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 56us/sample - loss: 0.2043 - f1_m: 0.8385 - val_loss: 0.2204 - val_f1_m: 0.9209\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 56us/sample - loss: 0.1867 - f1_m: 0.9302 - val_loss: 0.2033 - val_f1_m: 0.9248\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 54us/sample - loss: 0.1743 - f1_m: 0.9342 - val_loss: 0.1909 - val_f1_m: 0.9365\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 58us/sample - loss: 0.1649 - f1_m: 0.9355 - val_loss: 0.1808 - val_f1_m: 0.9365\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 54us/sample - loss: 0.1580 - f1_m: 0.9380 - val_loss: 0.1734 - val_f1_m: 0.9385\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1524 - f1_m: 0.9407 - val_loss: 0.1674 - val_f1_m: 0.9414\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 56us/sample - loss: 0.1484 - f1_m: 0.9445 - val_loss: 0.1632 - val_f1_m: 0.9414\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 51us/sample - loss: 0.1453 - f1_m: 0.9448 - val_loss: 0.1587 - val_f1_m: 0.9404\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1429 - f1_m: 0.9445 - val_loss: 0.1565 - val_f1_m: 0.9443\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1413 - f1_m: 0.9450 - val_loss: 0.1540 - val_f1_m: 0.9385\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1393 - f1_m: 0.9450 - val_loss: 0.1522 - val_f1_m: 0.9414\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1382 - f1_m: 0.9455 - val_loss: 0.1508 - val_f1_m: 0.9453\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1373 - f1_m: 0.9457 - val_loss: 0.1496 - val_f1_m: 0.9453\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1366 - f1_m: 0.9460 - val_loss: 0.1483 - val_f1_m: 0.9463\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1361 - f1_m: 0.9457 - val_loss: 0.1476 - val_f1_m: 0.9453\n",
      "0.94575\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 172us/sample - loss: 0.6063 - f1_m: 0.7945 - val_loss: 0.5377 - val_f1_m: 0.7871\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.5029 - f1_m: 0.7945 - val_loss: 0.4787 - val_f1_m: 0.7900\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.4152 - f1_m: 0.7945 - val_loss: 0.3452 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2874 - f1_m: 0.7945 - val_loss: 0.2570 - val_f1_m: 0.7842\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2325 - f1_m: 0.7945 - val_loss: 0.2233 - val_f1_m: 0.7900\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2065 - f1_m: 0.8625 - val_loss: 0.2026 - val_f1_m: 0.9238\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1897 - f1_m: 0.9290 - val_loss: 0.1872 - val_f1_m: 0.9346\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1769 - f1_m: 0.9360 - val_loss: 0.1766 - val_f1_m: 0.9297\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1681 - f1_m: 0.9350 - val_loss: 0.1685 - val_f1_m: 0.9346\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1617 - f1_m: 0.9365 - val_loss: 0.1627 - val_f1_m: 0.9326\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1564 - f1_m: 0.9373 - val_loss: 0.1578 - val_f1_m: 0.9404\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1528 - f1_m: 0.9388 - val_loss: 0.1543 - val_f1_m: 0.9346\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1500 - f1_m: 0.9395 - val_loss: 0.1517 - val_f1_m: 0.9365\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1478 - f1_m: 0.9377 - val_loss: 0.1499 - val_f1_m: 0.9365\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1459 - f1_m: 0.9413 - val_loss: 0.1479 - val_f1_m: 0.9434\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1450 - f1_m: 0.9410 - val_loss: 0.1469 - val_f1_m: 0.9404\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1441 - f1_m: 0.9413 - val_loss: 0.1458 - val_f1_m: 0.9434\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1431 - f1_m: 0.9422 - val_loss: 0.1449 - val_f1_m: 0.9443\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1423 - f1_m: 0.9415 - val_loss: 0.1443 - val_f1_m: 0.9414\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1417 - f1_m: 0.9423 - val_loss: 0.1440 - val_f1_m: 0.9443\n",
      "0.94225\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 189us/sample - loss: 0.6048 - f1_m: 0.7910 - val_loss: 0.5226 - val_f1_m: 0.8008\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.5060 - f1_m: 0.7910 - val_loss: 0.4685 - val_f1_m: 0.7979\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 52us/sample - loss: 0.4361 - f1_m: 0.7910 - val_loss: 0.3660 - val_f1_m: 0.8008\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.3122 - f1_m: 0.7910 - val_loss: 0.2535 - val_f1_m: 0.8037\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.2421 - f1_m: 0.7910 - val_loss: 0.2126 - val_f1_m: 0.8008\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2109 - f1_m: 0.8590 - val_loss: 0.1889 - val_f1_m: 0.9346\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1910 - f1_m: 0.9310 - val_loss: 0.1736 - val_f1_m: 0.9404\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 54us/sample - loss: 0.1776 - f1_m: 0.9330 - val_loss: 0.1635 - val_f1_m: 0.9424\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1667 - f1_m: 0.9357 - val_loss: 0.1550 - val_f1_m: 0.9473\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1587 - f1_m: 0.9408 - val_loss: 0.1485 - val_f1_m: 0.9502\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 52us/sample - loss: 0.1532 - f1_m: 0.9435 - val_loss: 0.1436 - val_f1_m: 0.9473\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1487 - f1_m: 0.9448 - val_loss: 0.1403 - val_f1_m: 0.9492\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1460 - f1_m: 0.9452 - val_loss: 0.1374 - val_f1_m: 0.9463\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 54us/sample - loss: 0.1428 - f1_m: 0.9465 - val_loss: 0.1360 - val_f1_m: 0.9463\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 59us/sample - loss: 0.1414 - f1_m: 0.9463 - val_loss: 0.1339 - val_f1_m: 0.9502\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1401 - f1_m: 0.9457 - val_loss: 0.1327 - val_f1_m: 0.9502\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 52us/sample - loss: 0.1388 - f1_m: 0.9457 - val_loss: 0.1321 - val_f1_m: 0.9502\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 57us/sample - loss: 0.1381 - f1_m: 0.9455 - val_loss: 0.1313 - val_f1_m: 0.9502\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 51us/sample - loss: 0.1374 - f1_m: 0.9460 - val_loss: 0.1308 - val_f1_m: 0.9502\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1369 - f1_m: 0.9455 - val_loss: 0.1301 - val_f1_m: 0.9463\n",
      "0.9455\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 172us/sample - loss: 0.6054 - f1_m: 0.7902 - val_loss: 0.5220 - val_f1_m: 0.8008\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5093 - f1_m: 0.7902 - val_loss: 0.4726 - val_f1_m: 0.8037\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4428 - f1_m: 0.7902 - val_loss: 0.3784 - val_f1_m: 0.8037\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.3108 - f1_m: 0.7902 - val_loss: 0.2659 - val_f1_m: 0.8008\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2407 - f1_m: 0.7902 - val_loss: 0.2286 - val_f1_m: 0.8008\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2113 - f1_m: 0.8565 - val_loss: 0.2092 - val_f1_m: 0.8945\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1927 - f1_m: 0.9310 - val_loss: 0.1972 - val_f1_m: 0.9102\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1793 - f1_m: 0.9323 - val_loss: 0.1880 - val_f1_m: 0.9131\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1699 - f1_m: 0.9330 - val_loss: 0.1825 - val_f1_m: 0.9141\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1623 - f1_m: 0.9355 - val_loss: 0.1792 - val_f1_m: 0.9150\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1568 - f1_m: 0.9400 - val_loss: 0.1755 - val_f1_m: 0.9160\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1524 - f1_m: 0.9427 - val_loss: 0.1739 - val_f1_m: 0.9199\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1495 - f1_m: 0.9433 - val_loss: 0.1730 - val_f1_m: 0.9209\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1469 - f1_m: 0.9425 - val_loss: 0.1728 - val_f1_m: 0.9209\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1452 - f1_m: 0.9435 - val_loss: 0.1723 - val_f1_m: 0.9209\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1435 - f1_m: 0.9437 - val_loss: 0.1719 - val_f1_m: 0.9170\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 51us/sample - loss: 0.1425 - f1_m: 0.9438 - val_loss: 0.1720 - val_f1_m: 0.9180\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1417 - f1_m: 0.9438 - val_loss: 0.1722 - val_f1_m: 0.9141\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1412 - f1_m: 0.9433 - val_loss: 0.1725 - val_f1_m: 0.9189\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1404 - f1_m: 0.9435 - val_loss: 0.1725 - val_f1_m: 0.9150\n",
      "0.9435\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 171us/sample - loss: 0.6134 - f1_m: 0.7882 - val_loss: 0.5207 - val_f1_m: 0.8145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5096 - f1_m: 0.7882 - val_loss: 0.4511 - val_f1_m: 0.8145\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.4216 - f1_m: 0.7882 - val_loss: 0.3222 - val_f1_m: 0.7998\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2902 - f1_m: 0.7882 - val_loss: 0.2285 - val_f1_m: 0.8086\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2351 - f1_m: 0.7882 - val_loss: 0.1937 - val_f1_m: 0.8145\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2079 - f1_m: 0.8745 - val_loss: 0.1738 - val_f1_m: 0.9434\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1900 - f1_m: 0.9305 - val_loss: 0.1598 - val_f1_m: 0.9443\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1771 - f1_m: 0.9342 - val_loss: 0.1491 - val_f1_m: 0.9453\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1678 - f1_m: 0.9362 - val_loss: 0.1412 - val_f1_m: 0.9434\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1603 - f1_m: 0.9413 - val_loss: 0.1356 - val_f1_m: 0.9570\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1548 - f1_m: 0.9427 - val_loss: 0.1307 - val_f1_m: 0.9570\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1508 - f1_m: 0.9442 - val_loss: 0.1272 - val_f1_m: 0.9570\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1477 - f1_m: 0.9448 - val_loss: 0.1244 - val_f1_m: 0.9570\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1454 - f1_m: 0.9440 - val_loss: 0.1223 - val_f1_m: 0.9541\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1442 - f1_m: 0.9442 - val_loss: 0.1213 - val_f1_m: 0.9541\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1423 - f1_m: 0.9445 - val_loss: 0.1200 - val_f1_m: 0.9541\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1409 - f1_m: 0.9445 - val_loss: 0.1196 - val_f1_m: 0.9570\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1405 - f1_m: 0.9445 - val_loss: 0.1182 - val_f1_m: 0.9482\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1397 - f1_m: 0.9450 - val_loss: 0.1172 - val_f1_m: 0.9570\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1391 - f1_m: 0.9452 - val_loss: 0.1173 - val_f1_m: 0.9541\n",
      "0.94525\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 170us/sample - loss: 0.6131 - f1_m: 0.7870 - val_loss: 0.5139 - val_f1_m: 0.8164\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5054 - f1_m: 0.7870 - val_loss: 0.4448 - val_f1_m: 0.8164\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.4204 - f1_m: 0.7870 - val_loss: 0.3321 - val_f1_m: 0.8135\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2987 - f1_m: 0.7870 - val_loss: 0.2429 - val_f1_m: 0.8135\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2392 - f1_m: 0.7870 - val_loss: 0.2062 - val_f1_m: 0.8047\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.2091 - f1_m: 0.8637 - val_loss: 0.1857 - val_f1_m: 0.9307\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1898 - f1_m: 0.9337 - val_loss: 0.1715 - val_f1_m: 0.9277\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1757 - f1_m: 0.9380 - val_loss: 0.1615 - val_f1_m: 0.9258\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1652 - f1_m: 0.9408 - val_loss: 0.1546 - val_f1_m: 0.9287\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1572 - f1_m: 0.9452 - val_loss: 0.1477 - val_f1_m: 0.9453\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1516 - f1_m: 0.9465 - val_loss: 0.1446 - val_f1_m: 0.9424\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1463 - f1_m: 0.9498 - val_loss: 0.1402 - val_f1_m: 0.9463\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1425 - f1_m: 0.9503 - val_loss: 0.1380 - val_f1_m: 0.9463\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1399 - f1_m: 0.9500 - val_loss: 0.1357 - val_f1_m: 0.9463\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1376 - f1_m: 0.9503 - val_loss: 0.1347 - val_f1_m: 0.9463\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1362 - f1_m: 0.9495 - val_loss: 0.1333 - val_f1_m: 0.9434\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1343 - f1_m: 0.9503 - val_loss: 0.1325 - val_f1_m: 0.9463\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1334 - f1_m: 0.9505 - val_loss: 0.1338 - val_f1_m: 0.9434\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 58us/sample - loss: 0.1327 - f1_m: 0.9507 - val_loss: 0.1328 - val_f1_m: 0.9463\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1315 - f1_m: 0.9503 - val_loss: 0.1320 - val_f1_m: 0.9463\n",
      "0.95025\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 171us/sample - loss: 0.6101 - f1_m: 0.7906 - val_loss: 0.5278 - val_f1_m: 0.7900\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5061 - f1_m: 0.7907 - val_loss: 0.4694 - val_f1_m: 0.7988\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4322 - f1_m: 0.7907 - val_loss: 0.3516 - val_f1_m: 0.8018\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.3010 - f1_m: 0.7907 - val_loss: 0.2401 - val_f1_m: 0.8018\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2369 - f1_m: 0.7907 - val_loss: 0.2015 - val_f1_m: 0.7988\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2080 - f1_m: 0.8710 - val_loss: 0.1806 - val_f1_m: 0.9453\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1901 - f1_m: 0.9290 - val_loss: 0.1656 - val_f1_m: 0.9482\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1769 - f1_m: 0.9320 - val_loss: 0.1556 - val_f1_m: 0.9482\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1672 - f1_m: 0.9355 - val_loss: 0.1481 - val_f1_m: 0.9482\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1599 - f1_m: 0.9427 - val_loss: 0.1416 - val_f1_m: 0.9502\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1542 - f1_m: 0.9442 - val_loss: 0.1370 - val_f1_m: 0.9541\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1501 - f1_m: 0.9445 - val_loss: 0.1340 - val_f1_m: 0.9551\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1469 - f1_m: 0.9445 - val_loss: 0.1312 - val_f1_m: 0.9541\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1446 - f1_m: 0.9445 - val_loss: 0.1290 - val_f1_m: 0.9541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1432 - f1_m: 0.9440 - val_loss: 0.1272 - val_f1_m: 0.9541\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1417 - f1_m: 0.9438 - val_loss: 0.1258 - val_f1_m: 0.9541\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1408 - f1_m: 0.9440 - val_loss: 0.1249 - val_f1_m: 0.9541\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1400 - f1_m: 0.9442 - val_loss: 0.1245 - val_f1_m: 0.9512\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1393 - f1_m: 0.9442 - val_loss: 0.1233 - val_f1_m: 0.9541\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1391 - f1_m: 0.9442 - val_loss: 0.1228 - val_f1_m: 0.9551\n",
      "0.94425\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 170us/sample - loss: 0.6058 - f1_m: 0.7877 - val_loss: 0.5093 - val_f1_m: 0.8135\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5038 - f1_m: 0.7877 - val_loss: 0.4460 - val_f1_m: 0.8164\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.4193 - f1_m: 0.7877 - val_loss: 0.3349 - val_f1_m: 0.8164\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2969 - f1_m: 0.7877 - val_loss: 0.2445 - val_f1_m: 0.8135\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2374 - f1_m: 0.7877 - val_loss: 0.2077 - val_f1_m: 0.8135\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2081 - f1_m: 0.8705 - val_loss: 0.1834 - val_f1_m: 0.9189\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1887 - f1_m: 0.9332 - val_loss: 0.1684 - val_f1_m: 0.9355\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1750 - f1_m: 0.9382 - val_loss: 0.1585 - val_f1_m: 0.9365\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1647 - f1_m: 0.9402 - val_loss: 0.1489 - val_f1_m: 0.9395\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1572 - f1_m: 0.9430 - val_loss: 0.1432 - val_f1_m: 0.9492\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1517 - f1_m: 0.9455 - val_loss: 0.1386 - val_f1_m: 0.9512\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1470 - f1_m: 0.9470 - val_loss: 0.1356 - val_f1_m: 0.9502\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1434 - f1_m: 0.9492 - val_loss: 0.1324 - val_f1_m: 0.9502\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1407 - f1_m: 0.9490 - val_loss: 0.1307 - val_f1_m: 0.9443\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1386 - f1_m: 0.9490 - val_loss: 0.1295 - val_f1_m: 0.9502\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1370 - f1_m: 0.9497 - val_loss: 0.1282 - val_f1_m: 0.9502\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1368 - f1_m: 0.9485 - val_loss: 0.1281 - val_f1_m: 0.9502\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1352 - f1_m: 0.9488 - val_loss: 0.1276 - val_f1_m: 0.9443\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1339 - f1_m: 0.9490 - val_loss: 0.1276 - val_f1_m: 0.9512\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1333 - f1_m: 0.9492 - val_loss: 0.1258 - val_f1_m: 0.9443\n",
      "0.94925\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 170us/sample - loss: 0.6024 - f1_m: 0.7937 - val_loss: 0.5331 - val_f1_m: 0.7871\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4957 - f1_m: 0.7937 - val_loss: 0.4723 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.4111 - f1_m: 0.7937 - val_loss: 0.3452 - val_f1_m: 0.7900\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2912 - f1_m: 0.7937 - val_loss: 0.2588 - val_f1_m: 0.7842\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2345 - f1_m: 0.7937 - val_loss: 0.2215 - val_f1_m: 0.7900\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2052 - f1_m: 0.8565 - val_loss: 0.1972 - val_f1_m: 0.9258\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1860 - f1_m: 0.9323 - val_loss: 0.1810 - val_f1_m: 0.9414\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1720 - f1_m: 0.9398 - val_loss: 0.1740 - val_f1_m: 0.9287\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1615 - f1_m: 0.9402 - val_loss: 0.1595 - val_f1_m: 0.9404\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1535 - f1_m: 0.9427 - val_loss: 0.1515 - val_f1_m: 0.9443\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1476 - f1_m: 0.9465 - val_loss: 0.1461 - val_f1_m: 0.9482\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1427 - f1_m: 0.9495 - val_loss: 0.1428 - val_f1_m: 0.9424\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1394 - f1_m: 0.9497 - val_loss: 0.1369 - val_f1_m: 0.9551\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1364 - f1_m: 0.9510 - val_loss: 0.1340 - val_f1_m: 0.9531\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1345 - f1_m: 0.9505 - val_loss: 0.1317 - val_f1_m: 0.9512\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1327 - f1_m: 0.9507 - val_loss: 0.1310 - val_f1_m: 0.9521\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1314 - f1_m: 0.9507 - val_loss: 0.1285 - val_f1_m: 0.9502\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1304 - f1_m: 0.9513 - val_loss: 0.1272 - val_f1_m: 0.9521\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1293 - f1_m: 0.9513 - val_loss: 0.1275 - val_f1_m: 0.9551\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1286 - f1_m: 0.9510 - val_loss: 0.1268 - val_f1_m: 0.9521\n",
      "0.951\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 172us/sample - loss: 0.6098 - f1_m: 0.7888 - val_loss: 0.5195 - val_f1_m: 0.8057\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5073 - f1_m: 0.7890 - val_loss: 0.4600 - val_f1_m: 0.8086\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4279 - f1_m: 0.7890 - val_loss: 0.3472 - val_f1_m: 0.8057\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.3011 - f1_m: 0.7890 - val_loss: 0.2521 - val_f1_m: 0.8086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2407 - f1_m: 0.7890 - val_loss: 0.2154 - val_f1_m: 0.8057\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2127 - f1_m: 0.8570 - val_loss: 0.1946 - val_f1_m: 0.9199\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1953 - f1_m: 0.9265 - val_loss: 0.1805 - val_f1_m: 0.9209\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1823 - f1_m: 0.9315 - val_loss: 0.1704 - val_f1_m: 0.9355\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1732 - f1_m: 0.9312 - val_loss: 0.1639 - val_f1_m: 0.9287\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1662 - f1_m: 0.9317 - val_loss: 0.1569 - val_f1_m: 0.9355\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1615 - f1_m: 0.9352 - val_loss: 0.1534 - val_f1_m: 0.9355\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1569 - f1_m: 0.9377 - val_loss: 0.1494 - val_f1_m: 0.9365\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1538 - f1_m: 0.9390 - val_loss: 0.1471 - val_f1_m: 0.9395\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1515 - f1_m: 0.9400 - val_loss: 0.1455 - val_f1_m: 0.9346\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1498 - f1_m: 0.9410 - val_loss: 0.1440 - val_f1_m: 0.9395\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1484 - f1_m: 0.9408 - val_loss: 0.1429 - val_f1_m: 0.9424\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1475 - f1_m: 0.9408 - val_loss: 0.1427 - val_f1_m: 0.9424\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1469 - f1_m: 0.9405 - val_loss: 0.1416 - val_f1_m: 0.9414\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1460 - f1_m: 0.9408 - val_loss: 0.1422 - val_f1_m: 0.9414\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1454 - f1_m: 0.9408 - val_loss: 0.1432 - val_f1_m: 0.9414\n",
      "0.94075\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 171us/sample - loss: 0.6113 - f1_m: 0.7897 - val_loss: 0.5233 - val_f1_m: 0.8057\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5041 - f1_m: 0.7897 - val_loss: 0.4537 - val_f1_m: 0.7998\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4122 - f1_m: 0.7897 - val_loss: 0.3251 - val_f1_m: 0.8086\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2881 - f1_m: 0.7897 - val_loss: 0.2385 - val_f1_m: 0.8027\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2321 - f1_m: 0.7897 - val_loss: 0.2034 - val_f1_m: 0.8086\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2033 - f1_m: 0.8772 - val_loss: 0.1813 - val_f1_m: 0.9414\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1842 - f1_m: 0.9377 - val_loss: 0.1657 - val_f1_m: 0.9463\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1705 - f1_m: 0.9425 - val_loss: 0.1537 - val_f1_m: 0.9443\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1601 - f1_m: 0.9438 - val_loss: 0.1458 - val_f1_m: 0.9502\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1524 - f1_m: 0.9480 - val_loss: 0.1387 - val_f1_m: 0.9492\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1463 - f1_m: 0.9495 - val_loss: 0.1339 - val_f1_m: 0.9482\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1418 - f1_m: 0.9505 - val_loss: 0.1285 - val_f1_m: 0.9521\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1378 - f1_m: 0.9520 - val_loss: 0.1253 - val_f1_m: 0.9561\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1349 - f1_m: 0.9525 - val_loss: 0.1220 - val_f1_m: 0.9600\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1325 - f1_m: 0.9530 - val_loss: 0.1205 - val_f1_m: 0.9600\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1308 - f1_m: 0.9532 - val_loss: 0.1175 - val_f1_m: 0.9541\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1289 - f1_m: 0.9535 - val_loss: 0.1164 - val_f1_m: 0.9600\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1285 - f1_m: 0.9532 - val_loss: 0.1158 - val_f1_m: 0.9600\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1271 - f1_m: 0.9525 - val_loss: 0.1146 - val_f1_m: 0.9600\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1262 - f1_m: 0.9530 - val_loss: 0.1145 - val_f1_m: 0.9600\n",
      "0.953\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 170us/sample - loss: 0.6099 - f1_m: 0.7870 - val_loss: 0.5110 - val_f1_m: 0.8135\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5096 - f1_m: 0.7870 - val_loss: 0.4496 - val_f1_m: 0.8135\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4279 - f1_m: 0.7870 - val_loss: 0.3319 - val_f1_m: 0.8164\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2990 - f1_m: 0.7870 - val_loss: 0.2350 - val_f1_m: 0.8135\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2383 - f1_m: 0.7870 - val_loss: 0.1993 - val_f1_m: 0.8135\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2095 - f1_m: 0.8892 - val_loss: 0.1787 - val_f1_m: 0.9297\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1913 - f1_m: 0.9295 - val_loss: 0.1655 - val_f1_m: 0.9355\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1785 - f1_m: 0.9325 - val_loss: 0.1557 - val_f1_m: 0.9375\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1686 - f1_m: 0.9340 - val_loss: 0.1490 - val_f1_m: 0.9473\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1615 - f1_m: 0.9385 - val_loss: 0.1437 - val_f1_m: 0.9453\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1559 - f1_m: 0.9433 - val_loss: 0.1399 - val_f1_m: 0.9482\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1520 - f1_m: 0.9430 - val_loss: 0.1372 - val_f1_m: 0.9473\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1488 - f1_m: 0.9442 - val_loss: 0.1348 - val_f1_m: 0.9482\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1465 - f1_m: 0.9442 - val_loss: 0.1336 - val_f1_m: 0.9453\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1449 - f1_m: 0.9442 - val_loss: 0.1331 - val_f1_m: 0.9482\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1437 - f1_m: 0.9442 - val_loss: 0.1314 - val_f1_m: 0.9482\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1427 - f1_m: 0.9442 - val_loss: 0.1317 - val_f1_m: 0.9482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1417 - f1_m: 0.9442 - val_loss: 0.1308 - val_f1_m: 0.9395\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1417 - f1_m: 0.9442 - val_loss: 0.1304 - val_f1_m: 0.9453\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1409 - f1_m: 0.9445 - val_loss: 0.1299 - val_f1_m: 0.9453\n",
      "0.9445\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 170us/sample - loss: 0.6083 - f1_m: 0.7930 - val_loss: 0.5338 - val_f1_m: 0.7900\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.4996 - f1_m: 0.7930 - val_loss: 0.4684 - val_f1_m: 0.7900\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.4058 - f1_m: 0.7930 - val_loss: 0.3331 - val_f1_m: 0.7959\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2764 - f1_m: 0.7930 - val_loss: 0.2511 - val_f1_m: 0.7900\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2233 - f1_m: 0.7930 - val_loss: 0.2189 - val_f1_m: 0.7930\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1970 - f1_m: 0.9005 - val_loss: 0.2004 - val_f1_m: 0.9199\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1798 - f1_m: 0.9385 - val_loss: 0.1867 - val_f1_m: 0.9238\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1671 - f1_m: 0.9405 - val_loss: 0.1766 - val_f1_m: 0.9160\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1575 - f1_m: 0.9435 - val_loss: 0.1693 - val_f1_m: 0.9375\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1501 - f1_m: 0.9480 - val_loss: 0.1643 - val_f1_m: 0.9287\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1443 - f1_m: 0.9517 - val_loss: 0.1609 - val_f1_m: 0.9316\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1401 - f1_m: 0.9510 - val_loss: 0.1567 - val_f1_m: 0.9316\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1368 - f1_m: 0.9520 - val_loss: 0.1546 - val_f1_m: 0.9316\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1341 - f1_m: 0.9520 - val_loss: 0.1532 - val_f1_m: 0.9316\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1321 - f1_m: 0.9517 - val_loss: 0.1525 - val_f1_m: 0.9375\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1307 - f1_m: 0.9513 - val_loss: 0.1525 - val_f1_m: 0.9375\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1293 - f1_m: 0.9515 - val_loss: 0.1513 - val_f1_m: 0.9375\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1285 - f1_m: 0.9515 - val_loss: 0.1512 - val_f1_m: 0.9375\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1280 - f1_m: 0.9517 - val_loss: 0.1507 - val_f1_m: 0.9375\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1272 - f1_m: 0.9517 - val_loss: 0.1515 - val_f1_m: 0.9375\n",
      "0.95175\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 170us/sample - loss: 0.6069 - f1_m: 0.7945 - val_loss: 0.5402 - val_f1_m: 0.7842\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.5005 - f1_m: 0.7945 - val_loss: 0.4823 - val_f1_m: 0.7842\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4165 - f1_m: 0.7945 - val_loss: 0.3550 - val_f1_m: 0.7842\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2894 - f1_m: 0.7945 - val_loss: 0.2632 - val_f1_m: 0.7842\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2333 - f1_m: 0.7945 - val_loss: 0.2273 - val_f1_m: 0.7812\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2074 - f1_m: 0.8607 - val_loss: 0.2064 - val_f1_m: 0.9160\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1901 - f1_m: 0.9255 - val_loss: 0.1948 - val_f1_m: 0.9307\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1779 - f1_m: 0.9320 - val_loss: 0.1816 - val_f1_m: 0.9297\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1686 - f1_m: 0.9325 - val_loss: 0.1740 - val_f1_m: 0.9277\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1620 - f1_m: 0.9355 - val_loss: 0.1683 - val_f1_m: 0.9316\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1571 - f1_m: 0.9383 - val_loss: 0.1638 - val_f1_m: 0.9346\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1530 - f1_m: 0.9405 - val_loss: 0.1603 - val_f1_m: 0.9385\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1498 - f1_m: 0.9408 - val_loss: 0.1581 - val_f1_m: 0.9385\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1478 - f1_m: 0.9420 - val_loss: 0.1563 - val_f1_m: 0.9346\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1459 - f1_m: 0.9420 - val_loss: 0.1552 - val_f1_m: 0.9346\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1448 - f1_m: 0.9415 - val_loss: 0.1541 - val_f1_m: 0.9375\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1437 - f1_m: 0.9417 - val_loss: 0.1537 - val_f1_m: 0.9375\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1430 - f1_m: 0.9420 - val_loss: 0.1538 - val_f1_m: 0.9336\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1424 - f1_m: 0.9422 - val_loss: 0.1525 - val_f1_m: 0.9316\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1418 - f1_m: 0.9420 - val_loss: 0.1515 - val_f1_m: 0.9375\n",
      "0.942\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 171us/sample - loss: 0.6078 - f1_m: 0.7895 - val_loss: 0.5179 - val_f1_m: 0.8096\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5026 - f1_m: 0.7895 - val_loss: 0.4504 - val_f1_m: 0.8008\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4167 - f1_m: 0.7895 - val_loss: 0.3243 - val_f1_m: 0.8066\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2922 - f1_m: 0.7895 - val_loss: 0.2357 - val_f1_m: 0.8096\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2349 - f1_m: 0.7895 - val_loss: 0.1978 - val_f1_m: 0.8008\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2050 - f1_m: 0.8707 - val_loss: 0.1756 - val_f1_m: 0.9346\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1854 - f1_m: 0.9345 - val_loss: 0.1586 - val_f1_m: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1707 - f1_m: 0.9415 - val_loss: 0.1465 - val_f1_m: 0.9551\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1606 - f1_m: 0.9448 - val_loss: 0.1373 - val_f1_m: 0.9609\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1523 - f1_m: 0.9492 - val_loss: 0.1304 - val_f1_m: 0.9639\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1465 - f1_m: 0.9498 - val_loss: 0.1251 - val_f1_m: 0.9639\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1419 - f1_m: 0.9520 - val_loss: 0.1205 - val_f1_m: 0.9619\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1387 - f1_m: 0.9513 - val_loss: 0.1169 - val_f1_m: 0.9658\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1360 - f1_m: 0.9515 - val_loss: 0.1140 - val_f1_m: 0.9658\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1336 - f1_m: 0.9507 - val_loss: 0.1117 - val_f1_m: 0.9648\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1322 - f1_m: 0.9513 - val_loss: 0.1101 - val_f1_m: 0.9648\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1308 - f1_m: 0.9515 - val_loss: 0.1087 - val_f1_m: 0.9648\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1296 - f1_m: 0.9513 - val_loss: 0.1071 - val_f1_m: 0.9658\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1291 - f1_m: 0.9515 - val_loss: 0.1061 - val_f1_m: 0.9658\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1284 - f1_m: 0.9515 - val_loss: 0.1054 - val_f1_m: 0.9658\n",
      "0.9515\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 170us/sample - loss: 0.6064 - f1_m: 0.7957 - val_loss: 0.5441 - val_f1_m: 0.7852\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4971 - f1_m: 0.7957 - val_loss: 0.4841 - val_f1_m: 0.7793\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4185 - f1_m: 0.7957 - val_loss: 0.3618 - val_f1_m: 0.7764\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.3009 - f1_m: 0.7957 - val_loss: 0.2728 - val_f1_m: 0.7764\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2423 - f1_m: 0.7957 - val_loss: 0.2311 - val_f1_m: 0.7852\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2142 - f1_m: 0.8277 - val_loss: 0.2081 - val_f1_m: 0.9355\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1954 - f1_m: 0.9240 - val_loss: 0.1920 - val_f1_m: 0.9414\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1827 - f1_m: 0.9290 - val_loss: 0.1786 - val_f1_m: 0.9355\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1726 - f1_m: 0.9317 - val_loss: 0.1684 - val_f1_m: 0.9434\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1650 - f1_m: 0.9347 - val_loss: 0.1618 - val_f1_m: 0.9385\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1596 - f1_m: 0.9365 - val_loss: 0.1542 - val_f1_m: 0.9463\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1554 - f1_m: 0.9395 - val_loss: 0.1493 - val_f1_m: 0.9502\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1523 - f1_m: 0.9402 - val_loss: 0.1456 - val_f1_m: 0.9541\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1495 - f1_m: 0.9413 - val_loss: 0.1431 - val_f1_m: 0.9502\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1475 - f1_m: 0.9417 - val_loss: 0.1397 - val_f1_m: 0.9521\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1456 - f1_m: 0.9420 - val_loss: 0.1383 - val_f1_m: 0.9473\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1446 - f1_m: 0.9423 - val_loss: 0.1352 - val_f1_m: 0.9531\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1439 - f1_m: 0.9413 - val_loss: 0.1336 - val_f1_m: 0.9541\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1426 - f1_m: 0.9423 - val_loss: 0.1324 - val_f1_m: 0.9541\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1418 - f1_m: 0.9430 - val_loss: 0.1312 - val_f1_m: 0.9561\n",
      "0.943\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 204us/sample - loss: 0.6070 - f1_m: 0.7937 - val_loss: 0.5386 - val_f1_m: 0.7871\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.5022 - f1_m: 0.7937 - val_loss: 0.4839 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.4322 - f1_m: 0.7937 - val_loss: 0.3761 - val_f1_m: 0.7842\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.3094 - f1_m: 0.7937 - val_loss: 0.2657 - val_f1_m: 0.7900\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2397 - f1_m: 0.7937 - val_loss: 0.2269 - val_f1_m: 0.7871\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.2089 - f1_m: 0.8577 - val_loss: 0.2040 - val_f1_m: 0.9248\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1890 - f1_m: 0.9302 - val_loss: 0.1887 - val_f1_m: 0.9287\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1747 - f1_m: 0.9367 - val_loss: 0.1772 - val_f1_m: 0.9326\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1643 - f1_m: 0.9385 - val_loss: 0.1692 - val_f1_m: 0.9355\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1563 - f1_m: 0.9413 - val_loss: 0.1628 - val_f1_m: 0.9375\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1505 - f1_m: 0.9455 - val_loss: 0.1580 - val_f1_m: 0.9414\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1458 - f1_m: 0.9477 - val_loss: 0.1547 - val_f1_m: 0.9424\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1426 - f1_m: 0.9485 - val_loss: 0.1532 - val_f1_m: 0.9395\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1400 - f1_m: 0.9482 - val_loss: 0.1513 - val_f1_m: 0.9424\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1381 - f1_m: 0.9482 - val_loss: 0.1495 - val_f1_m: 0.9424\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1363 - f1_m: 0.9485 - val_loss: 0.1480 - val_f1_m: 0.9424\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1352 - f1_m: 0.9482 - val_loss: 0.1474 - val_f1_m: 0.9395\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1342 - f1_m: 0.9485 - val_loss: 0.1475 - val_f1_m: 0.9395\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1338 - f1_m: 0.9488 - val_loss: 0.1466 - val_f1_m: 0.9424\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1330 - f1_m: 0.9480 - val_loss: 0.1461 - val_f1_m: 0.9424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 172us/sample - loss: 0.6079 - f1_m: 0.7890 - val_loss: 0.5141 - val_f1_m: 0.8086\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5053 - f1_m: 0.7890 - val_loss: 0.4510 - val_f1_m: 0.7998\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.4255 - f1_m: 0.7890 - val_loss: 0.3430 - val_f1_m: 0.8086\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.3064 - f1_m: 0.7890 - val_loss: 0.2505 - val_f1_m: 0.8057\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2455 - f1_m: 0.7890 - val_loss: 0.2122 - val_f1_m: 0.8027\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2154 - f1_m: 0.8410 - val_loss: 0.1903 - val_f1_m: 0.9248\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1961 - f1_m: 0.9243 - val_loss: 0.1752 - val_f1_m: 0.9316\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1822 - f1_m: 0.9292 - val_loss: 0.1642 - val_f1_m: 0.9326\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1716 - f1_m: 0.9360 - val_loss: 0.1564 - val_f1_m: 0.9414\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1638 - f1_m: 0.9408 - val_loss: 0.1505 - val_f1_m: 0.9463\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1583 - f1_m: 0.9427 - val_loss: 0.1460 - val_f1_m: 0.9443\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1540 - f1_m: 0.9423 - val_loss: 0.1426 - val_f1_m: 0.9473\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1505 - f1_m: 0.9435 - val_loss: 0.1400 - val_f1_m: 0.9463\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1478 - f1_m: 0.9437 - val_loss: 0.1382 - val_f1_m: 0.9404\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1462 - f1_m: 0.9442 - val_loss: 0.1370 - val_f1_m: 0.9443\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1443 - f1_m: 0.9438 - val_loss: 0.1355 - val_f1_m: 0.9443\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1432 - f1_m: 0.9438 - val_loss: 0.1348 - val_f1_m: 0.9434\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1424 - f1_m: 0.9438 - val_loss: 0.1339 - val_f1_m: 0.9463\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1416 - f1_m: 0.9435 - val_loss: 0.1332 - val_f1_m: 0.9443\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1411 - f1_m: 0.9440 - val_loss: 0.1327 - val_f1_m: 0.9473\n",
      "0.944\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 172us/sample - loss: 0.6095 - f1_m: 0.7915 - val_loss: 0.5289 - val_f1_m: 0.8018\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5019 - f1_m: 0.7915 - val_loss: 0.4618 - val_f1_m: 0.7988\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4203 - f1_m: 0.7915 - val_loss: 0.3417 - val_f1_m: 0.7959\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2989 - f1_m: 0.7915 - val_loss: 0.2471 - val_f1_m: 0.8018\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2399 - f1_m: 0.7915 - val_loss: 0.2089 - val_f1_m: 0.7988\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2098 - f1_m: 0.8572 - val_loss: 0.1851 - val_f1_m: 0.9404\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1897 - f1_m: 0.9295 - val_loss: 0.1694 - val_f1_m: 0.9512\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1751 - f1_m: 0.9362 - val_loss: 0.1565 - val_f1_m: 0.9492\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1642 - f1_m: 0.9438 - val_loss: 0.1473 - val_f1_m: 0.9590\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1561 - f1_m: 0.9480 - val_loss: 0.1411 - val_f1_m: 0.9551\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1502 - f1_m: 0.9480 - val_loss: 0.1357 - val_f1_m: 0.9580\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 58us/sample - loss: 0.1453 - f1_m: 0.9488 - val_loss: 0.1312 - val_f1_m: 0.9580\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1415 - f1_m: 0.9495 - val_loss: 0.1278 - val_f1_m: 0.9580\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1384 - f1_m: 0.9498 - val_loss: 0.1250 - val_f1_m: 0.9551\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1361 - f1_m: 0.9487 - val_loss: 0.1235 - val_f1_m: 0.9580\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1347 - f1_m: 0.9492 - val_loss: 0.1219 - val_f1_m: 0.9580\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1334 - f1_m: 0.9492 - val_loss: 0.1202 - val_f1_m: 0.9580\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1320 - f1_m: 0.9503 - val_loss: 0.1201 - val_f1_m: 0.9561\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1318 - f1_m: 0.9490 - val_loss: 0.1192 - val_f1_m: 0.9580\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1304 - f1_m: 0.9503 - val_loss: 0.1179 - val_f1_m: 0.9580\n",
      "0.95025\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 172us/sample - loss: 0.6094 - f1_m: 0.7897 - val_loss: 0.5226 - val_f1_m: 0.7998\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5096 - f1_m: 0.7897 - val_loss: 0.4690 - val_f1_m: 0.8027\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4455 - f1_m: 0.7897 - val_loss: 0.3742 - val_f1_m: 0.7998\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.3234 - f1_m: 0.7897 - val_loss: 0.2569 - val_f1_m: 0.8027\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2514 - f1_m: 0.7897 - val_loss: 0.2149 - val_f1_m: 0.8086\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2188 - f1_m: 0.8287 - val_loss: 0.1929 - val_f1_m: 0.9160\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1996 - f1_m: 0.9237 - val_loss: 0.1782 - val_f1_m: 0.9355\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1855 - f1_m: 0.9280 - val_loss: 0.1670 - val_f1_m: 0.9375\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1749 - f1_m: 0.9300 - val_loss: 0.1590 - val_f1_m: 0.9307\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1673 - f1_m: 0.9350 - val_loss: 0.1532 - val_f1_m: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1607 - f1_m: 0.9402 - val_loss: 0.1485 - val_f1_m: 0.9404\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1562 - f1_m: 0.9413 - val_loss: 0.1457 - val_f1_m: 0.9453\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1527 - f1_m: 0.9410 - val_loss: 0.1428 - val_f1_m: 0.9424\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1503 - f1_m: 0.9417 - val_loss: 0.1408 - val_f1_m: 0.9453\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1485 - f1_m: 0.9420 - val_loss: 0.1394 - val_f1_m: 0.9453\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1468 - f1_m: 0.9415 - val_loss: 0.1384 - val_f1_m: 0.9434\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1456 - f1_m: 0.9420 - val_loss: 0.1375 - val_f1_m: 0.9453\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1450 - f1_m: 0.9417 - val_loss: 0.1370 - val_f1_m: 0.9443\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1442 - f1_m: 0.9417 - val_loss: 0.1368 - val_f1_m: 0.9463\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1437 - f1_m: 0.9420 - val_loss: 0.1365 - val_f1_m: 0.9463\n",
      "0.942\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 171us/sample - loss: 0.6127 - f1_m: 0.7922 - val_loss: 0.5331 - val_f1_m: 0.7959\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5040 - f1_m: 0.7922 - val_loss: 0.4719 - val_f1_m: 0.7900\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4288 - f1_m: 0.7922 - val_loss: 0.3622 - val_f1_m: 0.7988\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.2956 - f1_m: 0.7922 - val_loss: 0.2538 - val_f1_m: 0.7930\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2333 - f1_m: 0.7922 - val_loss: 0.2161 - val_f1_m: 0.7900\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2058 - f1_m: 0.8610 - val_loss: 0.1950 - val_f1_m: 0.9385\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1876 - f1_m: 0.9315 - val_loss: 0.1813 - val_f1_m: 0.9326\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1753 - f1_m: 0.9350 - val_loss: 0.1699 - val_f1_m: 0.9355\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1654 - f1_m: 0.9377 - val_loss: 0.1617 - val_f1_m: 0.9355\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1586 - f1_m: 0.9420 - val_loss: 0.1552 - val_f1_m: 0.9453\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1528 - f1_m: 0.9448 - val_loss: 0.1504 - val_f1_m: 0.9414\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1485 - f1_m: 0.9440 - val_loss: 0.1470 - val_f1_m: 0.9434\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1453 - f1_m: 0.9462 - val_loss: 0.1440 - val_f1_m: 0.9434\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1430 - f1_m: 0.9445 - val_loss: 0.1419 - val_f1_m: 0.9473\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1411 - f1_m: 0.9455 - val_loss: 0.1412 - val_f1_m: 0.9463\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1402 - f1_m: 0.9452 - val_loss: 0.1390 - val_f1_m: 0.9482\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1394 - f1_m: 0.9452 - val_loss: 0.1390 - val_f1_m: 0.9434\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1381 - f1_m: 0.9448 - val_loss: 0.1373 - val_f1_m: 0.9453\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1377 - f1_m: 0.9448 - val_loss: 0.1368 - val_f1_m: 0.9482\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1374 - f1_m: 0.9455 - val_loss: 0.1363 - val_f1_m: 0.9424\n",
      "0.9455\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 185us/sample - loss: 0.6064 - f1_m: 0.7930 - val_loss: 0.5355 - val_f1_m: 0.7871\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5040 - f1_m: 0.7930 - val_loss: 0.4810 - val_f1_m: 0.7959\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.4349 - f1_m: 0.7930 - val_loss: 0.3807 - val_f1_m: 0.7871\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.3173 - f1_m: 0.7930 - val_loss: 0.2743 - val_f1_m: 0.7900\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2482 - f1_m: 0.7930 - val_loss: 0.2344 - val_f1_m: 0.7930\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2154 - f1_m: 0.8142 - val_loss: 0.2070 - val_f1_m: 0.9277\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1939 - f1_m: 0.9267 - val_loss: 0.1897 - val_f1_m: 0.9287\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1794 - f1_m: 0.9333 - val_loss: 0.1784 - val_f1_m: 0.9336\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1684 - f1_m: 0.9375 - val_loss: 0.1681 - val_f1_m: 0.9326\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1602 - f1_m: 0.9410 - val_loss: 0.1614 - val_f1_m: 0.9434\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1544 - f1_m: 0.9435 - val_loss: 0.1559 - val_f1_m: 0.9434\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1492 - f1_m: 0.9448 - val_loss: 0.1518 - val_f1_m: 0.9463\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1457 - f1_m: 0.9465 - val_loss: 0.1487 - val_f1_m: 0.9463\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1426 - f1_m: 0.9470 - val_loss: 0.1466 - val_f1_m: 0.9463\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1405 - f1_m: 0.9465 - val_loss: 0.1444 - val_f1_m: 0.9463\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1388 - f1_m: 0.9473 - val_loss: 0.1438 - val_f1_m: 0.9463\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1378 - f1_m: 0.9467 - val_loss: 0.1419 - val_f1_m: 0.9434\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1364 - f1_m: 0.9467 - val_loss: 0.1412 - val_f1_m: 0.9463\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1353 - f1_m: 0.9470 - val_loss: 0.1412 - val_f1_m: 0.9463\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1349 - f1_m: 0.9467 - val_loss: 0.1400 - val_f1_m: 0.9463\n",
      "0.9467499\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "if any\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 172us/sample - loss: 0.6116 - f1_m: 0.7892 - val_loss: 0.5219 - val_f1_m: 0.8018\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5054 - f1_m: 0.7892 - val_loss: 0.4550 - val_f1_m: 0.8018\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.4166 - f1_m: 0.7892 - val_loss: 0.3419 - val_f1_m: 0.8047\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2950 - f1_m: 0.7892 - val_loss: 0.2563 - val_f1_m: 0.8076\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2375 - f1_m: 0.7892 - val_loss: 0.2220 - val_f1_m: 0.8047\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2082 - f1_m: 0.8675 - val_loss: 0.2026 - val_f1_m: 0.9062\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1892 - f1_m: 0.9322 - val_loss: 0.1898 - val_f1_m: 0.9170\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1750 - f1_m: 0.9392 - val_loss: 0.1815 - val_f1_m: 0.9082\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1646 - f1_m: 0.9395 - val_loss: 0.1754 - val_f1_m: 0.9160\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1575 - f1_m: 0.9410 - val_loss: 0.1714 - val_f1_m: 0.9160\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1513 - f1_m: 0.9450 - val_loss: 0.1679 - val_f1_m: 0.9268\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1468 - f1_m: 0.9457 - val_loss: 0.1676 - val_f1_m: 0.9189\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1431 - f1_m: 0.9475 - val_loss: 0.1651 - val_f1_m: 0.9268\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1405 - f1_m: 0.9490 - val_loss: 0.1654 - val_f1_m: 0.9238\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1385 - f1_m: 0.9492 - val_loss: 0.1645 - val_f1_m: 0.9248\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1367 - f1_m: 0.9492 - val_loss: 0.1638 - val_f1_m: 0.9248\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1355 - f1_m: 0.9488 - val_loss: 0.1632 - val_f1_m: 0.9277\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1343 - f1_m: 0.9482 - val_loss: 0.1630 - val_f1_m: 0.9248\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1338 - f1_m: 0.9485 - val_loss: 0.1633 - val_f1_m: 0.9277\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1331 - f1_m: 0.9488 - val_loss: 0.1639 - val_f1_m: 0.9248\n",
      "0.94875\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 191us/sample - loss: 0.6091 - f1_m: 0.7920 - val_loss: 0.5267 - val_f1_m: 0.7881\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.4989 - f1_m: 0.7920 - val_loss: 0.4613 - val_f1_m: 0.7939\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.4070 - f1_m: 0.7920 - val_loss: 0.3371 - val_f1_m: 0.7969\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.2857 - f1_m: 0.7920 - val_loss: 0.2523 - val_f1_m: 0.7969\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.2312 - f1_m: 0.7920 - val_loss: 0.2175 - val_f1_m: 0.7998\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.2035 - f1_m: 0.8797 - val_loss: 0.1979 - val_f1_m: 0.9346\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1852 - f1_m: 0.9362 - val_loss: 0.1832 - val_f1_m: 0.9375\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 51us/sample - loss: 0.1721 - f1_m: 0.9390 - val_loss: 0.1732 - val_f1_m: 0.9316\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1619 - f1_m: 0.9420 - val_loss: 0.1660 - val_f1_m: 0.9307\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1543 - f1_m: 0.9433 - val_loss: 0.1609 - val_f1_m: 0.9326\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1486 - f1_m: 0.9460 - val_loss: 0.1555 - val_f1_m: 0.9375\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 53us/sample - loss: 0.1440 - f1_m: 0.9467 - val_loss: 0.1519 - val_f1_m: 0.9375\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 52us/sample - loss: 0.1405 - f1_m: 0.9485 - val_loss: 0.1510 - val_f1_m: 0.9385\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1377 - f1_m: 0.9488 - val_loss: 0.1473 - val_f1_m: 0.9434\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 53us/sample - loss: 0.1355 - f1_m: 0.9498 - val_loss: 0.1455 - val_f1_m: 0.9434\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 53us/sample - loss: 0.1342 - f1_m: 0.9500 - val_loss: 0.1443 - val_f1_m: 0.9434\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1328 - f1_m: 0.9497 - val_loss: 0.1431 - val_f1_m: 0.9434\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1317 - f1_m: 0.9500 - val_loss: 0.1426 - val_f1_m: 0.9414\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1307 - f1_m: 0.9500 - val_loss: 0.1420 - val_f1_m: 0.9404\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1301 - f1_m: 0.9505 - val_loss: 0.1421 - val_f1_m: 0.9385\n",
      "0.9505\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 195us/sample - loss: 0.6100 - f1_m: 0.7885 - val_loss: 0.5177 - val_f1_m: 0.8105\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 65us/sample - loss: 0.5104 - f1_m: 0.7885 - val_loss: 0.4613 - val_f1_m: 0.8047\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 61us/sample - loss: 0.4373 - f1_m: 0.7885 - val_loss: 0.3550 - val_f1_m: 0.8076\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 61us/sample - loss: 0.3061 - f1_m: 0.7885 - val_loss: 0.2518 - val_f1_m: 0.8105\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 61us/sample - loss: 0.2402 - f1_m: 0.7885 - val_loss: 0.2133 - val_f1_m: 0.8076\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 60us/sample - loss: 0.2095 - f1_m: 0.8547 - val_loss: 0.1940 - val_f1_m: 0.9287\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 60us/sample - loss: 0.1897 - f1_m: 0.9325 - val_loss: 0.1776 - val_f1_m: 0.9277\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 57us/sample - loss: 0.1760 - f1_m: 0.9367 - val_loss: 0.1674 - val_f1_m: 0.9277\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1644 - f1_m: 0.9402 - val_loss: 0.1604 - val_f1_m: 0.9316\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1561 - f1_m: 0.9460 - val_loss: 0.1543 - val_f1_m: 0.9297\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1500 - f1_m: 0.9480 - val_loss: 0.1508 - val_f1_m: 0.9346\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1453 - f1_m: 0.9490 - val_loss: 0.1479 - val_f1_m: 0.9404\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1418 - f1_m: 0.9490 - val_loss: 0.1461 - val_f1_m: 0.9404\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1391 - f1_m: 0.9495 - val_loss: 0.1458 - val_f1_m: 0.9404\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1370 - f1_m: 0.9492 - val_loss: 0.1435 - val_f1_m: 0.9404\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1359 - f1_m: 0.9482 - val_loss: 0.1431 - val_f1_m: 0.9316\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 51us/sample - loss: 0.1344 - f1_m: 0.9492 - val_loss: 0.1428 - val_f1_m: 0.9404\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1332 - f1_m: 0.9490 - val_loss: 0.1425 - val_f1_m: 0.9404\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1327 - f1_m: 0.9488 - val_loss: 0.1442 - val_f1_m: 0.9375\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 55us/sample - loss: 0.1322 - f1_m: 0.9490 - val_loss: 0.1422 - val_f1_m: 0.9375\n",
      "0.94899994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 174us/sample - loss: 0.6102 - f1_m: 0.7932 - val_loss: 0.5348 - val_f1_m: 0.7891\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 52us/sample - loss: 0.4994 - f1_m: 0.7932 - val_loss: 0.4750 - val_f1_m: 0.7861\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 54us/sample - loss: 0.4202 - f1_m: 0.7932 - val_loss: 0.3588 - val_f1_m: 0.7920\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 52us/sample - loss: 0.2984 - f1_m: 0.7932 - val_loss: 0.2625 - val_f1_m: 0.7920\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.2384 - f1_m: 0.7932 - val_loss: 0.2233 - val_f1_m: 0.7803\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2090 - f1_m: 0.8510 - val_loss: 0.2008 - val_f1_m: 0.9414\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1900 - f1_m: 0.9300 - val_loss: 0.1843 - val_f1_m: 0.9375\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1762 - f1_m: 0.9358 - val_loss: 0.1718 - val_f1_m: 0.9365\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1662 - f1_m: 0.9372 - val_loss: 0.1623 - val_f1_m: 0.9502\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1583 - f1_m: 0.9437 - val_loss: 0.1546 - val_f1_m: 0.9492\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1524 - f1_m: 0.9473 - val_loss: 0.1484 - val_f1_m: 0.9531\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1479 - f1_m: 0.9470 - val_loss: 0.1436 - val_f1_m: 0.9541\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1445 - f1_m: 0.9473 - val_loss: 0.1403 - val_f1_m: 0.9541\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1416 - f1_m: 0.9475 - val_loss: 0.1370 - val_f1_m: 0.9531\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1398 - f1_m: 0.9475 - val_loss: 0.1347 - val_f1_m: 0.9541\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1379 - f1_m: 0.9470 - val_loss: 0.1337 - val_f1_m: 0.9531\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1369 - f1_m: 0.9475 - val_loss: 0.1315 - val_f1_m: 0.9502\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1357 - f1_m: 0.9475 - val_loss: 0.1301 - val_f1_m: 0.9512\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1349 - f1_m: 0.9477 - val_loss: 0.1288 - val_f1_m: 0.9512\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1346 - f1_m: 0.9475 - val_loss: 0.1290 - val_f1_m: 0.9541\n",
      "0.9475\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 172us/sample - loss: 0.6076 - f1_m: 0.7927 - val_loss: 0.5313 - val_f1_m: 0.7939\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.5051 - f1_m: 0.7927 - val_loss: 0.4801 - val_f1_m: 0.7939\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4396 - f1_m: 0.7927 - val_loss: 0.3831 - val_f1_m: 0.7939\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.3161 - f1_m: 0.7927 - val_loss: 0.2662 - val_f1_m: 0.7910\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2435 - f1_m: 0.7927 - val_loss: 0.2251 - val_f1_m: 0.7939\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2129 - f1_m: 0.8440 - val_loss: 0.2032 - val_f1_m: 0.9131\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1947 - f1_m: 0.9262 - val_loss: 0.1861 - val_f1_m: 0.9277\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1809 - f1_m: 0.9330 - val_loss: 0.1738 - val_f1_m: 0.9326\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1715 - f1_m: 0.9337 - val_loss: 0.1652 - val_f1_m: 0.9268\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1642 - f1_m: 0.9350 - val_loss: 0.1585 - val_f1_m: 0.9336\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1589 - f1_m: 0.9360 - val_loss: 0.1534 - val_f1_m: 0.9336\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1546 - f1_m: 0.9370 - val_loss: 0.1517 - val_f1_m: 0.9336\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1516 - f1_m: 0.9395 - val_loss: 0.1465 - val_f1_m: 0.9424\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1493 - f1_m: 0.9398 - val_loss: 0.1449 - val_f1_m: 0.9414\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1478 - f1_m: 0.9413 - val_loss: 0.1439 - val_f1_m: 0.9385\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1464 - f1_m: 0.9423 - val_loss: 0.1419 - val_f1_m: 0.9434\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1454 - f1_m: 0.9427 - val_loss: 0.1392 - val_f1_m: 0.9473\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1444 - f1_m: 0.9422 - val_loss: 0.1384 - val_f1_m: 0.9443\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1438 - f1_m: 0.9417 - val_loss: 0.1407 - val_f1_m: 0.9443\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1436 - f1_m: 0.9425 - val_loss: 0.1399 - val_f1_m: 0.9453\n",
      "0.9425\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 169us/sample - loss: 0.6077 - f1_m: 0.7940 - val_loss: 0.5381 - val_f1_m: 0.7891\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.5034 - f1_m: 0.7940 - val_loss: 0.4833 - val_f1_m: 0.7861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.4200 - f1_m: 0.7940 - val_loss: 0.3509 - val_f1_m: 0.7920\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.2921 - f1_m: 0.7940 - val_loss: 0.2589 - val_f1_m: 0.7920\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.2344 - f1_m: 0.7940 - val_loss: 0.2219 - val_f1_m: 0.7861\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2069 - f1_m: 0.8595 - val_loss: 0.1997 - val_f1_m: 0.9209\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1878 - f1_m: 0.9332 - val_loss: 0.1823 - val_f1_m: 0.9395\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1742 - f1_m: 0.9365 - val_loss: 0.1707 - val_f1_m: 0.9385\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1640 - f1_m: 0.9380 - val_loss: 0.1598 - val_f1_m: 0.9434\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1561 - f1_m: 0.9435 - val_loss: 0.1524 - val_f1_m: 0.9404\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1499 - f1_m: 0.9465 - val_loss: 0.1462 - val_f1_m: 0.9531\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1450 - f1_m: 0.9495 - val_loss: 0.1419 - val_f1_m: 0.9482\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1417 - f1_m: 0.9488 - val_loss: 0.1398 - val_f1_m: 0.9531\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1389 - f1_m: 0.9495 - val_loss: 0.1363 - val_f1_m: 0.9512\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1369 - f1_m: 0.9492 - val_loss: 0.1335 - val_f1_m: 0.9541\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1358 - f1_m: 0.9477 - val_loss: 0.1321 - val_f1_m: 0.9541\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1340 - f1_m: 0.9485 - val_loss: 0.1318 - val_f1_m: 0.9482\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1337 - f1_m: 0.9480 - val_loss: 0.1299 - val_f1_m: 0.9541\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1322 - f1_m: 0.9488 - val_loss: 0.1289 - val_f1_m: 0.9531\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1318 - f1_m: 0.9490 - val_loss: 0.1280 - val_f1_m: 0.9473\n",
      "0.949\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 170us/sample - loss: 0.6102 - f1_m: 0.7925 - val_loss: 0.5338 - val_f1_m: 0.7920\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.5063 - f1_m: 0.7925 - val_loss: 0.4770 - val_f1_m: 0.7979\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4319 - f1_m: 0.7925 - val_loss: 0.3566 - val_f1_m: 0.7920\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.3041 - f1_m: 0.7925 - val_loss: 0.2542 - val_f1_m: 0.7891\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2412 - f1_m: 0.7925 - val_loss: 0.2164 - val_f1_m: 0.7920\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2120 - f1_m: 0.8435 - val_loss: 0.1962 - val_f1_m: 0.9395\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1941 - f1_m: 0.9267 - val_loss: 0.1805 - val_f1_m: 0.9404\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1809 - f1_m: 0.9292 - val_loss: 0.1702 - val_f1_m: 0.9385\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1716 - f1_m: 0.9333 - val_loss: 0.1619 - val_f1_m: 0.9375\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1642 - f1_m: 0.9347 - val_loss: 0.1558 - val_f1_m: 0.9385\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1587 - f1_m: 0.9383 - val_loss: 0.1516 - val_f1_m: 0.9463\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1547 - f1_m: 0.9415 - val_loss: 0.1475 - val_f1_m: 0.9434\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1513 - f1_m: 0.9410 - val_loss: 0.1459 - val_f1_m: 0.9414\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1494 - f1_m: 0.9405 - val_loss: 0.1428 - val_f1_m: 0.9463\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1473 - f1_m: 0.9410 - val_loss: 0.1416 - val_f1_m: 0.9434\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1465 - f1_m: 0.9405 - val_loss: 0.1401 - val_f1_m: 0.9434\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1451 - f1_m: 0.9410 - val_loss: 0.1395 - val_f1_m: 0.9453\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1446 - f1_m: 0.9408 - val_loss: 0.1386 - val_f1_m: 0.9434\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1440 - f1_m: 0.9415 - val_loss: 0.1382 - val_f1_m: 0.9434\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1434 - f1_m: 0.9413 - val_loss: 0.1378 - val_f1_m: 0.9434\n",
      "0.94125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 176us/sample - loss: 0.6091 - f1_m: 0.7897 - val_loss: 0.5154 - val_f1_m: 0.8057\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.5042 - f1_m: 0.7897 - val_loss: 0.4546 - val_f1_m: 0.8057\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4139 - f1_m: 0.7897 - val_loss: 0.3276 - val_f1_m: 0.7998\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2844 - f1_m: 0.7897 - val_loss: 0.2428 - val_f1_m: 0.7939\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2322 - f1_m: 0.7897 - val_loss: 0.2111 - val_f1_m: 0.8027\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2073 - f1_m: 0.8815 - val_loss: 0.1922 - val_f1_m: 0.9229\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1906 - f1_m: 0.9280 - val_loss: 0.1790 - val_f1_m: 0.9248\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1786 - f1_m: 0.9325 - val_loss: 0.1691 - val_f1_m: 0.9277\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1694 - f1_m: 0.9345 - val_loss: 0.1628 - val_f1_m: 0.9355\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1627 - f1_m: 0.9385 - val_loss: 0.1572 - val_f1_m: 0.9395\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1576 - f1_m: 0.9390 - val_loss: 0.1529 - val_f1_m: 0.9375\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1537 - f1_m: 0.9415 - val_loss: 0.1508 - val_f1_m: 0.9365\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1507 - f1_m: 0.9417 - val_loss: 0.1475 - val_f1_m: 0.9385\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1485 - f1_m: 0.9420 - val_loss: 0.1459 - val_f1_m: 0.9414\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1468 - f1_m: 0.9420 - val_loss: 0.1450 - val_f1_m: 0.9385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1455 - f1_m: 0.9425 - val_loss: 0.1443 - val_f1_m: 0.9395\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1446 - f1_m: 0.9415 - val_loss: 0.1438 - val_f1_m: 0.9414\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1438 - f1_m: 0.9415 - val_loss: 0.1435 - val_f1_m: 0.9375\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1434 - f1_m: 0.9422 - val_loss: 0.1442 - val_f1_m: 0.9395\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1431 - f1_m: 0.9423 - val_loss: 0.1437 - val_f1_m: 0.9307\n",
      "0.94225\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 171us/sample - loss: 0.6077 - f1_m: 0.7917 - val_loss: 0.5301 - val_f1_m: 0.7979\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.5032 - f1_m: 0.7917 - val_loss: 0.4656 - val_f1_m: 0.7920\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4054 - f1_m: 0.7917 - val_loss: 0.3245 - val_f1_m: 0.7949\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2774 - f1_m: 0.7917 - val_loss: 0.2430 - val_f1_m: 0.7861\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2260 - f1_m: 0.7917 - val_loss: 0.2124 - val_f1_m: 0.8008\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2003 - f1_m: 0.8967 - val_loss: 0.1942 - val_f1_m: 0.9277\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1830 - f1_m: 0.9342 - val_loss: 0.1818 - val_f1_m: 0.9248\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1706 - f1_m: 0.9365 - val_loss: 0.1733 - val_f1_m: 0.9277\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1617 - f1_m: 0.9408 - val_loss: 0.1673 - val_f1_m: 0.9355\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1548 - f1_m: 0.9427 - val_loss: 0.1625 - val_f1_m: 0.9346\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1499 - f1_m: 0.9455 - val_loss: 0.1594 - val_f1_m: 0.9346\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1456 - f1_m: 0.9473 - val_loss: 0.1571 - val_f1_m: 0.9355\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1426 - f1_m: 0.9475 - val_loss: 0.1555 - val_f1_m: 0.9316\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1403 - f1_m: 0.9475 - val_loss: 0.1547 - val_f1_m: 0.9326\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1387 - f1_m: 0.9475 - val_loss: 0.1542 - val_f1_m: 0.9355\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1371 - f1_m: 0.9475 - val_loss: 0.1532 - val_f1_m: 0.9326\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1361 - f1_m: 0.9475 - val_loss: 0.1527 - val_f1_m: 0.9346\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1355 - f1_m: 0.9473 - val_loss: 0.1527 - val_f1_m: 0.9355\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1351 - f1_m: 0.9473 - val_loss: 0.1526 - val_f1_m: 0.9355\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1343 - f1_m: 0.9472 - val_loss: 0.1527 - val_f1_m: 0.9355\n",
      "0.94724995\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 169us/sample - loss: 0.6073 - f1_m: 0.7895 - val_loss: 0.5162 - val_f1_m: 0.8037\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.5036 - f1_m: 0.7895 - val_loss: 0.4538 - val_f1_m: 0.8008\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4235 - f1_m: 0.7895 - val_loss: 0.3386 - val_f1_m: 0.8008\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.3037 - f1_m: 0.7895 - val_loss: 0.2438 - val_f1_m: 0.8066\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2420 - f1_m: 0.7895 - val_loss: 0.2026 - val_f1_m: 0.8008\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2091 - f1_m: 0.8587 - val_loss: 0.1783 - val_f1_m: 0.9512\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1881 - f1_m: 0.9330 - val_loss: 0.1606 - val_f1_m: 0.9580\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1726 - f1_m: 0.9395 - val_loss: 0.1468 - val_f1_m: 0.9541\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1613 - f1_m: 0.9450 - val_loss: 0.1373 - val_f1_m: 0.9590\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1530 - f1_m: 0.9507 - val_loss: 0.1301 - val_f1_m: 0.9600\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1464 - f1_m: 0.9523 - val_loss: 0.1247 - val_f1_m: 0.9639\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1416 - f1_m: 0.9517 - val_loss: 0.1198 - val_f1_m: 0.9590\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1376 - f1_m: 0.9532 - val_loss: 0.1161 - val_f1_m: 0.9619\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1347 - f1_m: 0.9530 - val_loss: 0.1139 - val_f1_m: 0.9619\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1323 - f1_m: 0.9530 - val_loss: 0.1111 - val_f1_m: 0.9619\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1307 - f1_m: 0.9528 - val_loss: 0.1093 - val_f1_m: 0.9619\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1296 - f1_m: 0.9535 - val_loss: 0.1090 - val_f1_m: 0.9648\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1282 - f1_m: 0.9525 - val_loss: 0.1065 - val_f1_m: 0.9619\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1270 - f1_m: 0.9535 - val_loss: 0.1061 - val_f1_m: 0.9619\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1264 - f1_m: 0.9530 - val_loss: 0.1049 - val_f1_m: 0.9648\n",
      "0.953\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "if any\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 167us/sample - loss: 0.6117 - f1_m: 0.7872 - val_loss: 0.5165 - val_f1_m: 0.8125\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.5087 - f1_m: 0.7872 - val_loss: 0.4468 - val_f1_m: 0.8154\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4185 - f1_m: 0.7872 - val_loss: 0.3155 - val_f1_m: 0.8125\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2875 - f1_m: 0.7872 - val_loss: 0.2275 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2318 - f1_m: 0.7872 - val_loss: 0.1955 - val_f1_m: 0.8154\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2052 - f1_m: 0.8932 - val_loss: 0.1785 - val_f1_m: 0.9404\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1869 - f1_m: 0.9323 - val_loss: 0.1656 - val_f1_m: 0.9404\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1744 - f1_m: 0.9340 - val_loss: 0.1538 - val_f1_m: 0.9404\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1641 - f1_m: 0.9392 - val_loss: 0.1463 - val_f1_m: 0.9404\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1570 - f1_m: 0.9435 - val_loss: 0.1415 - val_f1_m: 0.9492\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1515 - f1_m: 0.9463 - val_loss: 0.1372 - val_f1_m: 0.9492\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1470 - f1_m: 0.9467 - val_loss: 0.1348 - val_f1_m: 0.9492\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1441 - f1_m: 0.9477 - val_loss: 0.1327 - val_f1_m: 0.9492\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1414 - f1_m: 0.9477 - val_loss: 0.1312 - val_f1_m: 0.9434\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1397 - f1_m: 0.9473 - val_loss: 0.1295 - val_f1_m: 0.9463\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1381 - f1_m: 0.9480 - val_loss: 0.1293 - val_f1_m: 0.9463\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1373 - f1_m: 0.9470 - val_loss: 0.1284 - val_f1_m: 0.9492\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1364 - f1_m: 0.9473 - val_loss: 0.1282 - val_f1_m: 0.9463\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1357 - f1_m: 0.9477 - val_loss: 0.1294 - val_f1_m: 0.9482\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1358 - f1_m: 0.9470 - val_loss: 0.1274 - val_f1_m: 0.9492\n",
      "0.94699997\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 176us/sample - loss: 0.6087 - f1_m: 0.7960 - val_loss: 0.5463 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.5027 - f1_m: 0.7960 - val_loss: 0.4962 - val_f1_m: 0.7754\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.4312 - f1_m: 0.7960 - val_loss: 0.3831 - val_f1_m: 0.7725\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.3069 - f1_m: 0.7960 - val_loss: 0.2858 - val_f1_m: 0.7754\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.2409 - f1_m: 0.7960 - val_loss: 0.2389 - val_f1_m: 0.7754\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.2105 - f1_m: 0.8277 - val_loss: 0.2154 - val_f1_m: 0.9229\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 52us/sample - loss: 0.1926 - f1_m: 0.9277 - val_loss: 0.1994 - val_f1_m: 0.9160\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1799 - f1_m: 0.9340 - val_loss: 0.1879 - val_f1_m: 0.9258\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1705 - f1_m: 0.9360 - val_loss: 0.1781 - val_f1_m: 0.9248\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 53us/sample - loss: 0.1638 - f1_m: 0.9347 - val_loss: 0.1724 - val_f1_m: 0.9316\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1584 - f1_m: 0.9348 - val_loss: 0.1658 - val_f1_m: 0.9297\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1546 - f1_m: 0.9362 - val_loss: 0.1623 - val_f1_m: 0.9326\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.1516 - f1_m: 0.9352 - val_loss: 0.1594 - val_f1_m: 0.9307\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1496 - f1_m: 0.9367 - val_loss: 0.1599 - val_f1_m: 0.9326\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 55us/sample - loss: 0.1484 - f1_m: 0.9367 - val_loss: 0.1568 - val_f1_m: 0.9336\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1469 - f1_m: 0.9362 - val_loss: 0.1537 - val_f1_m: 0.9365\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1457 - f1_m: 0.9377 - val_loss: 0.1555 - val_f1_m: 0.9277\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1454 - f1_m: 0.9390 - val_loss: 0.1521 - val_f1_m: 0.9375\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1446 - f1_m: 0.9380 - val_loss: 0.1506 - val_f1_m: 0.9385\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1438 - f1_m: 0.9402 - val_loss: 0.1501 - val_f1_m: 0.9385\n",
      "0.94025\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 167us/sample - loss: 0.6065 - f1_m: 0.7920 - val_loss: 0.5267 - val_f1_m: 0.7910\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4898 - f1_m: 0.7920 - val_loss: 0.4448 - val_f1_m: 0.7969\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.3795 - f1_m: 0.7920 - val_loss: 0.3078 - val_f1_m: 0.7969\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2703 - f1_m: 0.7920 - val_loss: 0.2447 - val_f1_m: 0.7969\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2279 - f1_m: 0.7920 - val_loss: 0.2175 - val_f1_m: 0.7969\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2045 - f1_m: 0.9007 - val_loss: 0.2000 - val_f1_m: 0.9199\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1885 - f1_m: 0.9277 - val_loss: 0.1877 - val_f1_m: 0.9248\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1770 - f1_m: 0.9305 - val_loss: 0.1796 - val_f1_m: 0.9277\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1686 - f1_m: 0.9348 - val_loss: 0.1719 - val_f1_m: 0.9248\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 43us/sample - loss: 0.1617 - f1_m: 0.9372 - val_loss: 0.1670 - val_f1_m: 0.9346\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1567 - f1_m: 0.9413 - val_loss: 0.1639 - val_f1_m: 0.9268\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1533 - f1_m: 0.9410 - val_loss: 0.1611 - val_f1_m: 0.9336\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1502 - f1_m: 0.9420 - val_loss: 0.1588 - val_f1_m: 0.9355\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1480 - f1_m: 0.9430 - val_loss: 0.1575 - val_f1_m: 0.9346\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1463 - f1_m: 0.9420 - val_loss: 0.1563 - val_f1_m: 0.9316\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1451 - f1_m: 0.9420 - val_loss: 0.1557 - val_f1_m: 0.9346\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1443 - f1_m: 0.9420 - val_loss: 0.1560 - val_f1_m: 0.9326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1437 - f1_m: 0.9417 - val_loss: 0.1548 - val_f1_m: 0.9316\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1429 - f1_m: 0.9423 - val_loss: 0.1554 - val_f1_m: 0.9297\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1425 - f1_m: 0.9420 - val_loss: 0.1543 - val_f1_m: 0.9316\n",
      "0.942\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 168us/sample - loss: 0.6029 - f1_m: 0.7952 - val_loss: 0.5426 - val_f1_m: 0.7812\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.5003 - f1_m: 0.7952 - val_loss: 0.4876 - val_f1_m: 0.7812\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4213 - f1_m: 0.7952 - val_loss: 0.3597 - val_f1_m: 0.7812\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2921 - f1_m: 0.7952 - val_loss: 0.2607 - val_f1_m: 0.7812\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2316 - f1_m: 0.7952 - val_loss: 0.2236 - val_f1_m: 0.7842\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2044 - f1_m: 0.8642 - val_loss: 0.1997 - val_f1_m: 0.9238\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1871 - f1_m: 0.9302 - val_loss: 0.1821 - val_f1_m: 0.9424\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1741 - f1_m: 0.9345 - val_loss: 0.1696 - val_f1_m: 0.9424\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1643 - f1_m: 0.9365 - val_loss: 0.1616 - val_f1_m: 0.9404\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1575 - f1_m: 0.9392 - val_loss: 0.1528 - val_f1_m: 0.9551\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1518 - f1_m: 0.9445 - val_loss: 0.1467 - val_f1_m: 0.9551\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1476 - f1_m: 0.9455 - val_loss: 0.1425 - val_f1_m: 0.9541\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1445 - f1_m: 0.9452 - val_loss: 0.1384 - val_f1_m: 0.9551\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1419 - f1_m: 0.9457 - val_loss: 0.1359 - val_f1_m: 0.9551\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1399 - f1_m: 0.9455 - val_loss: 0.1335 - val_f1_m: 0.9551\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1387 - f1_m: 0.9460 - val_loss: 0.1326 - val_f1_m: 0.9512\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1375 - f1_m: 0.9452 - val_loss: 0.1310 - val_f1_m: 0.9541\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1369 - f1_m: 0.9452 - val_loss: 0.1297 - val_f1_m: 0.9541\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1362 - f1_m: 0.9455 - val_loss: 0.1309 - val_f1_m: 0.9531\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1355 - f1_m: 0.9455 - val_loss: 0.1306 - val_f1_m: 0.9531\n",
      "0.9455\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 168us/sample - loss: 0.6089 - f1_m: 0.7917 - val_loss: 0.5248 - val_f1_m: 0.7861\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.5008 - f1_m: 0.7917 - val_loss: 0.4632 - val_f1_m: 0.7979\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4127 - f1_m: 0.7917 - val_loss: 0.3391 - val_f1_m: 0.7949\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2918 - f1_m: 0.7917 - val_loss: 0.2550 - val_f1_m: 0.7920\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2373 - f1_m: 0.7917 - val_loss: 0.2224 - val_f1_m: 0.7920\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2095 - f1_m: 0.8605 - val_loss: 0.1990 - val_f1_m: 0.9199\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1915 - f1_m: 0.9302 - val_loss: 0.1843 - val_f1_m: 0.9277\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1788 - f1_m: 0.9325 - val_loss: 0.1731 - val_f1_m: 0.9268\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1696 - f1_m: 0.9355 - val_loss: 0.1657 - val_f1_m: 0.9424\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1625 - f1_m: 0.9400 - val_loss: 0.1587 - val_f1_m: 0.9375\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1567 - f1_m: 0.9395 - val_loss: 0.1544 - val_f1_m: 0.9385\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1527 - f1_m: 0.9430 - val_loss: 0.1506 - val_f1_m: 0.9443\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1491 - f1_m: 0.9448 - val_loss: 0.1478 - val_f1_m: 0.9453\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1465 - f1_m: 0.9438 - val_loss: 0.1457 - val_f1_m: 0.9443\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1446 - f1_m: 0.9442 - val_loss: 0.1458 - val_f1_m: 0.9424\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1429 - f1_m: 0.9445 - val_loss: 0.1425 - val_f1_m: 0.9443\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1417 - f1_m: 0.9442 - val_loss: 0.1435 - val_f1_m: 0.9443\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1409 - f1_m: 0.9445 - val_loss: 0.1415 - val_f1_m: 0.9453\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1402 - f1_m: 0.9438 - val_loss: 0.1404 - val_f1_m: 0.9414\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1399 - f1_m: 0.9448 - val_loss: 0.1399 - val_f1_m: 0.9453\n",
      "0.94475\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "if any\n",
      "if any\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 167us/sample - loss: 0.6054 - f1_m: 0.7930 - val_loss: 0.5302 - val_f1_m: 0.7930\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.5043 - f1_m: 0.7930 - val_loss: 0.4827 - val_f1_m: 0.7930\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.4406 - f1_m: 0.7930 - val_loss: 0.3947 - val_f1_m: 0.7930\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.3228 - f1_m: 0.7930 - val_loss: 0.2812 - val_f1_m: 0.7900\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2491 - f1_m: 0.7930 - val_loss: 0.2363 - val_f1_m: 0.7871\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2156 - f1_m: 0.8362 - val_loss: 0.2111 - val_f1_m: 0.9180\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1949 - f1_m: 0.9257 - val_loss: 0.1964 - val_f1_m: 0.9209\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1801 - f1_m: 0.9320 - val_loss: 0.1839 - val_f1_m: 0.9180\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1698 - f1_m: 0.9335 - val_loss: 0.1759 - val_f1_m: 0.9248\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1619 - f1_m: 0.9370 - val_loss: 0.1700 - val_f1_m: 0.9258\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1560 - f1_m: 0.9413 - val_loss: 0.1658 - val_f1_m: 0.9316\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1512 - f1_m: 0.9440 - val_loss: 0.1627 - val_f1_m: 0.9316\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1486 - f1_m: 0.9435 - val_loss: 0.1605 - val_f1_m: 0.9355\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1454 - f1_m: 0.9445 - val_loss: 0.1589 - val_f1_m: 0.9355\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1438 - f1_m: 0.9430 - val_loss: 0.1580 - val_f1_m: 0.9326\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1420 - f1_m: 0.9440 - val_loss: 0.1572 - val_f1_m: 0.9336\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1408 - f1_m: 0.9440 - val_loss: 0.1565 - val_f1_m: 0.9336\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1404 - f1_m: 0.9445 - val_loss: 0.1561 - val_f1_m: 0.9307\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1395 - f1_m: 0.9448 - val_loss: 0.1559 - val_f1_m: 0.9336\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1389 - f1_m: 0.9445 - val_loss: 0.1557 - val_f1_m: 0.9336\n",
      "0.9445\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 168us/sample - loss: 0.6058 - f1_m: 0.7932 - val_loss: 0.5318 - val_f1_m: 0.7891\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.4978 - f1_m: 0.7932 - val_loss: 0.4714 - val_f1_m: 0.7920\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4165 - f1_m: 0.7932 - val_loss: 0.3500 - val_f1_m: 0.7861\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2953 - f1_m: 0.7932 - val_loss: 0.2604 - val_f1_m: 0.7920\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2372 - f1_m: 0.7932 - val_loss: 0.2231 - val_f1_m: 0.7949\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2081 - f1_m: 0.8507 - val_loss: 0.2017 - val_f1_m: 0.9307\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1895 - f1_m: 0.9290 - val_loss: 0.1869 - val_f1_m: 0.9287\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1762 - f1_m: 0.9355 - val_loss: 0.1757 - val_f1_m: 0.9326\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1671 - f1_m: 0.9375 - val_loss: 0.1678 - val_f1_m: 0.9258\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1595 - f1_m: 0.9410 - val_loss: 0.1619 - val_f1_m: 0.9443\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1541 - f1_m: 0.9445 - val_loss: 0.1569 - val_f1_m: 0.9414\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1499 - f1_m: 0.9450 - val_loss: 0.1534 - val_f1_m: 0.9434\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1468 - f1_m: 0.9448 - val_loss: 0.1508 - val_f1_m: 0.9434\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1443 - f1_m: 0.9448 - val_loss: 0.1490 - val_f1_m: 0.9443\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1426 - f1_m: 0.9455 - val_loss: 0.1476 - val_f1_m: 0.9434\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1408 - f1_m: 0.9457 - val_loss: 0.1466 - val_f1_m: 0.9424\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1397 - f1_m: 0.9455 - val_loss: 0.1455 - val_f1_m: 0.9443\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1388 - f1_m: 0.9452 - val_loss: 0.1450 - val_f1_m: 0.9414\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1381 - f1_m: 0.9452 - val_loss: 0.1444 - val_f1_m: 0.9443\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1377 - f1_m: 0.9457 - val_loss: 0.1449 - val_f1_m: 0.9434\n",
      "0.94575\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "if any\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 166us/sample - loss: 0.6082 - f1_m: 0.7878 - val_loss: 0.5153 - val_f1_m: 0.8066\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.5064 - f1_m: 0.7880 - val_loss: 0.4521 - val_f1_m: 0.8066\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4215 - f1_m: 0.7880 - val_loss: 0.3354 - val_f1_m: 0.8096\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2961 - f1_m: 0.7880 - val_loss: 0.2414 - val_f1_m: 0.8125\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2358 - f1_m: 0.7880 - val_loss: 0.2034 - val_f1_m: 0.8125\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2054 - f1_m: 0.8705 - val_loss: 0.1822 - val_f1_m: 0.9248\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1852 - f1_m: 0.9350 - val_loss: 0.1680 - val_f1_m: 0.9375\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1708 - f1_m: 0.9405 - val_loss: 0.1578 - val_f1_m: 0.9375\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1602 - f1_m: 0.9467 - val_loss: 0.1508 - val_f1_m: 0.9473\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1523 - f1_m: 0.9513 - val_loss: 0.1452 - val_f1_m: 0.9473\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1463 - f1_m: 0.9523 - val_loss: 0.1414 - val_f1_m: 0.9473\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1418 - f1_m: 0.9515 - val_loss: 0.1393 - val_f1_m: 0.9453\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1383 - f1_m: 0.9515 - val_loss: 0.1367 - val_f1_m: 0.9473\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1357 - f1_m: 0.9523 - val_loss: 0.1358 - val_f1_m: 0.9443\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1337 - f1_m: 0.9523 - val_loss: 0.1348 - val_f1_m: 0.9473\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1321 - f1_m: 0.9515 - val_loss: 0.1336 - val_f1_m: 0.9443\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1308 - f1_m: 0.9517 - val_loss: 0.1330 - val_f1_m: 0.9473\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1300 - f1_m: 0.9515 - val_loss: 0.1334 - val_f1_m: 0.9404\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1289 - f1_m: 0.9523 - val_loss: 0.1332 - val_f1_m: 0.9463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1286 - f1_m: 0.9520 - val_loss: 0.1332 - val_f1_m: 0.9463\n",
      "0.952\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 197us/sample - loss: 0.6054 - f1_m: 0.7947 - val_loss: 0.5383 - val_f1_m: 0.7861\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 57us/sample - loss: 0.5026 - f1_m: 0.7947 - val_loss: 0.4899 - val_f1_m: 0.7861\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.4292 - f1_m: 0.7947 - val_loss: 0.3775 - val_f1_m: 0.7891\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.3014 - f1_m: 0.7947 - val_loss: 0.2764 - val_f1_m: 0.7861\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.2374 - f1_m: 0.7947 - val_loss: 0.2364 - val_f1_m: 0.7803\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 51us/sample - loss: 0.2072 - f1_m: 0.8512 - val_loss: 0.2129 - val_f1_m: 0.9082\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 52us/sample - loss: 0.1879 - f1_m: 0.9320 - val_loss: 0.1970 - val_f1_m: 0.9170\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.1740 - f1_m: 0.9327 - val_loss: 0.1855 - val_f1_m: 0.9229\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1636 - f1_m: 0.9405 - val_loss: 0.1768 - val_f1_m: 0.9277\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1559 - f1_m: 0.9457 - val_loss: 0.1708 - val_f1_m: 0.9326\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1503 - f1_m: 0.9470 - val_loss: 0.1659 - val_f1_m: 0.9355\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 48us/sample - loss: 0.1460 - f1_m: 0.9467 - val_loss: 0.1626 - val_f1_m: 0.9336\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 64us/sample - loss: 0.1427 - f1_m: 0.9465 - val_loss: 0.1600 - val_f1_m: 0.9326\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 54us/sample - loss: 0.1403 - f1_m: 0.9467 - val_loss: 0.1585 - val_f1_m: 0.9355\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 58us/sample - loss: 0.1388 - f1_m: 0.9467 - val_loss: 0.1570 - val_f1_m: 0.9326\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 53us/sample - loss: 0.1374 - f1_m: 0.9465 - val_loss: 0.1560 - val_f1_m: 0.9355\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 51us/sample - loss: 0.1360 - f1_m: 0.9465 - val_loss: 0.1577 - val_f1_m: 0.9365\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1353 - f1_m: 0.9465 - val_loss: 0.1559 - val_f1_m: 0.9375\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 60us/sample - loss: 0.1346 - f1_m: 0.9465 - val_loss: 0.1544 - val_f1_m: 0.9355\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 50us/sample - loss: 0.1343 - f1_m: 0.9465 - val_loss: 0.1544 - val_f1_m: 0.9297\n",
      "0.9465\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 169us/sample - loss: 0.6096 - f1_m: 0.7935 - val_loss: 0.5338 - val_f1_m: 0.7910\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.4992 - f1_m: 0.7935 - val_loss: 0.4690 - val_f1_m: 0.7939\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4141 - f1_m: 0.7935 - val_loss: 0.3418 - val_f1_m: 0.7910\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2940 - f1_m: 0.7935 - val_loss: 0.2567 - val_f1_m: 0.7910\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2383 - f1_m: 0.7935 - val_loss: 0.2224 - val_f1_m: 0.7910\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2108 - f1_m: 0.8500 - val_loss: 0.1961 - val_f1_m: 0.9414\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1922 - f1_m: 0.9275 - val_loss: 0.1795 - val_f1_m: 0.9365\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1787 - f1_m: 0.9325 - val_loss: 0.1672 - val_f1_m: 0.9414\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1685 - f1_m: 0.9355 - val_loss: 0.1574 - val_f1_m: 0.9424\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1604 - f1_m: 0.9402 - val_loss: 0.1485 - val_f1_m: 0.9561\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1547 - f1_m: 0.9433 - val_loss: 0.1431 - val_f1_m: 0.9541\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1505 - f1_m: 0.9448 - val_loss: 0.1378 - val_f1_m: 0.9561\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1471 - f1_m: 0.9430 - val_loss: 0.1336 - val_f1_m: 0.9561\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1442 - f1_m: 0.9450 - val_loss: 0.1315 - val_f1_m: 0.9541\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1422 - f1_m: 0.9447 - val_loss: 0.1289 - val_f1_m: 0.9561\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1405 - f1_m: 0.9452 - val_loss: 0.1271 - val_f1_m: 0.9541\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1396 - f1_m: 0.9448 - val_loss: 0.1254 - val_f1_m: 0.9531\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1385 - f1_m: 0.9450 - val_loss: 0.1244 - val_f1_m: 0.9531\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1377 - f1_m: 0.9455 - val_loss: 0.1235 - val_f1_m: 0.9561\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1370 - f1_m: 0.9457 - val_loss: 0.1228 - val_f1_m: 0.9531\n",
      "0.94574994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 169us/sample - loss: 0.6085 - f1_m: 0.7892 - val_loss: 0.5177 - val_f1_m: 0.8018\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.5080 - f1_m: 0.7892 - val_loss: 0.4556 - val_f1_m: 0.8047\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.4206 - f1_m: 0.7892 - val_loss: 0.3337 - val_f1_m: 0.8105\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2935 - f1_m: 0.7892 - val_loss: 0.2449 - val_f1_m: 0.8047\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2380 - f1_m: 0.7892 - val_loss: 0.2094 - val_f1_m: 0.8047\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2121 - f1_m: 0.8637 - val_loss: 0.1895 - val_f1_m: 0.9229\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1954 - f1_m: 0.9262 - val_loss: 0.1746 - val_f1_m: 0.9316\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1833 - f1_m: 0.9298 - val_loss: 0.1646 - val_f1_m: 0.9238\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1744 - f1_m: 0.9287 - val_loss: 0.1597 - val_f1_m: 0.9277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1685 - f1_m: 0.9315 - val_loss: 0.1498 - val_f1_m: 0.9385\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1630 - f1_m: 0.9345 - val_loss: 0.1463 - val_f1_m: 0.9365\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1589 - f1_m: 0.9355 - val_loss: 0.1415 - val_f1_m: 0.9443\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1562 - f1_m: 0.9387 - val_loss: 0.1388 - val_f1_m: 0.9492\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1544 - f1_m: 0.9380 - val_loss: 0.1365 - val_f1_m: 0.9492\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1520 - f1_m: 0.9390 - val_loss: 0.1351 - val_f1_m: 0.9492\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1510 - f1_m: 0.9390 - val_loss: 0.1339 - val_f1_m: 0.9492\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1500 - f1_m: 0.9390 - val_loss: 0.1340 - val_f1_m: 0.9473\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1495 - f1_m: 0.9390 - val_loss: 0.1318 - val_f1_m: 0.9492\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1487 - f1_m: 0.9392 - val_loss: 0.1312 - val_f1_m: 0.9492\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1482 - f1_m: 0.9392 - val_loss: 0.1316 - val_f1_m: 0.9473\n",
      "0.93924993\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 167us/sample - loss: 0.6098 - f1_m: 0.7950 - val_loss: 0.5383 - val_f1_m: 0.7881\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.5002 - f1_m: 0.7950 - val_loss: 0.4809 - val_f1_m: 0.7852\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4223 - f1_m: 0.7950 - val_loss: 0.3715 - val_f1_m: 0.7852\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.3016 - f1_m: 0.7950 - val_loss: 0.2760 - val_f1_m: 0.7852\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2411 - f1_m: 0.7950 - val_loss: 0.2354 - val_f1_m: 0.7793\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2120 - f1_m: 0.8372 - val_loss: 0.2103 - val_f1_m: 0.9209\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1930 - f1_m: 0.9235 - val_loss: 0.1939 - val_f1_m: 0.9316\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1789 - f1_m: 0.9325 - val_loss: 0.1819 - val_f1_m: 0.9355\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1689 - f1_m: 0.9355 - val_loss: 0.1713 - val_f1_m: 0.9297\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1612 - f1_m: 0.9397 - val_loss: 0.1649 - val_f1_m: 0.9443\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1552 - f1_m: 0.9442 - val_loss: 0.1597 - val_f1_m: 0.9414\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1508 - f1_m: 0.9445 - val_loss: 0.1557 - val_f1_m: 0.9424\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1475 - f1_m: 0.9450 - val_loss: 0.1540 - val_f1_m: 0.9424\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1450 - f1_m: 0.9457 - val_loss: 0.1502 - val_f1_m: 0.9404\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1429 - f1_m: 0.9452 - val_loss: 0.1481 - val_f1_m: 0.9424\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1414 - f1_m: 0.9445 - val_loss: 0.1464 - val_f1_m: 0.9404\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1397 - f1_m: 0.9455 - val_loss: 0.1460 - val_f1_m: 0.9434\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1388 - f1_m: 0.9447 - val_loss: 0.1454 - val_f1_m: 0.9434\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1377 - f1_m: 0.9457 - val_loss: 0.1441 - val_f1_m: 0.9434\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1374 - f1_m: 0.9450 - val_loss: 0.1436 - val_f1_m: 0.9434\n",
      "0.945\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 169us/sample - loss: 0.6083 - f1_m: 0.7940 - val_loss: 0.5394 - val_f1_m: 0.7891\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.5003 - f1_m: 0.7940 - val_loss: 0.4776 - val_f1_m: 0.7861\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4156 - f1_m: 0.7940 - val_loss: 0.3374 - val_f1_m: 0.7861\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2866 - f1_m: 0.7940 - val_loss: 0.2486 - val_f1_m: 0.7832\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2307 - f1_m: 0.7940 - val_loss: 0.2119 - val_f1_m: 0.7861\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2050 - f1_m: 0.8697 - val_loss: 0.1906 - val_f1_m: 0.9375\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1880 - f1_m: 0.9282 - val_loss: 0.1775 - val_f1_m: 0.9326\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1761 - f1_m: 0.9333 - val_loss: 0.1640 - val_f1_m: 0.9424\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1671 - f1_m: 0.9340 - val_loss: 0.1546 - val_f1_m: 0.9570\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1605 - f1_m: 0.9373 - val_loss: 0.1474 - val_f1_m: 0.9570\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1553 - f1_m: 0.9415 - val_loss: 0.1419 - val_f1_m: 0.9541\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1514 - f1_m: 0.9433 - val_loss: 0.1375 - val_f1_m: 0.9570\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1487 - f1_m: 0.9438 - val_loss: 0.1343 - val_f1_m: 0.9541\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 46us/sample - loss: 0.1461 - f1_m: 0.9435 - val_loss: 0.1316 - val_f1_m: 0.9561\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1447 - f1_m: 0.9435 - val_loss: 0.1308 - val_f1_m: 0.9531\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 55us/sample - loss: 0.1435 - f1_m: 0.9433 - val_loss: 0.1280 - val_f1_m: 0.9561\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1423 - f1_m: 0.9435 - val_loss: 0.1270 - val_f1_m: 0.9561\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1414 - f1_m: 0.9435 - val_loss: 0.1256 - val_f1_m: 0.9561\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1410 - f1_m: 0.9438 - val_loss: 0.1246 - val_f1_m: 0.9531\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1405 - f1_m: 0.9432 - val_loss: 0.1243 - val_f1_m: 0.9561\n",
      "0.94324994\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 174us/sample - loss: 0.6127 - f1_m: 0.7907 - val_loss: 0.5249 - val_f1_m: 0.8018\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4988 - f1_m: 0.7907 - val_loss: 0.4559 - val_f1_m: 0.7988\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4099 - f1_m: 0.7907 - val_loss: 0.3317 - val_f1_m: 0.8018\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2889 - f1_m: 0.7907 - val_loss: 0.2478 - val_f1_m: 0.8018\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2348 - f1_m: 0.7907 - val_loss: 0.2133 - val_f1_m: 0.7988\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.2079 - f1_m: 0.8702 - val_loss: 0.1925 - val_f1_m: 0.9307\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1898 - f1_m: 0.9302 - val_loss: 0.1787 - val_f1_m: 0.9307\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1771 - f1_m: 0.9360 - val_loss: 0.1685 - val_f1_m: 0.9316\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1677 - f1_m: 0.9375 - val_loss: 0.1617 - val_f1_m: 0.9414\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1608 - f1_m: 0.9392 - val_loss: 0.1556 - val_f1_m: 0.9453\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1557 - f1_m: 0.9402 - val_loss: 0.1512 - val_f1_m: 0.9424\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1520 - f1_m: 0.9417 - val_loss: 0.1483 - val_f1_m: 0.9424\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1491 - f1_m: 0.9413 - val_loss: 0.1455 - val_f1_m: 0.9463\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1469 - f1_m: 0.9430 - val_loss: 0.1438 - val_f1_m: 0.9463\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1451 - f1_m: 0.9438 - val_loss: 0.1431 - val_f1_m: 0.9385\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1439 - f1_m: 0.9435 - val_loss: 0.1414 - val_f1_m: 0.9443\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.1436 - f1_m: 0.9433 - val_loss: 0.1409 - val_f1_m: 0.9463\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1422 - f1_m: 0.9438 - val_loss: 0.1400 - val_f1_m: 0.9463\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1414 - f1_m: 0.9440 - val_loss: 0.1395 - val_f1_m: 0.9434\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1409 - f1_m: 0.9433 - val_loss: 0.1389 - val_f1_m: 0.9443\n",
      "0.94325\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 1s 167us/sample - loss: 0.6096 - f1_m: 0.7932 - val_loss: 0.5350 - val_f1_m: 0.7891\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 0s 45us/sample - loss: 0.4981 - f1_m: 0.7932 - val_loss: 0.4683 - val_f1_m: 0.7861\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 0s 49us/sample - loss: 0.4060 - f1_m: 0.7932 - val_loss: 0.3388 - val_f1_m: 0.7891\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.2847 - f1_m: 0.7932 - val_loss: 0.2586 - val_f1_m: 0.7832\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2328 - f1_m: 0.7932 - val_loss: 0.2237 - val_f1_m: 0.7949\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.2061 - f1_m: 0.8735 - val_loss: 0.2040 - val_f1_m: 0.9141\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1882 - f1_m: 0.9302 - val_loss: 0.1907 - val_f1_m: 0.9258\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1756 - f1_m: 0.9340 - val_loss: 0.1814 - val_f1_m: 0.9268\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1661 - f1_m: 0.9375 - val_loss: 0.1742 - val_f1_m: 0.9287\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1593 - f1_m: 0.9390 - val_loss: 0.1690 - val_f1_m: 0.9355\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1540 - f1_m: 0.9433 - val_loss: 0.1650 - val_f1_m: 0.9355\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1503 - f1_m: 0.9440 - val_loss: 0.1617 - val_f1_m: 0.9365\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1466 - f1_m: 0.9448 - val_loss: 0.1617 - val_f1_m: 0.9277\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1442 - f1_m: 0.9437 - val_loss: 0.1581 - val_f1_m: 0.9336\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1425 - f1_m: 0.9452 - val_loss: 0.1572 - val_f1_m: 0.9365\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1413 - f1_m: 0.9448 - val_loss: 0.1557 - val_f1_m: 0.9336\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1397 - f1_m: 0.9455 - val_loss: 0.1552 - val_f1_m: 0.9365\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1387 - f1_m: 0.9455 - val_loss: 0.1545 - val_f1_m: 0.9365\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1382 - f1_m: 0.9452 - val_loss: 0.1549 - val_f1_m: 0.9365\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 0s 44us/sample - loss: 0.1373 - f1_m: 0.9448 - val_loss: 0.1553 - val_f1_m: 0.9365\n",
      "0.94475\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "if any\n",
      "if any\n",
      "if any\n",
      "if any\n",
      "1037 3963\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 45 samples, validate on 12 samples\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.6943 - f1_m: 0.2476 - val_loss: 0.6923 - val_f1_m: 0.8333\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 126us/sample - loss: 0.6918 - f1_m: 0.8293 - val_loss: 0.6905 - val_f1_m: 0.8333\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 110us/sample - loss: 0.6905 - f1_m: 0.8365 - val_loss: 0.6892 - val_f1_m: 0.8333\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 107us/sample - loss: 0.6895 - f1_m: 0.7224 - val_loss: 0.6879 - val_f1_m: 0.8333\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 114us/sample - loss: 0.6883 - f1_m: 0.7680 - val_loss: 0.6867 - val_f1_m: 0.8333\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 102us/sample - loss: 0.6872 - f1_m: 0.7909 - val_loss: 0.6855 - val_f1_m: 0.8333\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 108us/sample - loss: 0.6861 - f1_m: 0.8137 - val_loss: 0.6843 - val_f1_m: 0.8333\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 97us/sample - loss: 0.6851 - f1_m: 0.7680 - val_loss: 0.6830 - val_f1_m: 0.8333\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 101us/sample - loss: 0.6839 - f1_m: 0.7909 - val_loss: 0.6818 - val_f1_m: 0.8333\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 101us/sample - loss: 0.6828 - f1_m: 0.8137 - val_loss: 0.6806 - val_f1_m: 0.8333\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 101us/sample - loss: 0.6816 - f1_m: 0.8365 - val_loss: 0.6793 - val_f1_m: 0.8333\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 101us/sample - loss: 0.6804 - f1_m: 0.8594 - val_loss: 0.6781 - val_f1_m: 0.8333\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 101us/sample - loss: 0.6794 - f1_m: 0.7909 - val_loss: 0.6768 - val_f1_m: 0.8333\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 99us/sample - loss: 0.6782 - f1_m: 0.8594 - val_loss: 0.6755 - val_f1_m: 0.8333\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 103us/sample - loss: 0.6771 - f1_m: 0.8137 - val_loss: 0.6743 - val_f1_m: 0.8333\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 102us/sample - loss: 0.6760 - f1_m: 0.7909 - val_loss: 0.6730 - val_f1_m: 0.8333\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 96us/sample - loss: 0.6749 - f1_m: 0.7909 - val_loss: 0.6718 - val_f1_m: 0.8333\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 97us/sample - loss: 0.6736 - f1_m: 0.8365 - val_loss: 0.6706 - val_f1_m: 0.8333\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 101us/sample - loss: 0.6725 - f1_m: 0.8137 - val_loss: 0.6694 - val_f1_m: 0.8333\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 97us/sample - loss: 0.6713 - f1_m: 0.8137 - val_loss: 0.6681 - val_f1_m: 0.8333\n",
      "0.81370187\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1\n",
      "6\n",
      "6\n",
      "3\n",
      "2\n",
      "11\n",
      "13\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "All Done\n"
     ]
    }
   ],
   "source": [
    "#increasing the size of equal subsample\n",
    "#the below code is for binary classification since MNSIT is a multi-class low-resolution image dataset. I am updating the code in the next cell.\n",
    "N=5000\n",
    "#Positive=Pos\n",
    "#Negative=Neg\n",
    "positiveN=int((Positive.shape[0]/dataset.shape[0])*N)\n",
    "negativeN=int(N-positiveN)\n",
    "print(positiveN, negativeN)\n",
    "#target variable\n",
    "#target_variable=\"default.payment.next.month\"\n",
    "df1=Positive.sample(positiveN)\n",
    "Positive.drop(df1.index, inplace=True)\n",
    "df2=Negative.sample(negativeN)\n",
    "Negative.drop(df2.index, inplace=True)\n",
    "test_data=df1.append(df2, ignore_index=True)\n",
    "test_data=test_data.sample(frac = 1) #This is to shuffel the training and testing data\n",
    "test_data=test_data.sample(frac = 1)\n",
    "test_data=test_data.sample(frac = 1)\n",
    "X_test=test_data.drop(columns=[target_variable])\n",
    "y_test=to_categorical(test_data[target_variable])\n",
    "\n",
    "# adding dense layer\n",
    "initial_model= get_initial_model(X_test.shape[1], 2)\n",
    "Models=[]\n",
    "val_acc=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "val_loss=[]\n",
    "train_loss=[]\n",
    "while Positive.empty==False and Negative.empty==False:\n",
    "  print(positiveN, negativeN)\n",
    "  df1=Positive.sample(min(positiveN, len(Positive)))\n",
    "  Positive.drop(df1.index, inplace=True)\n",
    "  df2=Negative.sample(min(negativeN, len(Negative)))\n",
    "  Negative.drop(df2.index, inplace=True)\n",
    "  train_data=df1.append(df2, ignore_index=True)\n",
    "  train_data=train_data.sample(frac = 1) #shuffel test data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel test data 3 times\n",
    "  train_data=train_data.sample(frac = 1) #shuffel test data 3 times\n",
    "    \n",
    "  #all models have different initialization\n",
    "  # define the sequential model\n",
    "  \"\"\"initial_model = keras.Sequential()\n",
    "\n",
    "    # adding dense layer\n",
    "  initial_model.add(Dense(5, input_dim=X_test.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "  initial_model.add(Dense(10, activation='relu'))\n",
    "  initial_model.add(Dense(5, activation='relu'))\n",
    "\n",
    "    # adding dense layer with softmax activation/output layer\n",
    "  initial_model.add(Dense(2, activation='softmax'))\n",
    "  #initial_model.summary()\"\"\"\n",
    "  ann_model=get_initial_model(X_test.shape[1], 2) #same intial weights\n",
    "  ann_model.set_weights(initial_model.get_weights())\n",
    "  X_train=train_data.drop(columns=[target_variable])\n",
    "  #train_data[target_variable]=train_data[target_variable]-1 #only for skin_nonskin dataset\n",
    "  y_train=to_categorical(train_data[target_variable])\n",
    "  #print(y_train)\n",
    "  ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m]) # metrics=['accuracy']\n",
    "  history = ann_model.fit(X_train, y_train, epochs=20, validation_split=0.2, verbose=1)\n",
    "  print(history.history['f1_m'][-1])\n",
    "  ann_model.set_weights(update_weights(ann_model.get_weights()))\n",
    "  pred_test=ann_model.predict(X_test)\n",
    "  present=False\n",
    "  for i in range(len(Models)):\n",
    "    if (check_models(Models[i][0], ann_model.get_weights())):\n",
    "      print(\"if any\")\n",
    "      Models[i][1]=Models[i][1]+1\n",
    "      val_acc[i].append(history.history['val_f1_m'])\n",
    "      train_acc[i].append(history.history['f1_m'])\n",
    "      test_acc.append(f1_m(y_test, pred_test).numpy())\n",
    "      val_loss[i].append(history.history['val_loss'])\n",
    "      train_loss[i].append(history.history['loss'])\n",
    "      present=True\n",
    "  if present==False:\n",
    "    Models.append([ann_model.get_weights(), 1])\n",
    "    val_acc.append([history.history['val_f1_m']])\n",
    "    train_acc.append([history.history['f1_m']])\n",
    "    test_acc.append([f1_m(y_test, pred_test).numpy()])\n",
    "    val_loss.append([history.history['val_loss']])\n",
    "    train_loss.append([history.history['loss']])\n",
    "for i in range(len(Models)):\n",
    "  print(Models[i][1])\n",
    "print(\"All Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "62c421a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 6 6 3 2 11 13 2 2 2 2 1 1 2 4 2 1 2 1 1 1 1 1]\n",
      "[ 6  5  1  2 14]\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#top 5 recurrent models\n",
    "#this works for getting sorted recurrent models by frequency\n",
    "A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "print(np.array(Models).T[1])\n",
    "print(A)\n",
    "temp=list(np.array(Models)[A])\n",
    "print(temp[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ccd847f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"\"\"\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#reducing the metrics lists to top 5 models only\n",
    "val_acc=list(np.array(val_acc)[A])\n",
    "test_acc=list(np.array(test_acc)[A])\n",
    "train_acc=list(np.array(train_acc)[A])\n",
    "val_loss=list(np.array(val_loss)[A])\n",
    "train_loss=list(np.array(train_loss)[A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95212924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting graphs for loss and accuracies:\n",
    "#plotting val_loss and loss for the models generated and the benchmark model.\n",
    "from random import randint\n",
    "import matplotlib.patches as mpatches\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "leg=[]\n",
    "for i in range(len(color)):\n",
    "    leg.append(mpatches.Patch(color=color[i], label=str(len(val_acc[i]))))\n",
    "n = len(val_acc)\n",
    "x_axis=np.arange(1, 21, 1)\n",
    "print(x_axis)\n",
    "for i in range(n):\n",
    "    for j in range(len(val_acc[i])):\n",
    "        plt.plot(x_axis,val_acc[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis, np.mean(val_acc[i], axis=0), color=color[i])\n",
    "#plt.xlim(-0.5,20.5)\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.plot(x_axis, benchmark_val_acc, color='black')\n",
    "plt.savefig(\"fig/SKIN_NONSKIN_F1_Val_20Epochs_5000.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b64202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79324996, 0.79324996, 0.79324996, 0.79324996, 0.79324996, 0.85099995, 0.92999995, 0.93575, 0.93724996, 0.94374996, 0.94725, 0.947, 0.94725, 0.9475, 0.9475, 0.947, 0.9475, 0.94749993, 0.9477499, 0.9475]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n",
      "0 10\n",
      "0 11\n",
      "0 12\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "1 10\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "3 5\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train accuracy \n",
    "from random import randint\n",
    "color = []\n",
    "print(train_acc[4][0])\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "x_axis=np.arange(1, 21, 1)\n",
    "print(x_axis)\n",
    "for i in range(n):\n",
    "    for j in range(len(train_acc[i])):\n",
    "        print(i,j)\n",
    "        plt.plot(x_axis,train_acc[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis,np.mean(train_acc[i], axis=0), color=color[i])\n",
    "plt.plot(x_axis,benchmark_acc, color='black')\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/SKIN_NONSKIN_012_F1_train_20Epochs_5000.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6aa6074b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training loss\n",
    "from random import randint\n",
    "color = []\n",
    "n = len(train_loss)\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "for i in range(n):\n",
    "    for j in range(len(train_loss[i])):\n",
    "        plt.plot(x_axis,train_loss[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis,np.mean(train_loss[i], axis=0), color=color[i])\n",
    "plt.plot(x_axis,benchmark_loss, color='black')\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/SKIN_NONSKIN_loss_train_20Epochs_5000.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a55aa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training loss\n",
    "from random import randint\n",
    "color = []\n",
    "n = len(train_loss)\n",
    "color = ['red', 'yellow','blue', 'green','cyan']\n",
    "for i in range(n):\n",
    "    for j in range(len(train_loss[i])):\n",
    "        plt.plot(x_axis,train_loss[i][j], color=color[i], alpha=0.2)\n",
    "    plt.plot(x_axis,np.mean(train_loss[i], axis=0), color=color[i])\n",
    "plt.plot(x_axis,benchmark_loss, color='black')\n",
    "plt.xticks([2.5,5.0,7.5,10.0,12.5,15.0,17.5,20.0],[2,5,7,10,12,15,17,20])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(handles=leg, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\", borderaxespad=0, ncol=5)\n",
    "plt.savefig(\"fig/SKIN_NONSKIN_loss_train_20Epochs_5000.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d555d910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb56d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
